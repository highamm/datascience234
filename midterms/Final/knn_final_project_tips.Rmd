---
title: "knn-Specific Instructions and Tips"
author: "Matt Higham"
output: 
  rmdformats::readthedown:
    code_folding: show
    toc_depth: 5
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## Some Background

The following two articles are useful resources to look through before beginning with your own data. The first article has some basic concepts, some of which were discussed in our own introductory video. The second article goes into slightly more detail (and, in the second article, you can completely ignore the code, as it is done in Python).

* <https://towardsdatascience.com/k-nearest-neighbors-algorithm-with-examples-in-r-simply-explained-knn-1f2c88da405c>

* <https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761>

## Cross-Validation: Choosing k and Choosing Predictors

How do you tell if the model you've fit is a good model? The simplest method is to use a model cross-validation procedure. 

What you'll do is divide your data set so that about 75% of the observations are in a __training__ data set and the remaining 25% of the observations are in a __holdout__ sample. Then, your knn model will use the __training__ data to fit the model and then use the fitted model on the __holdout__ sample so you can see how well the model is doing (__Note__: we are just going to do this method because it's the simplest: if you wanted to take this a step further, you'd repeat this process 5 or 10 times, using what's known as k-fold cross-validation).

You can see some code to create the training and holdout sample in the `knn_intro_code.Rmd`. Additionally, the two pages of the `training_holdout.pdf` may be a useful resource.

## What's a "Good" Model

But, how do we tell whether knn is doing a "good" or "bad" job with the holdout sample? Typically, if the response variable is categorical, we make a confusion matrix and calculate the accuracy of the model. Watch this video for an introduction on the confusion matrix (it's really not that confusing!):

* <https://www.youtube.com/watch?v=Kdsp6soqA7o> 

Prediction accuracy is the proportion of correct predictions divided by the proportion of mis-classified predictions. You might try different combinations of $k$ and different combinations of predictors until you find a model with the highest prediction accuracy!

<br>

## Using Your Model on Other Songs

Finally, you'll be asked to use your model on 10 songs that are of __different__ artists to the artists that you used. Your model will predict the artist for each of these 10 songs from the 4 artists you chose. In a way, we can think about the prediction as being the artist that is most similar to the song, of the 4 artists you selected.

To do this, complete the following steps:

* refit your final knn model using __all__ observations in your data set (observations in both the training and the holdout sample, combined). After selecting your predictors and selecting k, it's common to then refit your final model using the entire data set, so as not to discard any valuable information.
* the `test` part of your new model will be the data from the new artists. You'll need to scale this data set, and only keep the predictors that you chose to keep in your final model.
* type the name of your model to see the 10 "predictions." 

The following code is example code for the Pokemon data set, treating Grass type pokemon as the "new" data. You should be able to add the code to the end of the `knn_intro_code` file to get it to run.

```{r, results = "as.is", echo = TRUE}
library(tidyverse)
library(class)
set.seed(11232020) ## run this line so that you get the same 
## results as I do!
pokemon <- read_csv("pokemon_full.csv") %>% filter(Type %in% c("Steel", "Dark", "Fire", "Ice")) 

## scale the quantitative predictors
pokemon_scaled <- pokemon %>%
    mutate(across(where(is.numeric), ~ (.x - min(.x)) /
                                 (max(.x) - min(.x)))) 


## get the entire data set in scaled form, and select only
## the predictors we decided to use

pokemon_small <- pokemon_scaled %>% select(HP, Attack, Defense, Speed)
## put our response variable into a vector
pokemon_cat <- pokemon_scaled$Type

pokemon_new <- read_csv("pokemon_full.csv") %>% filter(Type %in% c("Grass")) %>% mutate(across(where(is.numeric), ~ (.x - min(.x)) /
                                 (max(.x) - min(.x))))
pokemon_newcat <- pokemon_new$Type


pokemon_new_predsonly <- pokemon_new %>% select(HP, Attack, Defense, Speed)

## fit the model using all available observations
knn_mod <- knn(train = pokemon_small, test = pokemon_new_predsonly,
               cl = pokemon_cat, k = 9)
knn_mod
```