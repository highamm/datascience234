[{"path":"index.html","id":"syllabus-and-course-information","chapter":" 1 Syllabus and Course Information","heading":" 1 Syllabus and Course Information","text":"","code":""},{"path":"index.html","id":"general-information","chapter":" 1 Syllabus and Course Information","heading":"1.1 General Information","text":"Instructor InformationProfessor: Matt HighamOffice: Bewkes 123Email: mhigham@stlawu.eduSemester: Fall 2021Office Hours:\nTuesday 1:30 - 3:30\nWednesday 2:30 - 3:30\nFriday 10:00 - 11:00\ntimes appointment\n-person, unless otherwise requested\n\nTuesday 1:30 - 3:30Wednesday 2:30 - 3:30Friday 10:00 - 11:00other times appointmentall -person, unless otherwise requested\nSections:\nMW 8:50 - 10:20\nMW 8:50 - 10:20Course MaterialsSTAT 234 Materials Bundle. primary source materials.Textbooks (used references):\nModern Data Science R Baumer, Kaplan, Horton, found free online version.\nR Data Science Grolemund Wickham, found free online version.\nModern Data Science R Baumer, Kaplan, Horton, found free online version.R Data Science Grolemund Wickham, found free online version.Computer Internet access.","code":""},{"path":"index.html","id":"course-information","chapter":" 1 Syllabus and Course Information","heading":"1.2 Course Information","text":"Welcome STAT 234! overall purpose course learn data science skills necessary complete large-scale data analysis projects. tool using achieve goal statistical software language R. work wide variety interesting data sets throughout semester build R skills. particular, focus Data Analysis Life Cycle (Grolemund Wickham 2020):put emphasis Import, Tidy, Transform, Visualize, Communicate parts cycle, introduction Modeling part covered STAT 213.","code":""},{"path":"index.html","id":"use-of-r-and-rstudio","chapter":" 1 Syllabus and Course Information","heading":"1.2.1 Use of R and RStudio","text":"use statistical software R construct graphs analyze data. notes:R RStudio free use.primarily using SLU R Studio server first: Link R Studio Server.Additionally, using RMarkdown data analysis reports.\nNote: ’s always nice start assignments projects early possible, particularly important assignments projects involving R. ’s fun try figure code working last minute. start early enough though, plenty time seek help therefore won’t waste lot time coding error.","code":""},{"path":"index.html","id":"general-course-outcomes","chapter":" 1 Syllabus and Course Information","heading":"1.3 General Course Outcomes","text":"Import data different types R analysis.Import data different types R analysis.Tidy data form can easily visualized, summarised, modeled.Tidy data form can easily visualized, summarised, modeled.Transform, Wrangle, Visualize variables data set assess patterns data.Transform, Wrangle, Visualize variables data set assess patterns data.Communicate results analysis target audience written report, , possibly oral presentation.Communicate results analysis target audience written report, , possibly oral presentation.Practice reproducible statistical practices use R Markdown data analysis projects.Practice reproducible statistical practices use R Markdown data analysis projects.Explain ethically important consider context data set comes .Explain ethically important consider context data set comes .Develop necessary skills able ask answer future data analysis questions , either using R another program, Python.Develop necessary skills able ask answer future data analysis questions , either using R another program, Python.paraphrase R Data Science textbook, 80% skills necessary complete data analysis project can learned coursework classes like one. , 20% particular project involve learning new things specific project. Achieving Goal # 6 allow learn extra 20% .","code":""},{"path":"index.html","id":"how-you-will-be-assessed","chapter":" 1 Syllabus and Course Information","heading":"1.4 How You Will Be Assessed","text":"components grade described :ClassClass participation assessed three times throughout semester 20 point rubric total 60 points. Additionally, 10-point “share something interesting found class” assignment nearly every day class, student volunteer ….share something interesting found data set working rest class. rubric used shared first day class, information extra 10 points also given first day class.ExercisesThere 14 sets weekly exercises often require read sections STAT 234 Materials Bundle first. worth either 10 5 points, depending length exercises, total 100 points. weeks toward beginning semester 10 point weeks won’t projects work . Exercises graded completion : many exercises, solutions provided course materials.QuizzesThere 10 Quizzes, worth 20 points total 180 points one dropped quiz. purpose quizzes practice ’ve learned week short, concise format. Quizzes consist two parts: (1) take-home component (2) -class component. take-home component take 15 minutes. allowed use course materials allowed work students course, long list names students top quiz. -class component 5 minutes. asked simple task pen paper, without using course notes materials.Mini ProjectsThere 3 mini-projects scattered throughout semester worth 60 points . mini-project prescriptive tasks questions investigate well section come subsequently answer questions relating data set.order get experience oral presentations results, student give short oral presentation 1 mini-project. Use R Markdown required presentation (opposed PowerPoint Prezi). details given later semester.Midterm ExamsThere two midterm exams, worth 150 points. information given later.Final ProjectThere one final project, worth 150 points. primary purpose final project give opportunity assemble topics throughout course one coherent data analysis. information final project given later.Final Exam course.","code":""},{"path":"index.html","id":"breakdown","chapter":" 1 Syllabus and Course Information","heading":"1.4.1 Breakdown","text":"70 points Class100 points Exercises180 points Quizzes180 points Mini-Projects + 20 points Presentation150 points two Midterm Exams150 points Final ProjectPoints add 1000 grade end semester number points ’ve earned across categories divided 1000.tutorials help complete exercises sets, \nhelp well quizzes, \nhelp complete mini-projects, \nhelp well midterm exams.\n\n\nhelp well quizzes, \nhelp complete mini-projects, \nhelp well midterm exams.\n\nhelp complete mini-projects, \nhelp well midterm exams.\nhelp well midterm exams., everything together help create awesome final project!","code":""},{"path":"index.html","id":"grading-scale","chapter":" 1 Syllabus and Course Information","heading":"1.4.2 Grading Scale","text":"following rough grading scale. reserve right make changes scale necessary.","code":""},{"path":"index.html","id":"collaboration-diversity-accessibility-and-academic-integrity","chapter":" 1 Syllabus and Course Information","heading":"1.5 Collaboration, Diversity, Accessibility, and Academic Integrity","text":"","code":""},{"path":"index.html","id":"rules-for-collaboration","chapter":" 1 Syllabus and Course Information","heading":"1.5.1 Rules for Collaboration","text":"Collaboration classmates handouts, tutorials, projects encouraged, must follow guidelines:must state name(s) collaborated top assessment.work must . means never send someone code via email let someone directly type code screen. Instead, can talk strategies solving problems help ask someone coding error.may use Internet StackExchange, also copy paste code directly website, without citing .isn’t rule, keep mind collaboration permitted quizzes, exams, limited collaboration permitted final project. Therefore, working someone, make sure really learning can success non-collaborative assessments.","code":""},{"path":"index.html","id":"diversity-statement","chapter":" 1 Syllabus and Course Information","heading":"1.5.2 Diversity Statement","text":"Diversity encompasses differences age, colour, ethnicity, national origin, gender, physical mental ability, religion, socioeconomic background, veteran status, sexual orientation, marginalized groups. interaction different human characteristics brings positive learning environment. Diversity respected valued classroom.","code":""},{"path":"index.html","id":"accessibility-statement","chapter":" 1 Syllabus and Course Information","heading":"1.5.3 Accessibility Statement","text":"learning difference/disability health impairment need accommodations please sure contact Student Accessibility Services Office right away can help get accommodations require. need use accommodations class, please meet instructor early provide Individualized Educational Accommodation Plan (IEAP) letter can best possible experience semester.Although required, instructor like know accommodations needed least 10 days quiz test. Please proactive set appointment meet someone Student Accessibility Services Office.Color-Vision Deficiency: Color-Vision Deficient, Student Accessibility Services office loan glasses students color vision deficient. Please contact office make appointment.specific information setting appointment Student Accessibility Services please see listed options :Telephone: 315.229.5537Email: studentaccessibility@stlawu.eduFor information Student Accessibility Services can check website : https://www.stlawu.edu/student-accessibility-services","code":""},{"path":"index.html","id":"academic-dishonesty","chapter":" 1 Syllabus and Course Information","heading":"1.5.4 Academic Dishonesty","text":"Academic dishonesty tolerated. specific policies course supplementary theHonor Code. According St. Lawrence University Academic Honor Policy,assumed work done student unless instructor/mentor/employer gives specific permission collaboration.Cheating examinations tests consists knowingly giving using attempting use unauthorized assistance examinations tests.Dishonesty work outside examinations tests consists handing presenting original work original, originality required.Claims ignorance academic personal pressure unacceptable excuses academic dishonesty. Students must learn constitutes one's work work others must acknowledged.information, refer www.stlawu.edu/acadaffairs/academic_honor_policy.pdf.avoid academic dishonesty, important follow directions collaboration rules ask clarification questions acceptable particular assignment exam. suspect academic dishonesty, score zero given entire assignment academic dishonesty occurred individuals involved Academic Honor Council notified. pattern academic dishonesty found occurred, grade 0.0 entire course can given.important work way maximizes learning. aware students rely much others homework projects tend poorly quizzes exams.Please note addition , assignments score reduced due academic dishonesty dropped according quiz policy e.g., receive zero quiz academic dishonesty, dropped grade.","code":""},{"path":"index.html","id":"tentative-schedule","chapter":" 1 Syllabus and Course Information","heading":"1.6 Tentative Schedule","text":"three mini-projects tentatively scheduled due September 27, October 25, November 8, though subject change.Final Exam, keep schedule open Final Exam time case decide use something.","code":""},{"path":"intro.html","id":"intro","chapter":" 2 Getting Started with R and R Studio","heading":" 2 Getting Started with R and R Studio","text":"Goals:Use R Studio serverUse R Studio serverUse R Markdown code chunksUse R Markdown code chunksLoad data R StudioLoad data R StudioRun code change things within codeRun code change things within codeCorrect common errors running code RCorrect common errors running code R","code":""},{"path":"intro.html","id":"intro-to-r-and-r-studio","chapter":" 2 Getting Started with R and R Studio","heading":"2.1 Intro to R and R Studio","text":"R statistical computing software used many statisticians well professionals fields, biology, ecology, business, psychology. goal Week 0 provide basic familiarity R R Markdown, using entire semester.Open R Studio SLU R Studio server \nhttp://rstudio.stlawu.local:8787 create folder called STAT_234 meaningful title . Note must campus use R Studio server, unless use VPN. Directions set-VPN \nhttps://infotech.stlawu.edu/support/content/11269 \n<> Macs https://stlawu.teamdynamix.com/TDClient/1805/Portal/KB/ArticleDet?ID=55118  Windows.Next, create subfolder within STAT_234 folder. Title Notes (whatever want really)., create R Project Clicking File -> New Project -> Existing Directory, navigate Notes folder, click Create Project.Within folder, click New Folder button bottom-left window name new folder data. , download data.zip file Sakai (Resources). Upload file server clicking “Upload” bottom right panel. dialog box appears, can click “Choose File” navigate folder saved zip file (probably Downloads default). zip file automatically expand uploaded. includes data sets use throughout course.Finally, want create new R Markdown file clicking File -> New File -> R Markdown. can give new R Markdown file title want, click okay.moving , click Knit button top-left window top menu bar (look knitting needle icon). Make sure file knits pretty-looking .html file. newly knitted .html file can now found folder R project.","code":""},{"path":"intro.html","id":"what-are-r-r-studio-and-r-markdown","chapter":" 2 Getting Started with R and R Studio","heading":"2.2 What are R, R Studio, and R Markdown?","text":"distinction 3 become clear later . now,\n* R statistical coding software used heavily data analysis statistical procedures.R Studio nice IDE (Integrated Development Environment) R lot convenient features. Think just convenient User Interface.R Studio nice IDE (Integrated Development Environment) R lot convenient features. Think just convenient User Interface.R Mardkown allows users mix regular Microsoft-Word-style text code. .Rmd file ending denotes R Mardkown file. R Markdown many options use heavily throughout semester, ’s need worry now.R Mardkown allows users mix regular Microsoft-Word-style text code. .Rmd file ending denotes R Mardkown file. R Markdown many options use heavily throughout semester, ’s need worry now.","code":""},{"path":"intro.html","id":"r-packages-and-the-tidyverse","chapter":" 2 Getting Started with R and R Studio","heading":"2.2.1 R Packages and the tidyverse","text":"can think R packages add-ons R let things R able . ’re video games, can think R packages extra Downloadable Content (DLC). , unlike gaming DLC, R packages always free make heavy use R packages.tidyverse series R packages useful data science. order encounter class, core tidyverse packages :ggplot2 plotting datadplyr data wrangling summarizingtidyr data tidying reshapingreadr data importtibble data storedstringr text dataforcats factor (categorical) datapurrr, functional programming, one core 8 won’t get useWe use packages outside core tidyverse well, tidyverse main focus.going change one option proceeding. top file menu, click Tools -> Global Options -> R Markdown uncheck box says “Show output inline R Markdown documents.” Don’t worry now, changing option just means code results appear bottom-left window graphs appear bottom-right window R Studio.","code":""},{"path":"intro.html","id":"putting-code-in-a-.rmd-file","chapter":" 2 Getting Started with R and R Studio","heading":"2.3 Putting Code in a .Rmd File","text":"first thing involves code load package R library() function. package just R add-lets just R . Load tidyverse package R typing running library(tidyverse) line. create code chunk, click Insert -> R. Within code chunk, type library(tidyverse) run code eitherClicking “Run” button menu bar top-left window R Studio orClicking “Run” button menu bar top-left window R Studio (Recommended) Clicking “Command + Enter” Mac “Control + Enter” PC.(Recommended) Clicking “Command + Enter” Mac “Control + Enter” PC.Note code appears grey boxes surrounded three backticks normal text different colour background backticks.run previous line, text appear bottom-left window. won’t worry much text means now, also won’t ignore completely. able spot 8 core tidyverse packages listed well numbers follow package. numbers correspond package version. ’s things , long text start “Error:” ’re good go!Congrats running first line code class! particular code isn’t particularly exciting doesn’t really anything can see.run R code using R chunk. R chunk, new line, try typing basic calculation, like 71 + 9 4 / 3, run line observe result., still wasn’t super exciting. R can perform basic calculations, just use calculator Excel . order look things bit interesting, need data.","code":"\nlibrary(tidyverse)"},{"path":"intro.html","id":"alcohol-data-example","chapter":" 2 Getting Started with R and R Studio","heading":"2.4 Alcohol Data Example","text":"looking two data sets just get little bit preview things working rest semester. Important: worry understanding following code point. plenty time understand weeks ahead. purpose section just get used using R: detailed explanations exercises functions used various options coming weeks. particular, following code uses ggplot2, dplyr, tidyr packages, cover detail throughout first ~ 3-4 weeks course.Data first part obtained fivethirtyeight Five Thirty Eight GitHub page.first step read data set R. Though already downloaded alcohol.csv data zip, still need load R. Check make sure alcohol.csv data folder bottom-right hand window. following code can copied R code chunk read data:Note need full file extension data set R project.something show console window? , great! , make sure data set data folder R project set .like name data set something easily reference later, name data set using <- operator, inYou can name data set whatever want (restrictions). ’ve named alcohol_data. Now, run line code name data set, run alcohol_data, see data set appear:’s data set? see variables columns:country: name countrybeer_servings: average number beer servings per person per yearspirit_servings: average number spirit (hard alcohol) servings per person per yearwine_servings: average number wine servings per person per yeartotal_litres_of_pure_alcohol: average total litres pure alcohol consumed per person per year.One goal class able pose questions data set use tools learn answer questions. example, might want know distribution total litres alcohol consumed per person looks like across countries. , can make plot ggplot2 package, one packages automatically loads tidyverse. might start constructing following plot. Reminder: goal everyone understand code plot, don’t worry much .now want see United States (USA) falls distribution drawing red vertical line total litres alcohol consumed United States. , ’ll first use filter() function dplyr package (, learn function detail later). Copy paste following lines code new R chunk. , run lines.looks like countries consume little alcohol. might want know countries :looks like 13 countries data set consume alcohol. Note , chunk , use total_litres_of_pure_alcohol variable name name variable data set. Even something like spelling litres American English liters (total_liters_of_pure_alcohol) throw error isn’t exact name variable data set. something can aggravating first learning coding language.Now suppose want know 3 countries consume beer, 3 countries consume spirits, 3 countries consume wine per person. ’re trivia person, can form guesses. Without cheating, going guess (Germany, USA, UK) beer, (Spain, Italy, USA) wine, (Russia, Poland, Lithuania) spirits. Let’s beer first!Let’s thing Wine Spirits:Finally, suppose want know country consumes wine relative beer consumption? Let’s first look question graphically. need tidy data first pivot_longer() function tidyr package:x-axis corresponds beer servings y-axis corresponds wine servings. reference line given countries line consuming wine beer. get make plot like later: now, copy code chunk change labeled point corresponds country interests (Denmark).\nmight able better answer original question numerically computing wine beer ratio country ordering largest ratio smallest ratio:one ratios Inf?","code":"\nread_csv(\"data/alcohol.csv\")\nalcohol_data <- read_csv(\"data/alcohol.csv\")\nalcohol_data\n#> # A tibble: 193 x 5\n#>    country       beer_servings spirit_servings wine_servings\n#>    <chr>                 <dbl>           <dbl>         <dbl>\n#>  1 Afghanistan               0               0             0\n#>  2 Albania                  89             132            54\n#>  3 Algeria                  25               0            14\n#>  4 Andorra                 245             138           312\n#>  5 Angola                  217              57            45\n#>  6 Antigua & Ba…           102             128            45\n#>  7 Argentina               193              25           221\n#>  8 Armenia                  21             179            11\n#>  9 Australia               261              72           212\n#> 10 Austria                 279              75           191\n#> # … with 183 more rows, and 1 more variable:\n#> #   total_litres_of_pure_alcohol <dbl>\nggplot(data = alcohol_data,\n       mapping = aes(total_litres_of_pure_alcohol)) +\n  geom_histogram(colour = \"black\", fill = \"white\", bins = 15)\nsmall_df <- alcohol_data %>% filter(country == \"USA\")\nggplot(data = alcohol_data,\n       mapping = aes(total_litres_of_pure_alcohol)) +\n  geom_histogram(colour = \"black\", fill = \"white\", bins = 15) +\n  geom_vline(data = small_df,\n             aes(xintercept = total_litres_of_pure_alcohol),\n             colour = \"red\")\nalcohol_data %>% filter(total_litres_of_pure_alcohol == 0)\n#> # A tibble: 13 x 5\n#>    country       beer_servings spirit_servings wine_servings\n#>    <chr>                 <dbl>           <dbl>         <dbl>\n#>  1 Afghanistan               0               0             0\n#>  2 Bangladesh                0               0             0\n#>  3 North Korea               0               0             0\n#>  4 Iran                      0               0             0\n#>  5 Kuwait                    0               0             0\n#>  6 Libya                     0               0             0\n#>  7 Maldives                  0               0             0\n#>  8 Marshall Isl…             0               0             0\n#>  9 Mauritania                0               0             0\n#> 10 Monaco                    0               0             0\n#> 11 Pakistan                  0               0             0\n#> 12 San Marino                0               0             0\n#> 13 Somalia                   0               0             0\n#> # … with 1 more variable:\n#> #   total_litres_of_pure_alcohol <dbl>\nalcohol_data %>% mutate(rankbeer = rank(desc(beer_servings))) %>%\n  arrange(rankbeer) %>% \n  filter(rankbeer <= 3)\nalcohol_data %>% mutate(rankwine = rank(desc(wine_servings))) %>%\n  arrange(rankwine) %>% \n  filter(rankwine <= 3)\n\nalcohol_data %>% mutate(rankspirits = rank(desc(spirit_servings))) %>%\n  arrange(rankspirits) %>% \n  filter(rankspirits <= 3)\nonecountry_df <- alcohol_data %>% \n  filter(country == \"Denmark\")\n\nlibrary(ggrepel)\nggplot(data = alcohol_data,\n       mapping = aes(x = beer_servings, y = wine_servings)) + \n  geom_point(alpha = 0.5) +\n  geom_label_repel(data = onecountry_df, aes(label = country),\n    colour = \"purple\") +\n  geom_point(data = onecountry_df, colour = \"purple\",\n             size = 2.5, shape = 1) +\n  geom_abline(aes(slope = 1, intercept = 0), alpha = 0.3)\nalcohol_data %>%\n  mutate(wbratio = wine_servings / beer_servings) %>%\n  arrange(desc(wbratio)) %>%\n  select(country, beer_servings, wine_servings, wbratio)\n#> # A tibble: 193 x 4\n#>    country             beer_servings wine_servings wbratio\n#>    <chr>                       <dbl>         <dbl>   <dbl>\n#>  1 Cook Islands                    0            74  Inf   \n#>  2 Qatar                           1             7    7   \n#>  3 Montenegro                     31           128    4.13\n#>  4 Timor-Leste                     1             4    4   \n#>  5 Syria                           5            16    3.2 \n#>  6 France                        127           370    2.91\n#>  7 Georgia                        52           149    2.87\n#>  8 Italy                          85           237    2.79\n#>  9 Equatorial Guinea              92           233    2.53\n#> 10 Sao Tome & Principe            56           140    2.5 \n#> # … with 183 more rows"},{"path":"intro.html","id":"exercise-1-1","chapter":" 2 Getting Started with R and R Studio","heading":"2.4.1 Exercises","text":"shape distribution total alcohol consumption? Left-skewed, right-skewed, approximately symmetric? Unimodal multimodal?shape distribution total alcohol consumption? Left-skewed, right-skewed, approximately symmetric? Unimodal multimodal?histogram total alcohol consumption, pick country USA interests . See can change code chunk made histogram red vertical line drawn country interests .histogram total alcohol consumption, pick country USA interests . See can change code chunk made histogram red vertical line drawn country interests .Hint: Use View() function look alcohol data set typing View(alcohol_data) bottom-left window help see countries data set.Note: careful capitalization: R case sensitive USA different usa.histogram total alcohol consumption, change fill colour bins histogram : changed code chunk?histogram total alcohol consumption, change fill colour bins histogram : changed code chunk?rankings code, wanted look top 5 countries instead top 3? See change code.rankings code, wanted look top 5 countries instead top 3? See change code.spirit rankings, think 2 countries showed instead 3? Can investigation case?spirit rankings, think 2 countries showed instead 3? Can investigation case?Change wine beer ratio code example find countries highest beer wine consumption (instead wine beer consumption).Change wine beer ratio code example find countries highest beer wine consumption (instead wine beer consumption).","code":"\nView(alcohol_data)"},{"path":"intro.html","id":"athlete-data-example","chapter":" 2 Getting Started with R and R Studio","heading":"2.5 Athlete Data Example","text":"Secondly, look data set top 100 highest paid athletes 2014. athletesdata obtained https://github.com/ali-ce/datasets data set information following variables 100 highest paid athletes 2014, according Forbes (pay includes salary endorsements):Name (name athlete)Rank (athlete ranks, 1 highest paid)Sport (sport athlete plays)endorsements (money sponsorships companies)totalpay (millions year 2014, salary + endorsements)salary (money tournaments contract salary)age athlete 2014Gender (Male Female)first read data set name athletes. can use head() function look first rows data set.many different interesting questions answer data set. First, might interested relationship athlete age salary top 100 athletes. Recall earlier stat course one appropriate graphic examine relationship scatterplot:see anything strange scatterplot? think y-axis tick labels 2.5e+07, 5.0e+07, etc. mean?Now let’s see can count number athletes Top 100 personal favourite sport, Tennis:looks like 6 athletes: can see sort Rank :Finally, let’s see can compare ratio endorsements (commercials products) salary professional athletes Top 100 2 sports: Football (referring American Football) Basketball. Recall earlier Stat class might want use side--side boxplots make comparison since one categorical variable (Sport Type) one quantitative variable (Ratio Endorsements Salary).graph endorsements / salary ratio 1 indicates person makes half overall pay endorsements half overall pay salary.sport looks like tends receive larger proportion overall pay endorsements athletes top 100?","code":"\nathletes <- read_csv(\"data/athletesdata.csv\")\nhead(athletes)\n#> # A tibble: 6 x 9\n#>      X1 Name   Rank Sport endorsements totalpay salary   age\n#>   <dbl> <chr> <dbl> <chr>        <dbl>    <dbl>  <dbl> <dbl>\n#> 1     1 Aaro…    55 Foot…      7500000 22000000 1.45e7    31\n#> 2     2 Adam…    95 Golf       9000000 17700000 8.7 e6    34\n#> 3     3 Adri…    60 Base…       400000 21500000 2.11e7    32\n#> 4     4 Alex…    48 Base…       300000 22900000 2.26e7    39\n#> 5     5 Alfo…    93 Base…        50000 18050000 1.8 e7    38\n#> 6     6 Amar…    27 Bask…      5000000 26700000 2.17e7    32\n#> # … with 1 more variable: Gender <chr>\nggplot(data = athletes, mapping = aes(x = age, y = salary)) + \n  geom_point() +\n  geom_smooth(se = FALSE)\nathletes %>% group_by(Sport) %>%\n  summarise(counts = n()) %>%\n  filter(Sport == \"Tennis\")\n#> # A tibble: 1 x 2\n#>   Sport  counts\n#>   <chr>   <int>\n#> 1 Tennis      6\nathletes %>%\n  filter(Sport == \"Tennis\") %>%\n  arrange(Rank)\n#> # A tibble: 6 x 9\n#>      X1 Name   Rank Sport endorsements totalpay salary   age\n#>   <dbl> <chr> <dbl> <chr>        <dbl>    <dbl>  <dbl> <dbl>\n#> 1    82 Roge…     7 Tenn…     52000000 56200000 4.2 e6    33\n#> 2    78 Rafa…     9 Tenn…     30000000 44500000 1.45e7    28\n#> 3    72 Nova…    17 Tenn…     21000000 33100000 1.21e7    27\n#> 4    64 Mari…    34 Tenn…     22000000 24400000 2.4 e6    27\n#> 5    60 Li Na    41 Tenn…     18000000 23600000 5.6 e6    32\n#> 6    89 Sere…    55 Tenn…     11000000 22000000 1.1 e7    33\n#> # … with 1 more variable: Gender <chr>\nathletes %>% filter(Sport == \"Football\" | Sport == \"Basketball\") %>%\n  ggplot(data = ., aes(x = Sport, y = endorsements / salary)) + \n  geom_boxplot() +\n  labs(y = \"Endorsements / Salary\")"},{"path":"intro.html","id":"exercise-1-2","chapter":" 2 Getting Started with R and R Studio","heading":"2.5.1 Exercises","text":"Instead looking relationship age salary top 100 athletes 2014, change plot look relationship age endorsements. change code ? Try !Instead looking relationship age salary top 100 athletes 2014, change plot look relationship age endorsements. change code ? Try !Pick Sport Tennis see can count number athletes top 100 sport well sort Rank. Careful: sports athletes Top 100.Pick Sport Tennis see can count number athletes top 100 sport well sort Rank. Careful: sports athletes Top 100.many athletes top 100 sport chose?endorsements / salary example, change one sports sport choice make comparison. sport tends receive larger proportion overall pay endorsements.endorsements / salary example, change one sports sport choice make comparison. sport tends receive larger proportion overall pay endorsements.qualification might want make statement previous exercise? (random sample athletes sport? matter?).qualification might want make statement previous exercise? (random sample athletes sport? matter?).side--side boxplots comparing endorsements salary ratio two different sports, ’ve changed y-axis label Endorsements / Salary using labs(y = \"Endorsements / Salary\") statement. Try changing x-axis label something else. think need add plot?side--side boxplots comparing endorsements salary ratio two different sports, ’ve changed y-axis label Endorsements / Salary using labs(y = \"Endorsements / Salary\") statement. Try changing x-axis label something else. think need add plot?","code":""},{"path":"intro.html","id":"finishing-up-common-errors-in-r","chapter":" 2 Getting Started with R and R Studio","heading":"2.6 Finishing Up: Common Errors in R","text":"now talk little bit getting errors R can done correct common errors.may encountered errors point document. Let’s go common errors well discuss comment code.missing parenthesis: open parenthesis ( needs close ). Try running following code chunk without fixing anything.Notice bottom-left window > symbol starts line changes +. generally bad!! means forgot close parenthesis ) quote (' \"). code run since R thinks still trying type something function. fix issue, click cursor bottom-left window press Esc. , try find error code chunk.Can find missing closing parenthesis ?Missing Comma. Try running following code chunk without fixing anything.R gives “Error: unexpected symbol ….” Oftentimes, means missing comma spelled variable name incorrectly.Can find missed comma ?Capitalization IssuesIn original data set, variable Sport capitalized. capitalizing means R won’t able find proclaims “object sport found.”Forgetting Quotes. Character strings need quotation marks around . discuss later, graph labels titles need quotes around since don’t directly refer columns rows data set:error forgetting quotes typically “Unexpected Symbol” though error also given issues.quotes missing code chunk ?Finally, can add comment code chunk # symbol (always use double ## reason though). allows type comment code chunk isn’t code:Comments useful longer code chunks, allow remember something. also tell someone ’ve shared code something.Save file clicking File -> Save using keyboard shortcut Command + s (Control + s PC). Knit file clicking Knit button top-left window (knitting needles). see .html file pop , errors code!","code":"ggplot(data = athletes, aes(x = Sport, y = salary) + \n  geom_boxplot()ggplot(data = athletes aes(x = Sport, y = salary)) + \n  geom_boxplot()\nathletes %>% filter(sport == \"Tennis\")ggplot(data = athletes, aes(x = Sport, y = endorsements)) + \n  geom_boxplot() + xlab(Popularity Measure)\n## this is a comment\n## this calculation might be useful later\n7 * 42\n#> [1] 294"},{"path":"intro.html","id":"chapexercise-1","chapter":" 2 Getting Started with R and R Studio","heading":"2.7 Chapter Exercises","text":"Note: Usually, exercises ask write code using week’s chapter reference. However, initial chapter, something little different.Open new .Rmd file (File -> New File -> R Markdown -> OK) delete text explaining R Markdown lines 10 . , complete following exercises.Exercise 1. Read short paper https://joss.theoj.org/papers/10.21105/joss.01686 Introduction tidyverse, answer questions R Markdown file. ’m imagining whole exercise take ~ 20-25 minutes.Answer following questions typing answers .Rmd document. need make new code chunks, questions don’t ask coding!two major areas tidyverse doesn’t provide tools ?two major areas tidyverse doesn’t provide tools ?authors define “tidy?”authors define “tidy?”mean tidyverse “human-centred?”mean tidyverse “human-centred?”2 sentences, describe data science “cycle” given diagram top page 3.2 sentences, describe data science “cycle” given diagram top page 3.Exercise 2. may continue use .Rmd file answer questions. question, type answer new line, line space answers. questions answered outside code chunks since answers text, code.name class year (first-year, sophomore, junior, senior)?name class year (first-year, sophomore, junior, senior)?/major(s) minor(s), either actual intended?/major(s) minor(s), either actual intended?taking course? (Major requirement?, Minor requirement?, recommended advisor student?, exploring field?, etc.).taking course? (Major requirement?, Minor requirement?, recommended advisor student?, exploring field?, etc.).semester year take STAT 113 professor?semester year take STAT 113 professor?taken STAT 213? taken CS 140?taken STAT 213? taken CS 140?hometown: city, state, country?hometown: city, state, country?play sport campus? , sport? , activity -campus?play sport campus? , sport? , activity -campus?favorite TV show movie band/musical artist?favorite TV show movie band/musical artist?Tell something .Tell something .Take look learning outcomes listed syllabus. excited ?Take look learning outcomes listed syllabus. excited ?expectations class /hope gain class?expectations class /hope gain class?Knit .Rmd file .html file submit knitted .html file Sakai. file won’t knit, submit .Rmd file instead. submit either file, first need get file server onto computer can upload Sakai. Use following steps :Click checkbox next knitted .html file.Click checkbox next knitted .html file.Click Gear Icon “” -> ExportClick Gear Icon “” -> ExportIf like, rename file something like Week0_YOURLASTNAME.html, , make sure keep correct extension (either .html .Rmd).like, rename file something like Week0_YOURLASTNAME.html, , make sure keep correct extension (either .html .Rmd).export , file appear downloads folder. Now, go Sakai -> Assignments -> Week 0 Exercises complete upload process.export , file appear downloads folder. Now, go Sakai -> Assignments -> Week 0 Exercises complete upload process.Nice work: dive ggplot() ggplot2 package next!","code":""},{"path":"intro.html","id":"solutions-1","chapter":" 2 Getting Started with R and R Studio","heading":"2.8 Exercise Solutions","text":"sections, exercise solutions posted end section. However, introduction, coding exercises class make sure start well.","code":""},{"path":"ggplot2.html","id":"ggplot2","chapter":" 3 Plotting with ggplot2","heading":" 3 Plotting with ggplot2","text":"Goals:Use ggplot2 package make exploratory plots STAT 113 single quantitative variable, two quantitative variables, quantitative categorical variable, single categorical variable, two categorical variables.Use ggplot2 package make exploratory plots STAT 113 single quantitative variable, two quantitative variables, quantitative categorical variable, single categorical variable, two categorical variables.Use plots produced answer questions Presidential election data set Fitness data set.Use plots produced answer questions Presidential election data set Fitness data set.practice running code R.practice running code R.","code":""},{"path":"ggplot2.html","id":"introduction-and-basic-terminology","chapter":" 3 Plotting with ggplot2","heading":"3.1 Introduction and Basic Terminology","text":"begin data science journey plotting ggplot2 package. starting plotting couple reasons:Plotting cool! get see immediate result coding efforts form nice--look-plot.Plotting cool! get see immediate result coding efforts form nice--look-plot.exploratory data analysis, typically start making plots data.exploratory data analysis, typically start making plots data.Plotting can lead us ask subsequently investigate interesting questions, see first example.Plotting can lead us ask subsequently investigate interesting questions, see first example.first use data set 2000 United States Presidential election former President George Bush Al Gore obtained http://www.econometrics.com/intro/votes.htm. unfamiliar U.S. political elections, enough know state allocated certain number “electoral votes” president: states award electoral votes candidate receives ballots state. can read strange system Wikipedia.Florida typically highly-contentious “battleground” state. data set following variables, recorded 67 counties Florida:Gore, number people voted Al Gore 2000Bush, number people voted George Bush 2000Buchanan, number people voted third-party candidate BuchananNader, number people voted third-party candidate NaderOther, number people voted candidate previous 4 listedCounty, name county FloridaTo get started exploring data, complete following steps learned Week 0:Log-SLU R Studio server http://rstudio.stlawu.local:8787Log-SLU R Studio server http://rstudio.stlawu.local:8787Create new .Rmd file folder Notes R Project using File -> New File -> R Markdown.Create new .Rmd file folder Notes R Project using File -> New File -> R Markdown.Finally, read name data set pres_df, take look data set running head(pres_df) line, shows first observations data set:Finally, read name data set pres_df, take look data set running head(pres_df) line, shows first observations data set:Pay special attention variable names: ’ll need use names make plots. , R case-sensitive, meaning , example, need use Gore, gore.trying go light technical code terminology start (come back things later semester). terminology make lot sense ’ve actually worked data. , three terms thrown around quite bit next weeks: function, argument, object.function R always* (*always class) followed open ( ended closed ). non-technical terms, function something inputs often analogous English verb. example, mean() function calculates mean, rank() functions ranks variable lowest highest, labs() used add labels plot. Every function help file can accessed typing ?name_of_function. Try typing ?mean lower left window.function R always* (*always class) followed open ( ended closed ). non-technical terms, function something inputs often analogous English verb. example, mean() function calculates mean, rank() functions ranks variable lowest highest, labs() used add labels plot. Every function help file can accessed typing ?name_of_function. Try typing ?mean lower left window.argument something goes inside parentheses function. Arguments include objects, might . bottom-left window, type ?mean view Help file R function. see mean() 3 arguments: x, R object, trim, na.rm. trim = 0 default, means , default, R trim numbers computing mean.argument something goes inside parentheses function. Arguments include objects, might . bottom-left window, type ?mean view Help file R function. see mean() 3 arguments: x, R object, trim, na.rm. trim = 0 default, means , default, R trim numbers computing mean.object something created R, usually <-. , looking code read data, pres_df R object.object something created R, usually <-. , looking code read data, pres_df R object.make sense go first couple weeks.","code":"\nlibrary(tidyverse)\npres_df <- read_table(\"data/PRES2000.txt\") \n## don't worry about the `read_table` function....yet\nhead(pres_df)\n#> # A tibble: 6 x 6\n#>     Gore   Bush Buchanan Nader Other County  \n#>    <dbl>  <dbl>    <dbl> <dbl> <dbl> <chr>   \n#> 1  47365  34124      263  3226   751 ALACHUA \n#> 2   2392   5610       73    53    26 BAKER   \n#> 3  18850  38637      248   828   242 BAY     \n#> 4   3075   5414       65    84    35 BRADFORD\n#> 5  97318 115185      570  4470   852 BREVARD \n#> 6 386561 177323      788  7101  1623 BROWAR"},{"path":"ggplot2.html","id":"basic-plot-structure","chapter":" 3 Plotting with ggplot2","heading":"3.2 Basic Plot Structure","text":"use ggplot() function ggplot2 package construct visualizations data. ggplot() function 3 basic components:data argument, specifying name data set (pres_df )mapping argument, specifying specifies aesthetics plot (aes()). Common aesthetics x position, y position, colour, size, shape, group, fill.geom_    () component, specifying geometric shape used display data.components combined following form:structure ggplot() plots based Grammar Graphics https://www.springer.com/gp/book/9780387245447. new things, components easier think examples.","code":"ggplot(data = name_of_data, mapping = aes(x = name_of_x_var, \n                                          y = name_of_y_var,\n                                          colour = name_of_colour_var,\n                                          etc.)) +\n  geom_nameofgeom() +\n  .....<other stuff>"},{"path":"ggplot2.html","id":"graphing-a-single-variable","chapter":" 3 Plotting with ggplot2","heading":"3.3 Graphing a Single Variable","text":"","code":""},{"path":"ggplot2.html","id":"histograms-and-frequency-plots-for-a-quantitative-variable","chapter":" 3 Plotting with ggplot2","heading":"3.3.1 Histograms and Frequency Plots for a Quantitative Variable","text":"Let’s go ahead begin exploration data making histogram number people voted Gore county. Recall histogram useful like graph single quantitative variable. Copy following code R chunk run code:1e+05, 2e+05, etc. labels x-axis mean?R gives us message “Pick better value binwidth” instead default bins = 30. Add , bins = 15 inside parentheses geom_histogram() change number bins histogram.Change colour inside bins “darkred.” think colour inside bins maps colour fill? Try !couple observations high vote values. explain large outliers?Another graph useful visualizing single quantitative variable frequency plot. code make frequency plot given . simply replacing geom_histogram() geom_freqpoly().frequency plot just like histogram counts connected line instead represented bins. can see relate including geom_freqpoly() geom_histogram() plot, though doesn’t make prettiest graph:","code":"\nggplot(data = pres_df, mapping = aes(x = Gore)) +\n  geom_histogram(colour = \"black\", fill = \"white\") +\n  xlab(\"Votes for Gore in Florida\")\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\nggplot(data = pres_df, mapping = aes(x = Gore)) +\n  geom_freqpoly(colour = \"black\") +\n  xlab(\"Votes for Gore in Florida\") \n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\nggplot(data = pres_df, mapping = aes(x = Gore)) +\n  geom_freqpoly(colour = \"black\") +\n  xlab(\"Votes for Gore in Florida\") +\n  geom_histogram() \n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`."},{"path":"ggplot2.html","id":"r-code-style","chapter":" 3 Plotting with ggplot2","heading":"3.3.2 R Code Style","text":"want code readable possible. benefits people may read code (like ), also benefits , particularly read code future. try follow Style Guide Advanced R book: http://adv-r..co.nz/Style.html. Feel free skim , don’t need worry much: able pick important elements just going course. might actually end better code style haven’t previous coding experience.quick example code style can important, consider following two code chunks, produce graph.code chunk want read two years now? code chunk want classmate/friend/coworker read? (assuming like classmate/friend/coworker….)","code":"\nggplot(data=pres_df,mapping=aes(x=Gore))+geom_histogram(colour=\"black\",fill=\"white\")+\n  xlab(\"Votes for Gore in Florida\")\nggplot(data = pres_df, mapping = aes(x = Gore)) +\n  geom_histogram(colour = \"black\", fill = \"white\") +\n  xlab(\"Votes for Gore in Florida\")"},{"path":"ggplot2.html","id":"bar-plots-for-a-categorical-variable","chapter":" 3 Plotting with ggplot2","heading":"3.3.3 Bar Plots for a Categorical Variable","text":"Recall STAT 113 bar plots useful want examine distribution one categorical variable. Side--side bar plots stacked bar plots plots useful looking relationship two categorical variables. actually aren’t categorical variables interesting plot data set, ’ll make one, called winner using code don’t need understand next week. winner \"Gore\" Gore won county \"Bush\" Bush won county. ’ll name new data set pres_cat.Using data set, can make bar plot geom_bar(). beauty ggplot() code super-similar used histograms frequency plots!Note , sometimes, data format one column contains levels categorical variable another column contains counts directly. example, can create data set using code learn next week:data set just two observations contains column two major presidential candidates column number counties candidate won. wanted make barplot showing number wins candidate, can’t use geom_bar(). Predict result running following code.Instead, can use geom_col(), takes x aesthetic giving column names levels categorical variable, y aesthetic giving column counts:","code":"\npres_cat <- pres_df %>% mutate(winner = if_else(Gore > Bush,\n                                                true = \"Gore\",\n                                                false = \"Bush\"))\npres_cat\n#> # A tibble: 67 x 7\n#>      Gore   Bush Buchanan Nader Other County    winner\n#>     <dbl>  <dbl>    <dbl> <dbl> <dbl> <chr>     <chr> \n#>  1  47365  34124      263  3226   751 ALACHUA   Gore  \n#>  2   2392   5610       73    53    26 BAKER     Bush  \n#>  3  18850  38637      248   828   242 BAY       Bush  \n#>  4   3075   5414       65    84    35 BRADFORD  Bush  \n#>  5  97318 115185      570  4470   852 BREVARD   Bush  \n#>  6 386561 177323      788  7101  1623 BROWAR    Gore  \n#>  7   2155   2873       90    39    17 CALHOUN   Bush  \n#>  8  29645  35426      182  1462   181 CHARLOTTE Bush  \n#>  9  25525  29765      270  1379   261 CITRUS    Bush  \n#> 10  14632  41736      186   562   237 CLAY      Bush  \n#> # … with 57 more rows\nggplot(data = pres_cat, aes(x = winner)) +\n  geom_bar()\npres_cat2 <- pres_cat %>% group_by(winner) %>%\n  summarise(nwins = n())\npres_cat2\n#> # A tibble: 2 x 2\n#>   winner nwins\n#>   <chr>  <int>\n#> 1 Bush      51\n#> 2 Gore      16\nggplot(pres_cat2, aes(x = winner)) +\n  geom_bar()\nggplot(pres_cat2, aes(x = winner, y = nwins)) +\n  geom_col()"},{"path":"ggplot2.html","id":"exercise-2-1","chapter":" 3 Plotting with ggplot2","heading":"3.3.4 Exercises","text":"Exercises marked * indicate exercise solution end chapter 3.7.Change frequency plot plot number votes Bush instead number Gore. obvious outliers Bush frequency plot?Change frequency plot plot number votes Bush instead number Gore. obvious outliers Bush frequency plot?preference histograms preference frequency plots? Can think situation one desirable ?preference histograms preference frequency plots? Can think situation one desirable ?looks like Bush won lot ….necessarily mean Bush won votes total Florida? ?looks like Bush won lot ….necessarily mean Bush won votes total Florida? ?using survey data STAT 113 2018-2019 academic year many exercises section. may taken STAT 113 AP credit another reason, STAT 113 survey given students STAT 113 across sections. analyses Intro Stat carried using survey.data set contains following variables:Year, FirstYear, Sophomore, Junior, SeniorSex, M F (data set, Sex considered binary).Hgt, height, inches.Wgt, weight, pounds.Haircut, much paid haircut, typically.GPAExercise, amount hours exercise typical week.Sport, whether student plays varsity sport.TV, amount hours spent watching TV typical week.Award, Award preferred: choices Olympic Medal, Nobel Prize, Academy Award.Pulse, pulse rate, beats per minute.SocialMedia, used social media platform (Instagram, SnapChat, FaceBook, Twitter, , None).* Create histogram Exercise variable, change x-axis label “Exercise (hours per typical week),” change number bins 14, change fill bins “lightpink2” outline colour bins black.* Create histogram Exercise variable, change x-axis label “Exercise (hours per typical week),” change number bins 14, change fill bins “lightpink2” outline colour bins black.* can change y-axis histogram “density” instead raw count. means bar shows proportion cases instead raw count. Google something like “geom_histogram density” figure create y aes() show density instead count.* can change y-axis histogram “density” instead raw count. means bar shows proportion cases instead raw count. Google something like “geom_histogram density” figure create y aes() show density instead count.Construct histogram using quantitative variable choice. Change fill colour using http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf help choose colours.Construct histogram using quantitative variable choice. Change fill colour using http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf help choose colours.Construct bar plot variable choosing. find?Construct bar plot variable choosing. find?format STAT 113 data set need construct bar plot geom_col() instead geom_bar()?format STAT 113 data set need construct bar plot geom_col() instead geom_bar()?","code":"\nlibrary(tidyverse)\nstat113_df <- read_csv(\"data/stat113.csv\")\nhead(stat113_df)\n#> # A tibble: 6 x 12\n#>   Year  Sex     Hgt   Wgt Haircut   GPA Exercise Sport    TV\n#>   <chr> <chr> <dbl> <dbl>   <dbl> <dbl>    <dbl> <chr> <dbl>\n#> 1 Soph… M        66   155       0  2.9        15 Yes       8\n#> 2 Firs… F        69   170      17  3.87       14 Yes      12\n#> 3 Firs… F        64   130      40  3.3         5 No        5\n#> 4 Firs… M        68   157      35  3.21       10 Yes      15\n#> 5 Firs… M        72   175      20  3.1         2 No        5\n#> 6 Juni… F        62   150      50  3.3         8 Yes       5\n#> # … with 3 more variables: Award <chr>, Pulse <dbl>,\n#> #   SocialMedia <chr>"},{"path":"ggplot2.html","id":"graphing-two-quantitative-variables-faceting-and-aes-options","chapter":" 3 Plotting with ggplot2","heading":"3.4 Graphing Two Quantitative Variables, Faceting, and aes() Options","text":"","code":""},{"path":"ggplot2.html","id":"scatterplots","chapter":" 3 Plotting with ggplot2","heading":"3.4.1 Scatterplots","text":"Moving back 2000 presidential election data set, thus far, ’ve figured couple counties large numbers votes Gore large number votes Bush. don’t know reason (counties democratic, republican, counties just populous). counties large number votes Bush also tend large number votes Gore? candidates: interesting patterns?Let’s start making scatterplot number votes Gore number votes Bush. Note geom_ making scatterplot called geom_point() adding layer points plot.patterns see scatterplot?Now, change x variable Gore Buchanan. notice something strange scatterplot. Try come one explanation outlying point many votes Buchanan.trying come explanation, nice figure Florida county outlying point nice knew something Florida counties. remedy first issue, recall can type View(pres_df) pull data set. new window open, click column heading Buchanan sort votes Buchanan high low figure county outlier.Use Google sleuthing skills find explanation: try search “2000 united states presidential election [name outlier county].” Write sentence find. Hint: nothing useful pops , try adding term “butterfly ballot” search.used 2000 Presidential data set find something really interesting! particular, used exploratory data analysis examine data set, without specific question interest want answer. type exploring often really useful, drawbacks, discuss later semester.","code":"\nggplot(data = pres_df, mapping = aes(x = Gore, y = Bush)) +\n  geom_point()"},{"path":"ggplot2.html","id":"aesthetics-in-aes","chapter":" 3 Plotting with ggplot2","heading":"3.4.2 Aesthetics in aes()","text":"remainder chapter, work fitness data collected Apple Watch since November 2018. higham_fitness_clean.csv contains information following variables:Start, month, day, year fitness data recorded onmonth, monthweekday, day weekdayofyear, day year (304 corresponds 304th day year)distance, distance walked milessteps, number steps takenflights, number flights stairs climbedactive_cals, number calories burned activitystepgoal, whether reached 10,000 steps dayweekend_ind, variable whether day week weekend day (Saturday Sunday) weekday (Monday - Friday).First, let’s make basic scatterplot illustrate ’s important plot data. ’ll use variable distance x-variable active_cals y-variable.One aspect plot may notice observations burned 0 active calories, yet walked/jogged/ran/moved distance. possible burn calories move ~ 4 miles? Probably , let’s drop observations data set make note dropped observations. Unfortunately, don’t tools yet, just run following chunk code without worrying much syntax.Let’s make plot fitness data set instead fitness_full see outliers actually gone. time, put aes() geom_point() function:Putting aes() ggplot() putting aes() geom_point() results graph case. put aes() ggplot(), R perpetuates aes() aesthetics geom_s plotting command. However, put aes() geom_point(), future geoms use need re-specify different aes(). ’ll see example exercises.aes() OptionsIn addition x y, can also use aes() map variables things like colour, size, shape. example, might make scatterplot Start x-axis (date) active_cals y-axis, colouring whether day week weekend.anything useful notice plot? anything plot improved?Instead using colour, can also specify point shape. useful, example, printing something black white.prefer colour shape? ?Finally, another common aes() size. example, make size points scatterplot change depending many flights stairs climbed.don’t think previous three plots necessarily “best” need work, , part fun exploratory data analysis making trying different plots see “works.”Inside vs Outside aes()’ve changed colour points correspond weekend_ind, just wanted change colour points colour, \"purple\". Try running following code chunk:graph look like? expected?Putting colour = ____ inside aes() outside aes() achieves different things. general,want map something data set (fitness) something plot (x, y, colour, size, etc.), put inside aes() geom_point(aes(colour = weekend_ind)).want map something data set (fitness) something plot (x, y, colour, size, etc.), put inside aes() geom_point(aes(colour = weekend_ind)).assign fixed characteristics don’t come data, put outside aes(), geom_point(colour = \"purple\").assign fixed characteristics don’t come data, put outside aes(), geom_point(colour = \"purple\").can also change overall point size shape. standard size 1 following code chunk makes points bigger. standard shape 19: can try changing integers see shapes can get.","code":"\nlibrary(tidyverse)\nfitness_full <- read_csv(\"data/higham_fitness_clean.csv\") %>% mutate(weekend_ind = case_when(weekday == \"Sat\" | weekday == \"Sun\" ~ \"weekend\",\n  TRUE ~ \"weekday\"))\n#> \n#> ── Column specification ────────────────────────────────────\n#> cols(\n#>   Start = col_date(format = \"\"),\n#>   month = col_character(),\n#>   weekday = col_character(),\n#>   dayofyear = col_double(),\n#>   distance = col_double(),\n#>   steps = col_double(),\n#>   flights = col_double(),\n#>   active_cals = col_double(),\n#>   stepgoal = col_character()\n#> )\nggplot(data = fitness_full, aes(x = distance, y = active_cals)) +\n  geom_point()\n## drop observations that have active calories < 50. \n## assuming that these are data errors or \n## days where the Apple Watch wasn't worn.\nfitness <- fitness_full %>%\n  filter(active_cals > 50)\nggplot(data = fitness) +\n  geom_point(aes(x = distance, y = active_cals))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals, colour = weekend_ind))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals, shape = weekend_ind))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals, size = flights))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals, colour = \"purple\"))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals), size = 1.5, shape = 19)"},{"path":"ggplot2.html","id":"using-more-than-one-geom","chapter":" 3 Plotting with ggplot2","heading":"3.4.3 Using More Than One geom()","text":"might also interested fitting smooth curve scatterplot. want put one “geom” plot, can use multiple geoms. Since want aes() apply geom_point() geom_smooth(), going move aes() command overall ggplot() line code:Within geom_smooth(), can set se = FALSE get rid grey standard errors around lines, can setmethod = \"lm\" fit straight linear regression lines instead smooth curves:look like increasing overall trend? decreasing? make sense use line model relationship prefer smooth curve?","code":"\nggplot(data = fitness, aes(x = Start, y = active_cals)) +\n  geom_point() +\n  geom_smooth()\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'\nggplot(data = fitness, aes(x = Start, y = active_cals)) +\n  geom_point() +\n  geom_smooth(se = FALSE, method = \"lm\")\n#> `geom_smooth()` using formula 'y ~ x'"},{"path":"ggplot2.html","id":"line-plots-with-geom_line","chapter":" 3 Plotting with ggplot2","heading":"3.4.4 Line Plots with geom_line()","text":"Line plots often useful quantitative variable ’d like explore time. y-axis quantitative variable x-axis typically time. generally, line plots often used x-axis variable one discrete value y-axis variable. example, suppose want explore step count changed time past couple years. Compare standard scatterplot following line plot: prefer?Can spot start pandemic graph? seemed happen step count?","code":"\nggplot(data = fitness, mapping = aes(x = Start, y = steps)) +\n  geom_point() + geom_smooth() + xlab(\"Date\")\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'\nggplot(data = fitness, mapping = aes(x = Start, y = steps)) +\n  geom_line() + geom_smooth() + xlab(\"Date\")\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'"},{"path":"ggplot2.html","id":"faceting","chapter":" 3 Plotting with ggplot2","heading":"3.4.5 Faceting","text":"Using colour colour points different levels categorical variable generally fine just couple levels /little overlap among levels. , lot two categories colour . example, let’s move back STAT 113 survey data set investigate relationship Pulse Exercise different class Year’s. might hypothesize students get exercise tend lower pulse rates.many different categories categorical variable (4 categories Year, particular plot still bit difficult read), can sometimes useful facet plot variable instead trying use different colours shapes.eliminated colour = argument added facet_wrap( ~ name_of_facet_variable). creates different scatterplot smooth line level name_of_facet_variable.can see plot harder see plot colour?data seem support hypothesis exercise associated lower pulse rates sample students?","code":"\nggplot(data = stat113_df, aes(x = Exercise, y = Pulse,\n                           colour = Year)) +\n  geom_point() +\n  geom_smooth(se = TRUE)\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'\n#> Warning: Removed 40 rows containing non-finite values\n#> (stat_smooth).\n#> Warning: Removed 40 rows containing missing values\n#> (geom_point).\nggplot(data = stat113_df, aes(x = Exercise, y = Pulse)) +\n  geom_point() +\n  geom_smooth(se = TRUE) +\n  facet_wrap(~ Year)\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'\n#> Warning: Removed 40 rows containing non-finite values\n#> (stat_smooth).\n#> Warning: Removed 40 rows containing missing values\n#> (geom_point)."},{"path":"ggplot2.html","id":"exercise-2-2","chapter":" 3 Plotting with ggplot2","heading":"3.4.6 Exercises","text":"Exercises marked * indicate exercise solution end chapter 3.7.Fix code chunk tried specify colour points purple actually make points “purple” moving colour = \"purple\" outside parentheses aes() (still inside geom_point()).Fix code chunk tried specify colour points purple actually make points “purple” moving colour = \"purple\" outside parentheses aes() (still inside geom_point()).console (bottom-left) window, type ?geom_smooth scroll “Arguments.” Find span, read , , within geom_smooth() argument line plot steps vs. date, add span argument make smooth line wigglier.console (bottom-left) window, type ?geom_smooth scroll “Arguments.” Find span, read , , within geom_smooth() argument line plot steps vs. date, add span argument make smooth line wigglier.Explain doesn’t make sense construct line plot Exercise vs. GPA.Explain doesn’t make sense construct line plot Exercise vs. GPA.* Make scatterplot Hgt y-axis Wgt x-axis, colouring Sport. Add smooth fitted curve scatterplot. , move colour = Sport aes() ggplot() function aes() geom_point() function. changes plot? Can give explanation change occurs?* Make scatterplot Hgt y-axis Wgt x-axis, colouring Sport. Add smooth fitted curve scatterplot. , move colour = Sport aes() ggplot() function aes() geom_point() function. changes plot? Can give explanation change occurs?* Faceting can used types plots ! Make pair faceted histograms quantitative variable choosing faceted categorical variable choosing.* Faceting can used types plots ! Make pair faceted histograms quantitative variable choosing faceted categorical variable choosing.","code":""},{"path":"ggplot2.html","id":"boxplots-stacked-barplots-and-others","chapter":" 3 Plotting with ggplot2","heading":"3.5 Boxplots, Stacked Barplots and Others","text":"common geoms useful throughout semester. skim surface: ’ll come back plotting weeks, ’re able data wrangling reshaping.","code":""},{"path":"ggplot2.html","id":"graphing-a-quant.-variable-vs.-a-cat.-variable","chapter":" 3 Plotting with ggplot2","heading":"3.5.1 Graphing a Quant. Variable vs. a Cat. Variable","text":"Another common plot used Intro Stat courses boxplot. Side--side boxplots particularly useful want compare quantitative response variable across two levels categorical variable. Let’s stick STAT 113 survey data examine relationship Exercise Award preference.can conclude plot?alternative side--side boxplots violin plots:Read Violin plots typing ?geom_violin console (bottom-left window). different boxplots?","code":"\nggplot(data = stat113_df, aes(x = Award, y = Exercise)) +\n  geom_boxplot()\n#> Warning: Removed 7 rows containing non-finite values\n#> (stat_boxplot).\nggplot(data = stat113_df, aes(x = Award, y = Exercise)) +\n  geom_violin()\n#> Warning: Removed 7 rows containing non-finite values\n#> (stat_ydensity)."},{"path":"ggplot2.html","id":"graphing-two-categorical-variables","chapter":" 3 Plotting with ggplot2","heading":"3.5.2 Graphing Two Categorical Variables","text":"combination two variables yet explore two variables categorical. Let’s look relationship Year SocialMedia first using stacked bar plot.make graph, specify position = \"fill\" bars “filled” stepgoal.patterns notice plot? anything plot improved?","code":"\nggplot(data = stat113_df, aes(x = Year, fill = SocialMedia)) +\n  geom_bar(position = \"fill\") +\n  ylab(\"Proportion\")"},{"path":"ggplot2.html","id":"exercise-2-3","chapter":" 3 Plotting with ggplot2","heading":"3.5.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 3.7.* Change colour inside boxplots Exercise vs. Award graph \"blue\". think ’ll use colour = \"blue\" fill = \"blue\"?* Change colour inside boxplots Exercise vs. Award graph \"blue\". think ’ll use colour = \"blue\" fill = \"blue\"?* Create side--side boxplot compares GPAs students prefer different Awards. change fill boxplot colour choice. notice plot?* Create side--side boxplot compares GPAs students prefer different Awards. change fill boxplot colour choice. notice plot?* making previous plot, R gives us warning message “Removed 70 rows containing non-finite values.” R’s robotic way telling us 70 GPA values missing data set. Use know data collected (Fall Spring semester 2018-2019 school-year) guess missing.* making previous plot, R gives us warning message “Removed 70 rows containing non-finite values.” R’s robotic way telling us 70 GPA values missing data set. Use know data collected (Fall Spring semester 2018-2019 school-year) guess missing.* Make stacked bar plot two variables choosing STAT 113 data set. Comment something notice plot.* Make stacked bar plot two variables choosing STAT 113 data set. Comment something notice plot.","code":""},{"path":"ggplot2.html","id":"chapexercise-2","chapter":" 3 Plotting with ggplot2","heading":"3.6 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 3.7.* default geom_smooth() use LOESS (locally estimated scatterplot smoothing). Read LOESS : . Write one two sentences explaining LOESS .* default geom_smooth() use LOESS (locally estimated scatterplot smoothing). Read LOESS : . Write one two sentences explaining LOESS .* Thus far, faceted single variable. Use Google figure facet two variables make plot shows relationship GPA (y-axis) Exercise (x-axis) four facets: one male students play sport, one female students play sport, one male students play sport, one female students play sport.* Thus far, faceted single variable. Use Google figure facet two variables make plot shows relationship GPA (y-axis) Exercise (x-axis) four facets: one male students play sport, one female students play sport, one male students play sport, one female students play sport.* Intro-Stat, boxplots typically introduced using * symbol identify outliers. Using combination help ?geom_boxplot Googling “R point shapes,” figure modify side--side boxplots outliers shown using *, default dots.* Intro-Stat, boxplots typically introduced using * symbol identify outliers. Using combination help ?geom_boxplot Googling “R point shapes,” figure modify side--side boxplots outliers shown using *, default dots., using Google, figure add mean boxplot “darkgreen” diamond-shaped symbol stat_summary().common theme ’ll see throughout course ’s advantageous know much background information possible data set analyzing. Data sets easier analyze pose questions ’re familiar subject matter.Give example something know STAT 113 survey data set helped answer pose question someone another university (therefore unfamiliar intro stat course) wouldn’t know.Give example something don’t know fitness data set person owns fitness data know. give advantage person familiar fitness data?","code":""},{"path":"ggplot2.html","id":"solutions-2","chapter":" 3 Plotting with ggplot2","heading":"3.7 Exercise Solutions","text":"","code":""},{"path":"ggplot2.html","id":"introduction-etc.-s","chapter":" 3 Plotting with ggplot2","heading":"3.7.1 Introduction etc. S","text":"","code":""},{"path":"ggplot2.html","id":"basic-plot-structure-s","chapter":" 3 Plotting with ggplot2","heading":"3.7.2 Basic Plot Structure S","text":"","code":""},{"path":"ggplot2.html","id":"graphing-a-single-variable-s","chapter":" 3 Plotting with ggplot2","heading":"3.7.3 Graphing a Single Variable S","text":"* Create histogram Exercise variable, change x-axis label “Exercise (hours per typical week),” change number bins 14, change fill bins “lightpink2” outline colour bins black.* can change y-axis histogram “density” instead raw count. means bar shows proportion cases instead raw count. Google something like “geom_histogram density” figure create y aes() show density instead count.","code":"\nggplot(data = stat113_df, aes(x = Exercise)) +\n  geom_histogram(bins = 14, fill = \"lightpink2\", colour = \"black\") +\n  xlab(\"Exercise (hours per typical week)\")\n#> Warning: Removed 7 rows containing non-finite values\n#> (stat_bin).\nggplot(data = stat113_df, aes(x = Exercise, y = ..density..)) +\n  geom_histogram(bins = 14, fill = \"lightpink2\", colour = \"black\") +\n  xlab(\"Exercise (hours per typical week)\")\n#> Warning: Removed 7 rows containing non-finite values\n#> (stat_bin)."},{"path":"ggplot2.html","id":"graphing-two-quant.-etc.-s","chapter":" 3 Plotting with ggplot2","heading":"3.7.4 Graphing Two Quant. etc. S","text":"* Make scatterplot Hgt y-axis Wgt x-axis, colouring Sport. Add smooth fitted curve scatterplot. , move colour = Sport aes() ggplot() function aes() geom_point() function. changes plot? Can give explanation change occurs?points now coloured Sport one smooth fitted line. makes sense geom_point() now two global aesthetics x y, well colour aesthetic. geom_smooth() longer colour aesthetic still inherits two global aesthetics, x y.* Faceting can used types plots ! Make pair faceted histograms quantitative variable choosing faceted categorical variable choosing.Answers vary:","code":"\nggplot(data = stat113_df, aes(x = Wgt, y = Hgt, colour = Sport)) +\n  geom_point() +\n  geom_smooth()\n\nggplot(data = stat113_df, aes(x = Wgt, y = Hgt)) +\n  geom_point(aes(colour = Sport)) +\n  geom_smooth()\nggplot(data = stat113_df, aes(x = GPA)) + \n  geom_histogram(bins = 15) +\n  facet_wrap( ~ Sport)"},{"path":"ggplot2.html","id":"boxplots-stacked-etc.-s","chapter":" 3 Plotting with ggplot2","heading":"3.7.5 Boxplots, Stacked, etc. S","text":"* Change colour inside boxplots Exercise vs. Award graph \"blue\". think ’ll use colour = \"blue\" fill = \"blue\"?fill ’s inside boxplots want modify. colour modify outline colour.* Create side--side boxplot compares GPAs students prefer different Awards. change fill boxplot colour choice. notice plot?outlier students, three groups overall seem similar GPAs.* making previous plot, R gives us warning message “Removed 70 rows containing non-finite values.” R’s robotic way telling us 70 GPA values missing data set. Use know data collected (Fall Spring semeseter 2018-2019 school-year) guess missing.STAT 113 first-year students: first-years taking course fall GPA report. Additionally, another reason might student chose report GPA.* Make stacked bar plot two variables choosing STAT 113 data set. Comment something notice plot.Answers vary.might expect, seem like higher proportion students play sport prefer win Olympic medal, compared students play sport.","code":"\nggplot(data = stat113_df, aes(x = Award, y = Exercise)) +\n  geom_boxplot(fill = \"blue\")\n#> Warning: Removed 7 rows containing non-finite values\n#> (stat_boxplot).\nggplot(data = stat113_df, aes(x = Award, y = GPA)) +\n  geom_boxplot(fill = \"lightpink1\")\n#> Warning: Removed 70 rows containing non-finite values\n#> (stat_boxplot).\nggplot(data = stat113_df, aes(x = Sport, fill = Award)) +\n  geom_bar(position = \"fill\")"},{"path":"ggplot2.html","id":"chapexercise-2-S","chapter":" 3 Plotting with ggplot2","heading":"3.7.6 Chapter Exercises S","text":"* default geom_smooth() use LOESS (locally estimated scatterplot smoothing). Read LOESS : . Write one two sentences explaining LOESS .Loess uses bunch local regressions predict y-variable point, giving weight observations near point interest x-axis. done every point, predictions connected smooth curve.* Thus far, faceted single variable. Use Google figure facet two variables make plot shows relationship GPA (y-axis) Exercise (x-axis) four facets: one male students play sport, one female students play sport, one male students play sport, one female students play sport.* Intro-Stat, boxplots typically introduced using * symbol identify outliers. Using combination help ?geom_boxplot Googling “R point shapes,” figure modify side--side boxplots outliers shown using *, default dots., using Google, figure add mean boxplot “darkgreen” diamond-shaped symbol stat_summary().","code":"\nggplot(data = stat113_df %>% filter(!is.na(Sport) & !is.na(Sex)),\n  aes(x = Exercise, y = GPA)) + \n  geom_point() + geom_smooth() +\n  facet_grid(Sex ~ Sport)\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'\n#> Warning: Removed 71 rows containing non-finite values\n#> (stat_smooth).\n#> Warning: Removed 71 rows containing missing values\n#> (geom_point).\nggplot(data = stat113_df, aes(x = Sex, y = GPA)) +\n  geom_boxplot(fill = \"lightpink1\", outlier.shape = 8) +\n  stat_summary(fun = mean, shape = 18, colour = \"darkgreen\")\n#> Warning: Removed 70 rows containing non-finite values\n#> (stat_boxplot).\n#> Warning: Removed 70 rows containing non-finite values\n#> (stat_summary).\n#> Warning: Removed 3 rows containing missing values\n#> (geom_segment)."},{"path":"ggplot2.html","id":"rcode-2","chapter":" 3 Plotting with ggplot2","heading":"3.8 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\npres_df <- read_table(\"data/PRES2000.txt\") \n## don't worry about the `read_table` function....yet\nhead(pres_df)\nggplot(data = pres_df, mapping = aes(x = Gore)) +\n  geom_histogram(colour = \"black\", fill = \"white\") +\n  xlab(\"Votes for Gore in Florida\")\nggplot(data = pres_df, mapping = aes(x = Gore)) +\n  geom_freqpoly(colour = \"black\") +\n  xlab(\"Votes for Gore in Florida\") \nggplot(data = pres_df, mapping = aes(x = Gore)) +\n  geom_freqpoly(colour = \"black\") +\n  xlab(\"Votes for Gore in Florida\") +\n  geom_histogram() \npres_cat <- pres_df %>% mutate(winner = if_else(Gore > Bush,\n                                                true = \"Gore\",\n                                                false = \"Bush\"))\npres_cat\nggplot(data = pres_cat, aes(x = winner)) +\n  geom_bar()\npres_cat2 <- pres_cat %>% group_by(winner) %>%\n  summarise(nwins = n())\npres_cat2\nggplot(pres_cat2, aes(x = winner)) +\n  geom_bar()\nggplot(pres_cat2, aes(x = winner, y = nwins)) +\n  geom_col()\nggplot(data = pres_df, mapping = aes(x = Gore, y = Bush)) +\n  geom_point()\nlibrary(tidyverse)\nfitness_full <- read_csv(\"data/higham_fitness_clean.csv\") %>% mutate(weekend_ind = case_when(weekday == \"Sat\" | weekday == \"Sun\" ~ \"weekend\",\n  TRUE ~ \"weekday\"))\nggplot(data = fitness_full, aes(x = distance, y = active_cals)) +\n  geom_point()\n## drop observations that have active calories < 50. \n## assuming that these are data errors or \n## days where the Apple Watch wasn't worn.\nfitness <- fitness_full %>%\n  filter(active_cals > 50)\nggplot(data = fitness) +\n  geom_point(aes(x = distance, y = active_cals))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals, colour = weekend_ind))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals, shape = weekend_ind))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals, size = flights))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals, colour = \"purple\"))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals), size = 1.5, shape = 19)\nggplot(data = fitness, aes(x = Start, y = active_cals)) +\n  geom_point() +\n  geom_smooth()\nggplot(data = fitness, aes(x = Start, y = active_cals)) +\n  geom_point() +\n  geom_smooth(se = FALSE, method = \"lm\")\nggplot(data = fitness, mapping = aes(x = Start, y = steps)) +\n  geom_point() + geom_smooth() + xlab(\"Date\")\nggplot(data = fitness, mapping = aes(x = Start, y = steps)) +\n  geom_line() + geom_smooth() + xlab(\"Date\")\nggplot(data = stat113_df, aes(x = Exercise, y = Pulse,\n                           colour = Year)) +\n  geom_point() +\n  geom_smooth(se = TRUE)\nggplot(data = stat113_df, aes(x = Exercise, y = Pulse)) +\n  geom_point() +\n  geom_smooth(se = TRUE) +\n  facet_wrap(~ Year)\nggplot(data = stat113_df, aes(x = Award, y = Exercise)) +\n  geom_boxplot()\nggplot(data = stat113_df, aes(x = Award, y = Exercise)) +\n  geom_violin()\nggplot(data = stat113_df, aes(x = Year, fill = SocialMedia)) +\n  geom_bar(position = \"fill\") +\n  ylab(\"Proportion\")"},{"path":"dplyr.html","id":"dplyr","chapter":" 4 Wrangling with dplyr","heading":" 4 Wrangling with dplyr","text":"Goals:Use mutate(), if_else(), case_when() functions create new variables.Use mutate(), if_else(), case_when() functions create new variables.Use filter() slice(), select(), arrange() functions dplyr choose certain rows keep get rid , choose certain columns keep get rid , sort data, respectively.Use filter() slice(), select(), arrange() functions dplyr choose certain rows keep get rid , choose certain columns keep get rid , sort data, respectively.Use group_by() summarise() create useful summaries data set.Use group_by() summarise() create useful summaries data set.Combine goals plotting explore babynames data set data set SLU majors.Combine goals plotting explore babynames data set data set SLU majors.Throughout chapter, use babynames data set babynames R package. begin, read data set, runningand typing ?babynames bottom-left window R Studio. see data set contains baby name data provided SSA United States dating back 1880:second data set use 27 observations, one SLU’s majors contains 3 variables:Major, name major.nfemales, number female graduates major 2015 - 2019.nmales, number male graduates major 2015 - 2019.data kindly provided Dr. Ramler. Notes R Project open, can read data set withThere many interesting informative plots make either data set, require data wrangling first. chapter provide foundation wrangling skills.","code":"\nlibrary(babynames)\nhead(babynames)\n#> # A tibble: 6 x 5\n#>    year sex   name          n   prop\n#>   <dbl> <chr> <chr>     <int>  <dbl>\n#> 1  1880 F     Mary       7065 0.0724\n#> 2  1880 F     Anna       2604 0.0267\n#> 3  1880 F     Emma       2003 0.0205\n#> 4  1880 F     Elizabeth  1939 0.0199\n#> 5  1880 F     Minnie     1746 0.0179\n#> 6  1880 F     Margaret   1578 0.0162\nlibrary(tidyverse)\nslumajors_df <- read_csv(\"data/SLU_Majors_15_19.csv\")\nslumajors_df\n#> # A tibble: 27 x 3\n#>    Major                        nfemales nmales\n#>    <chr>                           <dbl>  <dbl>\n#>  1 Anthropology                       34     15\n#>  2 Art & Art History                  65     11\n#>  3 Biochemistry                       14     11\n#>  4 Biology                           162     67\n#>  5 Business in the Liberal Arts      135    251\n#>  6 Chemistry                          26     14\n#>  7 Computer Science                   21     47\n#>  8 Conservation Biology               38     20\n#>  9 Economics                         128    349\n#> 10 English                           131     54\n#> # … with 17 more rows"},{"path":"dplyr.html","id":"mutate-create-variables","chapter":" 4 Wrangling with dplyr","heading":"4.1 mutate(): Create Variables","text":"Sometimes, want create new variable ’s data set, oftentimes using if_else(), case_when(), basic algebraic operations one columns already present data set.R understands following symbols:+ addition, - subtraction* multiplication, / division^ raising something power (3 ^ 2 equal 9)R also order operations usual: parentheses, exponents, multiplication division, addition subtraction.example, suppose want create variable slumajors_df total number students graduating major. can mutate():’s lot break code chunk: importantly, ’re seeing first many, many, many, many, many, many, many instances using %>% pipe! %>% operator approximately reads take slumajors_df “” mutate() .Piping really convenient, easy--read way build sequence commands. can read code :Take slumajors_df slumajors_df,Take slumajors_df slumajors_df,perform mutate() step create new variable called ntotal, nfemales plus nmales.perform mutate() step create new variable called ntotal, nfemales plus nmales.Since first time using mutate(), let’s also delve function . general, mutate() reads:mutate(name_of_new_variable = operations_on_old_variables).R just automatically assumes want operation every single row data set, often quite convenient!might also want create variable percentage students identifying female major:happened ntotal? still printout? ’s : created variable ntotal, didn’t actually save new data set anything. R makes prints new variable, doesn’t get saved data set. want save new data set, can use <- operator. , ’re saving new data set name old data set: slumajors_df. , ’re thing percfemale variable. won’t always want give new data set name old one: ’ll talk chapter exercises., can pipe many things together want , ’s probably easier just create variables one go. following chunk says “Take slumajors_df create new variable ntotal. new data set, create new variable called percfemale.” Finally, slumajors_df <- beginning says “save new data set data set name, slumajors_df.”","code":"\nslumajors_df %>% mutate(ntotal = nfemales + nmales)\n#> # A tibble: 27 x 4\n#>    Major                        nfemales nmales ntotal\n#>    <chr>                           <dbl>  <dbl>  <dbl>\n#>  1 Anthropology                       34     15     49\n#>  2 Art & Art History                  65     11     76\n#>  3 Biochemistry                       14     11     25\n#>  4 Biology                           162     67    229\n#>  5 Business in the Liberal Arts      135    251    386\n#>  6 Chemistry                          26     14     40\n#>  7 Computer Science                   21     47     68\n#>  8 Conservation Biology               38     20     58\n#>  9 Economics                         128    349    477\n#> 10 English                           131     54    185\n#> # … with 17 more rows\nslumajors_df %>%\n  mutate(percfemale = 100 * nfemales / (nfemales + nmales))\n#> # A tibble: 27 x 4\n#>    Major                        nfemales nmales percfemale\n#>    <chr>                           <dbl>  <dbl>      <dbl>\n#>  1 Anthropology                       34     15       69.4\n#>  2 Art & Art History                  65     11       85.5\n#>  3 Biochemistry                       14     11       56  \n#>  4 Biology                           162     67       70.7\n#>  5 Business in the Liberal Arts      135    251       35.0\n#>  6 Chemistry                          26     14       65  \n#>  7 Computer Science                   21     47       30.9\n#>  8 Conservation Biology               38     20       65.5\n#>  9 Economics                         128    349       26.8\n#> 10 English                           131     54       70.8\n#> # … with 17 more rows\nslumajors_df <- slumajors_df %>%\n  mutate(percfemale = 100 * nfemales / (nfemales + nmales))\nslumajors_df <- slumajors_df %>% mutate(ntotal = nfemales + nmales)\nslumajors_df <- slumajors_df %>%\n  mutate(ntotal = nfemales + nmales) %>%\n  mutate(percfemale = 100 * nfemales / (nfemales + nmales))"},{"path":"dplyr.html","id":"a-little-more-on-piping","chapter":" 4 Wrangling with dplyr","heading":"4.1.1 A Little More on Piping","text":"jumping straight using piping, want appreciation terrible life without . piping make whatever given %>% pipe first argument whatever function follows %>%. Sois equivalent toPiping really isn’t useful just something can done single %>%. , previous example without piping might look like:’s still bad aren’t many operations data set, ’s already much harder read. get examples using 5+ pipes.might also help use analogy thinking piping. Consider Ke$ha’s morning routine opening song Tik Tok. write morning routine terms piping,Kesha first wakes morning, Kesha woken grabs glasses, Kesha woken glasses brushes teeth, etc.","code":"\ndf %>% mutate(x = y + 4)\nmutate(df, x = y + 4)\nmutate(mutate(slumajors_df, ntotal = nfemales + nmales), percfemale = 100 * nfemales / (nfemales + nmales))\n#> # A tibble: 27 x 5\n#>    Major                   nfemales nmales percfemale ntotal\n#>    <chr>                      <dbl>  <dbl>      <dbl>  <dbl>\n#>  1 Anthropology                  34     15       69.4     49\n#>  2 Art & Art History             65     11       85.5     76\n#>  3 Biochemistry                  14     11       56       25\n#>  4 Biology                      162     67       70.7    229\n#>  5 Business in the Libera…      135    251       35.0    386\n#>  6 Chemistry                     26     14       65       40\n#>  7 Computer Science              21     47       30.9     68\n#>  8 Conservation Biology          38     20       65.5     58\n#>  9 Economics                    128    349       26.8    477\n#> 10 English                      131     54       70.8    185\n#> # … with 17 more rows\nkesha %>% wake_up(time = \"morning\", feels_like = \"P-Diddy\") %>%\n  grab(glasses) %>%\n  brush(teeth, item = \"jack\", unit = \"bottle\") %>% ...."},{"path":"dplyr.html","id":"if_else-and-case_when","chapter":" 4 Wrangling with dplyr","heading":"4.1.2 if_else() and case_when()","text":"Suppose want make new variable conditional another variable (one variable) data set. typically use mutate() coupled withif_else() new variable created one conditioncase_when() new variable created one conditionSuppose want create new variable tells us whether Major majority Women. , want new variable, morewomen \"Yes\" Major 50% women \"\" 50% less.mutate() statement reads: create new variable called morewomen equal \"Yes\" percfemale > 50 true equal \"\" perfemale > 0.5. first argument condition, second name new variable condition holds, third name variable condition hold.use conditions time every day life. example, New York quarantine order stating people coming 22 states July 2020 need quarantine. terms condition, read “traveling New York one 22 states, need quarantine 2 weeks. Else, , don’t need quarantine.” trick using conditions R getting used syntax code.can see set one condition, ’d need use different function (use nested if_else() statements, can nightmare read). one condition creating new variable, use case_when().example, looking output, see Biochemistry 56% female graduates. ’s “” 50/50 split, suppose want variable called large_majority “female” percent women 70 , “male” percent women 30 less, “none” percent female 30 70.case_when() function reads “percent female equal 70, assign new variable large_majority value ”female“, ’s less equal 30, assign 30 less 70, assign variable value ”none\" .\" & boolean operator: ’ll talk later don’t worry much now.Let’s save two new variables slumajors_df:","code":"\nslumajors_df %>% mutate(morewomen = if_else(percfemale > 50,\n                                            true = \"Yes\",\n                                            false = \"No\"))\n#> # A tibble: 27 x 6\n#>    Major         nfemales nmales percfemale ntotal morewomen\n#>    <chr>            <dbl>  <dbl>      <dbl>  <dbl> <chr>    \n#>  1 Anthropology        34     15       69.4     49 Yes      \n#>  2 Art & Art Hi…       65     11       85.5     76 Yes      \n#>  3 Biochemistry        14     11       56       25 Yes      \n#>  4 Biology            162     67       70.7    229 Yes      \n#>  5 Business in …      135    251       35.0    386 No       \n#>  6 Chemistry           26     14       65       40 Yes      \n#>  7 Computer Sci…       21     47       30.9     68 No       \n#>  8 Conservation…       38     20       65.5     58 Yes      \n#>  9 Economics          128    349       26.8    477 No       \n#> 10 English            131     54       70.8    185 Yes      \n#> # … with 17 more rows\nslumajors_df %>% mutate(large_majority =\n                          case_when(percfemale >= 70 ~ \"female\",\n                                    percfemale <= 30 ~ \"male\",\n                                    percfemale > 30 & percfemale < 70 ~ \"none\")) \n#> # A tibble: 27 x 6\n#>    Major    nfemales nmales percfemale ntotal large_majority\n#>    <chr>       <dbl>  <dbl>      <dbl>  <dbl> <chr>         \n#>  1 Anthrop…       34     15       69.4     49 none          \n#>  2 Art & A…       65     11       85.5     76 female        \n#>  3 Biochem…       14     11       56       25 none          \n#>  4 Biology       162     67       70.7    229 female        \n#>  5 Busines…      135    251       35.0    386 none          \n#>  6 Chemist…       26     14       65       40 none          \n#>  7 Compute…       21     47       30.9     68 none          \n#>  8 Conserv…       38     20       65.5     58 none          \n#>  9 Economi…      128    349       26.8    477 male          \n#> 10 English       131     54       70.8    185 female        \n#> # … with 17 more rows\nslumajors_df <- slumajors_df %>%\n  mutate(morewomen = if_else(percfemale > 50,\n                             true = \"Yes\",\n                             false = \"No\")) %>%\n  mutate(large_majority =\n           case_when(percfemale >= 70 ~ \"female\",\n                     percfemale <= 30 ~ \"male\",\n                     percfemale > 30 & percfemale < 70 ~ \"none\")) "},{"path":"dplyr.html","id":"exercise-3-1","chapter":" 4 Wrangling with dplyr","heading":"4.1.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 4.6.think ethical exclude non-binary genders analyses graphs slumajors data set? ?think ethical exclude non-binary genders analyses graphs slumajors data set? ?* Create new variable called major_size “large” total number majors 100 “small” total number majors less 100.* Create new variable called major_size “large” total number majors 100 “small” total number majors less 100.Create new variable called major_size2 “large total number majors 150 ,”medium\" total number majors 41 149, “small” total number majors 40 fewer.Create new variable called major_size2 “large total number majors 150 ,”medium\" total number majors 41 149, “small” total number majors 40 fewer.55% SLU students identify female. , definition morewomen variable, make sense use 55% cutoff 50%?55% SLU students identify female. , definition morewomen variable, make sense use 55% cutoff 50%?* Investigate happens case_when() give overlapping conditions give conditions don’t cover observations. overlapping conditions, create variable testcase \"Yes\" percfemale greater equal 40 \"\" percfemale greater 60 conditions don’t cover observations, create variable testcase2 \"Yes\" percefemale greater equal 55 \"\" percfemale less 35.* Investigate happens case_when() give overlapping conditions give conditions don’t cover observations. overlapping conditions, create variable testcase \"Yes\" percfemale greater equal 40 \"\" percfemale greater 60 conditions don’t cover observations, create variable testcase2 \"Yes\" percefemale greater equal 55 \"\" percfemale less 35.one two newly created variables mutate(), create plot investigates question interest might data.one two newly created variables mutate(), create plot investigates question interest might data.","code":""},{"path":"dplyr.html","id":"arrange-ordering-rows-select-choosing-columns-and-slice-and-filter-choosing-rows","chapter":" 4 Wrangling with dplyr","heading":"4.2 arrange() (Ordering Rows), select() (Choosing Columns), and slice() and filter() (Choosing Rows)","text":"arrange() used order rows data set according variable, select() used choose columns keep (get rid ) filter() used keep (get rid ) observations (rows).","code":""},{"path":"dplyr.html","id":"arrange-ordering-rows","chapter":" 4 Wrangling with dplyr","heading":"4.2.1 arrange(): Ordering Rows","text":"arrange() function allows us order rows data set using one variables. function straightforward. Suppose want order rows majors lowest percfemale first:major lowest percentage female graduates?see , default, arrange() orders rows low high. order high low majors highest percfemale first, use desc() around variable ordering :major highest percentage women graduates?","code":"\nslumajors_df %>% arrange(percfemale)\n#> # A tibble: 27 x 7\n#>    Major         nfemales nmales percfemale ntotal morewomen\n#>    <chr>            <dbl>  <dbl>      <dbl>  <dbl> <chr>    \n#>  1 Economics          128    349       26.8    477 No       \n#>  2 Physics              6     14       30       20 No       \n#>  3 Computer Sci…       21     47       30.9     68 No       \n#>  4 Business in …      135    251       35.0    386 No       \n#>  5 Music               13     21       38.2     34 No       \n#>  6 Geology             28     41       40.6     69 No       \n#>  7 History             62     82       43.1    144 No       \n#>  8 Philosophy          24     29       45.3     53 No       \n#>  9 Mathematics         74     83       47.1    157 No       \n#> 10 Government         127    116       52.3    243 Yes      \n#> # … with 17 more rows, and 1 more variable:\n#> #   large_majority <chr>\nslumajors_df %>% arrange(desc(percfemale))\n#> # A tibble: 27 x 7\n#>    Major         nfemales nmales percfemale ntotal morewomen\n#>    <chr>            <dbl>  <dbl>      <dbl>  <dbl> <chr>    \n#>  1 Art & Art Hi…       65     11       85.5     76 Yes      \n#>  2 Psychology         278     61       82.0    339 Yes      \n#>  3 French              27      7       79.4     34 Yes      \n#>  4 Spanish             35     10       77.8     45 Yes      \n#>  5 Statistics          28      9       75.7     37 Yes      \n#>  6 Global Studi…       69     27       71.9     96 Yes      \n#>  7 Neuroscience        61     24       71.8     85 Yes      \n#>  8 Performance …      144     57       71.6    201 Yes      \n#>  9 Religious St…       10      4       71.4     14 Yes      \n#> 10 English            131     54       70.8    185 Yes      \n#> # … with 17 more rows, and 1 more variable:\n#> #   large_majority <chr>"},{"path":"dplyr.html","id":"select-choose-columns","chapter":" 4 Wrangling with dplyr","heading":"4.2.2 select() Choose Columns","text":"might also interested getting rid columns data set. One reason overwhelming (30+) columns data set, know just need . easiest way use select() just input names columns want keep. example, interested majors totals, doIf wanted use data set anything else, ’d also need name, rename, <-. probably want name something slumajors_df overwrite original data set, case want use variables later!might also want use select() get rid one two columns. case, denote column want get rid -. example, might want get rid ntotal column made get rid nmales nfemales columns:select() comes many useful helper functions, oftentimes needed. One helper functions actually often useful everything(). can, example, use using mutate() put variable just created front data set make sure weren’t unexpected issues:Verify propfemale now appears first data set. everything() tacks remaining variables propfemale. , case, ’s useful way re-order columns might interested appears first.","code":"\nslumajors_df %>% select(Major, ntotal)\n#> # A tibble: 27 x 2\n#>    Major                        ntotal\n#>    <chr>                         <dbl>\n#>  1 Anthropology                     49\n#>  2 Art & Art History                76\n#>  3 Biochemistry                     25\n#>  4 Biology                         229\n#>  5 Business in the Liberal Arts    386\n#>  6 Chemistry                        40\n#>  7 Computer Science                 68\n#>  8 Conservation Biology             58\n#>  9 Economics                       477\n#> 10 English                         185\n#> # … with 17 more rows\nslumajors_df %>% select(-ntotal, -nfemales, -nmales)\n#> # A tibble: 27 x 4\n#>    Major                 percfemale morewomen large_majority\n#>    <chr>                      <dbl> <chr>     <chr>         \n#>  1 Anthropology                69.4 Yes       none          \n#>  2 Art & Art History           85.5 Yes       female        \n#>  3 Biochemistry                56   Yes       none          \n#>  4 Biology                     70.7 Yes       female        \n#>  5 Business in the Libe…       35.0 No        none          \n#>  6 Chemistry                   65   Yes       none          \n#>  7 Computer Science            30.9 No        none          \n#>  8 Conservation Biology        65.5 Yes       none          \n#>  9 Economics                   26.8 No        male          \n#> 10 English                     70.8 Yes       female        \n#> # … with 17 more rows\nslumajors_df %>% mutate(propfemale = percfemale / 100) %>%\n  select(propfemale, everything())\n#> # A tibble: 27 x 8\n#>    propfemale Major        nfemales nmales percfemale ntotal\n#>         <dbl> <chr>           <dbl>  <dbl>      <dbl>  <dbl>\n#>  1      0.694 Anthropology       34     15       69.4     49\n#>  2      0.855 Art & Art H…       65     11       85.5     76\n#>  3      0.56  Biochemistry       14     11       56       25\n#>  4      0.707 Biology           162     67       70.7    229\n#>  5      0.350 Business in…      135    251       35.0    386\n#>  6      0.65  Chemistry          26     14       65       40\n#>  7      0.309 Computer Sc…       21     47       30.9     68\n#>  8      0.655 Conservatio…       38     20       65.5     58\n#>  9      0.268 Economics         128    349       26.8    477\n#> 10      0.708 English           131     54       70.8    185\n#> # … with 17 more rows, and 2 more variables:\n#> #   morewomen <chr>, large_majority <chr>"},{"path":"dplyr.html","id":"slice-and-filter-choose-rows","chapter":" 4 Wrangling with dplyr","heading":"4.2.3 slice() and filter(): Choose Rows","text":"Instead choosing columns keep, can also choose certain rows keep using either slice() filter().slice() allows specify row numbers corresponding rows want keep. example, suppose want keep rows five popular majors:can alternatively use slice(1:5), shorthand slice(1, 2, 3, 4, 5). slice() useful, relatively simple. ’ll come back weeks well discuss subsetting base R.filter() way keep rows specifying condition related one variables data set. ’ve already seen conditions if_else() case_when() statements, ’ll now used “filter” rows data set.can keep rows based categorical variable quantitative variable combination number categorical quantitative variables. R uses following symbols make comparisons. ’ve already using intuitive symbols (like < >):< <= less less equal , respectively> >= greater greater equal , respectively== equal (careful: equal double equal sign ==)!= equal (general, ! denotes “”)’s probably time change data set ! ’ll working babynames data set rest chapter:needed, can remind babynames data set typing ?babynames console window.following statements ? See can guess running code.things put quotes, like \"Matthew\" things aren’t, like 2000? Can make pattern?can also combine conditions multiple variables filter() using Boolean operators. ’ve already seen one case_when() statement : & means “.”Look Venn diagrams R Data Science learn various Boolean operators can use R: https://r4ds..co.nz/transform.html#logical-operators. Boolean operators can used functions R well, ’ve already seen if_else() case_when().following gives examples. See can figure line code running .","code":"\nslumajors_df %>% arrange(desc(ntotal)) %>%\n  slice(1, 2, 3, 4, 5)\n#> # A tibble: 5 x 7\n#>   Major          nfemales nmales percfemale ntotal morewomen\n#>   <chr>             <dbl>  <dbl>      <dbl>  <dbl> <chr>    \n#> 1 Economics           128    349       26.8    477 No       \n#> 2 Business in t…      135    251       35.0    386 No       \n#> 3 Psychology          278     61       82.0    339 Yes      \n#> 4 Government          127    116       52.3    243 Yes      \n#> 5 Biology             162     67       70.7    229 Yes      \n#> # … with 1 more variable: large_majority <chr>\nlibrary(babynames)\nbabynames\n#> # A tibble: 1,924,665 x 5\n#>     year sex   name          n   prop\n#>    <dbl> <chr> <chr>     <int>  <dbl>\n#>  1  1880 F     Mary       7065 0.0724\n#>  2  1880 F     Anna       2604 0.0267\n#>  3  1880 F     Emma       2003 0.0205\n#>  4  1880 F     Elizabeth  1939 0.0199\n#>  5  1880 F     Minnie     1746 0.0179\n#>  6  1880 F     Margaret   1578 0.0162\n#>  7  1880 F     Ida        1472 0.0151\n#>  8  1880 F     Alice      1414 0.0145\n#>  9  1880 F     Bertha     1320 0.0135\n#> 10  1880 F     Sarah      1288 0.0132\n#> # … with 1,924,655 more rows\nbabynames %>% filter(name == \"Matthew\")\nbabynames %>% filter(year >= 2000)\nbabynames %>% filter(sex != \"M\")\nbabynames %>% filter(prop > 0.05)\nbabynames %>% filter(year == max(year))\nbabynames %>% filter(n > 20000 | prop > 0.05)\nbabynames %>% filter(sex == \"F\" & name == \"Mary\")\nbabynames %>% filter(sex == \"F\" & name == \"Mary\" & prop > 0.05)"},{"path":"dplyr.html","id":"exercise-3-2","chapter":" 4 Wrangling with dplyr","heading":"4.2.4 Exercises","text":"Exercises marked * indicate exercise solution end chapter 4.6.happens arrange() one categorical variables slumajors_df data set?happens arrange() one categorical variables slumajors_df data set?* Use select() everything() put large_majority variable first column slumajors_df data set.* Use select() everything() put large_majority variable first column slumajors_df data set.* babynames data set, use filter(), mutate() rank(), arrange() print 10 popular Male babynames 2017.* babynames data set, use filter(), mutate() rank(), arrange() print 10 popular Male babynames 2017.babynames data set, use filter() keep rows name (, another name interests ) one sex (either \"M\" \"F\"). Name new data set something construct line plot looks either n prop chosen name year.babynames data set, use filter() keep rows name (, another name interests ) one sex (either \"M\" \"F\"). Name new data set something construct line plot looks either n prop chosen name year.","code":""},{"path":"dplyr.html","id":"summarise-and-group_by-create-summaries","chapter":" 4 Wrangling with dplyr","heading":"4.3 summarise() and group_by(): Create Summaries","text":"summarise() function useful get summaries data. example, suppose want know average major size SLU across five year span total number majors across five years. can use summarise() summary function, like mean(), sum(), median(), max(), min(), n(), etc. ’ll notice format summarise() extremely similar format mutate(). Using slumajors_df data just one quick example,","code":"\nslumajors_df %>%\n  summarise(meantotalmajor = mean(ntotal),\n            totalgrad = sum(ntotal))\n#> # A tibble: 1 x 2\n#>   meantotalmajor totalgrad\n#>            <dbl>     <dbl>\n#> 1           124.      3347"},{"path":"dplyr.html","id":"group_by-groups","chapter":" 4 Wrangling with dplyr","heading":"4.3.1 group_by(): Groups","text":"summarise() often useful paired group_by() statement. allows us get summaries across different groups.example, suppose wanted total number registered births per year babynames data set:group_by() takes grouping variable, , using summarise() computes given summary function group.summary functions intuitive ’ve intro stat. , ’re sure whether summary getting maximum maximum() max(), just try !n() function can used within summarise() obtain number observations. give total number rows, used without group_by()Note n() typically doesn’t inputs. ’s typically useful paired group_by(): allows us see number observations within year, instance:","code":"\nbabynames %>% group_by(year) %>%\n  summarise(totalbirths = sum(n))\n#> # A tibble: 138 x 2\n#>     year totalbirths\n#>    <dbl>       <int>\n#>  1  1880      201484\n#>  2  1881      192696\n#>  3  1882      221533\n#>  4  1883      216946\n#>  5  1884      243462\n#>  6  1885      240854\n#>  7  1886      255317\n#>  8  1887      247394\n#>  9  1888      299473\n#> 10  1889      288946\n#> # … with 128 more rows\nbabynames %>% summarise(totalobs = n())\n#> # A tibble: 1 x 1\n#>   totalobs\n#>      <int>\n#> 1  1924665\nbabynames %>% group_by(year) %>%\n  summarise(ngroup = n())\n#> # A tibble: 138 x 2\n#>     year ngroup\n#>    <dbl>  <int>\n#>  1  1880   2000\n#>  2  1881   1935\n#>  3  1882   2127\n#>  4  1883   2084\n#>  5  1884   2297\n#>  6  1885   2294\n#>  7  1886   2392\n#>  8  1887   2373\n#>  9  1888   2651\n#> 10  1889   2590\n#> # … with 128 more rows"},{"path":"dplyr.html","id":"exercise-3-3","chapter":" 4 Wrangling with dplyr","heading":"4.3.2 Exercises","text":"Exercises marked * indicate exercise solution end chapter 4.6.Compare summarise() mutate() using following code. ’s difference two functions?Using data set group_by() n() combination,make line plot ngroup x-axis year y-axis. interpret plot?* Create data set column name column shows total number births name across years sexes.* Create data set column name column shows total number births name across years sexes.* group_by() can also used functions, including mutate(). Use group_by() mutate() rank names least popular year-sex combination.* group_by() can also used functions, including mutate(). Use group_by() mutate() rank names least popular year-sex combination.* data set 4, filter() data keep popular name year-sex combination construct summary table showing many times name appears popular name.* data set 4, filter() data keep popular name year-sex combination construct summary table showing many times name appears popular name.* Run following code. Intuitively, slice(1, 2, 3, 4, 5) grab first five rows data set, , try run , get 1380 rows. Try figure issue using Google search something like “dplyr slicing correctly using group .” find?* Run following code. Intuitively, slice(1, 2, 3, 4, 5) grab first five rows data set, , try run , get 1380 rows. Try figure issue using Google search something like “dplyr slicing correctly using group .” find?","code":"\nslumajors_df %>%\n  summarise(meantotalmajor = mean(ntotal),\n            totalgrad = sum(ntotal)) \nslumajors_df %>%\n  mutate(meantotalmajor = mean(ntotal),\n            totalgrad = sum(ntotal)) %>%\n  select(meantotalmajor, totalgrad, everything())\nbabynames %>% group_by(year) %>%\n  summarise(ngroup = n())\n#> # A tibble: 138 x 2\n#>     year ngroup\n#>    <dbl>  <int>\n#>  1  1880   2000\n#>  2  1881   1935\n#>  3  1882   2127\n#>  4  1883   2084\n#>  5  1884   2297\n#>  6  1885   2294\n#>  7  1886   2392\n#>  8  1887   2373\n#>  9  1888   2651\n#> 10  1889   2590\n#> # … with 128 more rows\nbabynames_test <- babynames %>%\n  group_by(year, sex) %>% mutate(ntest = n / prop)\nbabynames_test %>% slice(1, 2, 3, 4, 5)\n#> # A tibble: 1,380 x 6\n#> # Groups:   year, sex [276]\n#>     year sex   name          n   prop   ntest\n#>    <dbl> <chr> <chr>     <int>  <dbl>   <dbl>\n#>  1  1880 F     Mary       7065 0.0724  97605.\n#>  2  1880 F     Anna       2604 0.0267  97605.\n#>  3  1880 F     Emma       2003 0.0205  97605.\n#>  4  1880 F     Elizabeth  1939 0.0199  97605.\n#>  5  1880 F     Minnie     1746 0.0179  97605.\n#>  6  1880 M     John       9655 0.0815 118400.\n#>  7  1880 M     William    9532 0.0805 118400.\n#>  8  1880 M     James      5927 0.0501 118400.\n#>  9  1880 M     Charles    5348 0.0452 118400.\n#> 10  1880 M     George     5126 0.0433 118400.\n#> # … with 1,370 more rows"},{"path":"dplyr.html","id":"missing-values","chapter":" 4 Wrangling with dplyr","heading":"4.4 Missing Values","text":"data sets ’ve worked nice missing values. ’ll see plenty examples data sets missing values later, examine various functions ’ve talked far tackle missing values.Missing values R denoted NA “Available.” Run following code create toy data set missing values can see various functions ’ve used far deal NA values.","code":"\ntoy_df <- tibble(x = c(NA, 3, 4, 7),\n                 y = c(1, 4, 3, 2),\n                 z = c(\"A\", \"A\", \"B\", NA))\ntoy_df\n#> # A tibble: 4 x 3\n#>       x     y z    \n#>   <dbl> <dbl> <chr>\n#> 1    NA     1 A    \n#> 2     3     4 A    \n#> 3     4     3 B    \n#> 4     7     2 <NA>"},{"path":"dplyr.html","id":"exercise-3-4","chapter":" 4 Wrangling with dplyr","heading":"4.4.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 4.6.* mutate(). Try create new variable mutate() involving x. R missing value?* mutate(). Try create new variable mutate() involving x. R missing value?arrange(). Try arranging data set x. R missing value?arrange(). Try arranging data set x. R missing value?filter(). Try filtering observations x less 5 kept. R missing value?filter(). Try filtering observations x less 5 kept. R missing value?summarise(). Try using summarise() function involving x. R return?summarise(). Try using summarise() function involving x. R return?group_by() summarise(). statement 4, add group_by(z) statement summarise(). R return now?group_by() summarise(). statement 4, add group_by(z) statement summarise(). R return now?","code":""},{"path":"dplyr.html","id":"removing-missing-values","chapter":" 4 Wrangling with dplyr","heading":"4.4.2 Removing Missing Values","text":"Missing values removed without carefully examination note consequences might (e.g. values missing?). toy data set meaningless, aren’t asking questions now, data set missing values!investigated missing values comfortable removing , many functions use summarise() na.rm argument can set TRUE tell summarise() remove NAs taking mean(), median(), max(), etc.want remove missing values directly, can use .na() function combination filter(). variable NA (Available) observation, .na() evaluates TRUE; , .na() evaluates FALSE. Test using mutate() create new variable whether Median missing:missingx TRUE first observation. can use advantage filter() filter data set, without going extra step actually making new variable missingx:’ll commonly see written short-hand people’s code may come across :says “keep anything missing x value” (recall ! means “”).","code":"\ntoy_df %>% summarise(meanx = mean(x, na.rm = TRUE))\n#> # A tibble: 1 x 1\n#>   meanx\n#>   <dbl>\n#> 1  4.67\ntoy_df %>% mutate(missingx = is.na(x))\n#> # A tibble: 4 x 4\n#>       x     y z     missingx\n#>   <dbl> <dbl> <chr> <lgl>   \n#> 1    NA     1 A     TRUE    \n#> 2     3     4 A     FALSE   \n#> 3     4     3 B     FALSE   \n#> 4     7     2 <NA>  FALSE\ntoy_df %>% filter(is.na(x) != TRUE)\n#> # A tibble: 3 x 3\n#>       x     y z    \n#>   <dbl> <dbl> <chr>\n#> 1     3     4 A    \n#> 2     4     3 B    \n#> 3     7     2 <NA>\ntoy_df %>% filter(!is.na(x))\n#> # A tibble: 3 x 3\n#>       x     y z    \n#>   <dbl> <dbl> <chr>\n#> 1     3     4 A    \n#> 2     4     3 B    \n#> 3     7     2 <NA>"},{"path":"dplyr.html","id":"chapexercise-3","chapter":" 4 Wrangling with dplyr","heading":"4.5 Chapter Exercises","text":"found SLU majors data set FiveThirtyEight majors data set Statistics higher proportion women almost STEM fields. Read first two sections article. Write 2-3 sentences article’s reasoning women statistics STEM fields.found SLU majors data set FiveThirtyEight majors data set Statistics higher proportion women almost STEM fields. Read first two sections article. Write 2-3 sentences article’s reasoning women statistics STEM fields.* . Choose 5 names interest create new data set data 5 names.* . Choose 5 names interest create new data set data 5 names.Use group_by() summarise() add together number Females Males name year. Hint: can group_by() one variable!Use group_by() summarise() add together number Females Males name year. Hint: can group_by() one variable!Make line plot showing popularity 5 names time.Make line plot showing popularity 5 names time.Choose year sex interests filter data set contain observations year sex.\nChoose year sex interests filter data set contain observations year sex.Create new variable ranks names popular least popular.Create new variable ranks names popular least popular.Create bar plot shows 10 popular names well count name.Create bar plot shows 10 popular names well count name.* cases throughout chapter, ’ve renamed data sets using <- name likeIn cases, ’ve given data set new name, likeFor functions generally “safe” name data set using name using function. ?mutate()mutate()arrange()arrange()filter()filter()summarise()summarise()select()select()Pose question babynames data set answer question either graphic data summary.","code":"\ntoy_df <- toy_df %>% mutate(newvar = x / y)\ntoy_small <- toy_df %>% filter(!is.na(x))"},{"path":"dplyr.html","id":"solutions-3","chapter":" 4 Wrangling with dplyr","heading":"4.6 Exercise Solutions","text":"","code":""},{"path":"dplyr.html","id":"mutate-s","chapter":" 4 Wrangling with dplyr","heading":"4.6.1 mutate() S","text":"* Create new variable called major_size “large” total number majors 100 “small” total number majors less 100.* Investigate happens case_when() give overlapping conditions give conditions don’t cover observations. overlapping conditions, create variable testcase \"Yes\" percfemale greater equal 40 \"\" percfemale greater 60 conditions don’t cover observations, create variable testcase2 \"Yes\" percefemale greater equal 55 \"\" percfemale less 35.overlapping cases, case_when prioritizes first case given.non-coverage, observation covered given NA.","code":"\nslumajors_df %>% mutate(major_size = if_else(ntotal >= 100,\n                                             true = \"large\",\n                                             false = \"small\"))\n#> # A tibble: 27 x 8\n#>    Major         nfemales nmales percfemale ntotal morewomen\n#>    <chr>            <dbl>  <dbl>      <dbl>  <dbl> <chr>    \n#>  1 Anthropology        34     15       69.4     49 Yes      \n#>  2 Art & Art Hi…       65     11       85.5     76 Yes      \n#>  3 Biochemistry        14     11       56       25 Yes      \n#>  4 Biology            162     67       70.7    229 Yes      \n#>  5 Business in …      135    251       35.0    386 No       \n#>  6 Chemistry           26     14       65       40 Yes      \n#>  7 Computer Sci…       21     47       30.9     68 No       \n#>  8 Conservation…       38     20       65.5     58 Yes      \n#>  9 Economics          128    349       26.8    477 No       \n#> 10 English            131     54       70.8    185 Yes      \n#> # … with 17 more rows, and 2 more variables:\n#> #   large_majority <chr>, major_size <chr>\n## OR\nslumajors_df %>%\n  mutate(major_size = case_when(ntotal >= 100 ~ \"large\",\n                                ntotal < 100 ~ \"small\"))\n#> # A tibble: 27 x 8\n#>    Major         nfemales nmales percfemale ntotal morewomen\n#>    <chr>            <dbl>  <dbl>      <dbl>  <dbl> <chr>    \n#>  1 Anthropology        34     15       69.4     49 Yes      \n#>  2 Art & Art Hi…       65     11       85.5     76 Yes      \n#>  3 Biochemistry        14     11       56       25 Yes      \n#>  4 Biology            162     67       70.7    229 Yes      \n#>  5 Business in …      135    251       35.0    386 No       \n#>  6 Chemistry           26     14       65       40 Yes      \n#>  7 Computer Sci…       21     47       30.9     68 No       \n#>  8 Conservation…       38     20       65.5     58 Yes      \n#>  9 Economics          128    349       26.8    477 No       \n#> 10 English            131     54       70.8    185 Yes      \n#> # … with 17 more rows, and 2 more variables:\n#> #   large_majority <chr>, major_size <chr>#> # A tibble: 27 x 9\n#>    Major         nfemales nmales percfemale ntotal morewomen\n#>    <chr>            <dbl>  <dbl>      <dbl>  <dbl> <chr>    \n#>  1 Anthropology        34     15       69.4     49 Yes      \n#>  2 Art & Art Hi…       65     11       85.5     76 Yes      \n#>  3 Biochemistry        14     11       56       25 Yes      \n#>  4 Biology            162     67       70.7    229 Yes      \n#>  5 Business in …      135    251       35.0    386 No       \n#>  6 Chemistry           26     14       65       40 Yes      \n#>  7 Computer Sci…       21     47       30.9     68 No       \n#>  8 Conservation…       38     20       65.5     58 Yes      \n#>  9 Economics          128    349       26.8    477 No       \n#> 10 English            131     54       70.8    185 Yes      \n#> # … with 17 more rows, and 3 more variables:\n#> #   large_majority <chr>, testcase <chr>, testcase2 <chr>"},{"path":"dplyr.html","id":"arrange-select-.-s","chapter":" 4 Wrangling with dplyr","heading":"4.6.2 arrange(), select(), …. S","text":"* Use select() everything() put large_majority variable first column slumajors_df data set.* babynames data set, use filter(), mutate() rank(), arrange() print 10 popular Male babynames 2017.","code":"\nslumajors_df %>% select(large_majority, everything())\n#> # A tibble: 27 x 7\n#>    large_majority Major    nfemales nmales percfemale ntotal\n#>    <chr>          <chr>       <dbl>  <dbl>      <dbl>  <dbl>\n#>  1 none           Anthrop…       34     15       69.4     49\n#>  2 female         Art & A…       65     11       85.5     76\n#>  3 none           Biochem…       14     11       56       25\n#>  4 female         Biology       162     67       70.7    229\n#>  5 none           Busines…      135    251       35.0    386\n#>  6 none           Chemist…       26     14       65       40\n#>  7 none           Compute…       21     47       30.9     68\n#>  8 none           Conserv…       38     20       65.5     58\n#>  9 male           Economi…      128    349       26.8    477\n#> 10 female         English       131     54       70.8    185\n#> # … with 17 more rows, and 1 more variable: morewomen <chr>\nbabynames %>% filter(sex == \"M\" & year == 2017) %>%\n  mutate(rankname = rank(desc(n))) %>%\n  filter(rankname <= 10)\n#> # A tibble: 10 x 6\n#>     year sex   name         n    prop rankname\n#>    <dbl> <chr> <chr>    <int>   <dbl>    <dbl>\n#>  1  2017 M     Liam     18728 0.00954        1\n#>  2  2017 M     Noah     18326 0.00933        2\n#>  3  2017 M     William  14904 0.00759        3\n#>  4  2017 M     James    14232 0.00725        4\n#>  5  2017 M     Logan    13974 0.00712        5\n#>  6  2017 M     Benjamin 13733 0.00699        6\n#>  7  2017 M     Mason    13502 0.00688        7\n#>  8  2017 M     Elijah   13268 0.00676        8\n#>  9  2017 M     Oliver   13141 0.00669        9\n#> 10  2017 M     Jacob    13106 0.00668       10"},{"path":"dplyr.html","id":"summarise-and-group_by-s","chapter":" 4 Wrangling with dplyr","heading":"4.6.3 summarise() and group_by() S","text":"* Create data set column name column shows total number births name across years sexes.* group_by() can also used functions, including mutate(). Use group_by() mutate() rank names least popular year-sex combination.* data set 4, filter() data keep popular name year-sex combination construct summary table showing many times name appears popular name.* Run following code. Intuitively, slice(1, 2, 3, 4, 5) grab first five rows data set, , try run , get 1380 rows. Try figure issue using Google search something like “dplyr slicing correctly using group .” find?Functions like slice() rank() operate defined groups data set using function like group_by() first. Sometimes feature quite convenient. , longer want slice() rank() functions account groups, need add ungroup() pipe, simply drops groups formed:","code":"\nbabynames %>% group_by(name) %>%\n  summarise(totalbirths = sum(n))\n#> # A tibble: 97,310 x 2\n#>    name      totalbirths\n#>    <chr>           <int>\n#>  1 Aaban             107\n#>  2 Aabha              35\n#>  3 Aabid              10\n#>  4 Aabir               5\n#>  5 Aabriella          32\n#>  6 Aada                5\n#>  7 Aadam             254\n#>  8 Aadan             130\n#>  9 Aadarsh           199\n#> 10 Aaden            4658\n#> # … with 97,300 more rows\nranked_babynames <- babynames %>% group_by(year, sex) %>%\n  mutate(rankname = rank((desc(n))))\nranked_babynames %>% filter(rankname == 1) %>%\n  group_by(name) %>%\n  summarise(nappear = n()) %>%\n  arrange(desc(nappear))\n#> # A tibble: 18 x 2\n#>    name     nappear\n#>    <chr>      <int>\n#>  1 Mary          76\n#>  2 John          44\n#>  3 Michael       44\n#>  4 Robert        17\n#>  5 Jennifer      15\n#>  6 Jacob         14\n#>  7 James         13\n#>  8 Emily         12\n#>  9 Jessica        9\n#> 10 Lisa           8\n#> 11 Linda          6\n#> 12 Emma           5\n#> 13 Noah           4\n#> 14 Sophia         3\n#> 15 Ashley         2\n#> 16 Isabella       2\n#> 17 David          1\n#> 18 Liam           1\nbabynames_test <- babynames %>%\n  group_by(year, sex) %>% mutate(ntest = n / prop)\nbabynames_test %>% slice(1, 2, 3, 4, 5)\n#> # A tibble: 1,380 x 6\n#> # Groups:   year, sex [276]\n#>     year sex   name          n   prop   ntest\n#>    <dbl> <chr> <chr>     <int>  <dbl>   <dbl>\n#>  1  1880 F     Mary       7065 0.0724  97605.\n#>  2  1880 F     Anna       2604 0.0267  97605.\n#>  3  1880 F     Emma       2003 0.0205  97605.\n#>  4  1880 F     Elizabeth  1939 0.0199  97605.\n#>  5  1880 F     Minnie     1746 0.0179  97605.\n#>  6  1880 M     John       9655 0.0815 118400.\n#>  7  1880 M     William    9532 0.0805 118400.\n#>  8  1880 M     James      5927 0.0501 118400.\n#>  9  1880 M     Charles    5348 0.0452 118400.\n#> 10  1880 M     George     5126 0.0433 118400.\n#> # … with 1,370 more rows\nbabynames_test %>% ungroup() %>% slice(1:5)\n#> # A tibble: 5 x 6\n#>    year sex   name          n   prop  ntest\n#>   <dbl> <chr> <chr>     <int>  <dbl>  <dbl>\n#> 1  1880 F     Mary       7065 0.0724 97605.\n#> 2  1880 F     Anna       2604 0.0267 97605.\n#> 3  1880 F     Emma       2003 0.0205 97605.\n#> 4  1880 F     Elizabeth  1939 0.0199 97605.\n#> 5  1880 F     Minnie     1746 0.0179 97605."},{"path":"dplyr.html","id":"missing-values-s","chapter":" 4 Wrangling with dplyr","heading":"4.6.4 Missing Values S","text":"* mutate(). Try create new variable mutate() involving x. R missing value?R puts another NA place x times y observation missing x.","code":"\ntoy_df %>% mutate(xy = x * y)\n#> # A tibble: 4 x 5\n#>       x     y z     newvar    xy\n#>   <dbl> <dbl> <chr>  <dbl> <dbl>\n#> 1    NA     1 A      NA       NA\n#> 2     3     4 A       0.75    12\n#> 3     4     3 B       1.33    12\n#> 4     7     2 <NA>    3.5     14"},{"path":"dplyr.html","id":"chapexercise-3-S","chapter":" 4 Wrangling with dplyr","heading":"4.6.5 Chapter Exercises S","text":"* . Choose 5 names interest create new data set data 5 names.Use group_by() summarise() add together number Females Males name year. Hint: can group_by() one variable!Use group_by() summarise() add together number Females Males name year. Hint: can group_by() one variable!Make line plot showing popularity 5 names time.Make line plot showing popularity 5 names time.* cases throughout chapter, ’ve renamed data sets using <- name likeIn cases, ’ve given data set new name, likeFor functions generally “safe” name data set using name using function. ?mutate()Usually fine: mutating creates new variable, doesn’t change variables data set, things get messed new variable.arrange()Usually fine: ordering rows certain way won’t change plots doesn’t change underlying data.filter()Usually best practice. Naming data set name filter means permanently lose data filtered , unless re-read data set beginning.summarise()Usually best practice. , naming summarized data set original data means lose original data, unless re-read beginning. example,means now way access original data toy_df.select()can sometimes okay ’re sure variables removing won’t ever used.","code":"\nbaby5 <- babynames %>% filter(name == \"Matthew\" | name == \"Ivan\" |\n                                name == \"Jessica\" | name == \"Robin\" |\n                                name == \"Michael\")\nbaby5_tot <- baby5 %>% group_by(year, name) %>%\n  summarise(ntot = sum(n))\n#> `summarise()` has grouped output by 'year'. You can override using the `.groups` argument.\nggplot(data = baby5_tot, aes(x = year, y = ntot, colour = name)) +\n  geom_line()\ntoy_df <- toy_df %>% mutate(newvar = x / y)\ntoy_small <- toy_df %>% filter(!is.na(x))\ntoy_df <- toy_df %>% summarise(meanx = mean(x))\ntoy_df\n#> # A tibble: 1 x 1\n#>   meanx\n#>   <dbl>\n#> 1    NA"},{"path":"dplyr.html","id":"rcode-3","chapter":" 4 Wrangling with dplyr","heading":"4.7 Non-Exercise R Code","text":"","code":"\nlibrary(babynames)\nhead(babynames)\nlibrary(tidyverse)\nslumajors_df <- read_csv(\"data/SLU_Majors_15_19.csv\")\nslumajors_df\nslumajors_df %>% mutate(ntotal = nfemales + nmales)\nslumajors_df %>%\n  mutate(percfemale = 100 * nfemales / (nfemales + nmales))\nslumajors_df <- slumajors_df %>%\n  mutate(percfemale = 100 * nfemales / (nfemales + nmales))\nslumajors_df <- slumajors_df %>% mutate(ntotal = nfemales + nmales)\nslumajors_df <- slumajors_df %>%\n  mutate(ntotal = nfemales + nmales) %>%\n  mutate(percfemale = 100 * nfemales / (nfemales + nmales))\nmutate(mutate(slumajors_df, ntotal = nfemales + nmales), percfemale = 100 * nfemales / (nfemales + nmales))\nslumajors_df %>% mutate(morewomen = if_else(percfemale > 50,\n                                            true = \"Yes\",\n                                            false = \"No\"))\nslumajors_df %>% mutate(large_majority =\n                          case_when(percfemale >= 70 ~ \"female\",\n                                    percfemale <= 30 ~ \"male\",\n                                    percfemale > 30 & percfemale < 70 ~ \"none\")) \nslumajors_df <- slumajors_df %>%\n  mutate(morewomen = if_else(percfemale > 50,\n                             true = \"Yes\",\n                             false = \"No\")) %>%\n  mutate(large_majority =\n           case_when(percfemale >= 70 ~ \"female\",\n                     percfemale <= 30 ~ \"male\",\n                     percfemale > 30 & percfemale < 70 ~ \"none\")) \nslumajors_df %>% arrange(percfemale)\nslumajors_df %>% arrange(desc(percfemale))\nslumajors_df %>% select(Major, ntotal)\nslumajors_df %>% select(-ntotal, -nfemales, -nmales)\nslumajors_df %>% mutate(propfemale = percfemale / 100) %>%\n  select(propfemale, everything())\nslumajors_df %>% arrange(desc(ntotal)) %>%\n  slice(1, 2, 3, 4, 5)\nlibrary(babynames)\nbabynames\nbabynames %>% filter(name == \"Matthew\")\nbabynames %>% filter(year >= 2000)\nbabynames %>% filter(sex != \"M\")\nbabynames %>% filter(prop > 0.05)\nbabynames %>% filter(year == max(year))\nbabynames %>% filter(n > 20000 | prop > 0.05)\nbabynames %>% filter(sex == \"F\" & name == \"Mary\")\nbabynames %>% filter(sex == \"F\" & name == \"Mary\" & prop > 0.05)\nslumajors_df %>%\n  summarise(meantotalmajor = mean(ntotal),\n            totalgrad = sum(ntotal))\nbabynames %>% group_by(year) %>%\n  summarise(totalbirths = sum(n))\nbabynames %>% summarise(totalobs = n())\nbabynames %>% group_by(year) %>%\n  summarise(ngroup = n())\ntoy_df %>% summarise(meanx = mean(x, na.rm = TRUE))\ntoy_df %>% mutate(missingx = is.na(x))\ntoy_df %>% filter(is.na(x) != TRUE)\ntoy_df %>% filter(!is.na(x))"},{"path":"tidying-with-tidyr.html","id":"tidying-with-tidyr","chapter":" 5 Tidying with tidyr","heading":" 5 Tidying with tidyr","text":"Goals:describe means data set tidy.describe means data set tidy.use separate() unite() transform data set tidy form.use separate() unite() transform data set tidy form.use pivot_longer() pivot_wider() transform data set tidy form.use pivot_longer() pivot_wider() transform data set tidy form.combine tidyr functions dplyr ggplot2 functions form complete workflow.combine tidyr functions dplyr ggplot2 functions form complete workflow.Data: first use polling data set contains variables collected different polls July 2016 U.S. presidential election. data set scraped RealClear politics https://www.realclearpolitics.com/epolls/latest_polls/president/ Dr. Ramler. variables :Poll, name pollDate, date range poll conductedSample, contains sample size poll whether poll Likely Voters Registered VotersMoE, margin error poll (recall term IntroStat)Clinton (D), percentage people poll voting ClintonTrump (R), percentage people poll voting TrumpJohnson (L), percentage people poll voting JohnsonSteing (G), percentage people poll voting Stein","code":""},{"path":"tidying-with-tidyr.html","id":"what-is-tidy-data","chapter":" 5 Tidying with tidyr","heading":"5.1 What is Tidy Data?","text":"R usually (always) works best data tidy form. tidy data set characteristics. Note already quite familiar tidy data , point, data sets used class (probably data sets see STAT 113 data sets may seen STAT 213) tidy. definition tidy data taken R Data Science:every variable data set stored columnevery case data set stored roweach value variable stored one cellvalues data set contain unitsthere table headers footnotesWe begin focusing first characteristic: every variable data set stored column (correspondingly, number 3: value variable stored one cell).","code":""},{"path":"tidying-with-tidyr.html","id":"separate-and-unite-columns","chapter":" 5 Tidying with tidyr","heading":"5.2 separate() and unite() Columns","text":"fresh .Rmd file (File -> New File -> R Markdown) Notes project, copy paste following code R chunk:Suppose wanted know average sample size polls . Using dplyr functions,warning get? ?get similar warning (sometimes error) time want try use Sample size plotting summaries. issue Sample column actually contains two variables data set tidy.","code":"\nlibrary(tidyverse)\npolls <- read_csv(\"data/rcp-polls.csv\", na = \"--\")\npolls\n#> # A tibble: 7 x 8\n#>   Poll        Date    Sample   MoE `Clinton (D)` `Trump (R)`\n#>   <chr>       <chr>   <chr>  <dbl>         <dbl>       <dbl>\n#> 1 Monmouth    7/14 -… 688 LV   3.7            45          43\n#> 2 CNN/ORC     7/13 -… 872 RV   3.5            42          37\n#> 3 ABC News/W… 7/11 -… 816 RV   4              42          38\n#> 4 NBC News/W… 7/9 - … 1000 …   3.1            41          35\n#> 5 Economist/… 7/9 - … 932 RV   4.5            40          37\n#> 6 Associated… 7/7 - … 837 RV  NA              40          36\n#> 7 McClatchy/… 7/5 - … 1053 …   3              40          35\n#> # … with 2 more variables: Johnson (L) <dbl>,\n#> #   Stein (G) <dbl>\npolls %>% summarise(meansample = mean(Sample))"},{"path":"tidying-with-tidyr.html","id":"separate-a-column","chapter":" 5 Tidying with tidyr","heading":"5.2.1 separate() a Column","text":"Let’s separate() two variables Sample_size Sample_type:arguments separate() fairly easy learn:col name column data set want separate.col name column data set want separate.name new columns. anything want, entered vector (c() separate names)name new columns. anything want, entered vector (c() separate names)sep character want separate column . case, sample size sample type separated whitespace, sep = \" \", white space.sep character want separate column . case, sample size sample type separated whitespace, sep = \" \", white space.sep argument newest piece information . Note even using sep = \"\" produce error (space now, R doesn’t know separate ).Similarly, like Date column separated poll start date poll end date:use \" - \" separator instead \"-\"? Try using \"-\" aren’t sure: shouldn’t get error something look .happened Sample? back un-separated form?","code":"\npolls %>%\n  separate(col = Sample, into = c(\"Sample_size\", \"Sample_type\"), \n           sep = \" \")\n#> # A tibble: 7 x 9\n#>   Poll     Date  Sample_size Sample_type   MoE `Clinton (D)`\n#>   <chr>    <chr> <chr>       <chr>       <dbl>         <dbl>\n#> 1 Monmouth 7/14… 688         LV            3.7            45\n#> 2 CNN/ORC  7/13… 872         RV            3.5            42\n#> 3 ABC New… 7/11… 816         RV            4              42\n#> 4 NBC New… 7/9 … 1000        RV            3.1            41\n#> 5 Economi… 7/9 … 932         RV            4.5            40\n#> 6 Associa… 7/7 … 837         RV           NA              40\n#> 7 McClatc… 7/5 … 1053        RV            3              40\n#> # … with 3 more variables: Trump (R) <dbl>,\n#> #   Johnson (L) <dbl>, Stein (G) <dbl>\npolls %>%\n  separate(col = Sample, into = c(\"Sample_size\", \"Sample_type\"), \n           sep = \"\")\npolls_sep <- polls %>%\n  separate(col = Date, into = c(\"Start\", \"End\"),\n           sep = \" - \")"},{"path":"tidying-with-tidyr.html","id":"unite-columns","chapter":" 5 Tidying with tidyr","heading":"5.2.2 unite() Columns","text":"unite() “opposite” separate(): use one variable stored across multiple columns, row still represents single case. need use unite() less common separate(). current data set, need use . , sake seeing example, let’s separate Start date month day use unite() re-unite columns:situation occur practice: date variable multiple columns: one month one day (multiple years, third year). use unite() combine two columns single Date, called New_start_date:Note unite() just switches around first two arguments separate(). Argument 1 now name new column Argument 2 names columns data set want combine.also used c() function separate() unite(). c() general R function isn’t specific tidy data, first time ’re seeing course. c() officially stands concatenate, , simpler terms, c() combines two “things,” separated comma.useful function argument expects two “things”: example, separate(), argument requires two column names example. column names must specified combining names together c().","code":"\npolls_sillytest <- polls_sep %>%\n  separate(col = Start, into = c(\"Start_month\", \"Start_day\"), \n           sep = \"/\")\npolls_sillytest\n#> # A tibble: 7 x 10\n#>   Poll              Start_month Start_day End   Sample   MoE\n#>   <chr>             <chr>       <chr>     <chr> <chr>  <dbl>\n#> 1 Monmouth          7           14        7/16  688 LV   3.7\n#> 2 CNN/ORC           7           13        7/16  872 RV   3.5\n#> 3 ABC News/Wash Po… 7           11        7/14  816 RV   4  \n#> 4 NBC News/Wall St… 7           9         7/13  1000 …   3.1\n#> 5 Economist/YouGov  7           9         7/11  932 RV   4.5\n#> 6 Associated Press… 7           7         7/11  837 RV  NA  \n#> 7 McClatchy/Marist  7           5         7/9   1053 …   3  \n#> # … with 4 more variables: Clinton (D) <dbl>,\n#> #   Trump (R) <dbl>, Johnson (L) <dbl>, Stein (G) <dbl>\npolls_sillytest %>%\n  unite(\"New_start_date\", c(Start_month, Start_day),\n        sep = \"/\")\n#> # A tibble: 7 x 9\n#>   Poll       New_start_date End   Sample   MoE `Clinton (D)`\n#>   <chr>      <chr>          <chr> <chr>  <dbl>         <dbl>\n#> 1 Monmouth   7/14           7/16  688 LV   3.7            45\n#> 2 CNN/ORC    7/13           7/16  872 RV   3.5            42\n#> 3 ABC News/… 7/11           7/14  816 RV   4              42\n#> 4 NBC News/… 7/9            7/13  1000 …   3.1            41\n#> 5 Economist… 7/9            7/11  932 RV   4.5            40\n#> 6 Associate… 7/7            7/11  837 RV  NA              40\n#> 7 McClatchy… 7/5            7/9   1053 …   3              40\n#> # … with 3 more variables: Trump (R) <dbl>,\n#> #   Johnson (L) <dbl>, Stein (G) <dbl>\nc(1, 4, 2)\n#> [1] 1 4 2\nc(\"A\", \"A\", \"D\")\n#> [1] \"A\" \"A\" \"D\""},{"path":"tidying-with-tidyr.html","id":"column-names-and-rename","chapter":" 5 Tidying with tidyr","heading":"5.2.3 Column Names and rename()","text":"might noticed columns percentage votes Clinton, Trump, etc. surrounded backticks ` ` print polls polls_sep:happens column names space (also occur columns started number odd special characters ). , time want reference variable, need include backticks:variable names spaces doesn’t technically violate principle tidy data, can quite annoying. Always using backticks can huge pain. can rename variables easily rename(), just takes series new_name = old_name arguments.rename() can also useful variable names long type . rename() actually dplyr, tidyr, didn’t need dplyr data sets.","code":"\npolls_sep\n#> # A tibble: 7 x 9\n#>   Poll    Start End   Sample   MoE `Clinton (D)` `Trump (R)`\n#>   <chr>   <chr> <chr> <chr>  <dbl>         <dbl>       <dbl>\n#> 1 Monmou… 7/14  7/16  688 LV   3.7            45          43\n#> 2 CNN/ORC 7/13  7/16  872 RV   3.5            42          37\n#> 3 ABC Ne… 7/11  7/14  816 RV   4              42          38\n#> 4 NBC Ne… 7/9   7/13  1000 …   3.1            41          35\n#> 5 Econom… 7/9   7/11  932 RV   4.5            40          37\n#> 6 Associ… 7/7   7/11  837 RV  NA              40          36\n#> 7 McClat… 7/5   7/9   1053 …   3              40          35\n#> # … with 2 more variables: Johnson (L) <dbl>,\n#> #   Stein (G) <dbl>\npolls_sep %>%\n  summarise(meanclinton = mean(Clinton (D))) ## throws an error\npolls_sep %>%\n  summarise(meanclinton = mean(`Clinton (D)`)) ## backticks save the day!\npolls_new <- polls_sep %>%\n  rename(Clinton_D = `Clinton (D)`, Trump_R = `Trump (R)`,\n         Johnson_L = `Johnson (L)`, Stein_G = `Stein (G)`)\npolls_new\n#> # A tibble: 7 x 9\n#>   Poll  Start End   Sample   MoE Clinton_D Trump_R Johnson_L\n#>   <chr> <chr> <chr> <chr>  <dbl>     <dbl>   <dbl>     <dbl>\n#> 1 Monm… 7/14  7/16  688 LV   3.7        45      43         5\n#> 2 CNN/… 7/13  7/16  872 RV   3.5        42      37        13\n#> 3 ABC … 7/11  7/14  816 RV   4          42      38         8\n#> 4 NBC … 7/9   7/13  1000 …   3.1        41      35        11\n#> 5 Econ… 7/9   7/11  932 RV   4.5        40      37         5\n#> 6 Asso… 7/7   7/11  837 RV  NA          40      36         6\n#> 7 McCl… 7/5   7/9   1053 …   3          40      35        10\n#> # … with 1 more variable: Stein_G <dbl>"},{"path":"tidying-with-tidyr.html","id":"exercise-4-1","chapter":" 5 Tidying with tidyr","heading":"5.2.4 Exercises","text":"Exercises marked * indicate exercise solution end chapter 5.6.MLB salary data set contains salaries 862 players Major League Baseball 2016. data set obtained http://www.usatoday.com/sports/mlb/salaries/2016/player//Read data using following code chunk write sentence two explains data set tidy.* Tidy data set just thatDuration salary contract (currently given Year column) columnthe year range (also currently given Year column) split variable called Start variable called End year give start end years contract. can still special characters now (like ( )) start end year.received warning message. message mean? See can figure typing View(baseball_df) console window scrolling rows warning mentions: 48, 59, 60, etc.received warning message. message mean? See can figure typing View(baseball_df) console window scrolling rows warning mentions: 48, 59, 60, etc.won’t learn parse_number() readr, function straightforward enough mention . ’s useful extra characters values numeric variable (like $ (), just want grab actual number:won’t learn parse_number() readr, function straightforward enough mention . ’s useful extra characters values numeric variable (like $ (), just want grab actual number:Run code parsing saved baseball_df.* Using function dplyr. fix End variable created , example, first observation 2020 instead just 20.* Using function dplyr. fix End variable created , example, first observation 2020 instead just 20.* tidyr extremely useful, ’s glamorous. end data set ggplot2 dplyr can use cool things. , let’s something tidy data set make tidying little worth moving . Make graphic investigates player Salary compares different POS.* tidyr extremely useful, ’s glamorous. end data set ggplot2 dplyr can use cool things. , let’s something tidy data set make tidying little worth moving . Make graphic investigates player Salary compares different POS.* State reason making plot worked tidied data set.* State reason making plot worked tidied data set.","code":"\nlibrary(tidyverse)\nbaseball_df <- read_csv(\"data/mlb2016.csv\")\nhead(baseball_df)\n#> # A tibble: 6 x 7\n#>   Name    Team  POS   Salary   Years  Total.Value Avg.Annual\n#>   <chr>   <chr> <chr> <chr>    <chr>  <chr>       <chr>     \n#> 1 Clayto… LAD   SP    $ 33,00… 7 (20… $ 215,000,… $ 30,714,…\n#> 2 Zack G… ARI   SP    $ 31,79… 6 (20… $ 206,500,… $ 34,416,…\n#> 3 David … BOS   SP    $ 30,00… 7 (20… $ 217,000,… $ 31,000,…\n#> 4 Miguel… DET   1B    $ 28,00… 10 (2… $ 292,000,… $ 29,200,…\n#> 5 Justin… DET   SP    $ 28,00… 7 (20… $ 180,000,… $ 25,714,…\n#> 6 Yoenis… NYM   CF    $ 27,32… 3 (20… $ 75,000,0… $ 25,000,…\nbaseball_df <- baseball_df %>%\n  mutate(Salary = parse_number(Salary),\n         Total.Value = parse_number(Total.Value),\n         Avg.Annual = parse_number(Avg.Annual),\n         Start = parse_number(Start),\n         End = parse_number(End))"},{"path":"tidying-with-tidyr.html","id":"reshaping-with-pivot_","chapter":" 5 Tidying with tidyr","heading":"5.3 Reshaping with pivot_()","text":"continue use polling data set introduce pivoting functions data reshaping. make sure working data set, run following line code:data set polls_clean still isn’t tidy!! candidate variable spread 4 different columns values 4 columns actually represent 1 variable: poll percentage.Thinking data “tidyness” using definitions can sometimes little bit confusing. practice, oftentimes usually realize data set untidy go something super simple something turns super simple data current form.example, one thing might want make plot poll Start time x-axis, polling numbers y-axis, candidates represented different colours. small data set, might see trends time, imagine graph quite useful polling numbers June, July, August, September, etc.Take moment think make graph ggplot2: x-axis variable? variable specifying y-axis? colours?first attempt making graph :’re stuck. ’s certainly impossible make graph data current form (keep adding geom_point() re-specifying aesthetics, manually specify colours, manually specify legend), ’s definitely huge pain.pivot_longer() can help! https://www.youtube.com/watch?v=8w3wmQAMoxQ","code":"\npolls_clean <- polls %>%\n  separate(col = Sample, into = c(\"Sample_size\", \"Sample_type\"), \n           sep = \" \")  %>%\n  separate(col = Date, into = c(\"Start\", \"End\"),\n           sep = \" - \") %>% \n  rename(Clinton_D = `Clinton (D)`, Trump_R = `Trump (R)`,\n         Johnson_L = `Johnson (L)`, Stein_G = `Stein (G)`)\npolls_clean\n#> # A tibble: 7 x 10\n#>   Poll   Start End   Sample_size Sample_type   MoE Clinton_D\n#>   <chr>  <chr> <chr> <chr>       <chr>       <dbl>     <dbl>\n#> 1 Monmo… 7/14  7/16  688         LV            3.7        45\n#> 2 CNN/O… 7/13  7/16  872         RV            3.5        42\n#> 3 ABC N… 7/11  7/14  816         RV            4          42\n#> 4 NBC N… 7/9   7/13  1000        RV            3.1        41\n#> 5 Econo… 7/9   7/11  932         RV            4.5        40\n#> 6 Assoc… 7/7   7/11  837         RV           NA          40\n#> 7 McCla… 7/5   7/9   1053        RV            3          40\n#> # … with 3 more variables: Trump_R <dbl>, Johnson_L <dbl>,\n#> #   Stein_G <dbl>ggplot(data = polls_clean, aes(x = Start, y = Clinton_D)) + \n  geom_point(aes(colour = ....??????????))"},{"path":"tidying-with-tidyr.html","id":"pivot_longer-to-gather-columns","chapter":" 5 Tidying with tidyr","heading":"5.3.1 pivot_longer() to Gather Columns","text":"pivot_longer() “pivots” data set rows (hence “longer”) collapsing multiple columns two columns. One new column “key” column, new variable containing old data set’s column names. second new column “value” column, new variable containing old data set’s values old data set’s column names. ’s easier see example. know plotting exercise ’d really like candidate variable colour poll_percent variable y-axis plot. , can use pivot_longer() make two columns:pivot_longer() three important arguments:cols, names columns want PIVOT!names_to, name new variable old column names (anything want !)values_to, name new variable old column values (anything want !)happens omit names_to values_to arguments? Give try!Now can make plot using Week 1 ggplot functions. don’t forget give name new “long” data set first!","code":"\npolls_clean %>%\n  pivot_longer(cols = c(Clinton_D, Trump_R, Johnson_L, Stein_G),\n               names_to = \"candidate\", values_to = \"poll_percent\")\n#> # A tibble: 28 x 8\n#>    Poll  Start End   Sample_size Sample_type   MoE candidate\n#>    <chr> <chr> <chr> <chr>       <chr>       <dbl> <chr>    \n#>  1 Monm… 7/14  7/16  688         LV            3.7 Clinton_D\n#>  2 Monm… 7/14  7/16  688         LV            3.7 Trump_R  \n#>  3 Monm… 7/14  7/16  688         LV            3.7 Johnson_L\n#>  4 Monm… 7/14  7/16  688         LV            3.7 Stein_G  \n#>  5 CNN/… 7/13  7/16  872         RV            3.5 Clinton_D\n#>  6 CNN/… 7/13  7/16  872         RV            3.5 Trump_R  \n#>  7 CNN/… 7/13  7/16  872         RV            3.5 Johnson_L\n#>  8 CNN/… 7/13  7/16  872         RV            3.5 Stein_G  \n#>  9 ABC … 7/11  7/14  816         RV            4   Clinton_D\n#> 10 ABC … 7/11  7/14  816         RV            4   Trump_R  \n#> # … with 18 more rows, and 1 more variable:\n#> #   poll_percent <dbl>\npolls_long <- polls_clean %>%\n  pivot_longer(cols = c(Clinton_D, Trump_R, Johnson_L, Stein_G),\n               names_to = \"candidate\", values_to = \"poll_percent\")\n\n## ignore as.Date for now....we will get to dates later!\nggplot(data = polls_long,\n       aes(x = as.Date(Start, \"%m/%d\"), y = poll_percent,\n           colour = candidate)) +\n  geom_point() + xlab(\"Poll Start Date\")"},{"path":"tidying-with-tidyr.html","id":"pivot_wider-to-spread-to-multiple-columns","chapter":" 5 Tidying with tidyr","heading":"5.3.2 pivot_wider() to Spread to Multiple Columns","text":"“opposite” pivot_longer() pivot_wider(). need use pivot_wider() one case actually spread across multiple rows. , typically realize issue untidy data go something simple ’s .Let’s examine airline safety data fivethirtyeight used Travelers Avoid Flying Airlines Crashes Past? story: https://fivethirtyeight.com/features/-travelers-avoid-flying-airlines----crashes---past/\n. raw data can found .data set contains following columns:airline, name airlineavail_seat_km_per_week, available seat kilometers flown weekincidents 1985_1999, number incidents 1985 1999fatal_accidents 1985_1999, number fatal accidents 1985 1999fatalities 1985_1999, number fatalities 1985 1999incidents 2000_2014fatal_accidents 2000_2014fatalities 2000_2014There’s whole lot mess data set: really want variable year two values (1985-1999 2000-2014). Sometimes ’s tough know even start, one strategy draw sketch data frame ’d like end . example, think want data set following columns: airline, available seat km, years, incidents, fatal accidents, fatalities. , sketch might look something like:etc.Let’s start pivot_longer() see can get year variable (know year variable, want, make rows pivot_longer() seems like good place start):Instead giving pivot_longer() names variables, gave column numbers instead. c(3, 4, 5, 6, 7, 8) corresponds 3rd, 4th, …., 8th columns data set. didn’t quite give us year variable, excited see opportunity take advantage separate():format want data set ? Depending task, . , also might want accident types variable. , might want collapse data set variable incidents, variable fatal_accidents, variable fatalities. , want add columns data set, need use pivot_wider().pivot_wider() two main arguments:names_from, column old data set provide names new columns andnames_from, column old data set provide names new columns andvalues_from, column old data set provide values fill new columnsvalues_from, column old data set provide values fill new columnsWe see examples pivot_wider() pivot_longer() Exercises. Note tidy data isn’t necessarily always better: might find cases need “untidy” data using pivot_longer() pivot_wider(). However, functions R (languages) work best tidy data.","code":"\nairlines <- read_csv(\"data/airline-safety.csv\")\nhead(airlines)\n#> # A tibble: 6 x 8\n#>   airline avail_seat_km_p… `incidents 1985… `fatal_accident…\n#>   <chr>              <dbl>            <dbl>            <dbl>\n#> 1 Aer Li…        320906734                2                0\n#> 2 Aerofl…       1197672318               76               14\n#> 3 Aeroli…        385803648                6                0\n#> 4 Aerome…        596871813                3                1\n#> 5 Air Ca…       1865253802                2                0\n#> 6 Air Fr…       3004002661               14                4\n#> # … with 4 more variables: fatalities 1985_1999 <dbl>,\n#> #   incidents 2000_2014 <dbl>,\n#> #   fatal_accidents 2000_2014 <dbl>,\n#> #   fatalities 2000_2014 <dbl>\nairlines %>%\n  pivot_longer(c(3, 4, 5, 6, 7, 8), names_to = \"type_year\",\n  values_to = \"total_num\") \n#> # A tibble: 336 x 4\n#>    airline   avail_seat_km_per_… type_year         total_num\n#>    <chr>                   <dbl> <chr>                 <dbl>\n#>  1 Aer Ling…           320906734 incidents 1985_1…         2\n#>  2 Aer Ling…           320906734 fatal_accidents …         0\n#>  3 Aer Ling…           320906734 fatalities 1985_…         0\n#>  4 Aer Ling…           320906734 incidents 2000_2…         0\n#>  5 Aer Ling…           320906734 fatal_accidents …         0\n#>  6 Aer Ling…           320906734 fatalities 2000_…         0\n#>  7 Aeroflot*          1197672318 incidents 1985_1…        76\n#>  8 Aeroflot*          1197672318 fatal_accidents …        14\n#>  9 Aeroflot*          1197672318 fatalities 1985_…       128\n#> 10 Aeroflot*          1197672318 incidents 2000_2…         6\n#> # … with 326 more rows\nairlines %>% pivot_longer(c(3, 4, 5, 6, 7, 8), names_to = \"type_year\",\n                          values_to = \"total_num\") %>%\n  separate(type_year, into = c(\"type\", \"year\"), sep = \" \")\n#> # A tibble: 336 x 5\n#>    airline   avail_seat_km_per_… type       year   total_num\n#>    <chr>                   <dbl> <chr>      <chr>      <dbl>\n#>  1 Aer Ling…           320906734 incidents  1985_…         2\n#>  2 Aer Ling…           320906734 fatal_acc… 1985_…         0\n#>  3 Aer Ling…           320906734 fatalities 1985_…         0\n#>  4 Aer Ling…           320906734 incidents  2000_…         0\n#>  5 Aer Ling…           320906734 fatal_acc… 2000_…         0\n#>  6 Aer Ling…           320906734 fatalities 2000_…         0\n#>  7 Aeroflot*          1197672318 incidents  1985_…        76\n#>  8 Aeroflot*          1197672318 fatal_acc… 1985_…        14\n#>  9 Aeroflot*          1197672318 fatalities 1985_…       128\n#> 10 Aeroflot*          1197672318 incidents  2000_…         6\n#> # … with 326 more rows\n## name the long data set\nairlines_long <- airlines %>%\n  pivot_longer(c(3, 4, 5, 6, 7, 8), names_to = \"type_year\",\n               values_to = \"total_num\") %>%\n  separate(type_year, into = c(\"type\", \"year\"), sep = \" \")\n\n## use pivot_wider() to create variables for incidents, fatalities, and\n## fatal_accidents:\nairlines_long %>% pivot_wider(names_from = type,\n                              values_from = total_num)\n#> # A tibble: 112 x 6\n#>    airline  avail_seat_km_p… year  incidents fatal_accidents\n#>    <chr>               <dbl> <chr>     <dbl>           <dbl>\n#>  1 Aer Lin…        320906734 1985…         2               0\n#>  2 Aer Lin…        320906734 2000…         0               0\n#>  3 Aeroflo…       1197672318 1985…        76              14\n#>  4 Aeroflo…       1197672318 2000…         6               1\n#>  5 Aerolin…        385803648 1985…         6               0\n#>  6 Aerolin…        385803648 2000…         1               0\n#>  7 Aeromex…        596871813 1985…         3               1\n#>  8 Aeromex…        596871813 2000…         5               0\n#>  9 Air Can…       1865253802 1985…         2               0\n#> 10 Air Can…       1865253802 2000…         2               0\n#> # … with 102 more rows, and 1 more variable:\n#> #   fatalities <dbl>"},{"path":"tidying-with-tidyr.html","id":"exercise-4-2","chapter":" 5 Tidying with tidyr","heading":"5.3.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 5.6.handle data science terminology, ’s difficult transfer ’ve learned different language. example, students computer science might familiar Python. Google something like “pivot wide long python” find help achieving equivalent pivot_longer() Python.UBSprices2 data set contains information prices common commodities cities throughout world years 2003 2009. three commodities data set Rice (1 kg worth), Bread (1 kg worth), Big Mac https://media1.giphy.com/media/Fw5LicDKem6nC/source.gif* Convert data set tidier form year variable commodity variable 3 values: \"bigmac\", \"bread\", \"rice\"Hint: point, need separate commodity year , example, bread2009. , ’ll notice different uses separate() “-” \" \" “/” use separating character. Look help separate() scroll sep argument see can figure issue. first code chunk shows solution particular issue case get stuck part second code chunk shows entire solution.* Convert data set previous exercise commodity split 3 variables: bigmac price, rice price bread price.* Convert data set previous exercise commodity split 3 variables: bigmac price, rice price bread price.data set easiest make line plot year x-axis price rice y-axis lines city? data set easiest make line chart 3 lines, one type commodity, city Amsterdam?data set easiest make line plot year x-axis price rice y-axis lines city? data set easiest make line chart 3 lines, one type commodity, city Amsterdam?time, make plots!","code":"\nprices_df <- read_csv(\"data/UBSprices2.csv\")\nseparate(name_of_variable, into = c(\"newname1\", \"newname2\"), sep = -4)"},{"path":"tidying-with-tidyr.html","id":"skimming-data-with-skimr","chapter":" 5 Tidying with tidyr","heading":"5.4 Skimming Data with skimr","text":"’ve now talked plotting, wrangling, tidying data. first load data set, can helpful obtain quick summary variables data set. gives idea many observations missing, variables numeric character, basic distribution variable.helpful function skim() function skimr package. Load package library(skimr) obtain summaries data sets ’ve used far:Table 5.1: Data summaryVariable type: characterVariable type: numericFind output following:number rows data set number columnsthe number missing values variablethe number unique values character variablethe completion rate (proportion values non-missing).future, use skim() get brief summary data sets begin working .topics discuss tidying data. yet discussed 4th 5th characteristics tidy data (cells contain units headers footers), usually dealt read data. Therefore, issues covered discuss readr.","code":"\nlibrary(skimr)\nskim(airlines)"},{"path":"tidying-with-tidyr.html","id":"exercises-exercise-4-3","chapter":" 5 Tidying with tidyr","heading":"5.4.1 Exercises {exercise-4-3}","text":"Exercises marked * indicate exercise solution end chapter 5.6.under5mortality.csv file contains data mortality people age 5 countries around world (mortality deaths per 1000 people). data come https://www.gapminder.org/data/. data set extremely wide current form, column year data set. Read data set * Use skim() function skimr obtain preliminary information data set.* Use skim() function skimr obtain preliminary information data set.* Notice 217 columns (top print header, 217 second number). use tidyr, aren’t going want type c(2, 3, 4, 5, .....) way 217! R short-hand notation can use :. example, type 4:9 console window. Use notation tidy mortality_df data set.* Notice 217 columns (top print header, 217 second number). use tidyr, aren’t going want type c(2, 3, 4, 5, .....) way 217! R short-hand notation can use :. example, type 4:9 console window. Use notation tidy mortality_df data set.Note: ’ll need add something pivot_longer() function convert variable Year numeric. haven’t talked much variable types yet , values_to = \"Mortality\" statement, add , names_transform = list(Year = .numeric), making sure second ) close pivot_longer() function.Make line plot look overall 5 mortality trends country.Make line plot look overall 5 mortality trends country.overall trend 5 mortality? every single country follow trend? looks strange plot, specifically data collected 1900?overall trend 5 mortality? every single country follow trend? looks strange plot, specifically data collected 1900?Write two short paragraphs article found https://www.r-bloggers.com/. important thing exercise pick article interests . many choose , multiple posts put day. purposes assignment though, find article author actually provides code (“big-picture” views certain topics).Write two short paragraphs article found https://www.r-bloggers.com/. important thing exercise pick article interests . many choose , multiple posts put day. purposes assignment though, find article author actually provides code (“big-picture” views certain topics).first paragraph, answer following: () main purpose blog post? (b) data /author(s) using? (c) main findings? (d) important author data main findings?second paragraph, discuss () code see explicitly seen class, (b) code see explicitly seen class, (c) anything else find interesting article. , copy paste URL.","code":"\nmortality_df <- read_csv(\"data/under5mortality.csv\")\nhead(mortality_df)\n#> # A tibble: 6 x 217\n#>   `Under five mor… `1800` `1801` `1802` `1803` `1804` `1805`\n#>   <chr>             <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n#> 1 Abkhazia            NA     NA     NA     NA     NA     NA \n#> 2 Afghanistan        469.   469.   469.   469.   469.   469.\n#> 3 Akrotiri and Dh…    NA     NA     NA     NA     NA     NA \n#> 4 Albania            375.   375.   375.   375.   375.   375.\n#> 5 Algeria            460.   460.   460.   460.   460.   460.\n#> 6 American Samoa      NA     NA     NA     NA     NA     NA \n#> # … with 210 more variables: 1806 <dbl>, 1807 <dbl>,\n#> #   1808 <dbl>, 1809 <dbl>, 1810 <dbl>, 1811 <dbl>,\n#> #   1812 <dbl>, 1813 <dbl>, 1814 <dbl>, 1815 <dbl>,\n#> #   1816 <dbl>, 1817 <dbl>, 1818 <dbl>, 1819 <dbl>,\n#> #   1820 <dbl>, 1821 <dbl>, 1822 <dbl>, 1823 <dbl>,\n#> #   1824 <dbl>, 1825 <dbl>, 1826 <dbl>, 1827 <dbl>,\n#> #   1828 <dbl>, 1829 <dbl>, 1830 <dbl>, 1831 <dbl>,\n#> #   1832 <dbl>, 1833 <dbl>, 1834 <dbl>, 1835 <dbl>,\n#> #   1836 <dbl>, 1837 <dbl>, 1838 <dbl>, 1839 <dbl>,\n#> #   1840 <dbl>, 1841 <dbl>, 1842 <dbl>, 1843 <dbl>,\n#> #   1844 <dbl>, 1845 <dbl>, 1846 <dbl>, 1847 <dbl>,\n#> #   1848 <dbl>, 1849 <dbl>, 1850 <dbl>, 1851 <dbl>,\n#> #   1852 <dbl>, 1853 <dbl>, 1854 <dbl>, 1855 <dbl>,\n#> #   1856 <dbl>, 1857 <dbl>, 1858 <dbl>, 1859 <dbl>,\n#> #   1860 <dbl>, 1861 <dbl>, 1862 <dbl>, 1863 <dbl>,\n#> #   1864 <dbl>, 1865 <dbl>, 1866 <dbl>, 1867 <dbl>,\n#> #   1868 <dbl>, 1869 <dbl>, 1870 <dbl>, 1871 <dbl>,\n#> #   1872 <dbl>, 1873 <dbl>, 1874 <dbl>, 1875 <dbl>,\n#> #   1876 <dbl>, 1877 <dbl>, 1878 <dbl>, 1879 <dbl>,\n#> #   1880 <dbl>, 1881 <dbl>, 1882 <dbl>, 1883 <dbl>,\n#> #   1884 <dbl>, 1885 <dbl>, 1886 <dbl>, 1887 <dbl>,\n#> #   1888 <dbl>, 1889 <dbl>, 1890 <dbl>, 1891 <dbl>,\n#> #   1892 <dbl>, 1893 <dbl>, 1894 <dbl>, 1895 <dbl>,\n#> #   1896 <dbl>, 1897 <dbl>, 1898 <dbl>, 1899 <dbl>,\n#> #   1900 <dbl>, 1901 <dbl>, 1902 <dbl>, 1903 <dbl>,\n#> #   1904 <dbl>, 1905 <dbl>, …"},{"path":"tidying-with-tidyr.html","id":"chapexercise-4","chapter":" 5 Tidying with tidyr","heading":"5.5 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 5.6.use nfl salary data obtained FiveThirtyEight originally obtained Spotrac.com.data set top 100 paid players year position 2011 2018, broken player position. unfamiliar American football, positions data set Quarterback, Running Back, Wide Receiver, Tight End, Offensive Lineman offense, Cornerback, Defensive Lineman, Linebacker, Safety Defense, separate category Special Teams players includes punters kickers. can review summary player positions  .interested salaries compare top 100 players position salaries changed time position.Read data set withUse skim() head() functions look data, explain data set tidy form.Use skim() head() functions look data, explain data set tidy form.* Use function tidyr make data tidy, give tidy data set new name.* Use function tidyr make data tidy, give tidy data set new name.* data set previous exercise, add ranking variable ranks salaries within player position highest paid players position receive 1, second highest paid players receive 2, etc. Compare results default way R uses break ties two salaries using ties.method = \"first\".* data set previous exercise, add ranking variable ranks salaries within player position highest paid players position receive 1, second highest paid players receive 2, etc. Compare results default way R uses break ties two salaries using ties.method = \"first\".Hint: See Exercise 4 4.3.2 another example .* Find maximum salary player position year. , create two different line graphs shows maximum salary changed 2011 2018 position. one line graph, make colours lines different position. second line graph, facet position. graph like better?* Find maximum salary player position year. , create two different line graphs shows maximum salary changed 2011 2018 position. one line graph, make colours lines different position. second line graph, facet position. graph like better?* maximum salary dependent one specific player. Make graph, plot average salary top 20 players position year. notice? interesting patterns positions? ’re fan football, provide guess one positions salary plateau recent years.* maximum salary dependent one specific player. Make graph, plot average salary top 20 players position year. notice? interesting patterns positions? ’re fan football, provide guess one positions salary plateau recent years.* Sometimes graphs involving cost salary, want take account inflation rate. Google inflation rate 2011 2018 (Google something like “inflation rate 2011 2018” able find something). Adjust 2011 salaries inflation comparable 2018 salaries. , make similar line plot ignore years 2012 2017 (line plot just 2 points per position).* Sometimes graphs involving cost salary, want take account inflation rate. Google inflation rate 2011 2018 (Google something like “inflation rate 2011 2018” able find something). Adjust 2011 salaries inflation comparable 2018 salaries. , make similar line plot ignore years 2012 2017 (line plot just 2 points per position).adjusting inflation, many positions average higher salaries top 20 players position?Construct graph shows much salary decreases moving higher ranked players lower ranked players position year 2018. think depreciation large Quarterbacks?","code":"\nnfl_df <- read_csv(\"data/nfl_salary.csv\")"},{"path":"tidying-with-tidyr.html","id":"solutions-4","chapter":" 5 Tidying with tidyr","heading":"5.6 Exercise Solutions","text":"","code":""},{"path":"tidying-with-tidyr.html","id":"what-is-tidy-data-s","chapter":" 5 Tidying with tidyr","heading":"5.6.1 What is Tidy Data? S","text":"","code":""},{"path":"tidying-with-tidyr.html","id":"separate-and-unite-s","chapter":" 5 Tidying with tidyr","heading":"5.6.2 separate() and unite() S","text":"* Tidy data set just thatDuration salary contract (currently given Year column) columnthe year range (also currently given Year column) split variable called Start variable called End year give start end years contract. can still special characters now (like ( )) start end year.* Using function dplyr. fix End variable created , example, first observation 2020 instead just 20.somewhat lazy way get trouble (one years 1990s?) , ’s safe particular data set.* tidyr extremely useful, ’s glamorous. end data set ggplot2 dplyr can use cool things. , let’s something tidy data set make tidying little worth moving . Make graphic investigates player Salary compares different POS.* State reason making plot worked tidied data set.Salary variable dollar sign ggplot known plot .","code":"\nbaseball_df <- baseball_df %>%\n  separate(Years, into = c(\"Duration\", \"Range\"), sep = \" \") %>%\n  separate(Range, into = c(\"Start\", \"End\"), sep = \"-\")\nbaseball_df <- baseball_df %>% mutate(End = End + 2000)\nggplot(data = baseball_df, aes(x = POS, y = Salary)) +\n  geom_boxplot()\nggplot(data = baseball_df, aes(x = Salary, colour = POS)) + \n  geom_freqpoly() ## boxplots look better in this case"},{"path":"tidying-with-tidyr.html","id":"pivot_-s","chapter":" 5 Tidying with tidyr","heading":"5.6.3 pivot_() S","text":"* Convert data set tidier form year variable commodity variable 3 values: \"bigmac\", \"bread\", \"rice\"Hint: point, need separate commodity year , example, bread2009. , ’ll notice different uses separate() “-” \" \" “/” use separating character. Look help separate() scroll sep argument see can figure issue. first code chunk shows solution particular issue case get stuck part second code chunk shows entire solution.* Convert data set previous exercise commodity split 3 variables: bigmac price, rice price bread price.","code":"\nseparate(name_of_variable, into = c(\"newname1\", \"newname2\"), sep = -4)\nprices_long <- prices_df %>% pivot_longer(cols = c(2, 3, 4, 5, 6, 7),\n  names_to = \"commod_year\", values_to = \"price\") %>%\n  separate(col = \"commod_year\", into = c(\"commodity\", \"year\"), sep = -4)\nhead(prices_long)\n#> # A tibble: 6 x 4\n#>   city      commodity year  price\n#>   <chr>     <chr>     <chr> <dbl>\n#> 1 Amsterdam bigmac    2009     19\n#> 2 Amsterdam bread     2009     10\n#> 3 Amsterdam rice      2009     11\n#> 4 Amsterdam bigmac    2003     16\n#> 5 Amsterdam bread     2003      9\n#> 6 Amsterdam rice      2003      9\nprices_wide <- prices_long %>%\n  pivot_wider(names_from = commodity, values_from = price)\nhead(prices_wide)\n#> # A tibble: 6 x 5\n#>   city      year  bigmac bread  rice\n#>   <chr>     <chr>  <dbl> <dbl> <dbl>\n#> 1 Amsterdam 2009      19    10    11\n#> 2 Amsterdam 2003      16     9     9\n#> 3 Athens    2009      30    13    27\n#> 4 Athens    2003      21    12    19\n#> 5 Auckland  2009      19    19    13\n#> 6 Auckland  2003      19    19     9"},{"path":"tidying-with-tidyr.html","id":"skimming-data-with-skimr-s","chapter":" 5 Tidying with tidyr","heading":"5.6.4 Skimming Data with skimr() S","text":"* Use skim() function skimr obtain preliminary information data set.* Notice 217 columns (top print header, 217 second number). use tidyr, aren’t going want type c(2, 3, 4, 5, .....) way 217! R short-hand notation can use :. example, type 4:9 console window. Use notation tidy mortality_df data set.’ll need add something pivot_longer() function convert variable Year numeric. haven’t talked much variable types yet , values_to = \"Mortality\" statement, add , names_transform = list(Year = .numeric), making sure second ) close pivot_longer() function.","code":"\nlibrary(skimr)\nskim(mortality_df)\nmortality_long <- mortality_df %>%\n  pivot_longer(cols = 2:217, names_to = \"Year\",\n               values_to = \"Mortality\",\n               names_transform = list(Year = as.numeric))"},{"path":"tidying-with-tidyr.html","id":"chapexercise-4-S","chapter":" 5 Tidying with tidyr","heading":"5.6.5 Chapter Exercises S","text":"* Use function tidyr make data tidy, give tidy data set new name.* data set previous exercise, add ranking variable ranks salaries within player position highest paid players position receive 1, second highest paid players receive 2, etc. Compare results default way R uses break ties two salaries using ties.method = \"first\".Hint: See Exercise 4 4.3.2 another example .first ranking code allows observations ranking get rankings averaged together (e.g. two observations tied 5th get ranking (5 + 6) / 2 = 5.5).second ranking method, first observation data set gets “higher” rank.* Find maximum salary player position year. , create two different line graphs shows maximum salary changed 2011 2018 position. one line graph, make colours lines different position. second line graph, facet position. graph like better?number levels, personally prefer faceted graph cleaner look.* maximum salary dependent one specific player. Make graph, plot average salary top 20 players position year. notice? interesting patterns positions? ’re fan football, provide guess one positions salary plateau recent years.Running backs haven’t much salary increase whereas offensive positions large salary increase. many plausible explanations case. One NFL much “passing league” now decades ago.* Sometimes graphs involving cost salary, want take account inflation rate. Google inflation rate 2011 2018 (Google something like “inflation rate 2011 2018” able find something). Adjust 2011 salaries inflation comparable 2018 salaries. , make similar line plot ignore years 2012 2017 (line plot just 2 points per position).adjusting inflation, many positions average higher salaries top 20 players position?positions higher salaries, even adjusting inflation, except perhaps running backs (’s hard tell graph).","code":"\nnfl_long <- nfl_df %>%\n  pivot_longer(c(2, 3, 4, 5, 6, 7, 8, 9, 10, 11),\n               names_to = \"position\", values_to = \"salary\")\nnfl_long\n#> # A tibble: 8,000 x 3\n#>     year position            salary\n#>    <dbl> <chr>                <dbl>\n#>  1  2011 Cornerback        11265916\n#>  2  2011 Defensive Lineman 17818000\n#>  3  2011 Linebacker        16420000\n#>  4  2011 Offensive Lineman 15960000\n#>  5  2011 Quarterback       17228125\n#>  6  2011 Running Back      12955000\n#>  7  2011 Safety             8871428\n#>  8  2011 Special Teamer     4300000\n#>  9  2011 Tight End          8734375\n#> 10  2011 Wide Receiver     16250000\n#> # … with 7,990 more rows\nnfl_long_default <- nfl_long %>% group_by(position, year) %>%\n  mutate(rank = rank(desc(salary)))\n\nnfl_long <- nfl_long %>% group_by(position, year) %>%\n  mutate(rank = rank(desc(salary), ties.method = \"first\"))\nnfl_max <- nfl_long %>% group_by(position, year) %>%\n  summarise(maxsal = max(salary, na.rm = TRUE))\n#> `summarise()` has grouped output by 'position'. You can override using the `.groups` argument.\n\nggplot(data = nfl_max,\n  aes(x = year, y = maxsal, group = position, colour = position)) +\n  geom_line()\n\nggplot(data = nfl_max, aes(x = year, y = maxsal)) +\n  geom_line() +\n  facet_wrap( ~ position)\nnfl_rank <- nfl_long %>% filter(rank <= 20) %>%\n  group_by(position, year) %>%\n  summarise(mean20 = mean(salary, na.rm = TRUE))\n#> `summarise()` has grouped output by 'position'. You can override using the `.groups` argument.\n\nggplot(data = nfl_rank, aes(x = year, y = mean20)) +\n  geom_line() + \n  facet_wrap( ~ position)\n## 11.6% from 2011 to 2018.\nnfl_inf <- nfl_long %>%\n  mutate(salary_inf = if_else(year == 2011,\n                              true = salary * 1.116,\n                              false = salary)) %>% \n  filter(year == 2011 | year == 2018) %>% \n  filter(rank <= 20) %>% group_by(position, year) %>%\n  summarise(mean20 = mean(salary, na.rm = TRUE)) \n#> `summarise()` has grouped output by 'position'. You can override using the `.groups` argument.\n\nggplot(data = nfl_inf, aes(x = year, y = mean20)) +\n  geom_line() +\n  geom_point() +\n  facet_wrap( ~ position)"},{"path":"tidying-with-tidyr.html","id":"rcode-4","chapter":" 5 Tidying with tidyr","heading":"5.7 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\npolls <- read_csv(\"data/rcp-polls.csv\", na = \"--\")\npolls\npolls %>% summarise(meansample = mean(Sample))\npolls %>%\n  separate(col = Sample, into = c(\"Sample_size\", \"Sample_type\"), \n           sep = \" \")\npolls_sep <- polls %>%\n  separate(col = Date, into = c(\"Start\", \"End\"),\n           sep = \" - \")\npolls_sillytest <- polls_sep %>%\n  separate(col = Start, into = c(\"Start_month\", \"Start_day\"), \n           sep = \"/\")\npolls_sillytest\npolls_sillytest %>%\n  unite(\"New_start_date\", c(Start_month, Start_day),\n        sep = \"/\")\nc(1, 4, 2)\nc(\"A\", \"A\", \"D\")\npolls_sep\npolls_new <- polls_sep %>%\n  rename(Clinton_D = `Clinton (D)`, Trump_R = `Trump (R)`,\n         Johnson_L = `Johnson (L)`, Stein_G = `Stein (G)`)\npolls_new\npolls_clean <- polls %>%\n  separate(col = Sample, into = c(\"Sample_size\", \"Sample_type\"), \n           sep = \" \")  %>%\n  separate(col = Date, into = c(\"Start\", \"End\"),\n           sep = \" - \") %>% \n  rename(Clinton_D = `Clinton (D)`, Trump_R = `Trump (R)`,\n         Johnson_L = `Johnson (L)`, Stein_G = `Stein (G)`)\npolls_clean\npolls_clean %>%\n  pivot_longer(cols = c(Clinton_D, Trump_R, Johnson_L, Stein_G),\n               names_to = \"candidate\", values_to = \"poll_percent\")\npolls_long <- polls_clean %>%\n  pivot_longer(cols = c(Clinton_D, Trump_R, Johnson_L, Stein_G),\n               names_to = \"candidate\", values_to = \"poll_percent\")\n\n## ignore as.Date for now....we will get to dates later!\nggplot(data = polls_long,\n       aes(x = as.Date(Start, \"%m/%d\"), y = poll_percent,\n           colour = candidate)) +\n  geom_point() + xlab(\"Poll Start Date\")\nairlines <- read_csv(\"data/airline-safety.csv\")\nhead(airlines)\nairlines %>%\n  pivot_longer(c(3, 4, 5, 6, 7, 8), names_to = \"type_year\",\n  values_to = \"total_num\") \nairlines %>% pivot_longer(c(3, 4, 5, 6, 7, 8), names_to = \"type_year\",\n                          values_to = \"total_num\") %>%\n  separate(type_year, into = c(\"type\", \"year\"), sep = \" \")\n## name the long data set\nairlines_long <- airlines %>%\n  pivot_longer(c(3, 4, 5, 6, 7, 8), names_to = \"type_year\",\n               values_to = \"total_num\") %>%\n  separate(type_year, into = c(\"type\", \"year\"), sep = \" \")\n\n## use pivot_wider() to create variables for incidents, fatalities, and\n## fatal_accidents:\nairlines_long %>% pivot_wider(names_from = type,\n                              values_from = total_num)\nlibrary(skimr)\nskim(airlines)"},{"path":"communication-with-rmarkdown.html","id":"communication-with-rmarkdown","chapter":" 6 Communication with RMarkdown","heading":" 6 Communication with RMarkdown","text":"Goals:Explain reproducibility means explain ’s important analyses reproducible.Explain reproducibility means explain ’s important analyses reproducible.Explain R Markdown provides tools making analyses reproducible base R Microsoft Word Microsoft Excel.Explain R Markdown provides tools making analyses reproducible base R Microsoft Word Microsoft Excel.Use Code Options Markdown Text Options modify R Markdown file knits readable, professional .html file.Use Code Options Markdown Text Options modify R Markdown file knits readable, professional .html file.Use titles, labels, colour scales, annotations, themes make plots easy read, including people Colour Vision Deficiency.Use titles, labels, colour scales, annotations, themes make plots easy read, including people Colour Vision Deficiency.Overall: ’re making quick plots just , things communication won’t apply. , ’re planning sharing results (usually , eventually), communication tools become much important.","code":""},{"path":"communication-with-rmarkdown.html","id":"reproducbility","chapter":" 6 Communication with RMarkdown","heading":"6.1 Reproducbility","text":"’ve using R Markdown now, yet talked features anything except insert new code chunk. end section, want able use R Markdown options make nice-looking document (can implement options first mini-project).Reproducibility concept recently gained popularity sciences describing analyses another researcher able repeat. , analysis reproducible provide enough information person sitting next can obtain identical results long follow procedures. analysis reproducible isn’t case.\nR Markdown makes easy make analysis reproducible couple reasons:R Markdown file knit unless code runs, meaning won’t accidentally give someone code doesn’t work.R Markdown file knit unless code runs, meaning won’t accidentally give someone code doesn’t work.R Markdown combines “coding” steps “write-” steps one coherent document contains code, figures tables, explanations.R Markdown combines “coding” steps “write-” steps one coherent document contains code, figures tables, explanations.","code":""},{"path":"communication-with-rmarkdown.html","id":"r-scripts-vs.-r-markdown","chapter":" 6 Communication with RMarkdown","heading":"6.1.1 R Scripts vs. R Markdown","text":"’ve using R Markdown entirety course. , may noticed go File -> New File open new R Markdown file, ton options. first option R Script. Go ahead open new R Script file now.file open completely blank. R Script file reads R code. text , unless text commented #. example, copy paste code inside code chunk .Rmd file .R file run line line., advantages disadvantages using R Script file compared using R Markdown file? Let’s start advantages R Markdown. R Markdown allows fully integrate text explanations code results, actual tables figures , code make tables figures one cohesive document. see, using R Scripts write-analysis Word, lot copy-pasting involved results. reason, using R Markdown often results reproducible analyses.advantage R Script situation really aren’t presenting results anyone also don’t need text explanations. often occurs two situations. (1) lot data preparation steps. case, typically complete data prep steps R script write resulting clean data .csv ’d import R Markdown file. (2) ’re complicated statistically. case, code much focus text creating figures ’d use R Script.“demo” reproducible analysis class political data.","code":""},{"path":"communication-with-rmarkdown.html","id":"spell-checking","chapter":" 6 Communication with RMarkdown","heading":"6.1.2 Spell-Checking","text":"using R Markdown communication, probably want utilize spell-check feature. Go Edit -> Check Spelling, ’ll presented spell-checker lets change spelling words may misspelled.","code":""},{"path":"communication-with-rmarkdown.html","id":"exercise-5-1","chapter":" 6 Communication with RMarkdown","heading":"6.1.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 6.5.’s difference R R Markdown?’s difference R R Markdown?R Markdown analysis reproducible base R script analysis?R Markdown analysis reproducible base R script analysis?R Markdown analysis easier make reproducible analysis Excel?R Markdown analysis easier make reproducible analysis Excel?friend Chaz data analysis project Excel compare average GPA student athletes average GPA non-student athletes. two variables: whether student student athlete GPA. decides two-sample t-test appropriate procedure data (recall Intro Stat procedure appropriate comparing quantitative response (GPA) across two groups). steps analysis.friend Chaz data analysis project Excel compare average GPA student athletes average GPA non-student athletes. two variables: whether student student athlete GPA. decides two-sample t-test appropriate procedure data (recall Intro Stat procedure appropriate comparing quantitative response (GPA) across two groups). steps analysis.writes null alternative hypotheses words statistical notation.writes null alternative hypotheses words statistical notation.uses Excel make set side--side boxplots. changes labels limits y-axis using Point--Click Excel operations.uses Excel make set side--side boxplots. changes labels limits y-axis using Point--Click Excel operations.boxplots, see 3 outliers non-athlete group. three students GPAs 0 suspended repeatedly refusing wear masks indoors. Chaz decides 3 students removed analysis , stayed enrolled, GPAs different 0. deletes 3 rows Excel.boxplots, see 3 outliers non-athlete group. three students GPAs 0 suspended repeatedly refusing wear masks indoors. Chaz decides 3 students removed analysis , stayed enrolled, GPAs different 0. deletes 3 rows Excel.Chaz uses t.test function Excel run test. writes degrees freedom, T-stat, p-value.Chaz uses t.test function Excel run test. writes degrees freedom, T-stat, p-value.Chaz copies graph Word writes conclusion context problem.Chaz copies graph Word writes conclusion context problem.State 2 aspects Chaz’s analysis reproducible.","code":""},{"path":"communication-with-rmarkdown.html","id":"r-markdown-files","chapter":" 6 Communication with RMarkdown","heading":"6.2 R Markdown Files","text":"Let’s talk bit components R Markdown file used make reproducible analysis shown class.First, open new R Markdown file clicking File -> New File -> R Markdown keep new file knits HTML now.first six lines top file make YAML (Yet Another Markup Language) header. ’ll come back end, ’s frustrating part learn.Lines 8-10 set-chunk. , ’ll come back bit. now, just delete lines 12-30 copy paste following code chunks clean .Rmd file:cars data set built R ’s need anything read (already exists R ).","code":"\nlibrary(tidyverse)\nhead(cars)\nggplot(data = cars, aes(x = speed, y = dist)) +\n  geom_point()\nsummary(cars)"},{"path":"communication-with-rmarkdown.html","id":"code-chunk-options","chapter":" 6 Communication with RMarkdown","heading":"6.2.1 Code Chunk Options","text":"First, knit, new file (give name, prompted). see code, couple results tables, scatterplot.Chunk options allow control gets printed file knit. example, may may want: code printed, figure printed, results printed, tidyverse message printed, etc. See page 2 reference R chunk options: https://rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf. ’s ton ! going just focus commonly used.echo. set either TRUE print code FALSE print code. r first line first code chunk, add , echo = FALSE inside curly braces reknit see happens!can keep adding options, separated comma. options include:message. set either TRUE print messages FALSE print messages. load tidyverse, message automatically prints . code chunk, add , message = FALSE get rid message. Re-knit make sure message actually gone.message. set either TRUE print messages FALSE print messages. load tidyverse, message automatically prints . code chunk, add , message = FALSE get rid message. Re-knit make sure message actually gone.warning. set either TRUE print warnings FALSE print warnings. don’t warnings changing current code chunks won’t anything.warning. set either TRUE print warnings FALSE print warnings. don’t warnings changing current code chunks won’t anything.results. default, set ‘markup’ shows results tables. Change ‘hide’ print results. Practice adding , results = 'hide' code chunk R Markdown file summary(cars) re-knit make sure results summary(cars) gone.results. default, set ‘markup’ shows results tables. Change ‘hide’ print results. Practice adding , results = 'hide' code chunk R Markdown file summary(cars) re-knit make sure results summary(cars) gone.fig.keep. Add fig.keep = 'none' print figure. Practice adding , fig.keep = 'none' code chunk options scatterplot re-knit make sure figure gone. fig.keep can also set 'last', case R keep last figure created code chunk.fig.keep. Add fig.keep = 'none' print figure. Practice adding , fig.keep = 'none' code chunk options scatterplot re-knit make sure figure gone. fig.keep can also set 'last', case R keep last figure created code chunk.fig.height fig.width control height width figures. default, 7, often change fig.height make figures shorter (fig.height = 5, example).fig.height fig.width control height width figures. default, 7, often change fig.height make figures shorter (fig.height = 5, example).fig.cap adds figure caption figure. Try inserting , fig.cap = \"Figure 1: caption text blah blah blah\" chunk options.fig.cap adds figure caption figure. Try inserting , fig.cap = \"Figure 1: caption text blah blah blah\" chunk options.include, eval, collapse also sometimes useful: check reference guide!include, eval, collapse also sometimes useful: check reference guide!Finally, ’ll notice time make new document, code chunk beginning called “setup.” default, setup echo = TRUE global option. global option something gets applied code chunks entire document. , echo = TRUE means code chunks code printed, unless specifically overridden particular chunk. , echo = TRUE means code print, except chunks set echo = FALSE. can add options global chunk like fig.height = 5 make figures chunks height 5 instead adding option every chunk.","code":""},{"path":"communication-with-rmarkdown.html","id":"figures-and-tables","chapter":" 6 Communication with RMarkdown","heading":"6.2.2 Figures and Tables","text":"’ve already seen Figures pop automatically (unless set fig.keep = 'none'), quite convenient. Making tables look nice requires one extra step.Delete results = 'hide' option added earlier. knit .Rmd file now, results tables head(cars) summary(cars) look kind ugly. focus using kable() function knitr package make tables much aesthetically pleasing. Another option use pander() function pander package. pander() kable() simple functions generate tables sufficient purposes. generate complicated tables, see xtable package.use functions, simply replace add %>% pipe name table function want use. head(cars) %>% kable() make nice-looking table kable head(cars) %>% pander() use pander(). using kable(), ’ll need load library adding line library(knitr) head(cars) %>% kable(). using pander(), ’ll need load library adding line library(pander) head(cars) %>% pander(). Try R Markdown file.table like better case?plenty options making tables look presentable, discuss Exercises. Keep mind probably wouldn’t use making tables . ’re much useful ’re writing report want share others.","code":""},{"path":"communication-with-rmarkdown.html","id":"non-code-options","chapter":" 6 Communication with RMarkdown","heading":"6.2.3 Non-Code Options","text":"R Markdown combines R (code chunks, ’ve already discussed) Markdown syntax, comprises stuff outside code chunks, like ’re reading right now!many Markdown options, time, want something specific, can just Google . purpose follows just get us familiar basics things probably use often.Bullet Points Sub-bullet Points: Denoted * -, respectively. sub bullets indented 4 spaces. Note bullet points code appear code chunk.Note: Everything Markdown particular spacing. Things often precise. personally just love , can frustrating sometimes. example, indenting sub-bullet 3 spaces instead 4 spaces make sub-bullet.Numbered Lists bulleted ones, except * replaced numbers 1., 2., etc.Bold, Italics, Code. Surround text __bold text__ make text bold, _italic text_ make text Italics, backticks make text look like Code.Links: simplest way create link something web surround < > <https://www.youtube.com/watch?v=gJf_DDAfDXs>want name link something web address, use [name link](https://www.youtube.com/watch?v=gJf_DDAfDXs), show knitted document “name link” , clicked , take youtube video.Headers: Headers created ## fewer hashtags resulting bigger Header. Typing #Big Header beginning line make big header, ### Medium Header make medium header, ##### Small Header make small header. Headers important get mapped table contents.’s lot stuff explore: <href=“https://rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf” target=\"blank> https://rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf ., want something basics, Google definitely help.","code":"* Bullet 1\n* Bullet 2\n    - Sub bullet 1\n    - Sub bullet 2\n    - Sub bullet 3* Bullet 1\n   - Sub bullet 1"},{"path":"communication-with-rmarkdown.html","id":"yaml","chapter":" 6 Communication with RMarkdown","heading":"6.2.4 YAML","text":"Finally, can return ’s given top every .Rmd file: YAML header. YAML header frustrating part change ’s particular spacing.biggest thing can take advantage YAML themes people written R Markdown. default, ’re just using R Markdown’s default theme, looks okay.One package can use make “pretty” themed document easily rmdformats package using readthedown theme. lot heavy lifting making resulting .html file super nice look .example, paste following lines YAML header current .Rmd file.toc_depth: 5 controls required number header ##### something appear Table Contents (toc). document just knitted won’t anything table contents haven’t included headers 5 fewer hashtags.mentioned , spacing YAML headers extremely important. example, delete one spaces beginning line toc_depth: 5 R Markdown file created. file longer knit, deleted single space.Another package use create pretty .html file prettydoc package (might recall using package reports took STAT 213 Professor Higham). Try copying pasting following .Rmd YAML header R Markdown file created:prettydoc 5 themes choose . YAML header uses hpstr. choices cayman, tactile, architect, leonids.","code":"---\ntitle: \"Week 4: Communication with `R Markdown` and `ggplot2`\"\nauthor: \"Matt Higham\"\noutput: \n  rmdformats::readthedown:\n    toc_depth: 5\n------\ntitle: \"Title\"\nauthor: \"Name\"\ndate: \"Put Today's Date\"\noutput: \n  prettydoc::html_pretty:\n    theme: hpstr\n    toc: true\n---"},{"path":"communication-with-rmarkdown.html","id":"exercise-5-2","chapter":" 6 Communication with RMarkdown","heading":"6.2.5 Exercises","text":"Exercises marked * indicate exercise solution end chapter 5.6.rest section, use built-R data set mtcars, observations makes models cars. variables using :cyl, number cylinders car hasmpg, mileage car, miles per gallonBecause data set loaded every time R started , need line reads data set. can examine first observations * Create table showing mean mpg cyl group (cyl stands cylinder can 4-cylinder, 6-cylinder, 8-cylinder) kable() pander(). Hint: remember call knitr library pander library.* Create table showing mean mpg cyl group (cyl stands cylinder can 4-cylinder, 6-cylinder, 8-cylinder) kable() pander(). Hint: remember call knitr library pander library.* Type ?kable console window scroll Help file. Change rounding mean displays one number decimal. , add caption table says “First Table Caption!!”* Type ?kable console window scroll Help file. Change rounding mean displays one number decimal. , add caption table says “First Table Caption!!”* Google “Change Column Names kable” replace column names “Cylinder Numb.” “Mean Mileage.”* Google “Change Column Names kable” replace column names “Cylinder Numb.” “Mean Mileage.”Find table plan use first mini-project. Use column names, caption, digits options make table look nicer kable() function.Find table plan use first mini-project. Use column names, caption, digits options make table look nicer kable() function.Create new R chunk copy paste following new R chunk. Don’t worry factor() : cover next week!Create new R chunk copy paste following new R chunk. Don’t worry factor() : cover next week!Modify R chunk : () figure height 3, (b) code R chunk shows .html file, (c) results running head(cars) hidden .html file. Make (b) (c) local chunk option, set () global option applies R chunks.Change global options mini-project () hide messages loading tidyverse (b) show code.Change global options mini-project () hide messages loading tidyverse (b) show code.Use bullet points Introduction first mini-project explains important variables . , add header mini-project marks Introduction.Use bullet points Introduction first mini-project explains important variables . , add header mini-project marks Introduction.Change YAML header mini-project Author file uses either one prettydoc themes readthedown theme.Change YAML header mini-project Author file uses either one prettydoc themes readthedown theme.","code":"\nhead(mtcars)\n#>                    mpg cyl disp  hp drat    wt  qsec vs am\n#> Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1\n#> Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1\n#> Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1\n#> Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0\n#> Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0\n#> Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0\n#>                   gear carb\n#> Mazda RX4            4    4\n#> Mazda RX4 Wag        4    4\n#> Datsun 710           4    1\n#> Hornet 4 Drive       3    1\n#> Hornet Sportabout    3    2\n#> Valiant              3    1\nlibrary(tidyverse)\nhead(mtcars)\nggplot(data = mtcars, aes(x = factor(cyl), y = mpg)) +\n  geom_boxplot()"},{"path":"communication-with-rmarkdown.html","id":"ggplot2-communication","chapter":" 6 Communication with RMarkdown","heading":"6.3 ggplot2 Communication","text":"first introduced plotting, used histograms, boxplots, frequency plots, bar plots, scatterplots, line plots, help us explore data set. probably make many different plots single analysis, , exploring, ’s fine keep plots unlabeled untitled default colour scheme theme. ’re just , typically understand data variable means.However, ’ve finished exploring ’d like communicate results, graphically numerically, ’ll likely want tweak plots look aesthetically pleasing. certainly wouldn’t presenting every exploratory plot made tweaking needs done plots. might consider:changing x-axis y-axis labels, changing legend title, adding title, adding subtitle, adding caption + labs()changing x-axis y-axis labels, changing legend title, adding title, adding subtitle, adding caption + labs()changing limits x-axis y-axis + xlim() + ylim()changing limits x-axis y-axis + xlim() + ylim()changing colour scheme visually appealing easy see people colour-vision-deficiency (CVD)changing colour scheme visually appealing easy see people colour-vision-deficiency (CVD)labeling certain points lines + geom_label() + geom_text()labeling certain points lines + geom_label() + geom_text()changing default theme + theme_<name_of_theme>()changing default theme + theme_<name_of_theme>()bullet labeling certain points data set one reason second ggplot2 section now, opposed immediately first ggplot2 section. see, ’ll make use combining ’ve learned dplyr help us label interesting observations plots.DataThe Happy Planet Index (HPI) measure efficiently country uses ecological resources give citizens long “happy” lives. can read data :  ., basic idea HPI metric computes happy healthy country’s citizens , adjusts country’s ecological footprint (much “damage” country planet Earth). data set obtained  https://github.com/aepoetry/happy_planet_index_2016. Variables data set :HPIRank, rank country’s Happy Planet Index (lower better)Country, name countryLifeExpectancy, average life expectancy citizen (years)Wellbeing, average well score (scale 1 - 10). See ladder question documentation calculated.HappyLifeYears, combination LifeExpectancy WellbeingFootprint, ecological footprint per person (higher footprint means average person country less ecologically friendly)Read data set withLet’s look relationship HappyLifeYears Footprint countries different Regions world.region seems variability Ecological Footprint?","code":"\nlibrary(tidyverse)\nhpi_df <- read_csv(\"data/hpi-tidy.csv\")\nhead(hpi_df)\n#> # A tibble: 6 x 11\n#>   HPIRank Country    LifeExpectancy Wellbeing HappyLifeYears\n#>     <dbl> <chr>               <dbl>     <dbl>          <dbl>\n#> 1     109 Afghanist…           48.7      4.76           29.0\n#> 2      18 Albania              76.9      5.27           48.8\n#> 3      26 Algeria              73.1      5.24           46.2\n#> 4     127 Angola               51.1      4.21           28.2\n#> 5      17 Argentina            75.9      6.44           55.0\n#> 6      53 Armenia              74.2      4.37           41.9\n#> # … with 6 more variables: Footprint <dbl>,\n#> #   HappyPlanetIndex <dbl>, Population <dbl>,\n#> #   GDPcapita <dbl>, GovernanceRank <chr>, Region <chr>\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point()"},{"path":"communication-with-rmarkdown.html","id":"change-labels-and-titles","chapter":" 6 Communication with RMarkdown","heading":"6.3.1 Change Labels and Titles","text":"can add + labs() change various labels titles throughout plot:aes() use plot gets label can changed name_of_aethetic = \"Label\". example , changed three aes() labels: x, y, colour.text plot aren’t able change labs()?","code":"\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  labs(title = \"Countries with a Higher Ecological Footprint Tend to Have Citizens with Longer, Happier Lives\", \n       ## add title\n       subtitle = \"HappyLifeYears is a Combination of Life Expectancy and Citizen Well-Being\", \n       ## add subtitle (smaller text size than the title)\n       caption = \"Data Source: http://happyplanetindex.org/countries\", \n       ## add caption to the bottom of the figure\n       x = \"Ecological Footprint\", ## change x axis label\n       y = \"Happy Life Years\", ## change y axis label\n       colour = \"World Region\") ## change label of colour legend"},{"path":"communication-with-rmarkdown.html","id":"changing-x-and-y-axis-limits","chapter":" 6 Communication with RMarkdown","heading":"6.3.2 Changing x and y axis Limits","text":"can also change x-axis limits y-axis limits , example, start 0 y-axis:case, makes points plot bit harder see. can also change often tick marks appear x y-axes. special things like , think ’s best just resort Google (“ggplot change x-axis breaks tick marks” help).","code":"\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  ylim(c(0, 70))"},{"path":"communication-with-rmarkdown.html","id":"changing-a-colour-scale","chapter":" 6 Communication with RMarkdown","heading":"6.3.3 Changing A Colour Scale","text":"want use graphics communicate others clearly possible. also want inclusive possible communications. means , choose use colour, graphics made colour-vision-deficient (CVD) person can read graphs. 4.5% people colour vision deficient, ’s actually quite likely CVD person view graphics make (depending many people share ) Information CVD.colour scales R Colour Brewer readable common types CVD. list scales can found .typically use top scales variable colouring ordered sequentially (called seq sequential, like grades course: , B, C, D, F), bottom scales variable diverging (called div diverging, like Republican / Democrat lean middle colourless), middle set scales variable unordered categorical (called qual qualitative like names different treatment drugs medical experiment).3 situations World Region graph?want use one colour scales, just need add scale_colour_brewer() name scale want use.Try changing palette something else besides \"Accent\". like new palette better worse?One option easily change colour scale use viridis package. base viridis functions automatically load ggplot2 ’s need call package library(viridis). viridis colour scales made aesthetically pleasing CVD-friendly.drawback viridis package yellow can really hard see (least ).Read examples section Help file ?scale_colour_viridis_d. ’s difference scale_colour_viridis_d(), ?scale_colour_viridis_c(), scale_colour_viridis_b()?like better: Colour Brewer scale Viridis scale?","code":"\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Accent\")\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_viridis_d(option = \"plasma\")"},{"path":"communication-with-rmarkdown.html","id":"labeling-points-or-lines-of-interest","chapter":" 6 Communication with RMarkdown","heading":"6.3.4 Labeling Points or Lines of Interest","text":"One goal might communication highlighting particular points data set show something interesting. example, might want label points graph corresponding countries highest HPI region: countries best terms using resources efficiently maximize citizen happiness. , might want highlight “bad” example countries least efficient region. , might want label country graph.can done geom_label(). Let’s start labeling points. geom_label() needs one aesthetic called label name column data set labels want use.Yikes! ’s quite uncommon want label points. Let’s see can instead label country best HPI country’s region. , first need use dplyr skills create new data set 7 “best” countries. used group_by(), typically used summarise() afterward. , group_by() works filter() well!code previous chunk ?Now new data set, can use within geom_label(). Recall data = argument ggplot() carries geoms unless specify otherwise. Now chance “specify otherwise” including another data = argument within geom_label():think colour legend changed showing letter “” region?code chunk change “”’s back points?common issue, even labels, labels overlap. ggrepel package solves problem including geom_label_repel() geom automatically repels overlapping labels:final issue plot ’s always clear point plot labeled. trick used R Data Science book surround points labeled open circle using extra geom_point() function:code , shape = 1 says new point open circle size = 3 makes point bigger, ensuring goes around original point. show.legend = FALSE ensures larger open circles don’t become part legend.can use strategy label specific countries. ’m interested United States America falls graph ’m U.S. ’m also interested Denmark falls ’s country ’m interested visiting. Feel free replace countries ’re interested !","code":"\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label(aes(label = Country))\nplot_df <- hpi_df %>% group_by(Region) %>%\n  filter(HPIRank == min(HPIRank))\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label(data = plot_df, aes(label = Country))\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point(aes(colour = Region)) +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label(data = plot_df, aes(label = Country), show.legend = FALSE)\nlibrary(ggrepel)\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label_repel(data = plot_df, aes(label = Country),\n                   show.legend = FALSE) \nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears, colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label_repel(data = plot_df, aes(label = Country), show.legend = FALSE) +\n  geom_point(data = plot_df, size = 3, shape = 1, show.legend = FALSE) \nplot_df_us <- hpi_df %>%\n  filter(Country == \"United States of America\" | Country == \"Denmark\")\n\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_point(data = plot_df_us, size = 3, shape = 1,\n             show.legend = FALSE) +\n  geom_label_repel(data = plot_df_us, aes(label = Country),\n                   show.legend = FALSE)"},{"path":"communication-with-rmarkdown.html","id":"plot-themes","chapter":" 6 Communication with RMarkdown","heading":"6.3.5 Plot Themes","text":"Plot themes easy way change many aspects plot overall theme someone developed. default theme ggplot2 graphs theme_grey(), graph grey background ’ve using entirety class. 7 themes given R Data Science Figure 28.3.However, many choices ggthemes package. Load package library(ggthemes) check https://yutannihilation.github.io/allYourFigureAreBelongToUs/ggthemes/ themes package. personal favorites, given , theme_solarized(), theme_fivethirtyeight(), theme_economist(), choosing theme mostly matter personal taste.’s still much can ggplot2. fact, entire books . , specializations, can usually use Google help !","code":"\nlibrary(ggthemes)\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_point(data = plot_df_us, size = 3, shape = 1, show.legend = FALSE) +\n  geom_label_repel(data = plot_df_us, aes(label = Country), show.legend = FALSE) +\n  theme_solarized()\n\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_point(data = plot_df_us, size = 3, shape = 1, show.legend = FALSE) +\n  geom_label_repel(data = plot_df_us, aes(label = Country), show.legend = FALSE) +\n  theme_fivethirtyeight()\n\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_point(data = plot_df_us, size = 3, shape = 1, show.legend = FALSE) +\n  geom_label_repel(data = plot_df_us, aes(label = Country), show.legend = FALSE) +\n  theme_economist()"},{"path":"communication-with-rmarkdown.html","id":"exercise-5-3","chapter":" 6 Communication with RMarkdown","heading":"6.3.6 Exercises","text":"Exercises marked * indicate exercise solution end chapter 6.5.theme() function way really specialise plot. explore exercise .Using options theme() options change colours, shapes, sizes, etc., create ugliest possible ggplot2 graph can make. may change underlying data graph, goal investigate options given theme().practice communicating plots chapter exercises.","code":"\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point()"},{"path":"communication-with-rmarkdown.html","id":"chapexercise-5","chapter":" 6 Communication with RMarkdown","heading":"6.4 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 6.5.data sets exist within specific R packages. example, Jenny Bryan, quite famous stats/data science community, put together gapminder package users R access specific data set countries throughout world. https://github.com/jennybc/gapminder.load data set within specific R package, first need load package :, name data set something. case, name data set gapminder, ’s always name package . name data set country_df.Explore data set head(), skim(), ?gapminder proceeding following exercises.* Make line graph shows relationship lifeExp year countries data set, faceting graph continent also colouring continent (though redundant). Add x-axis label, y-axis label, legend label, title graph.* Make line graph shows relationship lifeExp year countries data set, faceting graph continent also colouring continent (though redundant). Add x-axis label, y-axis label, legend label, title graph.* Change colour palette CVD-friendly using either scale_colour_brewer() scale_colour_viridis_d().* Change colour palette CVD-friendly using either scale_colour_brewer() scale_colour_viridis_d().* can see couple interesting trends life expectancy. one country Africa one country Asia sees sharp decline life expectancy one point. Europe, one country substantially lower life expectancy rest 1950s catches European countries 2000s. Use filter() create data set 3 countries. , use geom_label() label three countries plot.* can see couple interesting trends life expectancy. one country Africa one country Asia sees sharp decline life expectancy one point. Europe, one country substantially lower life expectancy rest 1950s catches European countries 2000s. Use filter() create data set 3 countries. , use geom_label() label three countries plot.Google history countries Africa Asia just labeled. Add short description country experienced dip life expectancy caption graph.Google history countries Africa Asia just labeled. Add short description country experienced dip life expectancy caption graph.Read help file ?annotate. different geom_label(). one allows finer tuning? one takes code use? One functions (annotate() geom_label()) becomes pain use many labels. one becomes harder use ?Read help file ?annotate. different geom_label(). one allows finer tuning? one takes code use? One functions (annotate() geom_label()) becomes pain use many labels. one becomes harder use ?Suppose want legend appear bottom graph. Without using entirely different theme, use Google figure move legend right-hand side bottom.Suppose want legend appear bottom graph. Without using entirely different theme, use Google figure move legend right-hand side bottom.lot overlapping points overlapping lines, can use alpha control transparency lines. Google “change transparency lines ggplot” change alpha lines transparent.lot overlapping points overlapping lines, can use alpha control transparency lines. Google “change transparency lines ggplot” change alpha lines transparent.Change theme plot theme ggthemes package. , change order two commands change legend position change overall theme. happens?Change theme plot theme ggthemes package. , change order two commands change legend position change overall theme. happens?Modify .Rmd file :Modify .Rmd file :figure made Exercise 8 prints .html file. (Hint: use global options help ).figure made Exercise 8 prints .html file. (Hint: use global options help ).none code gets printed.none code gets printed.messages R prints default hidden code chunks.messages R prints default hidden code chunks.figure height 5 instead default 7.figure height 5 instead default 7.Create new .Rmd file knit file PDF. , knit file Microsoft Word. output format like best? Note PDF supports R Markdown theme options Word supports theme options.Create new .Rmd file knit file PDF. , knit file Microsoft Word. output format like best? Note PDF supports R Markdown theme options Word supports theme options.Read following “can software tools make research reproducible?” https://ropensci.github.io/reproducibility-guide/sections/introduction/. discussed article related R Markdown?Read following “can software tools make research reproducible?” https://ropensci.github.io/reproducibility-guide/sections/introduction/. discussed article related R Markdown?","code":"\nlibrary(gapminder)\ncountry_df <- gapminder"},{"path":"communication-with-rmarkdown.html","id":"solutions-5","chapter":" 6 Communication with RMarkdown","heading":"6.5 Exercise Solutions","text":"","code":""},{"path":"communication-with-rmarkdown.html","id":"reproducibility-s","chapter":" 6 Communication with RMarkdown","heading":"6.5.1 Reproducibility S","text":"","code":""},{"path":"communication-with-rmarkdown.html","id":"r-markdown-files-s","chapter":" 6 Communication with RMarkdown","heading":"6.5.2 R Markdown Files S","text":"* Create table showing mean mpg cyl group (cyl stands cylinder can 4-cylinder, 6-cylinder, 8-cylinder) kable() pander(). Hint: remember call knitr library pander library.* Type ?kable console window scroll Help file. Change rounding mean displays one number decimal. , add caption table says “First Table Caption!!”Table 6.1: First Table Caption!!* Google “Change Column Names kable” replace column names “Cylinder Numb.” “Mean Mileage.”Table 6.2: First Table Caption!!","code":"\nlibrary(knitr)\nlibrary(pander)\nlibrary(tidyverse)\nmpg_df <- mtcars %>% group_by(cyl) %>%\n  summarise(meanmpg = mean(mpg))\nmpg_df %>% kable()\nmpg_df %>% pander()\nkable(mpg_df, digits = 1, caption = \"My First Table Caption!!\")\nkable(mpg_df, digits = 1, caption = \"My First Table Caption!!\",\n  col.names = c(\"Cylinder Numb.\", \"Mean Mileage\"))"},{"path":"communication-with-rmarkdown.html","id":"ggplot2-communication-s","chapter":" 6 Communication with RMarkdown","heading":"6.5.3 ggplot2 Communication S","text":"","code":""},{"path":"communication-with-rmarkdown.html","id":"chapexercise-5-S","chapter":" 6 Communication with RMarkdown","heading":"6.5.4 Chapter Exercises S","text":"* Make line graph shows relationship lifeExp year countries data set, faceting graph continent also colouring continent (though redundant). Add x-axis label, y-axis label, legend label, title graph.* Make line graph shows relationship lifeExp year countries data set, faceting graph continent also colouring continent (though redundant). Add x-axis label, y-axis label, legend label, title graph.* Change colour palette CVD-friendly using either scale_colour_brewer() scale_colour_viridis_d().* Change colour palette CVD-friendly using either scale_colour_brewer() scale_colour_viridis_d().* can see couple interesting trends life expectancy. one country Africa one country Asia sees sharp decline life expxectancy one point. Europe, one country substantially lower life expectancy rest 1950s catches European countries 2000s. Use filter() create data set 3 countries. , use geom_label() label three countries plot.* can see couple interesting trends life expectancy. one country Africa one country Asia sees sharp decline life expxectancy one point. Europe, one country substantially lower life expectancy rest 1950s catches European countries 2000s. Use filter() create data set 3 countries. , use geom_label() label three countries plot.","code":"\ninterest_countries <- country_df %>% filter((year == 1952 & continent == \"Europe\" &\n    lifeExp < 50) | (year == 1992 & continent == \"Africa\" &\n    lifeExp < 30) | (year == 1977 & continent == \"Asia\" & \n    lifeExp < 35))\nggplot(data = country_df, aes(x = year, y = lifeExp, group = country,\n  colour = continent)) +\n  geom_line() +\n  facet_wrap( ~ continent) +\n  scale_colour_brewer(palette = \"Set2\") +\n  labs(x = \"Year\", y = \"Life Expectancy (Years)\", colour = \"Continent\",\n    title = \"Life Expectancy Increases Across time for nearly every country\") +\n  geom_label(data = interest_countries, aes(label = country),\n    nudge_x = 7)"},{"path":"communication-with-rmarkdown.html","id":"rcode-5","chapter":" 6 Communication with RMarkdown","heading":"6.6 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\nhpi_df <- read_csv(\"data/hpi-tidy.csv\")\nhead(hpi_df)\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point()\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  labs(title = \"Countries with a Higher Ecological Footprint Tend to Have Citizens with Longer, Happier Lives\", \n       ## add title\n       subtitle = \"HappyLifeYears is a Combination of Life Expectancy and Citizen Well-Being\", \n       ## add subtitle (smaller text size than the title)\n       caption = \"Data Source: http://happyplanetindex.org/countries\", \n       ## add caption to the bottom of the figure\n       x = \"Ecological Footprint\", ## change x axis label\n       y = \"Happy Life Years\", ## change y axis label\n       colour = \"World Region\") ## change label of colour legend\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  ylim(c(0, 70))\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Accent\")\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_viridis_d(option = \"plasma\")\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label(aes(label = Country))\nplot_df <- hpi_df %>% group_by(Region) %>%\n  filter(HPIRank == min(HPIRank))\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label(data = plot_df, aes(label = Country))\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point(aes(colour = Region)) +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label(data = plot_df, aes(label = Country), show.legend = FALSE)\nlibrary(ggrepel)\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label_repel(data = plot_df, aes(label = Country),\n                   show.legend = FALSE) \nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears, colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label_repel(data = plot_df, aes(label = Country), show.legend = FALSE) +\n  geom_point(data = plot_df, size = 3, shape = 1, show.legend = FALSE) \nplot_df_us <- hpi_df %>%\n  filter(Country == \"United States of America\" | Country == \"Denmark\")\n\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_point(data = plot_df_us, size = 3, shape = 1,\n             show.legend = FALSE) +\n  geom_label_repel(data = plot_df_us, aes(label = Country),\n                   show.legend = FALSE)\nlibrary(ggthemes)\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_point(data = plot_df_us, size = 3, shape = 1, show.legend = FALSE) +\n  geom_label_repel(data = plot_df_us, aes(label = Country), show.legend = FALSE) +\n  theme_solarized()\n\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_point(data = plot_df_us, size = 3, shape = 1, show.legend = FALSE) +\n  geom_label_repel(data = plot_df_us, aes(label = Country), show.legend = FALSE) +\n  theme_fivethirtyeight()\n\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_point(data = plot_df_us, size = 3, shape = 1, show.legend = FALSE) +\n  geom_label_repel(data = plot_df_us, aes(label = Country), show.legend = FALSE) +\n  theme_economist()\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point()"},{"path":"r-basics.html","id":"r-basics","chapter":" 7 R Basics","heading":" 7 R Basics","text":"Goals:describe common classes variables data set.explain R errors come class misspecifications.use indexing reference rows, columns, specific observations tibble data set.explain can use piping.describe server , install packages, benefit using R Projects.MotivationWhy chapter R basics first chapter discuss? certainly advantages things way, also advantages starting something like “classes variables R.”First, ’s inherently interesting thing look . ’s lot fun make plots wrangle data. long someone makes sure variables already “correct” class, ’s need talk .Second, much discuss make sense, previous four chapters belt. ’ll able see misspecified variable classes cause issues certain summaries plots already know make plots get summaries.","code":""},{"path":"r-basics.html","id":"variable-classes-in-r","chapter":" 7 R Basics","heading":"7.1 Variable Classes in R","text":"R different classes variables take, including numeric, factor, character Date, logical. delve specifics classes mean, let’s try make plots illustrate care classes mean.videogame_clean.csv file contains variables video games 2004 - 2019, includinggame, name gamerelease_date, release date gamerelease_date2, second coding release dateprice, price dollars,owners, number owners (given range)median_playtime, median playtime gamemetascore, score website Metacriticprice_cat, 1 Low (less 10.00 dollars), 2 Moderate (10 29.99 dollars), 3 High (30.00 dollars)meta_cat, Metacritic’s review system, following categories: “Overwhelming Dislike,” “Generally Unfavorable,” “Mixed Reviews,” “Generally Favorable,” “Universal Acclaim.”playtime_miss, whether median play time missing (TRUE) (FALSE)data set modified https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-07-30.Run code following R chunk read data.data frame tibble holds variables allowed different classes. variable different class expect, ’ll get strange errors results trying wrangle data make graphics.Run following lines code. cases, using first 100 observations videogame_small. Otherwise, code take long time run.first plot, release_date isn’t ordered according expect (date). Instead, R orders alphabetically.second plot, expect get plot 3 different colours, one level price_cat. Instead, get continuous colour scale, doesn’t make sense, given price_cat can 1, 2, 3.plots rendered correctly variable classes correct underlying data set. point, data provided almost always correct variable classes, default, won’t always case!’ve actually seen issues well (Date issue exercise data continuous colour scale cars data), , instances, code provided “fix” problem. section, ’ll tools fix many class issues !examine output following line codeyou’ll see , top output, right variable names, R provides classes variables tibble.<chr> character, used strings text.<fct> used variables factors, typically used character variables finite number possible values variable can take .<date> used dates.<dbl> stands double used numeric class.<int> numbers integers. practice, much difference class class dbl.<lgl> logical, variables either TRUE FALSE.","code":"\nlibrary(tidyverse)\nvideogame_df <- read_csv(\"data/videogame_clean.csv\")\nhead(videogame_df)\n#> # A tibble: 6 x 15\n#>   game          release_date release_date2 price owners     \n#>   <chr>         <chr>        <date>        <dbl> <chr>      \n#> 1 Half-Life 2   Nov 16, 2004 2004-11-16     9.99 10,000,000…\n#> 2 Counter-Stri… Nov 1, 2004  2004-11-01     9.99 10,000,000…\n#> 3 Counter-Stri… Mar 1, 2004  2004-03-01     9.99 10,000,000…\n#> 4 Half-Life 2:… Nov 1, 2004  2004-11-01     4.99 5,000,000 …\n#> 5 Half-Life: S… Jun 1, 2004  2004-06-01     9.99 2,000,000 …\n#> 6 CS2D          Dec 24, 2004 2004-12-24    NA    1,000,000 …\n#> # … with 10 more variables: median_playtime <dbl>,\n#> #   metascore <dbl>, price_cat <dbl>, meta_cat <chr>,\n#> #   playtime_miss <lgl>, number <dbl>, developer <chr>,\n#> #   publisher <chr>, average_playtime <dbl>,\n#> #   meta_cat_factor <chr>\nvideogame_small <- videogame_df %>% slice(1:100)\nggplot(data = videogame_small, aes(x = release_date, y = price)) +\n  geom_point() \n#> Warning: Removed 5 rows containing missing values\n#> (geom_point).\n\nggplot(data = videogame_small, aes(x = release_date2, y = metascore)) +\n  geom_point(aes(colour = price_cat))\n#> Warning: Removed 43 rows containing missing values\n#> (geom_point).\nhead(videogame_df)\n#> # A tibble: 6 x 15\n#>   game          release_date release_date2 price owners     \n#>   <chr>         <chr>        <date>        <dbl> <chr>      \n#> 1 Half-Life 2   Nov 16, 2004 2004-11-16     9.99 10,000,000…\n#> 2 Counter-Stri… Nov 1, 2004  2004-11-01     9.99 10,000,000…\n#> 3 Counter-Stri… Mar 1, 2004  2004-03-01     9.99 10,000,000…\n#> 4 Half-Life 2:… Nov 1, 2004  2004-11-01     4.99 5,000,000 …\n#> 5 Half-Life: S… Jun 1, 2004  2004-06-01     9.99 2,000,000 …\n#> 6 CS2D          Dec 24, 2004 2004-12-24    NA    1,000,000 …\n#> # … with 10 more variables: median_playtime <dbl>,\n#> #   metascore <dbl>, price_cat <dbl>, meta_cat <chr>,\n#> #   playtime_miss <lgl>, number <dbl>, developer <chr>,\n#> #   publisher <chr>, average_playtime <dbl>,\n#> #   meta_cat_factor <chr>"},{"path":"r-basics.html","id":"referencing-variables-and-using-str","chapter":" 7 R Basics","heading":"7.1.1 Referencing Variables and Using str()","text":"can use name_of_dataset$name_of_variable look specific variable data set:prints first thousand entries variable game. ways get class variable: way use often str(), stands “structure,” gives class variable, number observations (26688), well first couple observations:can also get variable’s class directly class()","code":"\nvideogame_df$game\nstr(videogame_df$game)\n#>  chr [1:26688] \"Half-Life 2\" \"Counter-Strike: Source\" ...\nclass(videogame_df$game)\n#> [1] \"character\""},{"path":"r-basics.html","id":"classes-in-detail","chapter":" 7 R Basics","heading":"7.2 Classes in Detail","text":"following gives summary information class variables R:","code":""},{"path":"r-basics.html","id":"chr-and-fct-class","chapter":" 7 R Basics","heading":"7.2.1 <chr> and <fct> Class","text":"character class, R give warning /missing value try perform numerical operations:also can’t convert character class numeric. can, however, convert character class <fct> class, using .factor(). <fct> class useful discuss forcats package, isn’t particularly useful now.general, ._____ lets convert classes. Note, however, aren’t saving converted variable anywhere. wanted conversion factor saved data set, can use mutate():R functions, won’t matter whether variable class character class factor. general, though, character classes variables ton different levels, like name videogame, whereas factors reserved categorical variables finite number levels.","code":"\nmean(videogame_df$game)\n#> Warning in mean.default(videogame_df$game): argument is not\n#> numeric or logical: returning NA\n#> [1] NA\nvideogame_df %>% summarise(maxgame = max(game))\n#> # A tibble: 1 x 1\n#>   maxgame\n#>   <chr>  \n#> 1 <NA>\nclass(videogame_df$meta_cat)\n#> [1] \"character\"\nclass(as.factor(videogame_df$meta_cat))\n#> [1] \"factor\"\nvideogame_df <- videogame_df %>%\n  mutate(meta_cat_factor = as.factor(meta_cat))\nstr(videogame_df$meta_cat_factor)\n#>  Factor w/ 4 levels \"Generally Favorable\",..: 4 1 3 NA NA NA 4 1 3 NA ..."},{"path":"r-basics.html","id":"date-class","chapter":" 7 R Basics","heading":"7.2.2 <date> Class","text":"<date> class used dates, <datetime> class used Dates times. R requires specific format dates times. Note , human eye, following variables contain dates, one class <date>:release_date class character, issue odd ordering dates earlier. can try converting using .Date, function doesn’t always work:Dates times can pretty complicated. fact, spend entire week covering using lubridate package.variables Date format, like release_date2, can use numerical operations:think taking median taking mean date class means?","code":"\nstr(videogame_df$release_date)\n#>  chr [1:26688] \"Nov 16, 2004\" \"Nov 1, 2004\" ...\nstr(videogame_df$release_date2)\n#>  Date[1:26688], format: \"2004-11-16\" \"2004-11-01\" \"2004-03-01\" ...\nas.Date(videogame_df$release_date)\n#> Error in charToDate(x): character string is not in a standard unambiguous format\nmedian(videogame_df$release_date2, na.rm = TRUE)\n#> [1] \"2017-06-09\"\nmean(videogame_df$release_date2, na.rm = TRUE)\n#> [1] \"2016-09-15\""},{"path":"r-basics.html","id":"dbl-and-int-class","chapter":" 7 R Basics","heading":"7.2.3 <dbl> and <int> Class","text":"Class <dbl> <int> probably self-explanatory classes. <dbl>, numeric class, just variables numbers <int> integers (…, -2, -1, 0, 1, 2, ….). can numerical operations either classes (’ve throughout semester). purposes, two classes interchangeable.Problems arise numeric variables coded something non-numeric, non-numeric variables coded numeric. example, examine:price_cat categorical coded 1 cheap games, 2 moderately priced games, 3 expensive games. Therefore, R thinks variable numeric, , ’s actually factor.cause odd colour scale encountered earlier can fixed converting price_cat factor:","code":"\nstr(videogame_df$price)\n#>  num [1:26688] 9.99 9.99 9.99 4.99 9.99 ...\nstr(videogame_df$price_cat)\n#>  num [1:26688] 1 1 1 1 1 NA 2 1 1 1 ...\nstr(as.factor(videogame_df$price_cat))\n#>  Factor w/ 3 levels \"1\",\"2\",\"3\": 1 1 1 1 1 NA 2 1 1 1 ...\nvideogame_df <- videogame_df %>%\n  mutate(price_factor = as.factor(price_cat)) \nggplot(data = videogame_df, aes(x = release_date2, y = metascore)) +\n  geom_point(aes(colour = price_factor))\n#> Warning: Removed 23838 rows containing missing values\n#> (geom_point)."},{"path":"r-basics.html","id":"lgl-class","chapter":" 7 R Basics","heading":"7.2.4 <lgl> Class","text":"Finally, class variables called logical. variables can take 2 values: TRUE FALSE. example, playtime_miss, variable whether median_playtime variable missing , logical:’s little strange first, R can perform numeric operations logical classes. R treat every TRUE 1 every FALSE 0. Therefore, sum() gives total number TRUEs mean() gives proportion TRUEs. , can find number proportion games missing median_playtime :’s lot games missing information!’ve actually used ideas logical variables quite time now, particularly statements involving if_else(), case_when(), filter(), mutate().primary purpose section able identify variable classes able convert different variable types mutate() “fix” variables incorrect class.","code":"\nstr(videogame_df$playtime_miss)\n#>  logi [1:26688] FALSE FALSE FALSE TRUE TRUE FALSE ...\nsum(videogame_df$playtime_miss)\n#> [1] 25837\nmean(videogame_df$playtime_miss)\n#> [1] 0.968113"},{"path":"r-basics.html","id":"exercise-6-2","chapter":" 7 R Basics","heading":"7.2.5 Exercises","text":"Exercises marked * indicate exercise solution end chapter 7.7.use fitness data set set exercises, data set issues variable class discussed. However, week 1, work work fix issues already done saw data. Now, ’ll get fix couple issues! Read data set :issue following plot? ’s need fix plot (’ll see fix introduce lubridate package).issue following plot? ’s need fix plot (’ll see fix introduce lubridate package).* issue following plot? figure issue, use mutate() create new variable fixes issue reconstruct graph.* issue following plot? figure issue, use mutate() create new variable fixes issue reconstruct graph.* third variable data set incorrect class?* third variable data set incorrect class?Create new variable, called step_goal 1 TRUE least 10000 steps walked 0 FALSE fewer 10000 steps walked. Using variable, find total number days goal met proportion days goal met.Create new variable, called step_goal 1 TRUE least 10000 steps walked 0 FALSE fewer 10000 steps walked. Using variable, find total number days goal met proportion days goal met.","code":"\nlibrary(tidyverse)\nfitness_df <- read_csv(\"data/higham_fitness_notclean.csv\")"},{"path":"r-basics.html","id":"object-types-and-subsetting","chapter":" 7 R Basics","heading":"7.3 Object Types and Subsetting","text":"Variables different classes can stored variety different objects R. almost exclusively used tibble object type. tidy tibbleis “rectangular” specific number rows columns.columns variableseach column must elements class, different columns can different classes. allows us character numeric variables tibble.","code":""},{"path":"r-basics.html","id":"tibble-and-data.frame","chapter":" 7 R Basics","heading":"7.3.1 tibble and data.frame","text":"tibble object similar data.frame object. can also check type object ’re working using str() command:small section tibbles coming weeks won’t focus . , take note , reference specific element tibble, called indexing, can use [# , #]. , example, videogame_df[5, 3] grabs value fifth row third column:often, ’d want grab entire row (range rows) entire column. can leaving row number blank (grab entire column) leaving column number blank (grab entire row):can also grab range columns rows using : operator:can grab different columns rows using c():get rid entire row column, use -: videogame_df[ ,-c(1, 2)] drops first second columns videogame_df[-c(1, 2), ] drops first second rows.","code":"\nstr(videogame_df) ## look at the beginning to see \"tibble\"\nvideogame_df[5, 3]\n#> # A tibble: 1 x 1\n#>   release_date2\n#>   <date>       \n#> 1 2004-06-01\nvideogame_df[ ,3] ## grab the third column\n\nvideogame_df[5, ] ## grab the fifth row\n3:7\n\nvideogame_df[ ,3:7] ## grab columns 3 through 7\n\nvideogame_df[3:7, ] ## grab rows 3 through 7\nvideogame_df[ ,c(1, 3, 4)] ## grab columns 1, 3, and 4\n\nvideogame_df[c(1, 3, 4), ] ## grab rows 1, 3, and 4"},{"path":"r-basics.html","id":"vectors","chapter":" 7 R Basics","heading":"7.3.2 Vectors","text":"vector object holds “things,” elements, class. can create vector R using c() function, stands “concatenate.” ’ve used c() function bind things together; just hadn’t yet discussed context creating vector.Notice vec2 character class. R requires elements vector one class; since R knows b can’t numeric, makes numbers characters well.Using dataset$variable draws vector tibble data.frame:wanted make vector “hand,” ’d need lot patience: c(96, 88, 65, NA, NA, NA, 93, .........)Just like tibbles, can save vectors something later use:get mean metascore using dplyr functions?Vectors one-dimensional: want grab 100th element vector just use name_of_vector[100]:aware , ’re coming math perspective, “vector” R doesn’t correspond “vector” mathematics physics.","code":"\nvec1 <- c(1, 3, 2)\nvec2 <- c(\"b\", 1, 2)\nvec3 <- c(FALSE, FALSE, TRUE)\nstr(vec1); str(vec2); str(vec3)\n#>  num [1:3] 1 3 2\n#>  chr [1:3] \"b\" \"1\" \"2\"\n#>  logi [1:3] FALSE FALSE TRUE\nvideogame_df$metascore\nmetavec <- videogame_df$metascore\nmean(metavec, na.rm = TRUE)\n#> [1] 71.89544\nmetavec[100] ## 100th element is missing\n#> [1] NA"},{"path":"r-basics.html","id":"lists","chapter":" 7 R Basics","heading":"7.3.3 Lists","text":"Lists one flexible objects R: can put objects different classes list lists aren’t required rectangular (like tibbles ). Lists extremely useful flexibility, , won’t use much class. Therefore, just see example list moving :testlist four elements: single character \"\", single number 4, vector 1, 4, 2, 6, tibble couple variables. Lists can therefore used store complex information wouldn’t easily stored vector tibble.","code":"\ntestlist <- list(\"a\", 4, c(1, 4, 2, 6),\n                 tibble(x = c(1, 2), y = c(3, 2)))\ntestlist\n#> [[1]]\n#> [1] \"a\"\n#> \n#> [[2]]\n#> [1] 4\n#> \n#> [[3]]\n#> [1] 1 4 2 6\n#> \n#> [[4]]\n#> # A tibble: 2 x 2\n#>       x     y\n#>   <dbl> <dbl>\n#> 1     1     3\n#> 2     2     2"},{"path":"r-basics.html","id":"exercise-6-3","chapter":" 7 R Basics","heading":"7.3.4 Exercises","text":"Exercises marked * indicate exercise solution end chapter 7.7.* Look subsetting commands [ , ]. dplyr functions can use thing?* Look subsetting commands [ , ]. dplyr functions can use thing?Create tibble called last100 last 100 days data set using (1) indexing [ , ] (2) dplyr function.Create tibble called last100 last 100 days data set using (1) indexing [ , ] (2) dplyr function.Create tibble doesn’t flights variable using (1) indexing [ , ] (2) dplyr function.Create tibble doesn’t flights variable using (1) indexing [ , ] (2) dplyr function.* Use following steps create new variable weekend_ind, “weekend” day week Saturday Sunday “weekday” day week day. current weekday variable coded 1 represents Sunday, 2 represents Monday, …., 7 represents Saturday.* Use following steps create new variable weekend_ind, “weekend” day week Saturday Sunday “weekday” day week day. current weekday variable coded 1 represents Sunday, 2 represents Monday, …., 7 represents Saturday.Create vector numbers corresponding two weekend days. Name vector create second vector numbers corresponding five weekday days.Create vector numbers corresponding two weekend days. Name vector create second vector numbers corresponding five weekday days.Use dplyr functions %% operator create new weekend_ind variable. can use following code chunk help %% :Use dplyr functions %% operator create new weekend_ind variable. can use following code chunk help %% :","code":"\n1 %in% c(1, 2, 3, 4)\n2 %in% c(1, 2, 3, 4)\n\n2 %in% c(3, 4, 5, 6)"},{"path":"r-basics.html","id":"piping-with-magrittr","chapter":" 7 R Basics","heading":"7.4 Piping with magrittr","text":"pipe %>% loaded automatically tidyverse library loaded, operator comes magrittr package. ’ve using pipe quite bit, let’s delve little deeper ’s actually .Let’s say want filter() data set include observations metascore isn’t missing. ’ve using:pipe putting videogame_df first argument filter() function piping statement chunk equivalent :want first filter games non-missing metascore, get rid observations median play time 0, obtain “median” median_playtime 3 price categories, typically useWe see summary , general, games tend give “bang buck”: expensive games tend larger median play time. Consecutive pipes build : can slowly build pipe step--step. Starting top, videogame_df first argument filter(!.na(metascore)) function:filter(videogame_df, !.na(metascore)) first argument filter(median_playtime > 0):filter(filter(videogame_df, !.na(metascore)), median_playtime > 0) first argument group_by(price_cat):group_by(filter(filter(videogame_df, !.na(metascore)), median_playtime > 0), price_cat) first argument summarise(avg_med_time = median(median_playtime, na.rm = TRUE)):obtain result without %>% pipe. example shows , purposes, pipe useful aiding readability code. ’s lot easier see ’s happening code chunk pipes previous code chunk without pipe.","code":"\nvideogame_df %>% filter(!is.na(metascore))\nfilter(videogame_df, !is.na(metascore))\nvideogame_df %>% filter(!is.na(metascore)) %>%\n  filter(median_playtime > 0) %>%\n  group_by(price_cat) %>%\n  summarise(avg_med_time = median(median_playtime, na.rm = TRUE))\nfilter(videogame_df, !is.na(metascore))\nfilter(filter(videogame_df, !is.na(metascore)), median_playtime > 0)\ngroup_by(filter(filter(videogame_df, !is.na(metascore)),\n                median_playtime > 0),\n  price_cat)\nsummarise(group_by(filter(filter(videogame_df, !is.na(metascore)),\n  median_playtime > 0), price_cat), \n  avg_med_time = median(median_playtime, na.rm = TRUE))"},{"path":"r-basics.html","id":"when-you-cant-use-the-pipe","chapter":" 7 R Basics","heading":"7.4.1 When You Can’t Use the Pipe","text":", pipe convenient way put precedes pipe first argument function follows pipe. ’s important understand learn R , functions tidyverse purposefully made make good use pipe, functions R utilize pipe. functions tidyverse first argument data set (can use pipes consecutively), isn’t case R functions.example, taken STAT 213, ’ve used lm() fit many different types linear models. haven’t taken STAT 213, lm(response ~ explanatory) stands “linear model” can used fit simple linear regression model learned STAT 113. might expect something like work:throws us error. Typing ?lm reveals first argument formula fit model, data set. function trying runwhich doesn’t work arguments function mixed (formula appear first data set appear second).","code":"\nvideogame_df %>% lm(metascore ~ price)\n#> Error in as.data.frame.default(data): cannot coerce class '\"formula\"' to a data.frame\nlm(videogame_df, metascore ~ price)\n#> Error in as.data.frame.default(data): cannot coerce class '\"formula\"' to a data.frame"},{"path":"r-basics.html","id":"exercise-6-4","chapter":" 7 R Basics","heading":"7.4.2 Exercises","text":"Exercises marked * indicate exercise solution end chapter 7.7.* Recode following look cleaner using pipe %>%:Explain following code gives warning message returns NA. Use list Arguments ?mean explanation.","code":"\nsummarise(group_by(filter(fitness_df, weekday == 1 | weekday == 7),\n                   month),\n          meanweekend = mean(distance, na.rm = TRUE)) \n#> # A tibble: 12 x 2\n#>    month meanweekend\n#>    <dbl>       <dbl>\n#>  1     1        3.96\n#>  2     2        4.94\n#>  3     3        5.15\n#>  4     4        5.48\n#>  5     5        4.96\n#>  6     6        3.78\n#>  7     7        5.81\n#>  8     8        5.59\n#>  9     9        4.62\n#> 10    10        3.98\n#> 11    11        2.86\n#> 12    12        3.55\nfitness_df %>% mean(distance, na.rm = TRUE)\n#> Warning in mean.default(., distance, na.rm = TRUE): argument\n#> is not numeric or logical: returning NA\n#> [1] NA"},{"path":"r-basics.html","id":"r-cleanup-other-topics","chapter":" 7 R Basics","heading":"7.5 R Cleanup: Other Topics","text":"","code":""},{"path":"r-basics.html","id":"r-projects-and-working-directories","chapter":" 7 R Basics","heading":"7.5.1 R Projects and Working Directories","text":"R Projects convenient way keep related code, data sets, analyses together. Read short introduction R Data Science : https://r4ds..co.nz/workflow-projects.html#paths--directories https://r4ds..co.nz/workflow-projects.html#rstudio-projects.rarely use absolute directory?Look top bottom-left terminal window. ’ve made R project (!), see file path current folder ’re working . R Studio look files default. ,starts path given console, looks folder called data path looks file called higham_fitness_notclean.csv data folder.zipped project sent someone else, ’d able open read data file without needing change directory code!","code":"\nfitness_df <- read_csv(\"data/higham_fitness_notclean.csv\")\n#> \n#> ── Column specification ────────────────────────────────────\n#> cols(\n#>   Start = col_character(),\n#>   month = col_double(),\n#>   weekday = col_double(),\n#>   dayofyear = col_double(),\n#>   distance = col_double(),\n#>   steps = col_double(),\n#>   flights = col_double(),\n#>   active_cals = col_double()\n#> )"},{"path":"r-basics.html","id":"r-studio-server","chapter":" 7 R Basics","heading":"7.5.2 R Studio Server","text":"R Studio server computer set-carry R-based analyses students remote access computer (case, SLU Login credentials). might helpful think server large machine keyboard screen: ’s purpose execute code.R R Studio completely free, can install computers (Chromebooks though). R Studio server couple advantages, particularly classroom workshop setting:using server ensures using version R. theory, one person gets error, everyone get error.using server ensures using version R. theory, one person gets error, everyone get error.installing R R Studio personal device much easier ’ve experience using server.installing R R Studio personal device much easier ’ve experience using server.don’t need computer capable running R use server (can use tablet Chromebook since server actual computation).don’t need computer capable running R use server (can use tablet Chromebook since server actual computation).week, however, move away server , device can install R (pretty much computer isn’t Chromebook), install R device. Though server advantages, also disadvantages:won’t SLU login forever, , wanted use R post graduation, ’d need know install .won’t SLU login forever, , wanted use R post graduation, ’d need know install .haven’t experience installing R packages. quite easy , ’ve installed necessary R packages server us haven’t worry step.haven’t experience installing R packages. quite easy , ’ve installed necessary R packages server us haven’t worry step.server requires good Internet access also potential crash.server requires good Internet access also potential crash.","code":""},{"path":"r-basics.html","id":"installing-r-packages","chapter":" 7 R Basics","heading":"7.5.3 Installing R Packages","text":"far, either one statistics faculty members installed packages ’ve needed use server globally. packages include tidyverse, ggthemes, ggrepel. However, want use package isn’t installed server, , want use package using R Studio personal computer, need install first.Installation needs happen (upgrade R, usually doesn’t happen often), whereas package needs loaded library() every time open R. analogy lightbulb might helpful. need screw lightbulb socket , , every time want lightbulb provide light, need flip light switch.lightbulb analogy, putting lightbulb socket correspond ? flipping light switch correspond ?R computer, ’ll need install packages want use (, remember just need install package ).","code":""},{"path":"r-basics.html","id":"exercise-6-5","chapter":" 7 R Basics","heading":"7.5.4 Exercises","text":"Exercises marked * indicate exercise solution end chapter 7.7.* Click “Packages” button lower-right hand window bring packages menu. Instead using library(name_of_package), can click checkbox package name load R. Try un-checking re-checking tidyverse. Explain, reproducibility perspective, loading packages way good practice.* Click “Packages” button lower-right hand window bring packages menu. Instead using library(name_of_package), can click checkbox package name load R. Try un-checking re-checking tidyverse. Explain, reproducibility perspective, loading packages way good practice.Occasionally, something odd happen R session “turn turn back ” strategy best fix. Save current file, restart R clicking Session -> Restart R.Occasionally, something odd happen R session “turn turn back ” strategy best fix. Save current file, restart R clicking Session -> Restart R.’ve seen R Projects useful keeping data analysis organized. large-scale data analysis projects, ’s usually nice specific folder “data” within R Project folder. Thus far, used data folder, also put data set directory R Project. Move fitness data set data folder folder current R Project.\n, click checkbox next video games data set fitness data set, click “” -> Move select main folder.’ve seen R Projects useful keeping data analysis organized. large-scale data analysis projects, ’s usually nice specific folder “data” within R Project folder. Thus far, used data folder, also put data set directory R Project. Move fitness data set data folder folder current R Project.\n, click checkbox next video games data set fitness data set, click “” -> Move select main folder.Now data set different spot, ’ll need let R know well read_csv() statements! , simply remove data/ name file read_csv() statement current .Rmd file statement involving fitness data.Now data set different spot, ’ll need let R know well read_csv() statements! , simply remove data/ name file read_csv() statement current .Rmd file statement involving fitness data.","code":""},{"path":"r-basics.html","id":"chapexercise-6","chapter":" 7 R Basics","heading":"7.6 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 7.7.class, work installing R R Studio personal laptop. already R R Studio installed basic packages working (STAT 213 Covid Spring 2020 class), can come class ~ 30 minutes late (though ’re also welcome come time work things first 45 minutes). ’re unsure whether device can install R R Studio, shoot email. probably can, unless ’s Chromebook.Step 1. Installing R: https://cran.rstudio.com/ choose appropriate version. Go installation steps.Step 2. isn’t necessary, ’s interesting see basic R interface looks like without R Studio. Open R pretty much just see something resembles lower-left window R Studio.Step 3. Installing R Studio: https://rstudio.com/products/rstudio/download/. Choose free version choose either Mac version Windows version (assuming don’t Linux). Go installation steps.Step 4a. Open R Studio. Recall one thing server change R Markdown option results plots wouldn’t appear -line. change , click R Studio -> Preferences -> R Markdown uncheck “Show output inline R Markdown documents.”Step 4b. Change colour theme! fun, least ….Go R Studio -> Preferences -> Appearance choose theme like. ’ve mine Cobalt really long time, Vibrant Ink theme always , tempting .Step 5. want STAT 234 materials server (!), ’ll need download personal device. Click checkbox next STAT 234 folder, click -> Export -> Download. now zipped folder materials Downloads folder. Double click unzip folder move STAT 234 folder place ’s convenient (since ’ll using lot semester, one place put Desktop).Verify contents downloaded opening Week5_R_Basics R Project double clicking R Project icon Week5 folder.Step 6. ’s lot packages ’ve used already installed server. far, largest package (one ’s likely give error installation) tidyverse package. Install package usingStep 7. Open Week4 Project new window verify .Rmd files can knit (’ll least need install ggthemes ggrepel possibly couple packages ’m thinking ).R installed ready go, work following exercises pertaining video game data set.* Read data set use filter() remove rows missing metascores, missing median playtime, median playtime 0 hours.Note: usually don’t want remove missing values without valid reason. case, missing metascore means game wasn’t “major” enough get enough critic reviews, missing 0 hour median playtime means weren’t enough users uploaded playtime database. Therefore, analyses constructed games popular enough get enough reviews metacritic enough users upload median playtimes.* Make scatterplot median_playtime y-axis metascore x-axis filtered data set.* Make scatterplot median_playtime y-axis metascore x-axis filtered data set.* Something may notice many points directly overlap one another. common least one variables scatterplot discrete: metascore can take integer values case. Change geom_point() previous plot geom_jitter(). , use help write sentence geom_jitter() .* Something may notice many points directly overlap one another. common least one variables scatterplot discrete: metascore can take integer values case. Change geom_point() previous plot geom_jitter(). , use help write sentence geom_jitter() .* Another option control point transparency alpha. geom_jitter() statement, change alpha can still see points, can tell plot lot points overlapping.* Another option control point transparency alpha. geom_jitter() statement, change alpha can still see points, can tell plot lot points overlapping.* Label points median playtimes 1500 hours. may want use ggrepel package labels don’t overlap.* Label points median playtimes 1500 hours. may want use ggrepel package labels don’t overlap.Choose one games got labeled Google game’s median, possibly average, play time. vicinity median_playtime recorded data set?Choose one games got labeled Google game’s median, possibly average, play time. vicinity median_playtime recorded data set?done outliers? discuss investigate issue class.done outliers? discuss investigate issue class.","code":"\ninstall.packages(\"tidyverse\")\nvideogame_df <- read_csv(\"data/videogame_clean.csv\")"},{"path":"r-basics.html","id":"solutions-6","chapter":" 7 R Basics","heading":"7.7 Exercise Solutions","text":"","code":""},{"path":"r-basics.html","id":"variable-classes-s","chapter":" 7 R Basics","heading":"7.7.1 Variable Classes S","text":"","code":""},{"path":"r-basics.html","id":"classes-in-detail-s","chapter":" 7 R Basics","heading":"7.7.2 Classes in Detail S","text":"* issue following plot? figure issue, use mutate() create new variable fixes issue reconstruct graph.issue weekday factor, numeric.* third variable data set incorrect class?Month ordered factor, numeric.","code":"\nfitness_df <- fitness_df %>% mutate(weekday_cat = as.factor(weekday))\nggplot(data = fitness_df, aes(x = active_cals)) +\n  geom_freqpoly(aes(group = weekday_cat, colour = weekday_cat)) +\n  scale_colour_viridis_d()\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`."},{"path":"r-basics.html","id":"object-types-s","chapter":" 7 R Basics","heading":"7.7.3 Object Types S","text":"* Look subsetting commands [ , ]. dplyr functions can use thing?slice() can used row indexing select() can used column indexing.* Use following steps create new variable weekend_ind, “weekend” day week Saturday Sunday “weekday” day week day. current weekday variable coded 1 represents Sunday, 2 represents Monday, …., 7 represents Saturday.Create vector numbers corresponding two weekend days. Name vector create second vector numbers corresponding five weekday days.Use dplyr functions %% operator create new weekend_ind variable. can use following code chunk help %% :","code":"\nvecweekend <- c(1, 7)\nvecweekday <- 2:6 ## or c(2, 3, 4, 5, 6)\n1 %in% c(1, 2, 3, 4)\n#> [1] TRUE\n2 %in% c(1, 2, 3, 4)\n#> [1] TRUE\n\n2 %in% c(3, 4, 5, 6)\n#> [1] FALSE\nfitness_df %>%\n  mutate(weekend_ind = case_when(weekday %in% vecweekend ~ \"weekend\",\n                                 weekday %in% vecweekday ~ \"weekday\")) %>%\n  select(weekend_ind, everything())\n#> # A tibble: 584 x 10\n#>    weekend_ind Start month weekday dayofyear distance  steps\n#>    <chr>       <chr> <dbl>   <dbl>     <dbl>    <dbl>  <dbl>\n#>  1 weekday     11/2…    11       4       332    0.930  1885.\n#>  2 weekday     11/2…    11       5       333    4.64   8953.\n#>  3 weekday     11/3…    11       6       334    6.05  11665 \n#>  4 weekend     12/1…    12       7       335    6.80  12117 \n#>  5 weekend     12/2…    12       1       336    4.61   8925.\n#>  6 weekday     12/3…    12       2       337    3.96   7205 \n#>  7 weekday     12/4…    12       3       338    6.60  12483.\n#>  8 weekday     12/5…    12       4       339    4.91   9258.\n#>  9 weekday     12/6…    12       5       340    7.50  14208 \n#> 10 weekday     12/7…    12       6       341    4.27   8269.\n#> # … with 574 more rows, and 3 more variables:\n#> #   flights <dbl>, active_cals <dbl>, weekday_cat <fct>\n\n## can also use if_else, which is actually a little simpler in this case:\nfitness_df %>% mutate(weekend_ind = if_else(weekday %in% vecweekend,\n  true = \"weekend\", false = \"weekday\")) %>%\n  select(weekend_ind, everything())\n#> # A tibble: 584 x 10\n#>    weekend_ind Start month weekday dayofyear distance  steps\n#>    <chr>       <chr> <dbl>   <dbl>     <dbl>    <dbl>  <dbl>\n#>  1 weekday     11/2…    11       4       332    0.930  1885.\n#>  2 weekday     11/2…    11       5       333    4.64   8953.\n#>  3 weekday     11/3…    11       6       334    6.05  11665 \n#>  4 weekend     12/1…    12       7       335    6.80  12117 \n#>  5 weekend     12/2…    12       1       336    4.61   8925.\n#>  6 weekday     12/3…    12       2       337    3.96   7205 \n#>  7 weekday     12/4…    12       3       338    6.60  12483.\n#>  8 weekday     12/5…    12       4       339    4.91   9258.\n#>  9 weekday     12/6…    12       5       340    7.50  14208 \n#> 10 weekday     12/7…    12       6       341    4.27   8269.\n#> # … with 574 more rows, and 3 more variables:\n#> #   flights <dbl>, active_cals <dbl>, weekday_cat <fct>"},{"path":"r-basics.html","id":"piping-s","chapter":" 7 R Basics","heading":"7.7.4 Piping S","text":"* Recode following look cleaner using pipe %>%:","code":"\nsummarise(group_by(filter(fitness_df, weekday == 1 | weekday == 7),\n                   month),\n          meanweekend = mean(distance, na.rm = TRUE)) \n#> # A tibble: 12 x 2\n#>    month meanweekend\n#>    <dbl>       <dbl>\n#>  1     1        3.96\n#>  2     2        4.94\n#>  3     3        5.15\n#>  4     4        5.48\n#>  5     5        4.96\n#>  6     6        3.78\n#>  7     7        5.81\n#>  8     8        5.59\n#>  9     9        4.62\n#> 10    10        3.98\n#> 11    11        2.86\n#> 12    12        3.55\nfitness_df %>% filter(weekday == 1 | weekday == 7) %>%\n  group_by(month) %>%\n  summarise(meanweekend = mean(distance, na.rm = TRUE)) \n#> # A tibble: 12 x 2\n#>    month meanweekend\n#>    <dbl>       <dbl>\n#>  1     1        3.96\n#>  2     2        4.94\n#>  3     3        5.15\n#>  4     4        5.48\n#>  5     5        4.96\n#>  6     6        3.78\n#>  7     7        5.81\n#>  8     8        5.59\n#>  9     9        4.62\n#> 10    10        3.98\n#> 11    11        2.86\n#> 12    12        3.55"},{"path":"r-basics.html","id":"other-r-topics-s","chapter":" 7 R Basics","heading":"7.7.5 Other R Topics S","text":"* Click “Packages” button lower-right hand windown bring packages menu. Instead using library(name_of_package), can click checkbox package name load R. Try un-checking re-checking tidyverse. Explain, reproducibility perspective, loading packages way good practice.loaded package checking box, analysis, gave code someone else, person couldn’t easily see packages loaded . Therefore, wouldn’t necessarily able reproduce results exactly.","code":""},{"path":"r-basics.html","id":"chapexercise-6-S","chapter":" 7 R Basics","heading":"7.7.6 Chapter Exercises S","text":"* Read data set use filter() remove rows missing metascores, missing median playtime, median playtime 0 hours.Note: usually don’t want remove missing values without valid reason. case, missing metascore means game wasn’t “major” enough get enough critic reviews, missing 0 hour median playtime means weren’t enough users uploaded playtime database. Therefore, analyses constructed games popular enough get enough reviews metacritic enough users upload median playtimes.* Make scatterplot median_playtime y-axis metascore x-axis filtered data set.* Something may notice many points directly overlap one another. common least one variables scatterplot discrete: metascore can take integer values case. Change geom_point() previous plot geom_jitter(). , use help write sentence geom_jitter() .geom_jitter() adds small amount “noise” data point points don’t overlap quite much.* Another option control point transparency alpha. geom_jitter() statement, change alpha can still see points, can tell plot lot points overlapping.* Label points median playtimes 1500 hours. may want use ggrepel package labels don’t overlap.","code":"\nvideogame_df <- read_csv(\"data/videogame_clean.csv\")\nvideogame_nomiss <- videogame_df %>%\n  filter(!is.na(median_playtime) &\n           !is.na(metascore) &\n           median_playtime != 0)\nggplot(data = videogame_nomiss, aes(x = metascore,\n                                    y = median_playtime)) + \n  geom_point()\nggplot(data = videogame_nomiss, aes(x = metascore,\n                                    y = median_playtime)) + \n  geom_jitter()\nggplot(data = videogame_nomiss, aes(x = metascore,\n                                    y = median_playtime)) + \n  geom_jitter(alpha = 0.4)\n## can see a lot of ponits have median playtimes close to 0\nlibrary(ggrepel)\nvideogame_long <- videogame_nomiss %>% filter(median_playtime > 1500)\nggplot(data = videogame_nomiss,\n       aes(x = metascore, y = median_playtime)) + \n  geom_jitter(alpha = 0.4) +\n  geom_label_repel(data = videogame_long, aes(label = game))"},{"path":"r-basics.html","id":"rcode-6","chapter":" 7 R Basics","heading":"7.8 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\nvideogame_df <- read_csv(\"data/videogame_clean.csv\")\nhead(videogame_df)\nvideogame_small <- videogame_df %>% slice(1:100)\nggplot(data = videogame_small, aes(x = release_date, y = price)) +\n  geom_point() \n\nggplot(data = videogame_small, aes(x = release_date2, y = metascore)) +\n  geom_point(aes(colour = price_cat))\nhead(videogame_df)\nvideogame_df$game\nstr(videogame_df$game)\nclass(videogame_df$game)\nmean(videogame_df$game)\nvideogame_df %>% summarise(maxgame = max(game))\nclass(videogame_df$meta_cat)\nclass(as.factor(videogame_df$meta_cat))\nvideogame_df <- videogame_df %>%\n  mutate(meta_cat_factor = as.factor(meta_cat))\nstr(videogame_df$meta_cat_factor)\nstr(videogame_df$release_date)\nstr(videogame_df$release_date2)\nmedian(videogame_df$release_date2, na.rm = TRUE)\nmean(videogame_df$release_date2, na.rm = TRUE)\nstr(videogame_df$price)\nstr(videogame_df$price_cat)\nstr(as.factor(videogame_df$price_cat))\nvideogame_df <- videogame_df %>%\n  mutate(price_factor = as.factor(price_cat)) \nggplot(data = videogame_df, aes(x = release_date2, y = metascore)) +\n  geom_point(aes(colour = price_factor))\nstr(videogame_df$playtime_miss)\nsum(videogame_df$playtime_miss)\nmean(videogame_df$playtime_miss)\nstr(videogame_df) ## look at the beginning to see \"tibble\"\nvideogame_df[5, 3]\nvideogame_df[ ,3] ## grab the third column\n\nvideogame_df[5, ] ## grab the fifth row\n3:7\n\nvideogame_df[ ,3:7] ## grab columns 3 through 7\n\nvideogame_df[3:7, ] ## grab rows 3 through 7\nvideogame_df[ ,c(1, 3, 4)] ## grab columns 1, 3, and 4\n\nvideogame_df[c(1, 3, 4), ] ## grab rows 1, 3, and 4\nvec1 <- c(1, 3, 2)\nvec2 <- c(\"b\", 1, 2)\nvec3 <- c(FALSE, FALSE, TRUE)\nstr(vec1); str(vec2); str(vec3)\nvideogame_df$metascore\nmetavec <- videogame_df$metascore\nmean(metavec, na.rm = TRUE)\nmetavec[100] ## 100th element is missing\ntestlist <- list(\"a\", 4, c(1, 4, 2, 6),\n                 tibble(x = c(1, 2), y = c(3, 2)))\ntestlist\nvideogame_df %>% filter(!is.na(metascore))\nfilter(videogame_df, !is.na(metascore))\nvideogame_df %>% filter(!is.na(metascore)) %>%\n  filter(median_playtime > 0) %>%\n  group_by(price_cat) %>%\n  summarise(avg_med_time = median(median_playtime, na.rm = TRUE))\nfilter(videogame_df, !is.na(metascore))\nfilter(filter(videogame_df, !is.na(metascore)), median_playtime > 0)\ngroup_by(filter(filter(videogame_df, !is.na(metascore)),\n                median_playtime > 0),\n  price_cat)\nsummarise(group_by(filter(filter(videogame_df, !is.na(metascore)),\n  median_playtime > 0), price_cat), \n  avg_med_time = median(median_playtime, na.rm = TRUE))\nfitness_df <- read_csv(\"data/higham_fitness_notclean.csv\")"},{"path":"factors-with-forcats.html","id":"factors-with-forcats","chapter":" 8 Factors with forcats","heading":" 8 Factors with forcats","text":"Goals:Use forcats package change levels factors, re-order levels factors way makes tables graphs easier read.","code":""},{"path":"factors-with-forcats.html","id":"change-factor-levels","chapter":" 8 Factors with forcats","heading":"8.1 Change Factor Levels","text":"Data: pokemon_allgen.csv data set contains observations Pokemon first 6 Generations (first 6 games). 20 variable data set, , particular interest chapter areType 1, first Type characteristic Pokemon (factor 13 levels)Type 2, second Type characteristic Pokemon (factor 13 levels, NA Pokemon one type)Generation, generation Pokemon first appeared (factor 6 levels)Read data set read_csv(). , use mutate() statement make Generation_cat variable factor.One easy way get quick summary factor variable use group_by() n() within summarise() statement:","code":"\nlibrary(tidyverse)\npokemon_df <- read_csv(\"data/pokemon_allgen.csv\") %>%\n  mutate(Generation_cat = factor(Generation))\npokemon_df %>% group_by(`Type 1`) %>%\n  summarise(counttype = n())\n#> # A tibble: 18 x 2\n#>    `Type 1` counttype\n#>    <chr>        <int>\n#>  1 Bug             75\n#>  2 Dark            31\n#>  3 Dragon          41\n#>  4 Electric        90\n#>  5 Fairy           18\n#>  6 Fighting        27\n#>  7 Fire            56\n#>  8 Flying           6\n#>  9 Ghost           58\n#> 10 Grass           73\n#> 11 Ground          42\n#> 12 Ice             24\n#> 13 Normal         108\n#> 14 Poison          30\n#> 15 Psychic         73\n#> 16 Rock            47\n#> 17 Steel           29\n#> 18 Water          119"},{"path":"factors-with-forcats.html","id":"fct_recode-to-rename-levels","chapter":" 8 Factors with forcats","heading":"8.1.1 fct_recode() to Rename Levels","text":"Now, let’s make bar plot examines many Legendary Pokemon first appear generation, using dplyr commands ’ve used simple geom_col():’ve discussed change many aspects ggplot2 graphs, haven’t discussed rename labels levels categorical variable, whether appear x-axis separate legend. easiest way rename levels factor using fct_recode(). Suppose, example, want relabel Generation number actual region corresponding game (Kanto, Johto, Hoenn, Sinnoh, Unova, Kalos). function fct_recode() takes name factor already present data set first argument series renaming schemes (new_name = “old_name”) remaining arguments.","code":"\npokemon_legend <- pokemon_df %>% filter(Legendary == TRUE) %>%\n  group_by(Generation_cat) %>%\n  summarise(nlegend = n())\nggplot(data = pokemon_legend, aes(x = Generation_cat, y = nlegend)) +\n  geom_col()\npokemon_legend <- pokemon_legend %>%\n  mutate(Generation_cat2 = fct_recode(Generation_cat, Kanto = \"1\",\n                                      Johto = \"2\", Hoenn = \"3\",\n                                      Sinnoh = \"4\", Unova = \"5\",\n                                      Kalos = \"6\")) %>%\n  select(Generation_cat2, everything())\nhead(pokemon_legend)\n#> # A tibble: 6 x 3\n#>   Generation_cat2 Generation_cat nlegend\n#>   <fct>           <fct>            <int>\n#> 1 Kanto           1                    6\n#> 2 Johto           2                    5\n#> 3 Hoenn           3                   34\n#> 4 Sinnoh          4                   17\n#> 5 Unova           5                   27\n#> 6 Kalos           6                   13\nggplot(data = pokemon_legend,\n       aes(x = Generation_cat2, y = nlegend)) +\n  geom_col()"},{"path":"factors-with-forcats.html","id":"collapsing-many-levels-into-fewer-levels-with-fct_collapse","chapter":" 8 Factors with forcats","heading":"8.1.2 Collapsing Many Levels Into Fewer Levels with fct_collapse()","text":"Sometimes, might want collapse levels two factors single level. Pokemon data set, isn’t example really makes sense, , exercises, ’ll see good use function social survey data set. practice, can collapse Ice Dark type Pokemon new level called Coolest can collapse Poison, Fighting, Fire type Pokemon new level called Least_Cool.happens levels aren’t re-specified?","code":"\npokemon_long <- pokemon_df %>% pivot_longer(c(`Type 1`, `Type 2`),\n                            names_to = \"Number\",\n                            values_to = \"Type\")\npokemon_long %>%\n  mutate(new_type = fct_collapse(Type, Coolest = c(\"Ice\", \"Dark\"),\n                                 Least_Cool = c(\"Fire\", \"Fighting\", \"Poison\"))) %>%\n  select(new_type, Type, everything())\n#> # A tibble: 1,894 x 22\n#>    new_type  Type     `#` Name    Total    HP Attack Defense\n#>    <fct>     <chr>  <dbl> <chr>   <dbl> <dbl>  <dbl>   <dbl>\n#>  1 Grass     Grass      1 Bulbas…   318    45     49      49\n#>  2 Least_Co… Poison     1 Bulbas…   318    45     49      49\n#>  3 Grass     Grass      2 Ivysaur   405    60     62      63\n#>  4 Least_Co… Poison     2 Ivysaur   405    60     62      63\n#>  5 Grass     Grass      3 Venusa…   525    80     82      83\n#>  6 Least_Co… Poison     3 Venusa…   525    80     82      83\n#>  7 Grass     Grass      3 Venusa…   525    80     82      83\n#>  8 Least_Co… Poison     3 Venusa…   525    80     82      83\n#>  9 Least_Co… Fire       4 Charma…   309    39     52      43\n#> 10 <NA>      <NA>       4 Charma…   309    39     52      43\n#> # … with 1,884 more rows, and 14 more variables:\n#> #   Sp. Atk <dbl>, Sp. Def <dbl>, Speed <dbl>,\n#> #   Generation <dbl>, Legendary <lgl>, id <chr>,\n#> #   identifier <chr>, height <dbl>, weight <dbl>,\n#> #   base_experience <dbl>, order <dbl>, is_default <dbl>,\n#> #   Generation_cat <fct>, Number <chr>"},{"path":"factors-with-forcats.html","id":"exercise-7-1","chapter":" 8 Factors with forcats","heading":"8.1.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 8.4.dplyr function(s) also use create new levels created fct_collapse()? might little easier use fct_collapse()?dplyr function(s) also use create new levels created fct_collapse()? might little easier use fct_collapse()?* properly explore data set making graphs , , fact, double counting Pokemon data set (another example familiar data set ’re working advantageous: people familiar Pokemon know fewer 947 Pokemon Generations 1 6).* properly explore data set making graphs , , fact, double counting Pokemon data set (another example familiar data set ’re working advantageous: people familiar Pokemon know fewer 947 Pokemon Generations 1 6).Figure Pokemon double counted. , create new data set keeps one observation per Pokemon #.Create bar plot non-duplicated data set. results significantly changed?","code":""},{"path":"factors-with-forcats.html","id":"reorder-factor-levels","chapter":" 8 Factors with forcats","heading":"8.2 Reorder Factor Levels","text":"","code":""},{"path":"factors-with-forcats.html","id":"change-the-order-of-levels-by-a-quantitative-variable-with-fct_reorder","chapter":" 8 Factors with forcats","heading":"8.2.1 Change the Order of Levels by a Quantitative Variable with fct_reorder()","text":"might also interested re-ordering x y-axis particular graph order factors correspond , example, median quantitative variable level. reason want easiest see example. example, suppose want look common Pokemon types across first 6 generations. use non-duplicated data set previous section’s exercises, pivot data type one column, remove observations missing Type, correspond second Type Pokemon single Type:R order levels Type factor, default? might like ordered make graph readable?following code creates new factor variable called Type_ordered orders type count_type variable. fct_reorder() takes factor first argument numeric variable re-order factor second argument. bar plot reconstructed new variable.fct_reorder() also works boxplots simple point plots show, example, median response level factor. following set plots investigate Defense stat changes different Pokemon typesThe following code makes point plot shows median defense type instead boxplots.preference boxplot graph point plot?New Data. gun_violence_us.csv data set obtained https://www.openintro.org/book/statdata/index.php?data=gun_violence_us contains following variables gun violence 2014:state, name U.S. statemortality_rate, number deaths gun violence per 100,000 peopleownership_rate, proportion adults gunregion, region U.S. (South, West, NE, MW)","code":"\npokemon_nodup <- pokemon_df %>% group_by(`#`) %>% slice(1) %>%\n  ungroup()\npokemon_long <- pokemon_nodup %>%\n  pivot_longer(c(`Type 1`, `Type 2`),\n               names_to = \"Number\",\n               values_to = \"Type\")\npokemon_sum <- pokemon_long %>%\n  group_by(Type) %>%\n  summarise(count_type = n()) %>%\n  filter(!is.na(Type))\nggplot(data = pokemon_sum, aes(x = Type,\n                               y = count_type)) +\n  geom_col() +\n  coord_flip()  ## flips the x and y axes\npokemon_sum <- pokemon_sum %>% \n  mutate(Type_ordered = fct_reorder(.f = Type, .x = count_type))\nggplot(data = pokemon_sum, aes(x = Type_ordered,\n                               y = count_type)) +\n  geom_col() +\n  coord_flip()\npokemon_long <- pokemon_long %>%\n  filter(!is.na(Type)) %>%\n  mutate(Type_Deford = fct_reorder(.f = Type, .x = Defense,\n                                   .fun = median))\nggplot(data = pokemon_long, aes(x = Type_Deford,\n                               y = Defense)) +\n  geom_boxplot() + \n  coord_flip()\npokemon_med <- pokemon_long %>% group_by(Type_Deford) %>%\n  summarise(med_def = median(Defense)) %>%\n  mutate(Type_Deford = fct_reorder(.f = Type_Deford, .x = med_def,\n                                   .fun = median))\n\nggplot(data = pokemon_med, aes(x = med_def, y = Type_Deford)) +\n  geom_point()\nmortality_df <- read_csv(\"data/gun_violence_us.csv\") %>%\n  mutate(region = factor(region))"},{"path":"factors-with-forcats.html","id":"re-leveling-by-two-quantitative-variables-with-fct_reorder2","chapter":" 8 Factors with forcats","heading":"8.2.2 Re-Leveling By Two Quantitative Variables with fct_reorder2()","text":"Suppose want investigate relationship mortality_rate ownership_rate using data set. Run following code create scatterplot mortality_rate vs. ownership_rate fitted linear regression lines region United States:Notice order levels legend. people prefer order actually match lines plot end, order alphabetical. achieve , can use fct_reorder2() change order factor levels:change order levels expect? fct_reorder2() actually looks points, lines, determining ordering. want levels match exactly, ’ll reorder levels manually fct_relevel():","code":"\nggplot(data = mortality_df,\n       aes(x = ownership_rate, y = mortality_rate, colour = region)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\nmortality_df <- mortality_df %>%\n  mutate(region_2 = fct_reorder2(region,\n                                 .x = ownership_rate,\n                                 .y = mortality_rate))\nggplot(data = mortality_df,\n       aes(x = ownership_rate, y = mortality_rate, colour = region_2)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")"},{"path":"factors-with-forcats.html","id":"reordering-levels-manually-with-fct_relevel","chapter":" 8 Factors with forcats","heading":"8.2.3 Reordering Levels Manually with fct_relevel()","text":"Factors ordered alphabetically default. want precise control order levels factor, can use fct_relevel(), takes factor vector new levels inputs:Reordering levels factor manually might also useful fitting linear models. Recall , default, R makes reference group linear model first level alphabetically. ’d like different reference group, can reorder levels factor:","code":"\nmortality_df <- mortality_df %>%\n  mutate(region_3 = fct_relevel(region, c(\"South\", \"West\", \"MW\", \"NE\")))\nggplot(data = mortality_df,\n       aes(x = ownership_rate, y = mortality_rate, colour = region_3)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\nmod <- lm(mortality_rate ~ ownership_rate + region, data = mortality_df)\nmod2 <- lm(mortality_rate ~ ownership_rate + region_2, data = mortality_df)\nmod3 <- lm(mortality_rate ~ ownership_rate + region_3, data = mortality_df)\nsummary(mod)\nsummary(mod2)\nsummary(mod3)"},{"path":"factors-with-forcats.html","id":"exercise-7-2","chapter":" 8 Factors with forcats","heading":"8.2.4 Exercises","text":"Make side--side boxplots pokemon data use ungroup() running following code.aren’t types ordered median defense anymore?.fun argument fct_reorder() controls Type factor ordered. Change specify ordering mean, max, min. ordering makes sense? ?","code":"\npokemon_nodup <- pokemon_df %>% group_by(`#`) %>% slice(1) ## %>%\n  ## ungroup()\npokemon_long <- pokemon_nodup %>%\n  pivot_longer(c(`Type 1`, `Type 2`),\n               names_to = \"Number\",\n               values_to = \"Type\")\n\npokemon_long <- pokemon_long %>%\n  filter(!is.na(Type)) %>%\n  mutate(Type_Deford = fct_reorder(.f = Type, .x = Defense,\n                                   .fun = median))\nggplot(data = pokemon_long, aes(x = Type_Deford,\n                               y = Defense)) +\n  geom_boxplot() + \n  coord_flip()"},{"path":"factors-with-forcats.html","id":"chapexercise-7","chapter":" 8 Factors with forcats","heading":"8.3 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 8.4.use general social survey data set, forcats library R. Wikipedia page better understand data comes Wikipedia.variables self-explanatory, couple aren’t :partyid, political leaning anddenom, religious denomination (unfamiliar , can think “specific” subset particular religion).Note exercises R Data Science textbook.Load data set * Using forcats function, change name level str republican Weak republican change name level str democrat Weak democrat. names closely match levels Strong republican Strong democrat. , create table counts shows number respondents political party partyid.Note: Levels aren’t specified forcats function change.Note 2: naming something Weak republican, ’ll need use backticks since space level name.* Use forcats function partyid just 4 categories: (corresponding answer, Don’t know, party), Ind (corresponding Ind,near rep, Independent, Ind, near dem), Rep (corresponding Strong republican str republican), Dem (corresponding str democrat Strong democrat).* Use forcats function partyid just 4 categories: (corresponding answer, Don’t know, party), Ind (corresponding Ind,near rep, Independent, Ind, near dem), Rep (corresponding Strong republican str republican), Dem (corresponding str democrat Strong democrat).* Run code create following plot shows average number hours television people watch various religions.* Run code create following plot shows average number hours television people watch various religions., use forcats function create new variable data set reorders religion factor levels remake barplot religion watches television, average, top, religion watches least television, average, bottom.* Run code make following line plot shows age x-axis, proportion y-axis, coloured various marital statuses (married, divorced, widowed, etc.):, use forcats function make plot legend labels line better different coloured marital status lines (e.g. label widowed first appears legend, label married second, etc.).haven’t talked much creating two-way tables (contingency tables). generally quite difficult make tidyverse functions, can use base R table() prop.table() functions make .Using data year 2014, run following code make 4 two-way tables party_small variable constructed earlier race:Use help ?prop.table figure three tables constructed.table think informative? conclusions help draw?","code":"\nlibrary(tidyverse)\ngss_cat\nrelig_summary <- gss_cat %>%\n  group_by(relig) %>%\n  summarise(\n    age = mean(age, na.rm = TRUE),\n    tvhours = mean(tvhours, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(data = relig_summary, aes(tvhours, relig)) +\n  geom_point()\nby_age <- gss_cat %>%\n  filter(!is.na(age)) %>%\n  count(age, marital) %>%\n  group_by(age) %>%\n  mutate(prop = n / sum(n))\n\nggplot(by_age, aes(age, prop,\n                  colour = marital)) +\n  geom_line(na.rm = TRUE) +\n  labs(colour = \"marital\")\ngss_cat <- gss_cat %>% mutate(party_small = fct_collapse(partyid,\n                                              Other = c(\"No answer\", \"Don't know\", \"Other party\"),\n                                              Ind = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n                                              Rep = c(\"Strong republican\", \"Not str republican\"),\n                                              Dem = c(\"Not str democrat\", \"Strong democrat\")))\n\ngss_recent <- gss_cat %>% filter(year != 2014)\n\ntab1 <- table(gss_recent$party_small, gss_recent$race)\ntab1\n#>        \n#>         Other Black White Not applicable\n#>   Other    39    46   375              0\n#>   Rep     215   127  4467              0\n#>   Ind     863   827  5631              0\n#>   Dem     580  1743  4032              0\nprop.table(tab1)\n#>        \n#>               Other       Black       White Not applicable\n#>   Other 0.002058591 0.002428081 0.019794141    0.000000000\n#>   Rep   0.011348641 0.006703616 0.235787807    0.000000000\n#>   Ind   0.045552916 0.043652679 0.297228820    0.000000000\n#>   Dem   0.030614938 0.092003167 0.212826603    0.000000000\nprop.table(tab1, margin = 1)\n#>        \n#>              Other      Black      White Not applicable\n#>   Other 0.08478261 0.10000000 0.81521739     0.00000000\n#>   Rep   0.04470784 0.02640882 0.92888334     0.00000000\n#>   Ind   0.11788007 0.11296271 0.76915722     0.00000000\n#>   Dem   0.09126672 0.27427223 0.63446105     0.00000000\nprop.table(tab1, margin = 2)\n#>        \n#>              Other      Black      White Not applicable\n#>   Other 0.02298173 0.01676996 0.02585315               \n#>   Rep   0.12669417 0.04629967 0.30796277               \n#>   Ind   0.50854449 0.30149471 0.38821096               \n#>   Dem   0.34177961 0.63543565 0.27797311"},{"path":"factors-with-forcats.html","id":"solutions-7","chapter":" 8 Factors with forcats","heading":"8.4 Exercise Solutions","text":"","code":""},{"path":"factors-with-forcats.html","id":"change-factor-levels-s","chapter":" 8 Factors with forcats","heading":"8.4.1 Change Factor Levels S","text":"* properly explore data set making graphs , , fact, double counting Pokemon data set (another example familiar data set ’re working advantageous: people familiar Pokemon know fewer 947 Pokemon Generations 1 6).Figure Pokemon double counted. , create new data set keeps one observation per Pokemon #.","code":"\npokemon_nodup <- pokemon_df %>% group_by(`#`) %>% slice(1) %>%\n  ungroup()"},{"path":"factors-with-forcats.html","id":"reorder-factor-levels-s","chapter":" 8 Factors with forcats","heading":"8.4.2 Reorder Factor Levels S","text":"","code":""},{"path":"factors-with-forcats.html","id":"chapexercise-7-S","chapter":" 8 Factors with forcats","heading":"8.4.3 Chapter Exercises S","text":"* Using forcats function, change name level str republican Weak republican change name level str democrat Weak democrat. names closely match levels Strong republican Strong democrat. , create table counts shows number respondents political party partyid.Note: Levels aren’t specified forcats function change.Note 2: naming something Weak republican, ’ll need use backticks since space level name.* Use forcats function partyid just 4 categories: (corresponding answer, Don’t know, party), Ind (corresponding Ind,near rep, Independent, Ind, near dem), Rep (corresponding Strong republican str republican), Dem (corresponding str democrat Strong democrat).* Run code create following plot shows average number hours television people watch various religions., use forcats function create new variable data set reorders religion factor levels remake barplot religion watches television, average, top, religion watches least television, average, bottom.* Run code make following line plot shows age x-axis, proportion y-axis, coloured various marital statuses (married, divorced, widowed, etc.):, use forcats function make plot legend labels line better different coloured marital status lines (e.g. label widowed first appears legend, label married second, etc.).","code":"\ngss_cat %>%\n  mutate(partyid_new = fct_recode(partyid,\n                                  `Weak republican` = \"Not str republican\",\n                                  `Weak democrat` = \"Not str democrat\")) %>% group_by(partyid_new) %>%\n  summarise(ncount = n())\ngss_cat <- gss_cat %>% mutate(party_small = fct_collapse(partyid,\n                                              Other = c(\"No answer\", \"Don't know\", \"Other party\"),\n                                              Ind = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n                                              Rep = c(\"Strong republican\", \"Not str republican\"),\n                                              Dem = c(\"Not str democrat\", \"Strong democrat\")))\nrelig_summary <- gss_cat %>%\n  group_by(relig) %>%\n  summarise(\n    age = mean(age, na.rm = TRUE),\n    tvhours = mean(tvhours, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(data = relig_summary, aes(tvhours, relig)) +\n  geom_point()\nrelig_summary <- relig_summary %>%\n  mutate(relig = fct_reorder(relig, tvhours))\nggplot(data = relig_summary, aes(tvhours, relig)) +\n  geom_point()\nby_age <- gss_cat %>%\n  filter(!is.na(age)) %>%\n  count(age, marital) %>%\n  group_by(age) %>%\n  mutate(prop = n / sum(n))\n\nggplot(by_age, aes(age, prop,\n                  colour = marital)) +\n  geom_line(na.rm = TRUE) +\n  labs(colour = \"marital\")\nby_age2 <- by_age %>% ungroup() %>%\n  mutate(marital2 = fct_reorder2(marital, .x = age, .y = prop))\nggplot(by_age2, aes(age, prop,\n                  colour = marital2)) +\n  geom_line(na.rm = TRUE) +\n  labs(colour = \"marital\") +\n  scale_colour_viridis_d()"},{"path":"factors-with-forcats.html","id":"rcode-7","chapter":" 8 Factors with forcats","heading":"8.5 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\npokemon_df <- read_csv(\"data/pokemon_allgen.csv\") %>%\n  mutate(Generation_cat = factor(Generation))\npokemon_df %>% group_by(`Type 1`) %>%\n  summarise(counttype = n())\npokemon_legend <- pokemon_df %>% filter(Legendary == TRUE) %>%\n  group_by(Generation_cat) %>%\n  summarise(nlegend = n())\nggplot(data = pokemon_legend, aes(x = Generation_cat, y = nlegend)) +\n  geom_col()\npokemon_legend <- pokemon_legend %>%\n  mutate(Generation_cat2 = fct_recode(Generation_cat, Kanto = \"1\",\n                                      Johto = \"2\", Hoenn = \"3\",\n                                      Sinnoh = \"4\", Unova = \"5\",\n                                      Kalos = \"6\")) %>%\n  select(Generation_cat2, everything())\nhead(pokemon_legend)\nggplot(data = pokemon_legend,\n       aes(x = Generation_cat2, y = nlegend)) +\n  geom_col()\npokemon_long <- pokemon_df %>% pivot_longer(c(`Type 1`, `Type 2`),\n                            names_to = \"Number\",\n                            values_to = \"Type\")\npokemon_long %>%\n  mutate(new_type = fct_collapse(Type, Coolest = c(\"Ice\", \"Dark\"),\n                                 Least_Cool = c(\"Fire\", \"Fighting\", \"Poison\"))) %>%\n  select(new_type, Type, everything())\npokemon_nodup <- pokemon_df %>% group_by(`#`) %>% slice(1) %>%\n  ungroup()\npokemon_long <- pokemon_nodup %>%\n  pivot_longer(c(`Type 1`, `Type 2`),\n               names_to = \"Number\",\n               values_to = \"Type\")\npokemon_sum <- pokemon_long %>%\n  group_by(Type) %>%\n  summarise(count_type = n()) %>%\n  filter(!is.na(Type))\nggplot(data = pokemon_sum, aes(x = Type,\n                               y = count_type)) +\n  geom_col() +\n  coord_flip()  ## flips the x and y axes\npokemon_sum <- pokemon_sum %>% \n  mutate(Type_ordered = fct_reorder(.f = Type, .x = count_type))\nggplot(data = pokemon_sum, aes(x = Type_ordered,\n                               y = count_type)) +\n  geom_col() +\n  coord_flip()\npokemon_long <- pokemon_long %>%\n  filter(!is.na(Type)) %>%\n  mutate(Type_Deford = fct_reorder(.f = Type, .x = Defense,\n                                   .fun = median))\nggplot(data = pokemon_long, aes(x = Type_Deford,\n                               y = Defense)) +\n  geom_boxplot() + \n  coord_flip()\npokemon_med <- pokemon_long %>% group_by(Type_Deford) %>%\n  summarise(med_def = median(Defense)) %>%\n  mutate(Type_Deford = fct_reorder(.f = Type_Deford, .x = med_def,\n                                   .fun = median))\n\nggplot(data = pokemon_med, aes(x = med_def, y = Type_Deford)) +\n  geom_point()\nmortality_df <- read_csv(\"data/gun_violence_us.csv\") %>%\n  mutate(region = factor(region))\nggplot(data = mortality_df,\n       aes(x = ownership_rate, y = mortality_rate, colour = region)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\nmortality_df <- mortality_df %>%\n  mutate(region_2 = fct_reorder2(region,\n                                 .x = ownership_rate,\n                                 .y = mortality_rate))\nggplot(data = mortality_df,\n       aes(x = ownership_rate, y = mortality_rate, colour = region_2)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\nmortality_df <- mortality_df %>%\n  mutate(region_3 = fct_relevel(region, c(\"South\", \"West\", \"MW\", \"NE\")))\nggplot(data = mortality_df,\n       aes(x = ownership_rate, y = mortality_rate, colour = region_3)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\nmod <- lm(mortality_rate ~ ownership_rate + region, data = mortality_df)\nmod2 <- lm(mortality_rate ~ ownership_rate + region_2, data = mortality_df)\nmod3 <- lm(mortality_rate ~ ownership_rate + region_3, data = mortality_df)\nsummary(mod)\nsummary(mod2)\nsummary(mod3)"},{"path":"reprexes-and-import.html","id":"reprexes-and-import","chapter":" 9 Reprexes and Import","heading":" 9 Reprexes and Import","text":"Goals:Use tibble create data sets R, describe benefits reprexes.Use tibble create data sets R, describe benefits reprexes.Use readr read data R .csv, .txt, .tsv files.Use readr read data R .csv, .txt, .tsv files.Use rvest scrape data public websites.Use rvest scrape data public websites.Use jsonlite read data JSON (Java Script Object Notation) files.Use jsonlite read data JSON (Java Script Object Notation) files.","code":""},{"path":"reprexes-and-import.html","id":"reprexes-and-tibble","chapter":" 9 Reprexes and Import","heading":"9.1 Reprexes and tibble","text":"can also create data set directly within R tibble() function tibble package. useful want make small reproducible example someone else may help code.reproducible example, reprex, chunk code can give someone else runs without outside data. used often StackExchange. following code chunk reprex people necessarily data set parsedf.csv.want post StackExchange someone help us convert variable character vector units numeric vector without units. want able give possible helpers small example data set work . , can create tiny data set tibble():library(tidyverse) necessary code chunk reprex?can copy paste code chunk question: ’s code anyone can run long tidyverse package installed, really encourages people help.","code":"\n## Hello! How do I get rid of the units from the values in\n## my variable `x`? Thanks!\nlibrary(tidyverse)\ntest_df <- read_csv(\"data/parsedf.csv\")\nhead(test_df)\n#> # A tibble: 3 x 2\n#>   x                   y\n#>   <chr>           <dbl>\n#> 1 20,000 dollars      1\n#> 2 40 dollars          2\n#> 3 only 13 dollars     3\n## Hello! How do I get rid of the units from the values in\n## my variable `xvar`? Thanks!\nlibrary(tidyverse)\ntest_df2 <- tibble(xvar = c(\"20,000 dollars\", \"40 dollars\"),\n                   yvar = c(1, 2))\ntest_df2\n#> # A tibble: 2 x 2\n#>   xvar            yvar\n#>   <chr>          <dbl>\n#> 1 20,000 dollars     1\n#> 2 40 dollars         2"},{"path":"reprexes-and-import.html","id":"exercise-8-1","chapter":" 9 Reprexes and Import","heading":"9.1.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 9.6.Project 2, work course evaluation data professor SLU. Overall, ’ll answer questions professor can improve courses SLU looking course evaluation data. variables data set described detail project description.* Suppose can’t figure create semester variable year variable Term evals_prof_S21.csv. (want split Term variable two variables: Semester levels F S Year levels 19, 20, 21).Put together reprex using tibble() someone able run help figure question.* actually able answer question using function learned couple weeks ago. , creating Semester Year variable.","code":"\nlibrary(tidyverse)\nevals_df <- read_csv(\"data/evals_prof_S21.csv\")\nhead(evals_df)\n#> # A tibble: 6 x 10\n#>   Term  Course Question               `Agree strongly` Agree\n#>   <chr> <chr>  <chr>                             <dbl> <dbl>\n#> 1 F19   113-02 1. Course has been a …                9     9\n#> 2 F19   113-02 2. Effectively Organi…               12     8\n#> 3 F19   113-02 3. Environment Conduc…               11     8\n#> 4 F19   113-02 5a. Fair Assessment o…                5    13\n#> 5 F19   113-02 5b. Timely Assessment…                8    12\n#> 6 F19   113-02 5c. Constructive Asse…                5     8\n#> # … with 5 more variables: Agree Somewhat <dbl>,\n#> #   Neutral <dbl>, Disagree Somewhat <dbl>, Disagree <dbl>,\n#> #   Disagree Strongly <dbl>"},{"path":"reprexes-and-import.html","id":"readr-to-read-in-data","chapter":" 9 Reprexes and Import","heading":"9.2 readr to Read in Data","text":"now, mostly worked data “R Ready”: meaning nice .csv file read R easily read_csv() readr package. begin looking options read_csv() function move formats .csv data commonly stored .","code":""},{"path":"reprexes-and-import.html","id":"read_csv-options","chapter":" 9 Reprexes and Import","heading":"9.2.1 read_csv() Options","text":"mtcarsex.csv observations different car models variables include things like gas mileage, number cylinders, etc. Read mtcarsex.csv data set following code. , examine data set head().notice data set seems odd? Open .csv file Excel program examine data set outside R.Type ?read_csv bottom-left window look options read_csv(). particular, use na skip arguments fix reading.Let’s start skip aren’t reading first two rows data set:looks better, still couple problems. notice?Go help read na argument. Let’s add option fix missing value issue.Now look classes variable. classes look like incorrect?’ve talked re-specify classes variables using mutate() .factor() .Date() .numeric() functions, sometimes ’s easier just respecify class reading data. Notice , use read_csv(), R gives us message column types. actually argument read_csv() called col_types. R prints ’s easy us copy paste read_csv() change classes. example, notice cyl = col_double() changed cyl = col_factor() code chunk :Finally, two rows missing values. aren’t providing anything useful can slice() :many possible file formats data storage. example, data set called oscars.tsv, tab-separated file. can read read_tsv() instead read_csv().’ll able work .txt files Excel files Exercises. Check https://rawgit.com/rstudio/cheatsheets/master/data-import.pdf data import cheatsheet.final issue discuss section occurs data set units within cells. Consider earlier example used reprex section:parse_number() function really useful just want number (commas, units, etc.). function often paired mutate() since creating new variable:","code":"\nlibrary(tidyverse)\ncars_df <- read_csv(\"data/mtcarsex.csv\")\nhead(cars_df)\n#> # A tibble: 6 x 11\n#>   `This is a data… X2    X3    X4    X5    X6    X7    X8   \n#>   <chr>            <chr> <chr> <chr> <chr> <chr> <chr> <chr>\n#> 1 \"I'm a na\\x95ve… <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n#> 2 \"mpg\"            cyl   disp  hp    drat  wt    qsec  vs   \n#> 3  <NA>            <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n#> 4  <NA>            <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n#> 5 \"-999\"           6     160   110   3.9   2.62  16.46 0    \n#> 6 \"21\"             6     160   110   3.9   2.875 17.02 0    \n#> # … with 3 more variables: X9 <chr>, X10 <chr>, X11 <chr>\ncars_df <- read_csv(\"data/mtcarsex.csv\", skip = 2)\n## first two lines will be skipped\nhead(cars_df)\n#> # A tibble: 6 x 11\n#>      mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n#>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n#> 1   NA      NA    NA    NA NA    NA     NA      NA    NA\n#> 2   NA      NA    NA    NA NA    NA     NA      NA    NA\n#> 3 -999       6   160   110  3.9   2.62  16.5     0     1\n#> 4   21       6   160   110  3.9   2.88  17.0     0     1\n#> 5   22.8     4   108    93  3.85  2.32  18.6     1     1\n#> 6   21.4     6   258   110  3.08  3.22  19.4     1     0\n#> # … with 2 more variables: gear <dbl>, carb <dbl>\ncars_df <- read_csv(\"data/mtcarsex.csv\", na = c(NA, \"-999\"), skip = 2)\nhead(cars_df)\n#> # A tibble: 6 x 11\n#>     mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n#>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n#> 1  NA      NA    NA    NA NA    NA     NA      NA    NA\n#> 2  NA      NA    NA    NA NA    NA     NA      NA    NA\n#> 3  NA       6   160   110  3.9   2.62  16.5     0     1\n#> 4  21       6   160   110  3.9   2.88  17.0     0     1\n#> 5  22.8     4   108    93  3.85  2.32  18.6     1     1\n#> 6  21.4     6   258   110  3.08  3.22  19.4     1     0\n#> # … with 2 more variables: gear <dbl>, carb <dbl>\ncars_df <- read_csv(\"data/mtcarsex.csv\", na = c(NA, \"-999\"), skip = 2,\n  col_types = cols(\n  mpg = col_double(),\n  cyl = col_factor(),\n  disp = col_double(),\n  hp = col_double(),\n  drat = col_double(),\n  wt = col_double(),\n  qsec = col_double(),\n  vs = col_factor(),\n  am = col_double(),\n  gear = col_double(),\n  carb = col_double()\n))\ncars_df <- read_csv(\"data/mtcarsex.csv\", na = c(NA, \"-999\"), skip = 2,\n  col_types = cols(\n  mpg = col_double(),\n  cyl = col_factor(),\n  disp = col_double(),\n  hp = col_double(),\n  drat = col_double(),\n  wt = col_double(),\n  qsec = col_double(),\n  vs = col_factor(),\n  am = col_double(),\n  gear = col_double(),\n  carb = col_double()\n)) %>%\n  slice(-(1:2))\nhead(cars_df)\n#> # A tibble: 6 x 11\n#>     mpg cyl    disp    hp  drat    wt  qsec vs       am\n#>   <dbl> <fct> <dbl> <dbl> <dbl> <dbl> <dbl> <fct> <dbl>\n#> 1  NA   6       160   110  3.9   2.62  16.5 0         1\n#> 2  21   6       160   110  3.9   2.88  17.0 0         1\n#> 3  22.8 4       108    93  3.85  2.32  18.6 1         1\n#> 4  21.4 6       258   110  3.08  3.22  19.4 1         0\n#> 5  NA   8       360   175  3.15  3.44  17.0 0         0\n#> 6  18.1 6       225   105  2.76  3.46  20.2 1         0\n#> # … with 2 more variables: gear <dbl>, carb <dbl>\noscars_df <- read_tsv(\"data/oscars.tsv\")\nhead(oscars_df)\n#> # A tibble: 6 x 51\n#>   FilmName            OscarYear Duration Rating DirectorName\n#>   <chr>                   <dbl>    <dbl>  <dbl> <chr>       \n#> 1 Crash                    2006      113      4 Haggis      \n#> 2 Brokeback Mountain       2006      134      4 Lee         \n#> 3 Capote                   2006      114      4 Miller      \n#> 4 Good Night, and Go…      2006       93      2 Clooney     \n#> 5 Munich                   2006      164      4 Spielberg   \n#> 6 The Departed             2007      151      4 Scorsese    \n#> # … with 46 more variables: DirectorGender <dbl>,\n#> #   OscarWinner <dbl>, GenreName <chr>, Genre_Drama <dbl>,\n#> #   Genre_Bio <dbl>, CountryName <chr>,\n#> #   ForeignandUSA <dbl>, ProductionName <chr>,\n#> #   ProductionCompany <dbl>, BudgetRevised <chr>,\n#> #   Budget <chr>, DomesticBoxOffice <dbl>,\n#> #   WorldwideRevised <dbl>, WorldwideBoxOffice <dbl>,\n#> #   DomesticPercent <dbl>, LimitedOpeningWnd <dbl>,\n#> #   LimitedTheaters <dbl>, LimitedAveragePThtr <dbl>,\n#> #   WideOpeningWkd <dbl>, WideTheaters <dbl>,\n#> #   WideTheaterAverage <dbl>, WidestTheaters <dbl>,\n#> #   Days <chr>, Rotten <dbl>, Metacritic <dbl>, IMDb <dbl>,\n#> #   CriticAverage <dbl>, MPrinicpalCast <dbl>,\n#> #   FPrincipalCast <dbl>, FPercentPrincipalCast <dbl>,\n#> #   MLeadTime <dbl>, FLeadTime <dbl>, GuestMLeadTIme <dbl>,\n#> #   GuestFLEadTime <dbl>, MLeadPercentinFilm <dbl>,\n#> #   FLeadPercentinFilm <dbl>, GMLeadPerinFilm <chr>,\n#> #   GFLeadPerinFilm <chr>, M/FDifference <dbl>,\n#> #   F/MRatio <dbl>, M/FPercentMore <dbl>, FHighLow <dbl>,\n#> #   LeadTime <dbl>, MorF <dbl>, MaleLAA <dbl>,\n#> #   FemaleLAA <dbl>\ntest_df <- read_csv(\"data/parsedf.csv\")\nhead(test_df)\n#> # A tibble: 3 x 2\n#>   x                   y\n#>   <chr>           <dbl>\n#> 1 20,000 dollars      1\n#> 2 40 dollars          2\n#> 3 only 13 dollars     3\ntest_df %>% mutate(x2 = parse_number(x))\n#> # A tibble: 3 x 3\n#>   x                   y    x2\n#>   <chr>           <dbl> <dbl>\n#> 1 20,000 dollars      1 20000\n#> 2 40 dollars          2    40\n#> 3 only 13 dollars     3    13"},{"path":"reprexes-and-import.html","id":"exercise-8-2","chapter":" 9 Reprexes and Import","heading":"9.2.2 Exercises","text":"Exercises marked * indicate exercise solution end chapter 9.6.* birthdays.txt file information birthdays various animals Animal Crossing island. also columns Animal’s Name, Animal Type, long animal lived island (weeks). Click file open look format data.Start following code chunk use options read_delim() read data (?read_delim). delim argument ’s already provided specifies delimiter (separator) ’ll use -, opposed , example, , .csv file. Arguments may need change includeskipcol_namesnatrim_wscol_types* Another common format data stored Excel file. Often, ’s easiest just save Excel file .csv file read using read_csv(). , sometimes route can difficult (example, Excel file thousands sheets). read directly Excel, ’ll need install readxl install.packages(\"readxl\"). installed, load package library(readxl), read first sheet evals_prof.xlsx data set, data set used Project 2, read_excel() function.* Another common format data stored Excel file. Often, ’s easiest just save Excel file .csv file read using read_csv(). , sometimes route can difficult (example, Excel file thousands sheets). read directly Excel, ’ll need install readxl install.packages(\"readxl\"). installed, load package library(readxl), read first sheet evals_prof.xlsx data set, data set used Project 2, read_excel() function.* Now, read second sheet Excel file, using help file ?read_excel change one arguments.* Now, read second sheet Excel file, using help file ?read_excel change one arguments.","code":"\nlibrary(tidyverse)\ndf <- read_delim(\"data/birthdays.txt\", delim = \" - \")\nhead(df)"},{"path":"reprexes-and-import.html","id":"data-scraping-with-rvest","chapter":" 9 Reprexes and Import","heading":"9.3 Data Scraping with rvest","text":"Sometimes, might want data public website isn’t provided file format. obtain data, ’ll need use web scraping, term just means “getting data website.” easiest way R rvest package. Note spend entire semester talking web scraping, focus websites scraping data “easy” won’t give us major errors.Go following website suppose wanted table gun violence statistics R: https://en.wikipedia.org/wiki/Gun_violence_in_the_United_States_by_state. try copy-pasting table Excel reading data set read_excel(). Depending format table, strategy may work may . Another way scrape directly rvest. Additionally, website continually updates (standings sports league, enrollment data school, best-selling products company, etc.), scraping much convenient, don’t need continually copy-paste updated data.following code chunk, read_html() reads entire html file url provided html_nodes() extracts tables website.’ll see , example, 3 tables provided. tables stored list can reference first table using [[1]], second table using [[2]], etc. purposes class, figure 3 tables one actually want using trial error.html_table() function converts table data.frame object.3 tables one want use analysis gun violence United States?another example, consider scraping data SLU’s athletics page. particular, suppose want analysis SLU’s baseball team.Go following website look table data want scrape: https://saintsathletics.com/sports/baseball/stats/2021.looking website, use following code scrape data set.’s now 72 different tables! See can figure first tables coming website.","code":"\nlibrary(tidyverse)\nlibrary(rvest)\n\n## provide the URL and name it something (in this case, url).\nurl <- \"https://en.wikipedia.org/wiki/Gun_violence_in_the_United_States_by_state\"\n\n## convert the html code into something R can read\nh <- read_html(url)\n\n## grabs the tables\ntab <- h %>% html_nodes(\"table\")\ntest1 <- tab[[1]] %>% html_table()\ntest2 <- tab[[2]] %>% html_table()\ntest3 <- tab[[3]] %>% html_table()\n\nhead(test1)\nhead(test2)\nhead(test3)\nurl <- \"https://saintsathletics.com/sports/baseball/stats/2021\"\nh <- read_html(url)\ntab <- h %>% html_nodes(\"table\")\ntab\nobj <- tab[[1]] %>% html_table(fill = TRUE)\nhead(obj)\ntail(obj)\nobj2 <- tab[[2]] %>% html_table(fill = TRUE)\nhead(obj2)\ntail(obj2)"},{"path":"reprexes-and-import.html","id":"exercise-8-3","chapter":" 9 Reprexes and Import","heading":"9.3.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 9.6.Choose topic/person/place/etc. interests tables Wikipedia scrape table related topic.Choose topic/person/place/etc. interests tables Wikipedia scrape table related topic.* SLU keeps track diversity faculty time makes data public following website: https://www.stlawu.edu/ir/diversity/faculty. Use rvest scrape data tables R.* SLU keeps track diversity faculty time makes data public following website: https://www.stlawu.edu/ir/diversity/faculty. Use rvest scrape data tables R.Hint: may need use extra argument html_table() like fill.","code":""},{"path":"reprexes-and-import.html","id":"json-files-with-jsonlite","chapter":" 9 Reprexes and Import","heading":"9.4 JSON Files with jsonlite","text":"final common data format discuss JSON (JavaScript Object Notation). cover basics JSON data use jsonlite package R read .json files. JSON files read R list object.","code":""},{"path":"reprexes-and-import.html","id":"everything-working-well","chapter":" 9 Reprexes and Import","heading":"9.4.1 Everything Working Well","text":"First, consider data mobile game Clash Royale. Install jsonlite package use read json file function fromJSON():get warning message, investigate class.Next, type View(cr_cards) console (bottom-left) window look data. See can pull data set clicking things View() window.following give couple ways grab data using code. as_tibble() function converts rectangular object familiar tibble.first option specifies name table ’s JSON file (case, name \"cards\"):second method uses flatten() function purrr package, package core tidyverse talk detail class. also different flatten() function jsonlite package. code , specify want use flatten() purrr purrr::flatten(). wanted use flatten() jsonlite, ’d use jsonlite::flatten()methods give tibble can use usual tidyverse tools ggplot2, dplyr, tidyr, etc. .","code":"\n## install.packages(\"jsonlite\")\nlibrary(jsonlite)\ncr_cards <- fromJSON(\"data/clash_royale_card_info.json\")\nlibrary(tidyverse)\ncr_cards_flat <- cr_cards[[\"cards\"]]\ncr_cards_df <- as_tibble(cr_cards_flat)\nhead(cr_cards_df)\n#> # A tibble: 6 x 8\n#>   key    name  elixir type  rarity arena description      id\n#>   <chr>  <chr>  <int> <chr> <chr>  <int> <chr>         <int>\n#> 1 knight Knig…      3 Troop Common     0 A tough mel… 2.6 e7\n#> 2 arche… Arch…      3 Troop Common     0 A pair of l… 2.60e7\n#> 3 gobli… Gobl…      2 Troop Common     1 Three fast,… 2.60e7\n#> 4 giant  Giant      5 Troop Rare       0 Slow but du… 2.60e7\n#> 5 pekka  P.E.…      7 Troop Epic       4 A heavily a… 2.60e7\n#> 6 minio… Mini…      3 Troop Common     0 Three fast,… 2.60e7\ncr_cards_flat2 <- purrr::flatten(cr_cards)\ncr_cards_df2 <- as_tibble(cr_cards_flat2)\nhead(cr_cards_df2)\n#> # A tibble: 6 x 8\n#>   key    name  elixir type  rarity arena description      id\n#>   <chr>  <chr>  <int> <chr> <chr>  <int> <chr>         <int>\n#> 1 knight Knig…      3 Troop Common     0 A tough mel… 2.6 e7\n#> 2 arche… Arch…      3 Troop Common     0 A pair of l… 2.60e7\n#> 3 gobli… Gobl…      2 Troop Common     1 Three fast,… 2.60e7\n#> 4 giant  Giant      5 Troop Rare       0 Slow but du… 2.60e7\n#> 5 pekka  P.E.…      7 Troop Epic       4 A heavily a… 2.60e7\n#> 6 minio… Mini…      3 Troop Common     0 Three fast,… 2.60e7"},{"path":"reprexes-and-import.html","id":"things-arent-always-so-easy","chapter":" 9 Reprexes and Import","heading":"9.4.2 Things Aren’t Always So Easy","text":"Now let’s try look animal crossing data obtained https://github.com/jefflomacy/villagerdb. first just want look data one individual villager (ace) file ace.json.Things now….complicated. example just show ’s always easy working JSON data. Lists can nested creates problems trying convert deeply nested list “rectangular” format ’s easy work .’s also added problem reading .json files villagers time loop mapping function purrr download read JSON files villagers. won’t delve deeply , ’s lot file formats ’ve discussed week, particularly web scraping .json files.","code":"\nacedata <- fromJSON(\"data/ace.json\")\naceflat <- purrr::flatten(acedata)\nhead(aceflat)\n#> $gender\n#> [1] \"male\"\n#> \n#> $species\n#> [1] \"bird\"\n#> \n#> $birthday\n#> [1] \"3-13\"\n#> \n#> $ac\n#> $ac$personality\n#> [1] \"jock\"\n#> \n#> $ac$clothes\n#> [1] \"spade-shirt\"\n#> \n#> $ac$song\n#> [1] \"K.K. Parade\"\n#> \n#> $ac$phrase\n#> [1] \"ace\"\n#> \n#> \n#> $`afe+`\n#> $`afe+`$personality\n#> [1] \"jock\"\n#> \n#> $`afe+`$clothes\n#> [1] \"spade-shirt\"\n#> \n#> $`afe+`$song\n#> [1] \"K.K. Parade\"\n#> \n#> \n#> $name\n#> [1] \"Ace\""},{"path":"reprexes-and-import.html","id":"exercise-8-4","chapter":" 9 Reprexes and Import","heading":"9.4.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 9.6.* Read pokedex.json file, data set information 151 original Pokemon. , use flatten() function purrr flatten list.* Read pokedex.json file, data set information 151 original Pokemon. , use flatten() function purrr flatten list.* Use as_tibble() convert flattened list tibble.* Use as_tibble() convert flattened list tibble.* Use parse_number() mutate() tidy two variables data set.* Use parse_number() mutate() tidy two variables data set.* Look type variable. looks odd ? happens try use , either plot, using dplyr function?* Look type variable. looks odd ? happens try use , either plot, using dplyr function?can unnest() Type variable unnest() function tidyr. didn’t discuss function feel free read ?unnestThere 6 pokemon spawn_chance 0. Figure 6 pokemon .6 pokemon spawn_chance 0. Figure 6 pokemon .Figure 5 common Pokemon types first generation (’ll need use unnest()-ed data set : ?).Figure 5 common Pokemon types first generation (’ll need use unnest()-ed data set : ?).","code":"\npokemon_unnest <- unnest(pokemon_df, cols = c(type))"},{"path":"reprexes-and-import.html","id":"chapexercise-8","chapter":" 9 Reprexes and Import","heading":"9.5 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 9.6.Choose sports team SLU, go team’s website (simply googling SLU name_of_sport). Scrape data tables “Results” “Statistics” section sport. scrape data, tidy data set. , choose one following options (different options might make /less sense different sports)(). Summarise different team statistics, either numerically graphically. Perhaps make graphs showing different statistics time.(b). Summarise different individual statistics, either numerically graphically.(c). Ask answer questions make sense particular sport looking !Note: sports (men’s women’s golf, example), give results PDF format. PDF format generally horrible way record share data, ’s difficult read almost program. Therefore, avoid sports PDF results purposes exercise.","code":""},{"path":"reprexes-and-import.html","id":"solutions-8","chapter":" 9 Reprexes and Import","heading":"9.6 Exercise Solutions","text":"","code":""},{"path":"reprexes-and-import.html","id":"reprexes-and-tibble-s","chapter":" 9 Reprexes and Import","heading":"9.6.1 Reprexes and tibble S","text":"* Suppose can’t figure create semester variable year variable Term evals_prof_S21.csv. (want split Term variable two variables: Semester levels F S Year levels 19, 20, 21).Put together reprex using tibble() someone able run help figure question.* actually able answer question using function learned couple weeks ago. , creating Semester Year variable.","code":"\nlibrary(tidyverse)\nevals_df <- read_csv(\"data/evals_prof_S21.csv\")\nhead(evals_df)\n#> # A tibble: 6 x 10\n#>   Term  Course Question               `Agree strongly` Agree\n#>   <chr> <chr>  <chr>                             <dbl> <dbl>\n#> 1 F19   113-02 1. Course has been a …                9     9\n#> 2 F19   113-02 2. Effectively Organi…               12     8\n#> 3 F19   113-02 3. Environment Conduc…               11     8\n#> 4 F19   113-02 5a. Fair Assessment o…                5    13\n#> 5 F19   113-02 5b. Timely Assessment…                8    12\n#> 6 F19   113-02 5c. Constructive Asse…                5     8\n#> # … with 5 more variables: Agree Somewhat <dbl>,\n#> #   Neutral <dbl>, Disagree Somewhat <dbl>, Disagree <dbl>,\n#> #   Disagree Strongly <dbl>\nlibrary(tidyverse)\ndf <- tibble(Term = c(\"F19\", \"S20\"), x = c(1, 2))\n## Hello! I need help creating a variable that has F/S and \n## a separate year variable that has 19 and 20 from the data set above.\n## Thanks!\nnew_df <- df %>% separate(Term, sep = 1, into = c(\"Semester\", \"Year\"))"},{"path":"reprexes-and-import.html","id":"readr-s","chapter":" 9 Reprexes and Import","heading":"9.6.2 readr S","text":"* birthdays.txt file information birthdays various animals Animal Crossing island. also columns Animal’s Name, Animal Type, long animal lived island (weeks). Click file open look format data.Start following code chunk use options read_delim() read data (?read_delim). delim argument ’s already provided specifies delimiter (separator) ’ll use -, opposed , example, , .csv file. Arguments may change includeskipcol_namesnatrim_wscol_types* Another common format data stored Excel file. Often, ’s easiest just save Excel file .csv file read using read_csv(). , sometimes route can difficult (example, Excel file thousands sheets). read directly Excel, ’ll need install readxl install.packages(\"readxl\"). installed, load package library(readxl), read first sheet evals_prof.xlsx data set, data set used Project 2, read_excel() function.* Now, read second sheet, using help file ?read_excel change one arguments.","code":"\nlibrary(tidyverse)\ndf <- read_delim(\"data/birthdays.txt\", delim = \" - \")\nhead(df)\nread_delim(\"data/birthdays.txt\", delim = \"-\", skip = 4,\n  col_names = c(\"Birthday\", \"Name\",\n    \"Animal\", \"Island\"),\n  na = c(\"N/A\", \"?\"),\n  trim_ws = TRUE,\n  col_types = list(\n    col_character(), col_character(), col_character(), col_number()\n  ))\n## install.packages(\"readxl\")\nlibrary(readxl)\nread_excel(\"data/evals_prof.xlsx\")\nread_excel(\"data/evals_prof.xlsx\", sheet = 2)"},{"path":"reprexes-and-import.html","id":"rvest-and-data-scraping-s","chapter":" 9 Reprexes and Import","heading":"9.6.3 rvest and Data Scraping S","text":"* SLU keeps track diversity faculty time makes data public following website: https://www.stlawu.edu/ir/diversity/faculty. Use rvest scrape data tables R.","code":"\nurl <- \"https://www.stlawu.edu/ir/diversity/faculty\"\nh <- read_html(url)\ntab <- h %>% html_nodes(\"table\")\nobj <- tab[[1]] %>% html_table(fill = TRUE)\nobj"},{"path":"reprexes-and-import.html","id":"json-with-jsonlite-s","chapter":" 9 Reprexes and Import","heading":"9.6.4 JSON with jsonlite S","text":"* Read pokedex.json file, data set information 151 original Pokemon. , use flatten() function purrr flatten list.* Use as_tibble() convert flattened list tibble.* Use parse_number() mutate() tidy two variables data set.* Look type variable. looks odd ? happens try use , either plot, using dplyr function?can unnest() Type variable unnest() function tidyr. didn’t discuss function feel free read ?unnest","code":"\nlibrary(jsonlite)\npokedex <- fromJSON(\"data/pokedex.json\")\ndf <- purrr::flatten(pokedex)\npokemon_df <- as_tibble(df)\npokemon_df <- pokemon_df %>% mutate(height = parse_number(height),\n                                    weight = parse_number(weight))\n## it's a variable of lists....this is happening because some \n## pokemon have more than one type.\n\n## most ggplot() and dplyr() functions won't work, or\n## won't work as you'd expect\npokemon_unnest <- unnest(pokemon_df, cols = c(type))"},{"path":"reprexes-and-import.html","id":"chapexercise-8-S","chapter":" 9 Reprexes and Import","heading":"9.6.5 Chapter Exercises S","text":"","code":""},{"path":"reprexes-and-import.html","id":"rcode-8","chapter":" 9 Reprexes and Import","heading":"9.7 Non-Exercise R Code","text":"","code":"\n## Hello! How do I get rid of the units from the values in\n## my variable `x`? Thanks!\nlibrary(tidyverse)\ntest_df <- read_csv(\"data/parsedf.csv\")\nhead(test_df)\n## Hello! How do I get rid of the units from the values in\n## my variable `xvar`? Thanks!\nlibrary(tidyverse)\ntest_df2 <- tibble(xvar = c(\"20,000 dollars\", \"40 dollars\"),\n                   yvar = c(1, 2))\ntest_df2\nlibrary(tidyverse)\ncars_df <- read_csv(\"data/mtcarsex.csv\")\nhead(cars_df)\ncars_df <- read_csv(\"data/mtcarsex.csv\", skip = 2)\n## first two lines will be skipped\nhead(cars_df)\ncars_df <- read_csv(\"data/mtcarsex.csv\", na = c(NA, \"-999\"), skip = 2)\nhead(cars_df)\ncars_df <- read_csv(\"data/mtcarsex.csv\", na = c(NA, \"-999\"), skip = 2,\n  col_types = cols(\n  mpg = col_double(),\n  cyl = col_factor(),\n  disp = col_double(),\n  hp = col_double(),\n  drat = col_double(),\n  wt = col_double(),\n  qsec = col_double(),\n  vs = col_factor(),\n  am = col_double(),\n  gear = col_double(),\n  carb = col_double()\n))\ncars_df <- read_csv(\"data/mtcarsex.csv\", na = c(NA, \"-999\"), skip = 2,\n  col_types = cols(\n  mpg = col_double(),\n  cyl = col_factor(),\n  disp = col_double(),\n  hp = col_double(),\n  drat = col_double(),\n  wt = col_double(),\n  qsec = col_double(),\n  vs = col_factor(),\n  am = col_double(),\n  gear = col_double(),\n  carb = col_double()\n)) %>%\n  slice(-(1:2))\nhead(cars_df)\noscars_df <- read_tsv(\"data/oscars.tsv\")\nhead(oscars_df)\ntest_df <- read_csv(\"data/parsedf.csv\")\nhead(test_df)\ntest_df %>% mutate(x2 = parse_number(x))\nlibrary(tidyverse)\nlibrary(rvest)\n\n## provide the URL and name it something (in this case, url).\nurl <- \"https://en.wikipedia.org/wiki/Gun_violence_in_the_United_States_by_state\"\n\n## convert the html code into something R can read\nh <- read_html(url)\n\n## grabs the tables\ntab <- h %>% html_nodes(\"table\")\ntest1 <- tab[[1]] %>% html_table()\ntest2 <- tab[[2]] %>% html_table()\ntest3 <- tab[[3]] %>% html_table()\n\nhead(test1)\nhead(test2)\nhead(test3)\nurl <- \"https://saintsathletics.com/sports/baseball/stats/2021\"\nh <- read_html(url)\ntab <- h %>% html_nodes(\"table\")\ntab\nobj <- tab[[1]] %>% html_table(fill = TRUE)\nhead(obj)\ntail(obj)\nobj2 <- tab[[2]] %>% html_table(fill = TRUE)\nhead(obj2)\ntail(obj2)\n## install.packages(\"jsonlite\")\nlibrary(jsonlite)\ncr_cards <- fromJSON(\"data/clash_royale_card_info.json\")\nlibrary(tidyverse)\ncr_cards_flat <- cr_cards[[\"cards\"]]\ncr_cards_df <- as_tibble(cr_cards_flat)\nhead(cr_cards_df)\ncr_cards_flat2 <- purrr::flatten(cr_cards)\ncr_cards_df2 <- as_tibble(cr_cards_flat2)\nhead(cr_cards_df2)\nacedata <- fromJSON(\"data/ace.json\")\naceflat <- purrr::flatten(acedata)\nhead(aceflat)"},{"path":"data-ethics.html","id":"data-ethics","chapter":" 10 Data Ethics","heading":" 10 Data Ethics","text":"Goals:explain data ethics important issue data science using couple examples.describe issues data privacy explain , just data doesn’t individual’s name doesn’t necessarily make data truly anonymous.explain difference hypothesis confirmation hypothesis exploration distinction matters.","code":""},{"path":"data-ethics.html","id":"ethical-examples","chapter":" 10 Data Ethics","heading":"10.1 Ethical Examples","text":"’ve tried interweave issues ethics throughout many examples used already course, purpose section put data ethics direct focus.questions consider data collected, especially data collected human subjects:gets use data purposes?gets use data purposes?collected data organization conflicts interest?collected data organization conflicts interest?presentation analysis harmful particular person group people? benefits analysis?presentation analysis harmful particular person group people? benefits analysis?subjects data collection procedure treated respectfully given consent information collected?\nconsent needed ? example, looked data professional athletes. need provide consent consent inherent spotlight?\n’ve also scraped data SLU’s athletics website look data pertaining ! ethical? line wouldn’t cross pertaining data collected named, individual people?\nsubjects data collection procedure treated respectfully given consent information collected?consent needed ? example, looked data professional athletes. need provide consent consent inherent spotlight?consent needed ? example, looked data professional athletes. need provide consent consent inherent spotlight?’ve also scraped data SLU’s athletics website look data pertaining ! ethical? line wouldn’t cross pertaining data collected named, individual people?’ve also scraped data SLU’s athletics website look data pertaining ! ethical? line wouldn’t cross pertaining data collected named, individual people?","code":""},{"path":"data-ethics.html","id":"exercise-9-1","chapter":" 10 Data Ethics","heading":"10.1.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 10.5.Read Sections 8.1 - 8.3 Modern Data Science R. , write one paragraph summary reading might pertain way use interpret data.Read Sections 8.1 - 8.3 Modern Data Science R. , write one paragraph summary reading might pertain way use interpret data.Data Feminism related data ethics, though two terms certainly synonymous. Recently, Catherine D’Ignazio Lauren F. Klein published book called Data Feminism https://datafeminism.io/ Data Feminism related data ethics, though two terms certainly synonymous. Recently, Catherine D’Ignazio Lauren F. Klein published book called Data Feminism https://datafeminism.io/ Read following blog post Data Feminism, focusing section Missing Data. https://teachdatascience.com/datafem/ .Pick one example bulleted list write 2 sentence explanation explains might important acknowledge missing data analysis.Choose 1 following two articles readhttps://www.theguardian.com/world/2017/sep/08/ai-gay-gaydar-algorithm-facial-recognition-criticism-stanford  use data LGBTQIA+ communityhttps://towardsdatascience.com/5-steps--take---antiracist-data-scientist-89712877c214  anti-racist data practices.LGBTQIA+ article, write two sentence summary side argument research facial recognition software identify members LGBTQ+ community occur, even viewpoint isn’t ., write two sentence summary side argument research facial recognition software identify members LGBTQ+ community okay long results used responsibly, even viewpoint isn’t .anti-racist data science article, Step 2, pick News Article read first paragraphs. Describe, 2-3 sentences, article’s example bias incidence bias matters.","code":""},{"path":"data-ethics.html","id":"data-privacy","chapter":" 10 Data Ethics","heading":"10.2 Data Privacy","text":"Related data ethics idea data privacy.data private data public? examples, may seem obvious, others (e.g. data government agency collects data people), answer might clear cut.anonymous data truly anonymous?type consent provided collecting data someone?explore issues following exercises.","code":""},{"path":"data-ethics.html","id":"exercise-9-2","chapter":" 10 Data Ethics","heading":"10.2.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 10.5.Recall course evaluations data set, used Mini-Project 2. might obvious, course evaluations course evaluations last year, felt ethically okay share . , data privacy always cut--dry issue. Consider following course evaluation formats, think whether consider ethically okay share evaluation information :gave course averages, also give PDFs student’s written responses. PDFs anonymous, student’s sex, year, whether took course Major, Minor, Distribution Requirement, etc. Assume also can obtain class roster class.gave course averages, also give PDFs student’s written responses. PDFs anonymous, student’s sex, year, whether took course Major, Minor, Distribution Requirement, etc. Assume also can obtain class roster class.gave course averages PDFs (), also give grade student received course PDF list responses (still anonymous can still obtain class roster).gave course averages PDFs (), also give grade student received course PDF list responses (still anonymous can still obtain class roster).Another professor SLU posts evaluation averages table personal website. scrape data table give , along professor’s name courses. don’t ask permission, website tables public.Another professor SLU posts evaluation averages table personal website. scrape data table give , along professor’s name courses. don’t ask permission, website tables public.Suppose collect data students Data Science class. setting () (d), suppose give data set following variables collected student class. option, , ethically okay share data students class.current grade time spent R Studio servercurrent grade time spent R Studio servercurrent grade, class year, whether student stat majorcurrent grade, class year, whether student stat majorfavorite R package, whether student took STAT 213, whether student took CS 140, Majorfavorite R package, whether student took STAT 213, whether student took CS 140, Majorfavorite R package, whether student took STAT 213, whether student took CS 140, current grade coursefavorite R package, whether student took STAT 213, whether student took CS 140, current grade courseHow anonymous SLU’s course evaluations? -class activity investigate .","code":""},{"path":"data-ethics.html","id":"hypothesis-generation-vs.-confirmation","chapter":" 10 Data Ethics","heading":"10.3 Hypothesis Generation vs. Confirmation","text":"focused hypothesis generation data sets particular course. Read following two articles explain difference hypothesis generation hypothesis confirmation:Read following two short articles, one textbook one another source:https://r4ds..co.nz/model-intro.html#hypothesis-generation-vs.-hypothesis-confirmationhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC6718169/","code":""},{"path":"data-ethics.html","id":"exercise-9-3","chapter":" 10 Data Ethics","heading":"10.3.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 10.5.Explain difference hypothesis generation hypothesis confirmation.Explain difference hypothesis generation hypothesis confirmation.many times can use single observation hypothesis generation? hypothesis confirmation?many times can use single observation hypothesis generation? hypothesis confirmation?following questions, pertaining someone’s fitness, sound suitable answered Hypothesis Exploration? Hypothesis Confirmation?following questions, pertaining someone’s fitness, sound suitable answered Hypothesis Exploration? Hypothesis Confirmation?want know , average, person exercises weekends weekdays, questions interest.want know , average, person exercises weekends weekdays, questions interest.want look general trends person’s step count try determine various events influenced step count.want look general trends person’s step count try determine various events influenced step count.want know person exercises winter summer, also like investigate seasonal trends.want know person exercises winter summer, also like investigate seasonal trends.Note: Prediction different hypothesis confirmation, typically don’t really care variables associated response. want model gives “best” predictions. , goal prediction, typically lot freedom many times can “use” single observation. talk little prediction later semester.","code":""},{"path":"data-ethics.html","id":"chapexercise-9","chapter":" 10 Data Ethics","heading":"10.4 Chapter Exercises","text":"chapter exercises chapter.","code":""},{"path":"data-ethics.html","id":"solutions-9","chapter":" 10 Data Ethics","heading":"10.5 Exercise Solutions","text":"exercise solutions chapter.","code":""},{"path":"merging-with-dplyr.html","id":"merging-with-dplyr","chapter":" 11 Merging with dplyr","heading":" 11 Merging with dplyr","text":"Goals:use bind_rows() stack two data sets bind_cols() merge two data sets.use bind_rows() stack two data sets bind_cols() merge two data sets.identify keys two related data sets.identify keys two related data sets.use mutating join functions dplyr merge two data sets key.use mutating join functions dplyr merge two data sets key.use filtering join functions dplyr filter one data set values another data set.use filtering join functions dplyr filter one data set values another data set.apply appropriate join() function given problem context.apply appropriate join() function given problem context.","code":""},{"path":"merging-with-dplyr.html","id":"stacking-rows-and-appending-columns","chapter":" 11 Merging with dplyr","heading":"11.1 Stacking Rows and Appending Columns","text":"","code":""},{"path":"merging-with-dplyr.html","id":"stacking-with-bind_rows","chapter":" 11 Merging with dplyr","heading":"11.1.1 Stacking with bind_rows()","text":"First, talk combining two data sets “stacking” top form one new data set. bind_rows() function can used purpose two data sets identical column names.common instance useful two data sets come source different locations years, exact column names.example, examine following website notice .csv files given year matches ATP (Association (men’s) Tennis Professionals). https://github.com/JeffSackmann/tennis_atp., read data sets, look many columns .combine results data sets,happens? Can fix error? Hint: runto get full column specifications use readr knowledge change couple column types. also discuss , , using col_type argument read_csv(), don’t need specify column types. Just specifying ones want change works . following code forces seed variables 2018 data set characters.can try combining data sets now.quick check make sure number rows atp_2018 plus number rows atp_2019 equals number rows atp_df.might seem little annoying, , default bind_rows() combine two data sets stacking rows data sets identical column names identical column classes, saw previous example.Now run following look output.behavior expect?","code":"\nlibrary(tidyverse)\natp_2019 <- read_csv(\"data/atp_matches_2019.csv\")\natp_2018 <- read_csv(\"data/atp_matches_2018.csv\")\nhead(atp_2019) \nhead(atp_2018)\natp_df <- bind_rows(atp_2018, atp_2019)\n#> Error: Can't combine `winner_seed` <double> and `winner_seed` <character>.\nspec(atp_2018)\natp_2018 <- read_csv(\"data/atp_matches_2018.csv\",\n                     col_types = cols(winner_seed = col_character(),\n                                      loser_seed = col_character()))\natp_df <- bind_rows(atp_2018, atp_2019)\natp_df\ndf_test2a <- tibble(xvar = c(1, 2))\ndf_test2b <- tibble(xvar = c(1, 2), y = c(5, 1))\nbind_rows(df_test2a, df_test2b)\n#> # A tibble: 4 x 2\n#>    xvar     y\n#>   <dbl> <dbl>\n#> 1     1    NA\n#> 2     2    NA\n#> 3     1     5\n#> 4     2     1"},{"path":"merging-with-dplyr.html","id":"binding-columns-with-bind_cols","chapter":" 11 Merging with dplyr","heading":"11.1.2 Binding Columns with bind_cols()","text":"won’t spend much time talking bind together columns ’s generally little dangerous.use couple test data sets, df_test1a df_test1b, see action:larger data set, might dangerous way combine data? must sure way data collected order combine data way?","code":"\ndf_test1a <- tibble(xvar = c(1, 2), yvar = c(5, 1))\ndf_test1b <- tibble(x = c(1, 2), y = c(5, 1))\nbind_cols(df_test1a, df_test1b)\n#> # A tibble: 2 x 4\n#>    xvar  yvar     x     y\n#>   <dbl> <dbl> <dbl> <dbl>\n#> 1     1     5     1     5\n#> 2     2     1     2     1"},{"path":"merging-with-dplyr.html","id":"exercise-10-1","chapter":" 11 Merging with dplyr","heading":"11.1.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 11.6.* Run following explain R simply stack rows. , fix issue rename() function.","code":"\ndf_test1a <- tibble(xvar = c(1, 2), yvar = c(5, 1))\ndf_test1b <- tibble(x = c(1, 2), y = c(5, 1))\nbind_rows(df_test1a, df_test1b)\n#> # A tibble: 4 x 4\n#>    xvar  yvar     x     y\n#>   <dbl> <dbl> <dbl> <dbl>\n#> 1     1     5    NA    NA\n#> 2     2     1    NA    NA\n#> 3    NA    NA     1     5\n#> 4    NA    NA     2     1"},{"path":"merging-with-dplyr.html","id":"mutating-joins","chapter":" 11 Merging with dplyr","heading":"11.2 Mutating Joins","text":"goal combine two data sets using common variable(s) data sets , need different tools simply stacking rows appending columns. merging together two data sets, need matching identification variable data set. variable commonly called key. key can identification number, name, date, etc, must present data sets.simple first example, considerOur goal combine two data sets people’s favorite sports favorite colours one data set.Identify key example . can longer use bind_cols() ?","code":"\nlibrary(tidyverse)\ndf1 <- tibble(name = c(\"Emily\", \"Miguel\", \"Tonya\"), fav_sport = c(\"Swimming\", \"Football\", \"Tennis\"))\ndf2 <- tibble(name = c(\"Tonya\", \"Miguel\", \"Emily\"),\n              fav_colour = c(\"Robin's Egg Blue\", \"Tickle Me Pink\", \"Goldenrod\"))"},{"path":"merging-with-dplyr.html","id":"keep-all-rows-of-data-set-1-with-left_join","chapter":" 11 Merging with dplyr","heading":"11.2.1 Keep All Rows of Data Set 1 with left_join()","text":"Consider babynames R package, following data sets:lifetables: cohort life tables different sex different year variables, starting year 1900.births: number births United States year, since 1909babynames: popularity different baby names per year sex since year 1880.Read data set ?babynames, ?births ?lifetables.Suppose want combine births data set babynames data set, row babynames now total number births year. first need identify key data set use joining. case, data set year variable, can use left_join() keep observations babynames_df, even years births_df data set.births missing head(combined_left) tail(combined_left)?","code":"\n##install.packages(\"babynames\")\nlibrary(babynames)\nlife_df <- babynames::lifetables\nbirth_df <- babynames::births\nbabynames_df <- babynames::babynames\nhead(babynames)\nhead(births)\nhead(lifetables)\ncombined_left <- left_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))\nhead(combined_left)\n#> # A tibble: 6 x 6\n#>    year sex   name          n   prop births\n#>   <dbl> <chr> <chr>     <int>  <dbl>  <int>\n#> 1  1880 F     Mary       7065 0.0724     NA\n#> 2  1880 F     Anna       2604 0.0267     NA\n#> 3  1880 F     Emma       2003 0.0205     NA\n#> 4  1880 F     Elizabeth  1939 0.0199     NA\n#> 5  1880 F     Minnie     1746 0.0179     NA\n#> 6  1880 F     Margaret   1578 0.0162     NA\ntail(combined_left)\n#> # A tibble: 6 x 6\n#>    year sex   name       n       prop  births\n#>   <dbl> <chr> <chr>  <int>      <dbl>   <int>\n#> 1  2017 M     Zyhier     5 0.00000255 3855500\n#> 2  2017 M     Zykai      5 0.00000255 3855500\n#> 3  2017 M     Zykeem     5 0.00000255 3855500\n#> 4  2017 M     Zylin      5 0.00000255 3855500\n#> 5  2017 M     Zylis      5 0.00000255 3855500\n#> 6  2017 M     Zyrie      5 0.00000255 3855500"},{"path":"merging-with-dplyr.html","id":"keep-all-rows-of-data-set-2-with-right_join","chapter":" 11 Merging with dplyr","heading":"11.2.2 Keep All Rows of Data Set 2 with right_join()","text":"Recall accompanying handout need ever use right_join() using left_join() first two data set arguments switched:Therefore, ’s usually easier just always use left_join() ignore right_join() completely.","code":"\n## these will always do the same exact thing\nright_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))\n#> # A tibble: 1,839,952 x 6\n#>     year sex   name          n   prop  births\n#>    <dbl> <chr> <chr>     <int>  <dbl>   <int>\n#>  1  1909 F     Mary      19259 0.0523 2718000\n#>  2  1909 F     Helen      9250 0.0251 2718000\n#>  3  1909 F     Margaret   7359 0.0200 2718000\n#>  4  1909 F     Ruth       6509 0.0177 2718000\n#>  5  1909 F     Dorothy    6253 0.0170 2718000\n#>  6  1909 F     Anna       5804 0.0158 2718000\n#>  7  1909 F     Elizabeth  5176 0.0141 2718000\n#>  8  1909 F     Mildred    5054 0.0137 2718000\n#>  9  1909 F     Marie      4301 0.0117 2718000\n#> 10  1909 F     Alice      4170 0.0113 2718000\n#> # … with 1,839,942 more rows\nleft_join(birth_df, babynames_df, by = c(\"year\" = \"year\"))\n#> # A tibble: 1,839,952 x 6\n#>     year  births sex   name          n   prop\n#>    <dbl>   <int> <chr> <chr>     <int>  <dbl>\n#>  1  1909 2718000 F     Mary      19259 0.0523\n#>  2  1909 2718000 F     Helen      9250 0.0251\n#>  3  1909 2718000 F     Margaret   7359 0.0200\n#>  4  1909 2718000 F     Ruth       6509 0.0177\n#>  5  1909 2718000 F     Dorothy    6253 0.0170\n#>  6  1909 2718000 F     Anna       5804 0.0158\n#>  7  1909 2718000 F     Elizabeth  5176 0.0141\n#>  8  1909 2718000 F     Mildred    5054 0.0137\n#>  9  1909 2718000 F     Marie      4301 0.0117\n#> 10  1909 2718000 F     Alice      4170 0.0113\n#> # … with 1,839,942 more rows"},{"path":"merging-with-dplyr.html","id":"keep-all-rows-of-both-data-sets-with-full_join","chapter":" 11 Merging with dplyr","heading":"11.2.3 Keep All Rows of Both Data Sets with full_join()","text":"full_join() keep rows data set 1 don’t matching key data set 2, also keep rows data set 2 don’t matching key data set 1, filling NA missing values necessary. example merging babynames_df birth_df,","code":"\nfull_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))"},{"path":"merging-with-dplyr.html","id":"keep-only-rows-with-matching-keys-with-inner_join","chapter":" 11 Merging with dplyr","heading":"11.2.4 Keep Only Rows with Matching Keys with inner_join()","text":"can also keep rows matching keys inner_join(). join, row data set 1 without matching key data set 2 dropped, row data set 2 without matching key data set 1 also dropped.","code":"\ninner_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))\n#> # A tibble: 1,839,952 x 6\n#>     year sex   name          n   prop  births\n#>    <dbl> <chr> <chr>     <int>  <dbl>   <int>\n#>  1  1909 F     Mary      19259 0.0523 2718000\n#>  2  1909 F     Helen      9250 0.0251 2718000\n#>  3  1909 F     Margaret   7359 0.0200 2718000\n#>  4  1909 F     Ruth       6509 0.0177 2718000\n#>  5  1909 F     Dorothy    6253 0.0170 2718000\n#>  6  1909 F     Anna       5804 0.0158 2718000\n#>  7  1909 F     Elizabeth  5176 0.0141 2718000\n#>  8  1909 F     Mildred    5054 0.0137 2718000\n#>  9  1909 F     Marie      4301 0.0117 2718000\n#> 10  1909 F     Alice      4170 0.0113 2718000\n#> # … with 1,839,942 more rows"},{"path":"merging-with-dplyr.html","id":"which-xxxx_join","chapter":" 11 Merging with dplyr","heading":"11.2.5 Which xxxx_join()?","text":"join function use depend context data questions answering analysis. importantly, ’re using left_join(), right_join() inner_join(), ’re potentially cutting data. ’s important aware data ’re omitting. example, babynames births data, want keep note left_join() removed observations 1909 joined data set.","code":""},{"path":"merging-with-dplyr.html","id":"the-importance-of-a-good-key","chapter":" 11 Merging with dplyr","heading":"11.2.6 The Importance of a Good Key","text":"key variable important joining always available “perfect” form. Recall college majors data sets , called slumajors_df, information majors SLU. Another data set, collegemajors_df, different statistics college majors nationwide. ’s lots interesting variables data sets, ’ll focus Major variable . Read examine two data sets :logical key joining two data sets Major, joining data sets won’t actually work. following attempt using Major key.collegemajors_df give NA values tried merge major?example underscores importance key matches exactly. , , issues involved joining two data sets can solved functions stringr package (discussed weeks). example, capitalization issue can solved str_to_title() function, converts -caps majors collegemajors_df majors first letter word capitalized:can see, solves issue majors others still different naming conventions two data sets.","code":"\nslumajors_df <- read_csv(\"data/SLU_Majors_15_19.csv\")\ncollegemajors_df <- read_csv(\"data/college-majors.csv\")\nhead(slumajors_df)\n#> # A tibble: 6 x 3\n#>   Major                        nfemales nmales\n#>   <chr>                           <dbl>  <dbl>\n#> 1 Anthropology                       34     15\n#> 2 Art & Art History                  65     11\n#> 3 Biochemistry                       14     11\n#> 4 Biology                           162     67\n#> 5 Business in the Liberal Arts      135    251\n#> 6 Chemistry                          26     14\nhead(collegemajors_df)\n#> # A tibble: 6 x 12\n#>   Major  Total   Men Women Major_category Employed Full_time\n#>   <chr>  <dbl> <dbl> <dbl> <chr>             <dbl>     <dbl>\n#> 1 PETRO…  2339  2057   282 Engineering        1976      1849\n#> 2 MININ…   756   679    77 Engineering         640       556\n#> 3 METAL…   856   725   131 Engineering         648       558\n#> 4 NAVAL…  1258  1123   135 Engineering         758      1069\n#> 5 CHEMI… 32260 21239 11021 Engineering       25694     23170\n#> 6 NUCLE…  2573  2200   373 Engineering        1857      2038\n#> # … with 5 more variables: Part_time <dbl>,\n#> #   Unemployed <dbl>, Median <dbl>, P25th <dbl>,\n#> #   P75th <dbl>\nleft_join(slumajors_df, collegemajors_df, by = c(\"Major\" = \"Major\"))\n#> # A tibble: 27 x 14\n#>    Major    nfemales nmales Total   Men Women Major_category\n#>    <chr>       <dbl>  <dbl> <dbl> <dbl> <dbl> <chr>         \n#>  1 Anthrop…       34     15    NA    NA    NA <NA>          \n#>  2 Art & A…       65     11    NA    NA    NA <NA>          \n#>  3 Biochem…       14     11    NA    NA    NA <NA>          \n#>  4 Biology       162     67    NA    NA    NA <NA>          \n#>  5 Busines…      135    251    NA    NA    NA <NA>          \n#>  6 Chemist…       26     14    NA    NA    NA <NA>          \n#>  7 Compute…       21     47    NA    NA    NA <NA>          \n#>  8 Conserv…       38     20    NA    NA    NA <NA>          \n#>  9 Economi…      128    349    NA    NA    NA <NA>          \n#> 10 English       131     54    NA    NA    NA <NA>          \n#> # … with 17 more rows, and 7 more variables:\n#> #   Employed <dbl>, Full_time <dbl>, Part_time <dbl>,\n#> #   Unemployed <dbl>, Median <dbl>, P25th <dbl>,\n#> #   P75th <dbl>\ncollegemajors_df <- collegemajors_df %>%\n  mutate(Major = str_to_title(Major))\nleft_join(slumajors_df, collegemajors_df)\n#> Joining, by = \"Major\"\n#> # A tibble: 27 x 14\n#>    Major nfemales nmales  Total    Men  Women Major_category\n#>    <chr>    <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <chr>         \n#>  1 Anth…       34     15     NA     NA     NA <NA>          \n#>  2 Art …       65     11     NA     NA     NA <NA>          \n#>  3 Bioc…       14     11     NA     NA     NA <NA>          \n#>  4 Biol…      162     67 280709 111762 168947 Biology & Lif…\n#>  5 Busi…      135    251     NA     NA     NA <NA>          \n#>  6 Chem…       26     14  66530  32923  33607 Physical Scie…\n#>  7 Comp…       21     47 128319  99743  28576 Computers & M…\n#>  8 Cons…       38     20     NA     NA     NA <NA>          \n#>  9 Econ…      128    349 139247  89749  49498 Social Science\n#> 10 Engl…      131     54     NA     NA     NA <NA>          \n#> # … with 17 more rows, and 7 more variables:\n#> #   Employed <dbl>, Full_time <dbl>, Part_time <dbl>,\n#> #   Unemployed <dbl>, Median <dbl>, P25th <dbl>,\n#> #   P75th <dbl>"},{"path":"merging-with-dplyr.html","id":"exercise-10-2","chapter":" 11 Merging with dplyr","heading":"11.2.7 Exercises","text":"Exercises marked * indicate exercise solution end chapter 11.6.Examine following two joins ’ve done, explain one resulting data set fewer observations (rows) .Evaluate whether following statement true false: inner_join() always result data set fewer rows full_join().Evaluate whether following statement true false: inner_join() always result data set fewer rows full_join().Evaluate whether following statement true false: inner_join() always result data set fewer rows left_join().Evaluate whether following statement true false: inner_join() always result data set fewer rows left_join().","code":"\nleft_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))\n#> # A tibble: 1,924,665 x 6\n#>     year sex   name          n   prop births\n#>    <dbl> <chr> <chr>     <int>  <dbl>  <int>\n#>  1  1880 F     Mary       7065 0.0724     NA\n#>  2  1880 F     Anna       2604 0.0267     NA\n#>  3  1880 F     Emma       2003 0.0205     NA\n#>  4  1880 F     Elizabeth  1939 0.0199     NA\n#>  5  1880 F     Minnie     1746 0.0179     NA\n#>  6  1880 F     Margaret   1578 0.0162     NA\n#>  7  1880 F     Ida        1472 0.0151     NA\n#>  8  1880 F     Alice      1414 0.0145     NA\n#>  9  1880 F     Bertha     1320 0.0135     NA\n#> 10  1880 F     Sarah      1288 0.0132     NA\n#> # … with 1,924,655 more rows\nleft_join(birth_df, babynames_df, by = c(\"year\" = \"year\"))\n#> # A tibble: 1,839,952 x 6\n#>     year  births sex   name          n   prop\n#>    <dbl>   <int> <chr> <chr>     <int>  <dbl>\n#>  1  1909 2718000 F     Mary      19259 0.0523\n#>  2  1909 2718000 F     Helen      9250 0.0251\n#>  3  1909 2718000 F     Margaret   7359 0.0200\n#>  4  1909 2718000 F     Ruth       6509 0.0177\n#>  5  1909 2718000 F     Dorothy    6253 0.0170\n#>  6  1909 2718000 F     Anna       5804 0.0158\n#>  7  1909 2718000 F     Elizabeth  5176 0.0141\n#>  8  1909 2718000 F     Mildred    5054 0.0137\n#>  9  1909 2718000 F     Marie      4301 0.0117\n#> 10  1909 2718000 F     Alice      4170 0.0113\n#> # … with 1,839,942 more rows"},{"path":"merging-with-dplyr.html","id":"filtering-joins","chapter":" 11 Merging with dplyr","heading":"11.3 Filtering Joins","text":"Filtering joins (semi_join() anti_join()) useful like keep variables one data set, want filter observations variable second data set.Consider two data sets men’s tennis matches 2018 2019.","code":"\natp_2019 <- read_csv(\"data/atp_matches_2019.csv\")\natp_2018 <- read_csv(\"data/atp_matches_2018.csv\")\natp_2019\n#> # A tibble: 2,781 x 49\n#>    tourney_id tourney_name surface draw_size tourney_level\n#>    <chr>      <chr>        <chr>       <dbl> <chr>        \n#>  1 2019-M020  Brisbane     Hard           32 A            \n#>  2 2019-M020  Brisbane     Hard           32 A            \n#>  3 2019-M020  Brisbane     Hard           32 A            \n#>  4 2019-M020  Brisbane     Hard           32 A            \n#>  5 2019-M020  Brisbane     Hard           32 A            \n#>  6 2019-M020  Brisbane     Hard           32 A            \n#>  7 2019-M020  Brisbane     Hard           32 A            \n#>  8 2019-M020  Brisbane     Hard           32 A            \n#>  9 2019-M020  Brisbane     Hard           32 A            \n#> 10 2019-M020  Brisbane     Hard           32 A            \n#> # … with 2,771 more rows, and 44 more variables:\n#> #   tourney_date <dbl>, match_num <dbl>, winner_id <dbl>,\n#> #   winner_seed <chr>, winner_entry <chr>,\n#> #   winner_name <chr>, winner_hand <chr>, winner_ht <dbl>,\n#> #   winner_ioc <chr>, winner_age <dbl>, loser_id <dbl>,\n#> #   loser_seed <chr>, loser_entry <chr>, loser_name <chr>,\n#> #   loser_hand <chr>, loser_ht <dbl>, loser_ioc <chr>,\n#> #   loser_age <dbl>, score <chr>, best_of <dbl>,\n#> #   round <chr>, minutes <dbl>, w_ace <dbl>, w_df <dbl>,\n#> #   w_svpt <dbl>, w_1stIn <dbl>, w_1stWon <dbl>,\n#> #   w_2ndWon <dbl>, w_SvGms <dbl>, w_bpSaved <dbl>,\n#> #   w_bpFaced <dbl>, l_ace <dbl>, l_df <dbl>, l_svpt <dbl>,\n#> #   l_1stIn <dbl>, l_1stWon <dbl>, l_2ndWon <dbl>,\n#> #   l_SvGms <dbl>, l_bpSaved <dbl>, l_bpFaced <dbl>,\n#> #   winner_rank <dbl>, winner_rank_points <dbl>,\n#> #   loser_rank <dbl>, loser_rank_points <dbl>\natp_2018\n#> # A tibble: 2,889 x 49\n#>    tourney_id tourney_name surface draw_size tourney_level\n#>    <chr>      <chr>        <chr>       <dbl> <chr>        \n#>  1 2018-M020  Brisbane     Hard           32 A            \n#>  2 2018-M020  Brisbane     Hard           32 A            \n#>  3 2018-M020  Brisbane     Hard           32 A            \n#>  4 2018-M020  Brisbane     Hard           32 A            \n#>  5 2018-M020  Brisbane     Hard           32 A            \n#>  6 2018-M020  Brisbane     Hard           32 A            \n#>  7 2018-M020  Brisbane     Hard           32 A            \n#>  8 2018-M020  Brisbane     Hard           32 A            \n#>  9 2018-M020  Brisbane     Hard           32 A            \n#> 10 2018-M020  Brisbane     Hard           32 A            \n#> # … with 2,879 more rows, and 44 more variables:\n#> #   tourney_date <dbl>, match_num <dbl>, winner_id <dbl>,\n#> #   winner_seed <dbl>, winner_entry <chr>,\n#> #   winner_name <chr>, winner_hand <chr>, winner_ht <dbl>,\n#> #   winner_ioc <chr>, winner_age <dbl>, loser_id <dbl>,\n#> #   loser_seed <dbl>, loser_entry <chr>, loser_name <chr>,\n#> #   loser_hand <chr>, loser_ht <dbl>, loser_ioc <chr>,\n#> #   loser_age <dbl>, score <chr>, best_of <dbl>,\n#> #   round <chr>, minutes <dbl>, w_ace <dbl>, w_df <dbl>,\n#> #   w_svpt <dbl>, w_1stIn <dbl>, w_1stWon <dbl>,\n#> #   w_2ndWon <dbl>, w_SvGms <dbl>, w_bpSaved <dbl>,\n#> #   w_bpFaced <dbl>, l_ace <dbl>, l_df <dbl>, l_svpt <dbl>,\n#> #   l_1stIn <dbl>, l_1stWon <dbl>, l_2ndWon <dbl>,\n#> #   l_SvGms <dbl>, l_bpSaved <dbl>, l_bpFaced <dbl>,\n#> #   winner_rank <dbl>, winner_rank_points <dbl>,\n#> #   loser_rank <dbl>, loser_rank_points <dbl>"},{"path":"merging-with-dplyr.html","id":"filtering-with-semi_join","chapter":" 11 Merging with dplyr","heading":"11.3.0.0.1 Filtering with semi_join()","text":"Suppose want keep matches 2019 winning player 10 wins 2018. might useful want consider players 2018 played couple matches, perhaps got injured perhaps received special wildcard draw one event.accomplish , can first create data set names players won 10 matches 2018, using functions learned dplyr earlier semester:Next, apply semi_join(), takes names two data sets (second one contains information first “filtered”). third argument gives name key (winner_name) case.Note keeps matches 2019 winner 10 match wins 2018. drops matches loser lost someone 10 match wins 2018. isn’t yet perfect take little thought matches actually want keep particular analysis.","code":"\nwin10 <- atp_2018 %>% group_by(winner_name) %>%\n  summarise(nwin = n()) %>% \n  filter(nwin >= 10)\nwin10\n#> # A tibble: 93 x 2\n#>    winner_name       nwin\n#>    <chr>            <int>\n#>  1 Adrian Mannarino    26\n#>  2 Albert Ramos        21\n#>  3 Alex De Minaur      29\n#>  4 Alexander Zverev    58\n#>  5 Aljaz Bedene        19\n#>  6 Andreas Seppi       24\n#>  7 Andrey Rublev       20\n#>  8 Benoit Paire        27\n#>  9 Borna Coric         40\n#> 10 Cameron Norrie      19\n#> # … with 83 more rows\ntennis_2019_10 <- semi_join(atp_2019, win10,\n                            by = c(\"winner_name\" = \"winner_name\"))\ntennis_2019_10$winner_name"},{"path":"merging-with-dplyr.html","id":"filtering-with-anti_join","chapter":" 11 Merging with dplyr","heading":"11.3.1 Filtering with anti_join()","text":"Now suppose want keep matches 2019 winning player wins 2018. might think players “emerging players” 2019, players coming back injury, etc.. , can use anti_join(), keeps rows first data set match second data set.can examine many wins “new” (perhaps previously injured) players 2019:filtering join functions useful want filter observations criterion different data set.","code":"\nnew_winners <- anti_join(atp_2019, atp_2018,\n                         by = c(\"winner_name\" = \"winner_name\")) \nnew_winners$winner_name\nnew_winners %>% group_by(winner_name) %>%\n  summarise(nwin = n()) %>%\n  arrange(desc(nwin))\n#> # A tibble: 59 x 2\n#>    winner_name           nwin\n#>    <chr>                <int>\n#>  1 Christian Garin         32\n#>  2 Juan Ignacio Londero    22\n#>  3 Miomir Kecmanovic       22\n#>  4 Hugo Dellien            12\n#>  5 Attila Balazs            7\n#>  6 Cedrik Marcel Stebe      7\n#>  7 Janko Tipsarevic         7\n#>  8 Jannik Sinner            7\n#>  9 Soon Woo Kwon            7\n#> 10 Gregoire Barrere         6\n#> # … with 49 more rows"},{"path":"merging-with-dplyr.html","id":"exercise-10-3","chapter":" 11 Merging with dplyr","heading":"11.3.2 Exercises","text":"Exercises marked * indicate exercise solution end chapter 11.6.Take semi_join() tennis example, now suppose want keep matches 2019 either winning player losing player 10 match wins 2018. can modify code achieve goal?* Take semi_join() tennis example, now suppose want keep matches 2019 winning player losing player 10 match wins 2018. can modify code achieve goal?","code":"\ntennis_2019_10 <- semi_join(atp_2019, win10,\n                            by = c(\"winner_name\" = \"winner_name\"))\ntennis_2019_10$winner_name\ntennis_2019_10 <- semi_join(atp_2019, win10,\n                            by = c(\"winner_name\" = \"winner_name\"))\ntennis_2019_10$winner_name"},{"path":"merging-with-dplyr.html","id":"a-note-on-sql","chapter":" 11 Merging with dplyr","heading":"11.4 A Note on SQL","text":"dplyr functions ’ve used (ones Week 2 Joins week) corresponding components SQL. dbplyr package useful ’re interested learning SQL . Given dplyr pipe base R function, dbplyr can show equivalent command SQL. general, SQL code much harder read, SQL isn’t designed specifically data analysis like dplyr .examples dbplyr’s translate_sql() function translation R code SQL :resource learning https://dbplyr.tidyverse.org/articles/sql-translation.html.","code":"\nlibrary(dbplyr)\ntranslate_sql(semi_join(atp_2019, win10,\n                        c(\"winner_name\" = \"winner_name\")))\n#> <SQL> semi_join(`atp_2019`, `win10`, 'winner_name' AS `winner_name`)\n\ntranslate_sql(atp_2018 %>% group_by(winner_name) %>%\n  summarise(n()) %>% \n  filter(nwin >= 10))\n#> <SQL> filter(summarise(group_by(`atp_2018`, `winner_name`), COUNT(*) OVER ()), `nwin` >= 10.0)"},{"path":"merging-with-dplyr.html","id":"chapexercise-10","chapter":" 11 Merging with dplyr","heading":"11.5 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 11.6.* Read gun violence data set, suppose want add row data set statistics gun ownership mortality rate District Columbia (Washington D.C., NE region, 16.7 deaths per 100,000 people, gun ownership rate 8.7%). , create tibble() single row representing D.C. combine new tibble overall gun violence data set. Name new data set all_df.Explain attempt combining D.C. data overall data doesn’t work incorrect.Examine following data sets R’s base library demographic statistics U.S. states state abbreviations:Combine two data sets bind_cols(). assuming data sets order use function?* Combine columns states data set made Exercise 3 mortality data set without Washington D.C.* Combine columns states data set made Exercise 3 mortality data set without Washington D.C.* Use join function combine mortality data set (all_df) D.C. states data set Exercise 3 (states_df). exercise, keep row Washington D.C., take NA values variable observed states data.* Use join function combine mortality data set (all_df) D.C. states data set Exercise 3 (states_df). exercise, keep row Washington D.C., take NA values variable observed states data.* Repeat Exercise 5, now drop Washington D.C. merging process. Practice join function (opposed slice()-ing explicitly).* Repeat Exercise 5, now drop Washington D.C. merging process. Practice join function (opposed slice()-ing explicitly).* Use semi_join() create subset states_df NE region. Hint: need filter all_df first contain states NE region.* Use semi_join() create subset states_df NE region. Hint: need filter all_df first contain states NE region.* thing Exercise 7, time, use anti_join(). Hint: ’ll need filter all_df different way achieve .* thing Exercise 7, time, use anti_join(). Hint: ’ll need filter all_df different way achieve .Examine following data sets (first df1 second df2) , without running code, answer following questions.Examine following data sets (first df1 second df2) , without running code, answer following questions.many rows data set left_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set left_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set left_join(df2, df1, = c(\"id\" = \"id\"))?many rows data set left_join(df2, df1, = c(\"id\" = \"id\"))?many rows data set full_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set full_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set inner_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set inner_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set semi_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set semi_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set anti_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set anti_join(df1, df2, = c(\"id\" = \"id\"))?","code":"\nlibrary(tidyverse)\nmortality_df <- read_csv(\"data/gun_violence_us.csv\")\ntest1 <- tibble(state = \"Washington D.C.\", mortality_rate = 16.7,\n                ownership_rate = 8.7, region = \"NE\")\nbind_rows(mortality_df, test1)\n\ntest2 <- tibble(state = \"Washington D.C.\", mortality_rate = 16.7,\n       ownership_rate = 0.087, region = NE)\n#> Error in eval_tidy(xs[[j]], mask): object 'NE' not found\nbind_rows(mortality_df, test2)\n#> Error in list2(...): object 'test2' not found\n\ntest3 <- tibble(state = \"Washington D.C.\", mortality_rate = \"16.7\",\n       ownership_rate = \"0.087\", region = \"NE\")\nbind_rows(mortality_df, test3)\n#> Error: Can't combine `mortality_rate` <double> and `mortality_rate` <character>.\ndf1 <- as_tibble(state.x77)\ndf2 <- as_tibble(state.abb)\ndf1\n#> # A tibble: 50 x 8\n#>    Population Income Illiteracy `Life Exp` Murder `HS Grad`\n#>         <dbl>  <dbl>      <dbl>      <dbl>  <dbl>     <dbl>\n#>  1       3615   3624        2.1       69.0   15.1      41.3\n#>  2        365   6315        1.5       69.3   11.3      66.7\n#>  3       2212   4530        1.8       70.6    7.8      58.1\n#>  4       2110   3378        1.9       70.7   10.1      39.9\n#>  5      21198   5114        1.1       71.7   10.3      62.6\n#>  6       2541   4884        0.7       72.1    6.8      63.9\n#>  7       3100   5348        1.1       72.5    3.1      56  \n#>  8        579   4809        0.9       70.1    6.2      54.6\n#>  9       8277   4815        1.3       70.7   10.7      52.6\n#> 10       4931   4091        2         68.5   13.9      40.6\n#> # … with 40 more rows, and 2 more variables: Frost <dbl>,\n#> #   Area <dbl>\ndf2\n#> # A tibble: 50 x 1\n#>    value\n#>    <chr>\n#>  1 AL   \n#>  2 AK   \n#>  3 AZ   \n#>  4 AR   \n#>  5 CA   \n#>  6 CO   \n#>  7 CT   \n#>  8 DE   \n#>  9 FL   \n#> 10 GA   \n#> # … with 40 more rows"},{"path":"merging-with-dplyr.html","id":"solutions-10","chapter":" 11 Merging with dplyr","heading":"11.6 Exercise Solutions","text":"","code":""},{"path":"merging-with-dplyr.html","id":"bind_rows-and-bind_cols-s","chapter":" 11 Merging with dplyr","heading":"11.6.1 bind_rows() and bind_cols() S","text":"* Run following explain R simply stack rows. , fix issue rename() function.","code":"\ndf_test1a <- tibble(xvar = c(1, 2), yvar = c(5, 1))\ndf_test1b <- tibble(x = c(1, 2), y = c(5, 1))\nbind_rows(df_test1a, df_test1b)\n#> # A tibble: 4 x 4\n#>    xvar  yvar     x     y\n#>   <dbl> <dbl> <dbl> <dbl>\n#> 1     1     5    NA    NA\n#> 2     2     1    NA    NA\n#> 3    NA    NA     1     5\n#> 4    NA    NA     2     1\n## This doesn't stack rows because the columns are named differently\n## in the two data sets. If xvar is the same variable as x and \n## yvar is the same variable as y, then we can rename the columns in\n## one of the data sets:\n\ndf_test1a <- df_test1a %>% rename(x = \"xvar\", y = \"yvar\")\nbind_rows(df_test1a, df_test1b)\n#> # A tibble: 4 x 2\n#>       x     y\n#>   <dbl> <dbl>\n#> 1     1     5\n#> 2     2     1\n#> 3     1     5\n#> 4     2     1"},{"path":"merging-with-dplyr.html","id":"mutating-joins-s","chapter":" 11 Merging with dplyr","heading":"11.6.2 Mutating Joins S","text":"","code":""},{"path":"merging-with-dplyr.html","id":"filtering-joins-s","chapter":" 11 Merging with dplyr","heading":"11.6.3 Filtering Joins S","text":"* Take semi_join() tennis example, now suppose want keep matches 2019 winning player losing player 10 match wins 2018. can modify code achieve goal?","code":"\ntennis_2019_10 <- semi_join(atp_2019, win10,\n                            by = c(\"winner_name\" = \"winner_name\"))\ntennis_2019_10$winner_name\n## There are many ways to do this, and this solution gives just one way\n## A first step would be to create a data set that keeps only\n## the katches with losing players with 10 or more wins in 2018\ntennis_2019_10_lose <- semi_join(atp_2019, win10,\n                            by = c(\"loser_name\" = \"winner_name\"))\n\n## Using `bind_rows()` would result in many duplicate matches. A way\n## to avoid duplicates with joining functions is\n\ntennis_temp <- anti_join(tennis_2019_10_lose, tennis_2019_10)\n#> Joining, by = c(\"tourney_id\", \"tourney_name\", \"surface\", \"draw_size\", \"tourney_level\", \"tourney_date\", \"match_num\", \"winner_id\", \"winner_seed\", \"winner_entry\", \"winner_name\", \"winner_hand\", \"winner_ht\", \"winner_ioc\", \"winner_age\", \"loser_id\", \"loser_seed\", \"loser_entry\", \"loser_name\", \"loser_hand\", \"loser_ht\", \"loser_ioc\", \"loser_age\", \"score\", \"best_of\", \"round\", \"minutes\", \"w_ace\", \"w_df\", \"w_svpt\", \"w_1stIn\", \"w_1stWon\", \"w_2ndWon\", \"w_SvGms\", \"w_bpSaved\", \"w_bpFaced\", \"l_ace\", \"l_df\", \"l_svpt\", \"l_1stIn\", \"l_1stWon\", \"l_2ndWon\", \"l_SvGms\", \"l_bpSaved\", \"l_bpFaced\", \"winner_rank\", \"winner_rank_points\", \"loser_rank\", \"loser_rank_points\")\ntennis_temp\n## there are 383 matches in the lose data set that aren't in the \n## win data set. Now, we can bind_rows():\n\nfinal_df <- bind_rows(tennis_2019_10, tennis_temp)"},{"path":"merging-with-dplyr.html","id":"chapexercise-10-S","chapter":" 11 Merging with dplyr","heading":"11.6.4 Chapter Exercises S","text":"* Read gun violence data set, suppose want add row data set statistics gun ownership mortality rate District Columbia (Washington D.C., NE region, 16.7 deaths per 100,000 people, gun ownership rate 8.7%). , create tibble() single row representing D.C. combine new tibble overall gun violence data set. Name new data set all_df.* Combine columns states data set made Section Exercise 3 mortality data set without Washington D.C.* Use join function combine mortality data set D.C. states data set Exercise 3. exercise, keep row Washington D.C., take NA values variable observed states data.* Repeat Exercise 5, now drop Washington D.C. merging process. Practice join function (opposed slice() ing explictly).* Use semi_join() create subset states_df NE region. Hint: need filter all_df first contain states NE region.* thing Exercise 7, time, use anti_join(). Hint: ’ll need filter all_df different way achieve .","code":"\nlibrary(tidyverse)\nmortality_df <- read_csv(\"data/gun_violence_us.csv\")\n#> \n#> ── Column specification ────────────────────────────────────\n#> cols(\n#>   state = col_character(),\n#>   mortality_rate = col_double(),\n#>   ownership_rate = col_double(),\n#>   region = col_character()\n#> )\ndc_df <- tibble(state = \"Washington D.C.\", mortality_rate = 16.7,\n       ownership_rate = 0.087, region = \"NE\")\nall_df <- bind_rows(mortality_df, dc_df)\nbind_cols(mortality_df, states_df)\nleft_join(all_df, states_df, by = c(\"state\" = \"value\"))\n#> # A tibble: 51 x 12\n#>    state mortality_rate ownership_rate region Population\n#>    <chr>          <dbl>          <dbl> <chr>       <dbl>\n#>  1 AL              16.7          0.489 South        3615\n#>  2 AK              18.8          0.617 West          365\n#>  3 AZ              13.4          0.323 West         2212\n#>  4 AR              16.4          0.579 South        2110\n#>  5 CA               7.4          0.201 West        21198\n#>  6 CO              12.1          0.343 West         2541\n#>  7 CT               4.9          0.166 NE           3100\n#>  8 DE              11.1          0.052 NE            579\n#>  9 FL              11.5          0.325 South        8277\n#> 10 GA              13.7          0.316 South        4931\n#> # … with 41 more rows, and 7 more variables: Income <dbl>,\n#> #   Illiteracy <dbl>, Life Exp <dbl>, Murder <dbl>,\n#> #   HS Grad <dbl>, Frost <dbl>, Area <dbl>\n## or\nfull_join(all_df, states_df, by = c(\"state\" = \"value\"))\n#> # A tibble: 51 x 12\n#>    state mortality_rate ownership_rate region Population\n#>    <chr>          <dbl>          <dbl> <chr>       <dbl>\n#>  1 AL              16.7          0.489 South        3615\n#>  2 AK              18.8          0.617 West          365\n#>  3 AZ              13.4          0.323 West         2212\n#>  4 AR              16.4          0.579 South        2110\n#>  5 CA               7.4          0.201 West        21198\n#>  6 CO              12.1          0.343 West         2541\n#>  7 CT               4.9          0.166 NE           3100\n#>  8 DE              11.1          0.052 NE            579\n#>  9 FL              11.5          0.325 South        8277\n#> 10 GA              13.7          0.316 South        4931\n#> # … with 41 more rows, and 7 more variables: Income <dbl>,\n#> #   Illiteracy <dbl>, Life Exp <dbl>, Murder <dbl>,\n#> #   HS Grad <dbl>, Frost <dbl>, Area <dbl>\ninner_join(all_df, states_df, by = c(\"state\" = \"value\"))\n#> # A tibble: 50 x 12\n#>    state mortality_rate ownership_rate region Population\n#>    <chr>          <dbl>          <dbl> <chr>       <dbl>\n#>  1 AL              16.7          0.489 South        3615\n#>  2 AK              18.8          0.617 West          365\n#>  3 AZ              13.4          0.323 West         2212\n#>  4 AR              16.4          0.579 South        2110\n#>  5 CA               7.4          0.201 West        21198\n#>  6 CO              12.1          0.343 West         2541\n#>  7 CT               4.9          0.166 NE           3100\n#>  8 DE              11.1          0.052 NE            579\n#>  9 FL              11.5          0.325 South        8277\n#> 10 GA              13.7          0.316 South        4931\n#> # … with 40 more rows, and 7 more variables: Income <dbl>,\n#> #   Illiteracy <dbl>, Life Exp <dbl>, Murder <dbl>,\n#> #   HS Grad <dbl>, Frost <dbl>, Area <dbl>\n## or\nleft_join(states_df, all_df, by = c(\"value\" = \"state\"))\n#> # A tibble: 50 x 12\n#>    Population Income Illiteracy `Life Exp` Murder `HS Grad`\n#>         <dbl>  <dbl>      <dbl>      <dbl>  <dbl>     <dbl>\n#>  1       3615   3624        2.1       69.0   15.1      41.3\n#>  2        365   6315        1.5       69.3   11.3      66.7\n#>  3       2212   4530        1.8       70.6    7.8      58.1\n#>  4       2110   3378        1.9       70.7   10.1      39.9\n#>  5      21198   5114        1.1       71.7   10.3      62.6\n#>  6       2541   4884        0.7       72.1    6.8      63.9\n#>  7       3100   5348        1.1       72.5    3.1      56  \n#>  8        579   4809        0.9       70.1    6.2      54.6\n#>  9       8277   4815        1.3       70.7   10.7      52.6\n#> 10       4931   4091        2         68.5   13.9      40.6\n#> # … with 40 more rows, and 6 more variables: Frost <dbl>,\n#> #   Area <dbl>, value <chr>, mortality_rate <dbl>,\n#> #   ownership_rate <dbl>, region <chr>\nne_df <- all_df %>% filter(region == \"NE\")\nsemi_join(states_df, ne_df, by = c(\"value\" = \"state\"))\n#> # A tibble: 10 x 9\n#>    Population Income Illiteracy `Life Exp` Murder `HS Grad`\n#>         <dbl>  <dbl>      <dbl>      <dbl>  <dbl>     <dbl>\n#>  1       3100   5348        1.1       72.5    3.1      56  \n#>  2        579   4809        0.9       70.1    6.2      54.6\n#>  3       1058   3694        0.7       70.4    2.7      54.7\n#>  4       4122   5299        0.9       70.2    8.5      52.3\n#>  5       5814   4755        1.1       71.8    3.3      58.5\n#>  6        812   4281        0.7       71.2    3.3      57.6\n#>  7       7333   5237        1.1       70.9    5.2      52.5\n#>  8      18076   4903        1.4       70.6   10.9      52.7\n#>  9        931   4558        1.3       71.9    2.4      46.4\n#> 10        472   3907        0.6       71.6    5.5      57.1\n#> # … with 3 more variables: Frost <dbl>, Area <dbl>,\n#> #   value <chr>\nnotne_df <- all_df %>% filter(region != \"NE\")\nanti_join(states_df, notne_df, by = c(\"value\" = \"state\"))\n#> # A tibble: 10 x 9\n#>    Population Income Illiteracy `Life Exp` Murder `HS Grad`\n#>         <dbl>  <dbl>      <dbl>      <dbl>  <dbl>     <dbl>\n#>  1       3100   5348        1.1       72.5    3.1      56  \n#>  2        579   4809        0.9       70.1    6.2      54.6\n#>  3       1058   3694        0.7       70.4    2.7      54.7\n#>  4       4122   5299        0.9       70.2    8.5      52.3\n#>  5       5814   4755        1.1       71.8    3.3      58.5\n#>  6        812   4281        0.7       71.2    3.3      57.6\n#>  7       7333   5237        1.1       70.9    5.2      52.5\n#>  8      18076   4903        1.4       70.6   10.9      52.7\n#>  9        931   4558        1.3       71.9    2.4      46.4\n#> 10        472   3907        0.6       71.6    5.5      57.1\n#> # … with 3 more variables: Frost <dbl>, Area <dbl>,\n#> #   value <chr>"},{"path":"merging-with-dplyr.html","id":"rcode-10","chapter":" 11 Merging with dplyr","heading":"11.7 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\natp_2019 <- read_csv(\"data/atp_matches_2019.csv\")\natp_2018 <- read_csv(\"data/atp_matches_2018.csv\")\nhead(atp_2019) \nhead(atp_2018)\nspec(atp_2018)\natp_2018 <- read_csv(\"data/atp_matches_2018.csv\",\n                     col_types = cols(winner_seed = col_character(),\n                                      loser_seed = col_character()))\natp_df <- bind_rows(atp_2018, atp_2019)\natp_df\ndf_test2a <- tibble(xvar = c(1, 2))\ndf_test2b <- tibble(xvar = c(1, 2), y = c(5, 1))\nbind_rows(df_test2a, df_test2b)\ndf_test1a <- tibble(xvar = c(1, 2), yvar = c(5, 1))\ndf_test1b <- tibble(x = c(1, 2), y = c(5, 1))\nbind_cols(df_test1a, df_test1b)\nlibrary(tidyverse)\ndf1 <- tibble(name = c(\"Emily\", \"Miguel\", \"Tonya\"), fav_sport = c(\"Swimming\", \"Football\", \"Tennis\"))\ndf2 <- tibble(name = c(\"Tonya\", \"Miguel\", \"Emily\"),\n              fav_colour = c(\"Robin's Egg Blue\", \"Tickle Me Pink\", \"Goldenrod\"))\n##install.packages(\"babynames\")\nlibrary(babynames)\nlife_df <- babynames::lifetables\nbirth_df <- babynames::births\nbabynames_df <- babynames::babynames\nhead(babynames)\nhead(births)\nhead(lifetables)\ncombined_left <- left_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))\nhead(combined_left)\ntail(combined_left)\n## these will always do the same exact thing\nright_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))\nleft_join(birth_df, babynames_df, by = c(\"year\" = \"year\"))\nfull_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))\ninner_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))\nslumajors_df <- read_csv(\"data/SLU_Majors_15_19.csv\")\ncollegemajors_df <- read_csv(\"data/college-majors.csv\")\nhead(slumajors_df)\nhead(collegemajors_df)\nleft_join(slumajors_df, collegemajors_df, by = c(\"Major\" = \"Major\"))\ncollegemajors_df <- collegemajors_df %>%\n  mutate(Major = str_to_title(Major))\nleft_join(slumajors_df, collegemajors_df)\natp_2019 <- read_csv(\"data/atp_matches_2019.csv\")\natp_2018 <- read_csv(\"data/atp_matches_2018.csv\")\natp_2019\natp_2018\nwin10 <- atp_2018 %>% group_by(winner_name) %>%\n  summarise(nwin = n()) %>% \n  filter(nwin >= 10)\nwin10\ntennis_2019_10 <- semi_join(atp_2019, win10,\n                            by = c(\"winner_name\" = \"winner_name\"))\ntennis_2019_10$winner_name\nnew_winners <- anti_join(atp_2019, atp_2018,\n                         by = c(\"winner_name\" = \"winner_name\")) \nnew_winners$winner_name\nnew_winners %>% group_by(winner_name) %>%\n  summarise(nwin = n()) %>%\n  arrange(desc(nwin))\nlibrary(dbplyr)\ntranslate_sql(semi_join(atp_2019, win10,\n                        c(\"winner_name\" = \"winner_name\")))\n\ntranslate_sql(atp_2018 %>% group_by(winner_name) %>%\n  summarise(n()) %>% \n  filter(nwin >= 10))"},{"path":"dates-with-lubridate.html","id":"dates-with-lubridate","chapter":" 12 Dates with lubridate","heading":" 12 Dates with lubridate","text":"Goals:use lubridate functions convert character variable <date> variable.use lubridate functions extract useful information <date> variable, including year, month, day week, day year.","code":""},{"path":"dates-with-lubridate.html","id":"converting-variables-to-date","chapter":" 12 Dates with lubridate","heading":"12.1 Converting Variables to <date>","text":"lubridate package built easily work Date objects DateTime objects. R actually class stores Time objects (unless install separate package). Dates tend much common Times, , primarily focus Dates, functions see easy extensions Times.begin, install lubridate package, load package library(). today() function prints today’s date now() prints today’s date time. can sometimes useful contexts, just run code see R stores dates date-times.first section deal convert variable R Date. use data set holidays Animal Crossing January April. columns data set :Holiday, name holiday andvarious columns different date formatsRead data set withWhich columns specified Dates? example, none columns <date> specification: date columns read character variables.","code":"\nlibrary(tidyverse)\nlibrary(lubridate)\ntoday()\n#> [1] \"2021-08-09\"\nnow()\n#> [1] \"2021-08-09 11:13:33 EDT\"\nholiday_df <- read_csv(\"data/animal_crossing_holidays.csv\")\nholiday_df\n#> # A tibble: 6 x 10\n#>   Holiday  Date1  Date2  Date3 Date4 Date5 Month  Year   Day\n#>   <chr>    <chr>  <chr>  <chr> <chr> <chr> <dbl> <dbl> <dbl>\n#> 1 New Yea… 1-Jan… Jan-1… 1/1/… 1/1/… 2020…     1  2020     1\n#> 2 Groundh… 2-Feb… Feb-2… 2/2/… 2/2/… 2020…     2  2020     2\n#> 3 Valenti… 14-Fe… Feb-1… 2/14… 2020… 2020…     2  2020    14\n#> 4 Shamroc… 17-Ma… Mar-1… 3/17… 2020… 2020…     3  2020    17\n#> 5 Bunny D… 12-Ap… Apr-1… 4/12… 12/4… 2020…     4  2020    12\n#> 6 Earth D… 22-Ap… Apr-2… 4/22… 2020… 2020…     4  2020    22\n#> # … with 1 more variable: Month2 <chr>"},{"path":"dates-with-lubridate.html","id":"from-chr-to-date","chapter":" 12 Dates with lubridate","heading":"12.1.1 From <chr> to <date>","text":"use dmy() series functions lubridate convert character variables dates. typically pair new function mutate() statement: much like forcats functions, almost always creating new variable.series dmy()-type variables, corresponding different Day-Month-Year order.dmy() used parse date character vector day first, month second, year last.ymd() used parse date year first, month second, date lastydm() used parse date year first, day second, month last,….dym(), mdy(), myd() work similarly. lubridate usually “smart” picks dates kinds different formats (e.g. can pick specifying October month Oct month 10 month).Let’s try Date1 Date2:Reminder: <date> objects even matter? Compare following two plots: one made date <chr> form date appropriate <date> form.plot ordering x-axis make sense?","code":"\nholiday_df %>% mutate(Date_test = dmy(Date1)) %>%\n  select(Date_test, everything())\n#> # A tibble: 6 x 11\n#>   Date_test  Holiday   Date1  Date2  Date3 Date4 Date5 Month\n#>   <date>     <chr>     <chr>  <chr>  <chr> <chr> <chr> <dbl>\n#> 1 2020-01-01 New Year… 1-Jan… Jan-1… 1/1/… 1/1/… 2020…     1\n#> 2 2020-02-02 Groundho… 2-Feb… Feb-2… 2/2/… 2/2/… 2020…     2\n#> 3 2020-02-14 Valentin… 14-Fe… Feb-1… 2/14… 2020… 2020…     2\n#> 4 2020-03-17 Shamrock… 17-Ma… Mar-1… 3/17… 2020… 2020…     3\n#> 5 2020-04-12 Bunny Day 12-Ap… Apr-1… 4/12… 12/4… 2020…     4\n#> 6 2020-04-22 Earth Day 22-Ap… Apr-2… 4/22… 2020… 2020…     4\n#> # … with 3 more variables: Year <dbl>, Day <dbl>,\n#> #   Month2 <chr>\nholiday_df %>% mutate(Date_test = mdy(Date2)) %>%\n  select(Date_test, everything())\n#> # A tibble: 6 x 11\n#>   Date_test  Holiday   Date1  Date2  Date3 Date4 Date5 Month\n#>   <date>     <chr>     <chr>  <chr>  <chr> <chr> <chr> <dbl>\n#> 1 2020-01-01 New Year… 1-Jan… Jan-1… 1/1/… 1/1/… 2020…     1\n#> 2 2020-02-02 Groundho… 2-Feb… Feb-2… 2/2/… 2/2/… 2020…     2\n#> 3 2020-02-14 Valentin… 14-Fe… Feb-1… 2/14… 2020… 2020…     2\n#> 4 2020-03-17 Shamrock… 17-Ma… Mar-1… 3/17… 2020… 2020…     3\n#> 5 2020-04-12 Bunny Day 12-Ap… Apr-1… 4/12… 12/4… 2020…     4\n#> 6 2020-04-22 Earth Day 22-Ap… Apr-2… 4/22… 2020… 2020…     4\n#> # … with 3 more variables: Year <dbl>, Day <dbl>,\n#> #   Month2 <chr>\nggplot(data = holiday_df, aes(x = Date1, y = Holiday)) +\n  geom_point()\nholiday_df <- holiday_df %>% mutate(Date_test_plot = dmy(Date1)) %>%\n  select(Date_test_plot, everything())\nggplot(data = holiday_df, aes(x = Date_test_plot, y = Holiday)) +\n  geom_point()"},{"path":"dates-with-lubridate.html","id":"making-a-date-variable-from-date-components","chapter":" 12 Dates with lubridate","heading":"12.1.2 Making a <date> variable from Date Components","text":"Another way create Date object assemble make_date() month, day, year components, stored separate column:, Month stored character (e.g. February) instead number (e.g. 2), problems arise make_date() function:make_date() function requires specific format year, month, day columns. may take little pre-processing put particular data set format.","code":"\nholiday_df %>% mutate(Date_test2 = make_date(year = Year,\n                                             month = Month,\n                                             day = Day)) %>%\n  select(Date_test2, everything())\n#> # A tibble: 6 x 12\n#>   Date_test2 Date_test_plot Holiday  Date1 Date2 Date3 Date4\n#>   <date>     <date>         <chr>    <chr> <chr> <chr> <chr>\n#> 1 2020-01-01 2020-01-01     New Yea… 1-Ja… Jan-… 1/1/… 1/1/…\n#> 2 2020-02-02 2020-02-02     Groundh… 2-Fe… Feb-… 2/2/… 2/2/…\n#> 3 2020-02-14 2020-02-14     Valenti… 14-F… Feb-… 2/14… 2020…\n#> 4 2020-03-17 2020-03-17     Shamroc… 17-M… Mar-… 3/17… 2020…\n#> 5 2020-04-12 2020-04-12     Bunny D… 12-A… Apr-… 4/12… 12/4…\n#> 6 2020-04-22 2020-04-22     Earth D… 22-A… Apr-… 4/22… 2020…\n#> # … with 5 more variables: Date5 <chr>, Month <dbl>,\n#> #   Year <dbl>, Day <dbl>, Month2 <chr>\nholiday_df %>% mutate(Date_test2 = make_date(year = Year,\n                                             month = Month2,\n                                             day = Day)) %>%\n  select(Date_test2, everything())\n#> Warning in make_date(year = Year, month = Month2, day =\n#> Day): NAs introduced by coercion\n#> # A tibble: 6 x 12\n#>   Date_test2 Date_test_plot Holiday  Date1 Date2 Date3 Date4\n#>   <date>     <date>         <chr>    <chr> <chr> <chr> <chr>\n#> 1 NA         2020-01-01     New Yea… 1-Ja… Jan-… 1/1/… 1/1/…\n#> 2 NA         2020-02-02     Groundh… 2-Fe… Feb-… 2/2/… 2/2/…\n#> 3 NA         2020-02-14     Valenti… 14-F… Feb-… 2/14… 2020…\n#> 4 NA         2020-03-17     Shamroc… 17-M… Mar-… 3/17… 2020…\n#> 5 NA         2020-04-12     Bunny D… 12-A… Apr-… 4/12… 12/4…\n#> 6 NA         2020-04-22     Earth D… 22-A… Apr-… 4/22… 2020…\n#> # … with 5 more variables: Date5 <chr>, Month <dbl>,\n#> #   Year <dbl>, Day <dbl>, Month2 <chr>"},{"path":"dates-with-lubridate.html","id":"exercise-11-1","chapter":" 12 Dates with lubridate","heading":"12.1.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 12.4.* ’s issue trying convert Date4 <date> form? may want investigate Date4 answer question.* Practice converting Date3 Date5 <date> variables lubridate functions.","code":"\nholiday_df %>% mutate(Date_test = ymd(Date4)) %>%\n  select(Date_test, everything())\n#> Warning: 3 failed to parse.\n#> # A tibble: 6 x 12\n#>   Date_test  Date_test_plot Holiday  Date1 Date2 Date3 Date4\n#>   <date>     <date>         <chr>    <chr> <chr> <chr> <chr>\n#> 1 2001-01-20 2020-01-01     New Yea… 1-Ja… Jan-… 1/1/… 1/1/…\n#> 2 2002-02-20 2020-02-02     Groundh… 2-Fe… Feb-… 2/2/… 2/2/…\n#> 3 NA         2020-02-14     Valenti… 14-F… Feb-… 2/14… 2020…\n#> 4 NA         2020-03-17     Shamroc… 17-M… Mar-… 3/17… 2020…\n#> 5 2012-04-20 2020-04-12     Bunny D… 12-A… Apr-… 4/12… 12/4…\n#> 6 NA         2020-04-22     Earth D… 22-A… Apr-… 4/22… 2020…\n#> # … with 5 more variables: Date5 <chr>, Month <dbl>,\n#> #   Year <dbl>, Day <dbl>, Month2 <chr>"},{"path":"dates-with-lubridate.html","id":"functions-for-date-variables","chapter":" 12 Dates with lubridate","heading":"12.2 Functions for <date> Variables","text":"object <date> format, special functions lubridate can used date variable. investigate functions, pull stock market data Yahoo using quantmod package. Install package, run following code, gets stock market price data Apple, Nintendo, Chipotle, S & P 500 Index 2011 now. Note ability understand code , skip code now focus new information section (information date functions).’ll chance Exercises choose stocks investigate. now, ’ve made data set three variables:start_date, opening date stock marketStock_Type, factor 4 levels: Apple, Nintendo, Chipotle, S & P 500Price, price stock?First, let’s make line plot shows S & P 500 changed time:, ’s information can get start_date variable. might interested things like day week, monthly trends, yearly trends. extract variables like “weekday” “month” <date> variable, series functions fairly straightforward use. discuss year() month(), mday(), yday(), wday() functions.","code":"\n## install.packages(\"quantmod\")\nlibrary(quantmod)\n\nstart <- ymd(\"2011-01-01\")\nend <- ymd(\"2021-5-19\")\ngetSymbols(c(\"AAPL\", \"NTDOY\", \"CMG\", \"SPY\"), src = \"yahoo\",\n           from = start, to = end)\n#> [1] \"AAPL\"  \"NTDOY\" \"CMG\"   \"SPY\"\n\ndate_tib <- as_tibble(index(AAPL)) %>%\n  rename(start_date = value)\napp_tib <- as_tibble(AAPL)\nnint_tib <- as_tibble(NTDOY)\nchip_tib <- as_tibble(CMG)\nspy_tib <- as_tibble(SPY)\nall_stocks <- bind_cols(date_tib, app_tib, nint_tib, chip_tib, spy_tib)\n\nstocks_long <- all_stocks %>%\n  select(start_date, AAPL.Adjusted, NTDOY.Adjusted,\n                      CMG.Adjusted, SPY.Adjusted) %>%\n  pivot_longer(2:5, names_to = \"Stock_Type\", values_to = \"Price\") %>%\n  mutate(Stock_Type = fct_recode(Stock_Type,\n                                 Apple = \"AAPL.Adjusted\",\n                                 Nintendo = \"NTDOY.Adjusted\",\n                                 Chipotle = \"CMG.Adjusted\",\n                                 `S & P 500` = \"SPY.Adjusted\"\n                                 ))\ntail(stocks_long)\n#> # A tibble: 6 x 3\n#>   start_date Stock_Type  Price\n#>   <date>     <fct>       <dbl>\n#> 1 2021-05-17 Chipotle   1332. \n#> 2 2021-05-17 S & P 500   414. \n#> 3 2021-05-18 Apple       125. \n#> 4 2021-05-18 Nintendo     70.4\n#> 5 2021-05-18 Chipotle   1325. \n#> 6 2021-05-18 S & P 500   411.\nstocks_sp <- stocks_long %>% filter(Stock_Type == \"S & P 500\")\nggplot(data = stocks_sp, aes(x = start_date, y = Price)) +\n  geom_line()"},{"path":"dates-with-lubridate.html","id":"year-month-and-mday","chapter":" 12 Dates with lubridate","heading":"12.2.1 year(), month(), and mday()","text":"functions year(), month(), mday() can grab year, month, day month, respectively, <date> variable. Like forcats functions, almost always paired mutate() statement create new variable:","code":"\nstocks_long %>% mutate(year_stock = year(start_date))\nstocks_long %>% mutate(month_stock = month(start_date))\nstocks_long %>% mutate(day_stock = mday(start_date))"},{"path":"dates-with-lubridate.html","id":"yday-and-wday","chapter":" 12 Dates with lubridate","heading":"12.2.2 yday() and wday()","text":"yday() function grabs day year <date> object. example,returns 309, indicating November 4th 309th day year 2020. Using function mutate() statement creates new variable yday observation:Finally, function wday() grabs day week <date>. default, wday() puts day week numeric, find confusing, can’t ever remember whether 1 means Sunday 1 means Monday. Adding, label = TRUE creates weekday variable Sunday, Monday, Tuesday, etc.:Possible uses functions :want look differences years (year())want look differences years (year())want look differences months (month())want look differences months (month())want look differences days week (wday())want look differences days week (wday())want see whether yearly trends within years (yday())want see whether yearly trends within years (yday())Note: Working times extremely similar working dates. Instead ymd(), mdy(), etc., tack extra letters specify order hour, minute, seconds appear variable: ymd_hms() converts character vector order year, month, day, hour, minute, second <datetime>.Additionally, functions hour(), minute(), second() grab hour, minute, second <datetime> variable.Note Complications: Things can get complicated, especially start consider things like time duration. reason time system inherently confusing. Consider following might affect analysis involving time duration:time zonesleap years (years number days)differing number days given monthdaylight saving time (days number hours)","code":"\ntest <- mdy(\"November 4, 2020\")\nyday(test)\n#> [1] 309\nstocks_long %>% mutate(day_in_year = yday(start_date))\n#> # A tibble: 10,444 x 4\n#>    start_date Stock_Type Price day_in_year\n#>    <date>     <fct>      <dbl>       <dbl>\n#>  1 2011-01-03 Apple       10.1           3\n#>  2 2011-01-03 Nintendo    36.7           3\n#>  3 2011-01-03 Chipotle   224.            3\n#>  4 2011-01-03 S & P 500  103.            3\n#>  5 2011-01-04 Apple       10.2           4\n#>  6 2011-01-04 Nintendo    35.5           4\n#>  7 2011-01-04 Chipotle   222.            4\n#>  8 2011-01-04 S & P 500  103.            4\n#>  9 2011-01-05 Apple       10.2           5\n#> 10 2011-01-05 Nintendo    34.6           5\n#> # … with 10,434 more rows\nstocks_long %>% mutate(day_of_week = wday(start_date))\nstocks_long %>% mutate(day_of_week = wday(start_date,\n                                          label = TRUE, abbr = FALSE))"},{"path":"dates-with-lubridate.html","id":"exercise-11-2","chapter":" 12 Dates with lubridate","heading":"12.2.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 12.4.month() function gives numbers corresponding month default. Type ?month figure argument need change get names (January, February, etc.) instead month numbers. abbreviations (Jan, Feb, etc.) month instead month numbers? Try making changes mutate() statement .","code":"\nstocks_long %>% mutate(month_stock = month(start_date))"},{"path":"dates-with-lubridate.html","id":"chapexercise-11","chapter":" 12 Dates with lubridate","heading":"12.3 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 12.4.truncated argument ymd(), dmy(), mdy(), etc. allow R parse dates aren’t actually complete. example,parses 2019 January 1, 2019 month day missing. 2 means last two parts date (case, month day) allowed missing. Similarly,truncates year (given 0000). truncate function usually useful context first example truncated month /day.Examine ds_google.csv, containsMonth, year month 2004 nowData_Science, relative popularity data science (Google keeps calculates “popularity” somewhat mystery likely based number times people search term “Data Science”)* Use lubridate function truncated option convert Month variable <date> format.* Use lubridate function truncated option convert Month variable <date> format.* Make plot popularity Data Science Time. Add smoother plot. patterns notice?* Make plot popularity Data Science Time. Add smoother plot. patterns notice?data obtained Google Trends: Google Trends. Google Trends incredibly cool explore, even without R.* Google Trends, Enter search term, change Time dropdown menu 2004-present. , enter second search term want compare. can also change country want (, can keep country United States).search terms “super smash” “animal crossing,” something interests !top-right window graph, click arrow download data set. Delete first two rows data set (either Excel R), read data set, change date variable ’s Date format.* Make plot Popularity variables time. Hint: data set need tidied first?* Make plot Popularity variables time. Hint: data set need tidied first?* Using data set explored variable two 2004 now, make table average popularity year. Hint: ’ll need lubridate function extract year variable date object.* Using data set explored variable two 2004 now, make table average popularity year. Hint: ’ll need lubridate function extract year variable date object.* Clear search now enter search term ’d like investigate past 90 days. Mine “Pittsburgh Steelers” , , something interests .* Clear search now enter search term ’d like investigate past 90 days. Mine “Pittsburgh Steelers” , , something interests ., click download button read data R. Convert date variable <date> format.* Make plot popularity variable time, adding smoother.* Make plot popularity variable time, adding smoother.Using data set explored variable past 90 days, construct table compares average popularity day week (Monday Saturday).Using data set explored variable past 90 days, construct table compares average popularity day week (Monday Saturday).Examine ds_df data set , data set data science Google Trends, suppose observation day every year (just one observation per month). want look whether data science popular certain days week. Explain following strategy wouldn’t really work well.Examine ds_df data set , data set data science Google Trends, suppose observation day every year (just one observation per month). want look whether data science popular certain days week. Explain following strategy wouldn’t really work well.create weekday variable wday()use summarise() group_by() find average popularity day weekUse code tutorial section Stocks data get data frame stock prices couple different stocks interest . start end date use completely .Explore stock data chose, constructing line plot price time, well graphs summaries show interesting patterns across years, months, days, days week, etc.Use lag() function create new variable previous day’s stock price. Can predict current stock price based previous day’s stock price accurately? ? Use either graphical numerical evidence.","code":"\nlibrary(lubridate)\nymd(\"2019\", truncated = 2)\n#> [1] \"2019-01-01\"\ndmy(\"19-10\", truncated = 1)\n#> [1] \"0000-10-19\"\nlibrary(tidyverse)\nlibrary(lubridate)\nds_df <- read_csv(\"data/ds_google.csv\")\nds_df\n#> # A tibble: 202 x 2\n#>    Month   Data_Science\n#>    <chr>          <dbl>\n#>  1 2004-01           14\n#>  2 2004-02            8\n#>  3 2004-03           16\n#>  4 2004-04           11\n#>  5 2004-05            5\n#>  6 2004-06            8\n#>  7 2004-07            7\n#>  8 2004-08            9\n#>  9 2004-09           13\n#> 10 2004-10           11\n#> # … with 192 more rows"},{"path":"dates-with-lubridate.html","id":"solutions-11","chapter":" 12 Dates with lubridate","heading":"12.4 Exercise Solutions","text":"","code":""},{"path":"dates-with-lubridate.html","id":"converting-variables-to-date-s","chapter":" 12 Dates with lubridate","heading":"12.4.1 Converting Variables to <date> S","text":"* ’s issue trying convert Date4 <date> form?* Practice converting Date3 Date5 date objects lubridate functions.","code":"\nholiday_df %>% mutate(Date_test = ymd(Date4)) %>%\n  select(Date_test, everything())\n#> Warning: 3 failed to parse.\n#> # A tibble: 6 x 12\n#>   Date_test  Date_test_plot Holiday  Date1 Date2 Date3 Date4\n#>   <date>     <date>         <chr>    <chr> <chr> <chr> <chr>\n#> 1 2001-01-20 2020-01-01     New Yea… 1-Ja… Jan-… 1/1/… 1/1/…\n#> 2 2002-02-20 2020-02-02     Groundh… 2-Fe… Feb-… 2/2/… 2/2/…\n#> 3 NA         2020-02-14     Valenti… 14-F… Feb-… 2/14… 2020…\n#> 4 NA         2020-03-17     Shamroc… 17-M… Mar-… 3/17… 2020…\n#> 5 2012-04-20 2020-04-12     Bunny D… 12-A… Apr-… 4/12… 12/4…\n#> 6 NA         2020-04-22     Earth D… 22-A… Apr-… 4/22… 2020…\n#> # … with 5 more variables: Date5 <chr>, Month <dbl>,\n#> #   Year <dbl>, Day <dbl>, Month2 <chr>\n## Date4 has two __different__ formats, \n## which creates problems for `lubridate` functions\nholiday_df %>% mutate(Date_test = mdy(Date3)) %>%\n  select(Date_test, everything())\n#> # A tibble: 6 x 12\n#>   Date_test  Date_test_plot Holiday  Date1 Date2 Date3 Date4\n#>   <date>     <date>         <chr>    <chr> <chr> <chr> <chr>\n#> 1 2020-01-01 2020-01-01     New Yea… 1-Ja… Jan-… 1/1/… 1/1/…\n#> 2 2020-02-02 2020-02-02     Groundh… 2-Fe… Feb-… 2/2/… 2/2/…\n#> 3 2020-02-14 2020-02-14     Valenti… 14-F… Feb-… 2/14… 2020…\n#> 4 2020-03-17 2020-03-17     Shamroc… 17-M… Mar-… 3/17… 2020…\n#> 5 2020-04-12 2020-04-12     Bunny D… 12-A… Apr-… 4/12… 12/4…\n#> 6 2020-04-22 2020-04-22     Earth D… 22-A… Apr-… 4/22… 2020…\n#> # … with 5 more variables: Date5 <chr>, Month <dbl>,\n#> #   Year <dbl>, Day <dbl>, Month2 <chr>\nholiday_df %>% mutate(Date_test = ymd(Date5)) %>%\n  select(Date_test, everything())\n#> # A tibble: 6 x 12\n#>   Date_test  Date_test_plot Holiday  Date1 Date2 Date3 Date4\n#>   <date>     <date>         <chr>    <chr> <chr> <chr> <chr>\n#> 1 2020-01-01 2020-01-01     New Yea… 1-Ja… Jan-… 1/1/… 1/1/…\n#> 2 2020-02-02 2020-02-02     Groundh… 2-Fe… Feb-… 2/2/… 2/2/…\n#> 3 2020-02-14 2020-02-14     Valenti… 14-F… Feb-… 2/14… 2020…\n#> 4 2020-03-17 2020-03-17     Shamroc… 17-M… Mar-… 3/17… 2020…\n#> 5 2020-04-12 2020-04-12     Bunny D… 12-A… Apr-… 4/12… 12/4…\n#> 6 2020-04-22 2020-04-22     Earth D… 22-A… Apr-… 4/22… 2020…\n#> # … with 5 more variables: Date5 <chr>, Month <dbl>,\n#> #   Year <dbl>, Day <dbl>, Month2 <chr>"},{"path":"dates-with-lubridate.html","id":"functions-for-date-variables-s","chapter":" 12 Dates with lubridate","heading":"12.4.2 Functions for <date> Variables S","text":"","code":""},{"path":"dates-with-lubridate.html","id":"chapexercise-11-S","chapter":" 12 Dates with lubridate","heading":"12.4.3 Chapter Exercises S","text":"* Use lubridate function truncated option convert Month variable <date> format.* Make plot popularity Data Science Time. Add smoother plot. patterns notice?* Google Trends, Enter search term, change Time dropdown menu 2004-present. , enter second search term want compare. can also change country want (, can keep country United States).search terms “super smash” “animal crossing,” something interests !top-right window graph, click arrow download data set. Delete first two rows data set (either Excel R), read data set, change date variable ’s Date format.* Make plot Popularity variables time. Hint: data set need tidied first?* Using data set explored variable two 2004 now, make table average popularity year. Hint: ’ll need lubridate function extract year variable date object.* Using data set explored variable two 2004 now, make table average popularity year. Hint: ’ll need lubridate function extract year variable date object.* Clear search now enter search term ’d like investigate past 90 days. Mine “pittsburgh steelers” , , something interests .* Clear search now enter search term ’d like investigate past 90 days. Mine “pittsburgh steelers” , , something interests ., click download button read data R. Convert date variable <date> format.* Make plot popularity variable time, adding smoother.","code":"\nds_df <- ds_df %>% mutate(Month = ymd(Month, truncated = 1))\nds_df\nggplot(data = ds_df, aes(x = Month, y = Data_Science)) +\n  geom_line() +\n  geom_smooth(se = FALSE)\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'\n## it's like super popular!!!!\nvideogame_df <- read_csv(\"data/smash_animal_crossing.csv\")\n#> \n#> ── Column specification ────────────────────────────────────\n#> cols(\n#>   Month = col_character(),\n#>   super_smash = col_double(),\n#>   animal_crossing = col_double()\n#> )\nvideogame_df <- videogame_df %>% mutate(date = ymd(Month, truncated = 1))\nvideogame_long <- videogame_df %>%\n  pivot_longer(cols = c(\"super_smash\", \"animal_crossing\"),\n                              names_to = \"game\",\n                              values_to = \"popularity\")\nggplot(data = videogame_long, aes(x = date, \n                                  y = popularity,\n                                  colour = game)) +\n  geom_line() +\n  scale_colour_viridis_d(begin = 0, end = 0.9)\nsteelers_df <- read_csv(\"data/steelers.csv\")\n#> \n#> ── Column specification ────────────────────────────────────\n#> cols(\n#>   Day = col_character(),\n#>   Steelers = col_double()\n#> )\nsteelers_df <- steelers_df %>% mutate(day_var = mdy(Day))\nggplot(data = steelers_df, aes(x = day_var, y = Steelers)) +\n  geom_smooth() + \n  geom_line() +\n  labs(y = \"Popularity\")\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'"},{"path":"dates-with-lubridate.html","id":"rcode-11","chapter":" 12 Dates with lubridate","heading":"12.5 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\nlibrary(lubridate)\ntoday()\nnow()\nholiday_df <- read_csv(\"data/animal_crossing_holidays.csv\")\nholiday_df\nholiday_df %>% mutate(Date_test = dmy(Date1)) %>%\n  select(Date_test, everything())\nholiday_df %>% mutate(Date_test = mdy(Date2)) %>%\n  select(Date_test, everything())\nggplot(data = holiday_df, aes(x = Date1, y = Holiday)) +\n  geom_point()\nholiday_df <- holiday_df %>% mutate(Date_test_plot = dmy(Date1)) %>%\n  select(Date_test_plot, everything())\nggplot(data = holiday_df, aes(x = Date_test_plot, y = Holiday)) +\n  geom_point()\nholiday_df %>% mutate(Date_test2 = make_date(year = Year,\n                                             month = Month,\n                                             day = Day)) %>%\n  select(Date_test2, everything())\nholiday_df %>% mutate(Date_test2 = make_date(year = Year,\n                                             month = Month2,\n                                             day = Day)) %>%\n  select(Date_test2, everything())\n## install.packages(\"quantmod\")\nlibrary(quantmod)\n\nstart <- ymd(\"2011-01-01\")\nend <- ymd(\"2021-5-19\")\ngetSymbols(c(\"AAPL\", \"NTDOY\", \"CMG\", \"SPY\"), src = \"yahoo\",\n           from = start, to = end)\n\ndate_tib <- as_tibble(index(AAPL)) %>%\n  rename(start_date = value)\napp_tib <- as_tibble(AAPL)\nnint_tib <- as_tibble(NTDOY)\nchip_tib <- as_tibble(CMG)\nspy_tib <- as_tibble(SPY)\nall_stocks <- bind_cols(date_tib, app_tib, nint_tib, chip_tib, spy_tib)\n\nstocks_long <- all_stocks %>%\n  select(start_date, AAPL.Adjusted, NTDOY.Adjusted,\n                      CMG.Adjusted, SPY.Adjusted) %>%\n  pivot_longer(2:5, names_to = \"Stock_Type\", values_to = \"Price\") %>%\n  mutate(Stock_Type = fct_recode(Stock_Type,\n                                 Apple = \"AAPL.Adjusted\",\n                                 Nintendo = \"NTDOY.Adjusted\",\n                                 Chipotle = \"CMG.Adjusted\",\n                                 `S & P 500` = \"SPY.Adjusted\"\n                                 ))\ntail(stocks_long)\nstocks_sp <- stocks_long %>% filter(Stock_Type == \"S & P 500\")\nggplot(data = stocks_sp, aes(x = start_date, y = Price)) +\n  geom_line()\nstocks_long %>% mutate(year_stock = year(start_date))\nstocks_long %>% mutate(month_stock = month(start_date))\nstocks_long %>% mutate(day_stock = mday(start_date))\ntest <- mdy(\"November 4, 2020\")\nyday(test)\nstocks_long %>% mutate(day_in_year = yday(start_date))\nstocks_long %>% mutate(day_of_week = wday(start_date))\nstocks_long %>% mutate(day_of_week = wday(start_date,\n                                          label = TRUE, abbr = FALSE))"},{"path":"strings-with-stringr.html","id":"strings-with-stringr","chapter":" 13 Strings with stringr","heading":" 13 Strings with stringr","text":"Incomplete Chapter (Section 13.2).Goals:use functions stringr package analyze text data.introduce issues manipulating strings don’t pertain numeric factor data.","code":""},{"path":"strings-with-stringr.html","id":"friday-friday","chapter":" 13 Strings with stringr","heading":"13.1 Friday, Friday","text":"string lyrics Rebecca Black’s critically reviewed song Friday: https://www.youtube.com/watch?v=kfVsfOSbJY0. particular, answer following questions:many times Rebecca Black say word “Friday” song?many times say word involving “day” song?popular words song?questions may seem simple, can actually still somewhat challenging answer. Issues like punctuation, filler words, parsing long string give us challenges work .first goal parse every word object. Run following examine rblack object. \\n denotes line break string.first step use \\n separator split lyric strings character using str_split() function. str_split() takes string first argument want split string (\\n case) second argument. simplify = TRUE puts results matrix instead list.’s much better look ! Look structure rblack2 :see rblack2 matrix 1 row 76 columns. , now want word separate string. can using str_split() , , time getting rid spaces.Look carefully rblack2 rblack3: ’s difference? rblack2, ’s quotes surrounding line rblack3, ’s quotes surrounding word.can use unlist() function convert list regular vector:happen tried count number times Rebecca Black says Friday words ? Let’s try see!issue approach instances Friday , without. Based issue, let’s go back vector words rblack4 see can fix using str_remove(), removes given patterns string. example,removes commas.Another issue , word starts sentence, ’s capitalized R thinks Partyin' completely different word partyin'. str_to_lower() function converts characters lowercase:Finally, might want get rid “non-interesting” words, commonly known “stop words.” words like “,” “,” “,” “,” etc. don’t really provide meaning song. tidytext package data set list stop words prepackaged. Install package, load tidytext library, examine stop words :Next, let’s make Friday words tibble tibble() function:can now use anti_join() function get rid stop words Rebecca Black data set.see 98 words dropped data set, words weren’t picked (like yeah-ah-ah). leave now, , remove filter(words != \"yeah-ah-ah\") Finally, can get counts words song Friday aren’t “stop words.”","code":"\nlibrary(tidyverse)\nlibrary(stringr)\nrblack <- c([2156 chars quoted with '\"'])\nrblack\nrblack2 <- str_split(rblack, \"\\n\", simplify = TRUE)\nrblack2\nstr(rblack2)\nrblack3 <- str_split(rblack2, c(\" \"))\nrblack3\nrblack4 <- unlist(rblack3)\nrblack4\nrblack_df <- tibble(words = rblack4)\nrblack_df %>% group_by(words) %>%\n  summarise(word_count = n()) %>%\n  arrange(desc(word_count))\n#> # A tibble: 126 x 2\n#>    words   word_count\n#>    <chr>        <int>\n#>  1 the             20\n#>  2 Friday          17\n#>  3 to              15\n#>  4 weekend         13\n#>  5 forward         12\n#>  6 Gotta           10\n#>  7 on              10\n#>  8 down             9\n#>  9 Friday,          9\n#> 10 fun,             9\n#> # … with 116 more rows\nrblack5 <- str_remove(rblack4, pattern = c(\",\"))\nrblack5\nrblack6 <- str_to_lower(rblack5)\nrblack6\n##install.packages(\"tidytext\")\nlibrary(tidytext)\nstop_words\nrblack_df <- tibble(words = rblack6)\nrblack_df\n#> # A tibble: 360 x 1\n#>    words              \n#>    <chr>              \n#>  1 oo-ooh-ooh         \n#>  2 hoo                \n#>  3 yeah               \n#>  4 yeah               \n#>  5 (yeah              \n#>  6 ah-ah-ah-ah-ah-ark)\n#>  7 yeah               \n#>  8 yeah               \n#>  9 yeah-ah-ah         \n#> 10 yeah-ah-ah         \n#> # … with 350 more rows\nrblack_small <- anti_join(rblack_df, stop_words,\n                          by = c(\"words\" = \"word\"))\nrblack_small\n#> # A tibble: 208 x 1\n#>    words              \n#>    <chr>              \n#>  1 oo-ooh-ooh         \n#>  2 hoo                \n#>  3 yeah               \n#>  4 yeah               \n#>  5 (yeah              \n#>  6 ah-ah-ah-ah-ah-ark)\n#>  7 yeah               \n#>  8 yeah               \n#>  9 yeah-ah-ah         \n#> 10 yeah-ah-ah         \n#> # … with 198 more rows\nrblack_small %>% group_by(words) %>%\n  summarise(word_count = n()) %>%\n  arrange(desc(word_count))\n#> # A tibble: 60 x 2\n#>    words       word_count\n#>    <chr>            <int>\n#>  1 friday              26\n#>  2 fun                 19\n#>  3 weekend             17\n#>  4 partyin'            16\n#>  5 gotta               13\n#>  6 forward             12\n#>  7 lookin'             12\n#>  8 everybody's          9\n#>  9 (yeah)               8\n#> 10 yeah                 7\n#> # … with 50 more rows"},{"path":"strings-with-stringr.html","id":"exercise-12-1","chapter":" 13 Strings with stringr","heading":"13.1.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 13.4.* Look remaining words. look like stop words missed stop words tidytext package? Create tibble couple stop words picked tidytext package, use join function drop words rblack_small.* Look remaining words. look like stop words missed stop words tidytext package? Create tibble couple stop words picked tidytext package, use join function drop words rblack_small.* Ignore parentheses now. Make point plot shows 10 common words Rebecca Black’s Friday, words ordered common least common graph.* Ignore parentheses now. Make point plot shows 10 common words Rebecca Black’s Friday, words ordered common least common graph.can also make wordcloud (though word clouds issues). R wordcloud package called wordcloud. Run following code make word cloud words song Friday.can also make wordcloud (though word clouds issues). R wordcloud package called wordcloud. Run following code make word cloud words song Friday., type ?wordcloud explore options. particular, try increase number words plotted cloud.Finally, pesky parentheses? Certain characters R treated special: $, (, ., ) examples. Dealing fairly annoying: need “escape” backslash “escape” backslash another backslash. ’s confusing, worries: won’t focus much special characters class.remove front parenthesis, useand remove back parenthesis, useThese “regular expressions:” interested, can read R4DS textbook.analyzed short text data set, , can imagine extending type analysis things like:song lyrics, lyrics songs artist https://rpubs.com/RosieB/taylorswiftlyricanalysisbook analysis, text entire book series bookstv analysis, scripts episodes tv showIf one analyses, lots cool functions tidytext help !","code":"\nrblack_sum <- rblack_small %>% group_by(words) %>%\n  summarise(word_count = n()) %>%\n  arrange(desc(word_count))\n## install.packages(\"wordcloud\")\nlibrary(wordcloud)\nwordcloud(rblack_sum$words, rblack_sum$word_count, \n          colors = brewer.pal(8, \"Dark2\"), scale = c(5, .2),\n          random.order = FALSE, random.color = FALSE)\nrblack7 <- str_remove(rblack6, pattern = c(\"\\\\(\"))\nrblack7\nrblack8 <- str_remove(rblack7, pattern = c(\"\\\\)\"))\nrblack8"},{"path":"strings-with-stringr.html","id":"add-second-example-here","chapter":" 13 Strings with stringr","heading":"13.2 Add Second Example Here","text":"maybe office package? maybe friends package?","code":""},{"path":"strings-with-stringr.html","id":"chapexercise-12","chapter":" 13 Strings with stringr","heading":"13.3 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 13.4.* Read beyonce_lyrics.csv file, lyrics beyonce’s songs construct either word cloud point plot shows common non-stop words either Beyonce’s songs. best can (might minor errors, like parentheses Friday’s “yeah” don’t tools fix).Hint: can actually skip couple steps Friday analysis, , example, “\\n” character remove Beyonce’s lyrics.","code":"\nbeyonce <- read_csv(\"data/beyonce_lyrics.csv\")\nbeyonce_lyrics <- beyonce$line"},{"path":"strings-with-stringr.html","id":"solutions-12","chapter":" 13 Strings with stringr","heading":"13.4 Exercise Solutions","text":"","code":""},{"path":"strings-with-stringr.html","id":"friday-friday-s","chapter":" 13 Strings with stringr","heading":"13.4.1 Friday, Friday S","text":"* Look remaining words. look like stop words missed stop words tidytext package? Create tibble couple stop words picked tidytext package, use join function drop words rblack_small.* Ignore parentheses now. Make point plot shows 10 common words Rebecca Black’s Friday, words ordered common least common graph.","code":"\nextra_stops <- tibble(other_stop_words = c(\"gonna\", \"yeah\"))\nrblack_small2 <- anti_join(rblack_small, extra_stops, by = c(\"words\" = \"other_stop_words\"))\nrblack_wordcounts <- rblack_small2 %>% group_by(words) %>%\n  summarise(word_count = n()) %>%\n  arrange(desc(word_count))\nrblack10 <- rblack_wordcounts %>% slice(1:10)\nrblack10 <- rblack10 %>% mutate(words_ord = fct_reorder(words, .x = word_count))\nggplot(data = rblack10, aes(x = words_ord, y = word_count)) +\n  geom_col() +\n  coord_flip()"},{"path":"strings-with-stringr.html","id":"second-example-s","chapter":" 13 Strings with stringr","heading":"13.4.2 Second Example S","text":"","code":""},{"path":"strings-with-stringr.html","id":"chapexercise-12-S","chapter":" 13 Strings with stringr","heading":"13.4.3 Chapter Exercises S","text":"* Read beyonce_lyrics.csv file, lyrics beyonce’s songs construct either word cloud point plot shows common non-stop words either Beyonce’s songs. best can (might minor errors, like parentheses Friday’s “yeah” don’t tools fix).Hint: can actually skip couple steps Friday analysis, , example, “\\n” character remove Beyonce’s lyrics.","code":"\nbeyonce <- read_csv(\"data/beyonce_lyrics.csv\")\nbeyonce_lyrics <- beyonce$line\nbeyonce_lines <- str_split(beyonce$line, c(\" \"))\nwords_only <- unlist(beyonce_lines)\n\nbeyonce_lines2 <- str_remove(words_only, pattern = c(\",\"))\nbeyonce_lines2\nbeyonce_lines3 <- str_remove(beyonce_lines2, pattern = c(\";\"))\nbeyonce_lines3\nbeyonce_lines4 <- str_to_lower(beyonce_lines3)\nbeyonce_lines4\n\nbeyonce_df <- tibble(b_words = beyonce_lines4)\nbeyonce_small <- anti_join(beyonce_df, stop_words, by = c(\"b_words\" = \"word\"))\nbeyonce_small\n\nbeyonce_sum <- beyonce_small %>% group_by(b_words) %>%\n  summarise(word_count = n()) %>%\n  arrange(desc(word_count)) %>%\n  filter(word_count > 100)\n\nlibrary(wordcloud)\nwordcloud(beyonce_sum$b_words, beyonce_sum$word_count, \n          colors = brewer.pal(8, \"Dark2\"), scale = c(5, .2),\n          random.order = FALSE, random.color = FALSE)\nbeyonce_bigwords <- beyonce_sum %>% filter(word_count > 250) %>%\n  mutate(b_words = fct_reorder(b_words, .x = word_count))\nggplot(data = beyonce_bigwords, aes(x = word_count, y = b_words)) +\n  geom_col()\n## there's still some stopwords in there (yeah, ya, wanna, 'cause)\n## but these can be removed with dplyr."},{"path":"strings-with-stringr.html","id":"rcode-12","chapter":" 13 Strings with stringr","heading":"13.5 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\nlibrary(stringr)\nrblack <- c([2156 chars quoted with '\"'])\nrblack\nrblack2 <- str_split(rblack, \"\\n\", simplify = TRUE)\nrblack2\nstr(rblack2)\nrblack3 <- str_split(rblack2, c(\" \"))\nrblack3\nrblack4 <- unlist(rblack3)\nrblack4\nrblack_df <- tibble(words = rblack4)\nrblack_df %>% group_by(words) %>%\n  summarise(word_count = n()) %>%\n  arrange(desc(word_count))\nrblack5 <- str_remove(rblack4, pattern = c(\",\"))\nrblack5\nrblack6 <- str_to_lower(rblack5)\nrblack6\n##install.packages(\"tidytext\")\nlibrary(tidytext)\nstop_words\nrblack_df <- tibble(words = rblack6)\nrblack_df\nrblack_small <- anti_join(rblack_df, stop_words,\n                          by = c(\"words\" = \"word\"))\nrblack_small\nrblack_small %>% group_by(words) %>%\n  summarise(word_count = n()) %>%\n  arrange(desc(word_count))"},{"path":"predictive-modeling-with-knn.html","id":"predictive-modeling-with-knn","chapter":" 14 Predictive Modeling with knn","heading":" 14 Predictive Modeling with knn","text":"Goalsexplain ’s necessary use training data test data building predictive model.describe k-nearest neighbors (knn) procedure.interpret confusion matrix.use knn predict level categorical response variable.","code":""},{"path":"predictive-modeling-with-knn.html","id":"introduction-to-classification","chapter":" 14 Predictive Modeling with knn","heading":"14.1 Introduction to Classification","text":"k-nearest neighbors (knn) introductory supervised machine learning algorithm, commonly used classification algorithm. Classification refers prediction categorical response variable two categories. example, data set SLU students, might interested predicting whether student graduates four years (response two categories: graduates 4 years doesn’t). might want classify response based various student characteristics like anticipated major, GPA, standardized test scores, etc. knn can also used predict quantitative response, ’ll focus categorical responses throughout section.’ve STAT 213, might try draw parallels knn classification using logistic regression. Note, however, logistic regression required response two levels knn can classify response variable two levels.introduce , using pokemon_full.csv data. Pokemon different Types: use Type categorical response interested predicting. simplicity, use Pokemon’s primary type use 4 different types:goal develop k-nearest-neighbors model able classify/predict Pokemon Type set predictors, like Pokemon HP, Attack, Defense, etc.","code":"\nset.seed(1119)\nlibrary(tidyverse)\npokemon <- read_csv(\"data/pokemon_full.csv\") %>%\n  filter(Type %in% c(\"Steel\", \"Dark\", \"Fire\", \"Ice\"))"},{"path":"predictive-modeling-with-knn.html","id":"training-and-test-data","chapter":" 14 Predictive Modeling with knn","heading":"14.1.1 Training and Test Data","text":"order develop knn model (note still haven’t discussed knn actually yet!), first need discuss terms applies almost predictive/classification modeling: training test data. training data set subset full data set used fit various models. example , training data set just 15 observations pedagogical purposes. commonly, training data set contain 50%-80% observations full data set.test data set consists remaining 20%-50% observations training data set. test data set used assess different performances various models fit using training data set. need division? Using full data set training model testing model “cheating:” model perform better using observation twice: fitting testing. separate test data set wasn’t used fit model gives model “fair” test, observations supposed new data model hasn’t yet seen.following code uses sample_n() function randomly select 15 observations training data set. anti_join() makes test data set without 15 pokemon training data set.ideas training data set test data set pervasive predictive classification models, including models related knn. Note going method ’s simplest: wanted take step , ’d repeat training test process 5 10 times, using ’s known k-fold cross-validation.","code":"\ntrain_sample <- pokemon %>%\n  sample_n(15)\ntest_sample <- anti_join(pokemon, train_sample)\n\ntrain_sample %>% head()\n#> # A tibble: 6 x 14\n#>      X1 Name    Type     HP Attack Defense Speed SpAtk SpDef\n#>   <dbl> <chr>   <chr> <dbl>  <dbl>   <dbl> <dbl> <dbl> <dbl>\n#> 1   491 Darkrai Dark     70     90      90   125   135    90\n#> 2   136 Flareon Fire     65    130      60    65    95   110\n#> 3   571 Zoroark Dark     60    105      60   105   120    60\n#> 4   221 Pilosw… Ice     100    100      80    50    60    60\n#> 5   668 Pyroar  Fire     86     68      72   106   109    66\n#> 6   262 Mighty… Dark     70     90      70    70    60    60\n#> # … with 5 more variables: Generation <dbl>,\n#> #   Legendary <lgl>, height <dbl>, weight <dbl>,\n#> #   base_experience <dbl>\ntest_sample %>% head()\n#> # A tibble: 6 x 14\n#>      X1 Name    Type     HP Attack Defense Speed SpAtk SpDef\n#>   <dbl> <chr>   <chr> <dbl>  <dbl>   <dbl> <dbl> <dbl> <dbl>\n#> 1     4 Charma… Fire     39     52      43    65    60    50\n#> 2     5 Charme… Fire     58     64      58    80    80    65\n#> 3    37 Vulpix  Fire     38     41      40    65    50    65\n#> 4    38 Nineta… Fire     73     76      75   100    81   100\n#> 5    58 Growli… Fire     55     70      45    60    70    50\n#> 6    59 Arcani… Fire     90    110      80    95   100    80\n#> # … with 5 more variables: Generation <dbl>,\n#> #   Legendary <lgl>, height <dbl>, weight <dbl>,\n#> #   base_experience <dbl>"},{"path":"predictive-modeling-with-knn.html","id":"exercise-13-1","chapter":" 14 Predictive Modeling with knn","heading":"14.1.2 Exercises","text":"Exercises marked * indicate exercise solution end chapter 14.5.Explain anti_join() joins isn’t specified specifying argument works example.","code":""},{"path":"predictive-modeling-with-knn.html","id":"knn-introduction","chapter":" 14 Predictive Modeling with knn","heading":"14.2 knn Introduction","text":"","code":""},{"path":"predictive-modeling-with-knn.html","id":"knn-with-k-1-and-1-predictor","chapter":" 14 Predictive Modeling with knn","heading":"14.2.1 knn with k = 1 and 1 Predictor","text":"Suppose just 15 pokemon training data set. want predict Type just one predictor, Defense. plot shows defenses 15 pokemon training data set, points coloured Type different shapes Type.see plot Steel type Pokemon tend pretty high defense values. Now suppose want predict Type one Pokemon test data set, Dialga. know Dialga Defense stat 120: plot shows Dialga marked large black X.prediction Dialga ? ? According knn k = 1, predict Dialga Fire type. k = 1 means using 1st nearest neighbor: case point closest Dialga green triangle, corresponding Fire type Pokemon.","code":"\nggplot(data = train_sample, aes(x = Defense, y = 1, colour = Type, shape = Type)) +\n  geom_point(size = 4) +  theme(axis.title.y=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank())\ndialga <- test_sample %>% slice(63)\nggplot(data = train_sample, aes(x = Defense, y = 1, colour = Type, shape = Type)) +\n  geom_point(size = 4) +  theme(axis.title.y=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank()) +\n  geom_point(data = dialga, colour = \"black\", shape = 4, size = 7)"},{"path":"predictive-modeling-with-knn.html","id":"knn-with-k-1-and-one-predictor","chapter":" 14 Predictive Modeling with knn","heading":"14.2.2 knn with k > 1 and One Predictor","text":", might necessarily want predict response value based single nearest neighbor. Dialga also near many purple plus signs: factor ? can extend knn different values k. example, \\(k = 3\\) looks 3 nearest neighbors, assigns prediction category appears among 3 nearest neighbors.Using k = 3, prediction Dialga ? ?","code":""},{"path":"predictive-modeling-with-knn.html","id":"knn-with-k-1-and-more-than-one-predictor","chapter":" 14 Predictive Modeling with knn","heading":"14.2.3 knn with k > 1 and More Than One Predictor","text":"can increase number predictors knn model well. can generally include many predictors like, visualizing becomes challenging 2 predictors nearly impossible 3 predictors. case two predictors, suppose want use Defense Speed predictors Type. Dialga, Pokemon want predict , marked large black X.\\(k = 1\\), predict Dialga Steel, closest point purple + sign top-left corner graph. \\(k = 3\\), Type predict Dialga? question, ’s little hard tell three points closest Dialga without computing distances numerically, something let R knn() function.","code":"\nggplot(data = train_sample, aes(x = Defense, y = Speed, colour = Type, shape = Type)) +\n  geom_point(size = 3) +\n  geom_point(data = dialga, colour = \"black\", shape = 4, size = 5)"},{"path":"predictive-modeling-with-knn.html","id":"scaling-predictor-variables-before-using-knn","chapter":" 14 Predictive Modeling with knn","heading":"14.2.4 Scaling Predictor Variables before Using knn","text":"general, want scale quantitative predictors using knn relies distances points predictions. easiest see example. Suppose, Pokemon example, want use height weight predictors knn model. just 2 observations training data set: Dark Type pokemon height 15 centimeters weight 505 pounds, Fire Type Pokemon height 9 centimeters weight 250 pounds.plot also given Pokemon test data set wish predict Type , marked black X. Upon visual inspection, k = 1, looks like classify pokemon Dark. However, units weight height different scales. compute actual distances class see conclusion calculation matches visual conclusion.get around issue, customary scale quantitative predictors applying knn. One method applying\\[\nscaled_x = \\frac{x - min(x)}{max(x) - min(x)}\n\\]example, scaling weight 15 original pokemon:puts weights 0 1:height, variables contribute “equally” distance metric used knn.code scales numeric variables data set, using across() function. across() applies transformation every column data set satisfies condition given argument.","code":"\ntrain_tiny <- train_sample %>% slice(1:2)\nnewobs <- tibble(height = 15, weight = 350, Type = \"Unknown\")\nggplot(data = train_tiny, aes(x = height, y = weight, shape = Type)) +\n  geom_point(size = 5, aes(colour = Type)) + xlim(c(7, 17)) + ylim(c(200, 550)) +\n  geom_point(data = newobs, shape = 4, size = 10)\ntrain_sample %>% select(weight) %>% head()\n#> # A tibble: 6 x 1\n#>   weight\n#>    <dbl>\n#> 1    505\n#> 2    250\n#> 3    811\n#> 4    558\n#> 5    815\n#> 6    370\ntrain_sample %>% mutate(weight_s = (weight - min(weight)) / \n                          (max(weight) - min(weight))) %>%\n  select(weight_s) %>%\n  head()\n#> # A tibble: 6 x 1\n#>   weight_s\n#>      <dbl>\n#> 1   0.187 \n#> 2   0.0835\n#> 3   0.312 \n#> 4   0.209 \n#> 5   0.314 \n#> 6   0.132\n## ?across\nlibrary(pander)\ntrain_sample %>%\n  mutate(across(where(is.numeric), ~ (.x - min(.x)) /\n                                 (max(.x) - min(.x)))) %>%\n  slice(1:3)\n#> # A tibble: 3 x 14\n#>      X1 Name    Type     HP Attack Defense Speed SpAtk SpDef\n#>   <dbl> <chr>   <chr> <dbl>  <dbl>   <dbl> <dbl> <dbl> <dbl>\n#> 1 0.720 Darkrai Dark  0.417  0.444     0.4 1     1     0.658\n#> 2 0.193 Flareon Fire  0.333  0.889     0.1 0.368 0.619 0.921\n#> 3 0.838 Zoroark Dark  0.25   0.611     0.1 0.789 0.857 0.263\n#> # … with 5 more variables: Generation <dbl>,\n#> #   Legendary <lgl>, height <dbl>, weight <dbl>,\n#> #   base_experience <dbl>"},{"path":"predictive-modeling-with-knn.html","id":"exercise-13-2","chapter":" 14 Predictive Modeling with knn","heading":"14.2.5 Exercises","text":"Exercises marked * indicate exercise solution end chapter 14.5.* Consider toy example just two observations training data set unscaled weight height predictors.actual (height, weight) coordinates Fire pokemon (9, 250), actual coordinates Dark pokemon (15, 505), actual coordinates test pokemon (15, 350). mentioned , visually, pokemon looks “closer” Dark type pokemon. Verify actually case computing actual distances numerically.* scaling according formula section, coordinates (height, weight) Fire pokemon (0, 0) coordinates Dark pokemon (1, 1). (Since two observations, formula doesn’t give output 0 1 tiny example). scaled coordinates test pokemon (1, 0.39). Verify , scaling, test pokemon “closer” Dark type pokemon numerically computing distances.* scaling according formula section, coordinates (height, weight) Fire pokemon (0, 0) coordinates Dark pokemon (1, 1). (Since two observations, formula doesn’t give output 0 1 tiny example). scaled coordinates test pokemon (1, 0.39). Verify , scaling, test pokemon “closer” Dark type pokemon numerically computing distances.Consider example 15 pokemon training data set single predictor, Defense.Consider example 15 pokemon training data set single predictor, Defense.k = 2, tie Fire Steel. Come way might break ties knn algorithm.Explain knn use prediction test observations k equals number observations training data set.Explain knn use prediction test observations k equals number observations training data set.advantages making k smaller advantages making k larger?advantages making k smaller advantages making k larger?","code":"\nggplot(data = train_tiny, aes(x = height, y = weight, shape = Type)) +\n  geom_point(size = 5, aes(colour = Type)) + xlim(c(7, 17)) +\n  ylim(c(200, 550)) +\n  geom_point(data = newobs, shape = 4, size = 10)\nggplot(data = train_sample, aes(x = Defense, y = 1, colour = Type, shape = Type)) +\n  geom_point(size = 4) +  theme(axis.title.y=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank()) +\n  geom_point(data = dialga, colour = \"black\", shape = 4, size = 7)"},{"path":"predictive-modeling-with-knn.html","id":"choosing-predictors-and-k","chapter":" 14 Predictive Modeling with knn","heading":"14.3 Choosing Predictors and k","text":"now know knn classifies observations test data set, choose predictors used knn algorithm? choose number neighbors, k? want measure “good” models different predictors different k’s , first need define “good” means.","code":""},{"path":"predictive-modeling-with-knn.html","id":"the-confusion-matrix","chapter":" 14 Predictive Modeling with knn","heading":"14.3.1 The Confusion Matrix","text":"One definition “good” classification context model high proportion correct predictions test data set. make intuitive sense, hope “good” model correctly classifies Dark pokemon Dark, Fire pokemon Fire, etc.order examine performance particular model, ’ll create confusion matrix shows results model’s classification observations test data set. Note STAT 213, didn’t call confusion matrix; instead called classification table.following video explains confusion matrices detail also cement ideas training test data. https://www.youtube.com/watch?v=Kdsp6soqA7o.","code":""},{"path":"predictive-modeling-with-knn.html","id":"using-knn-in-r","chapter":" 14 Predictive Modeling with knn","heading":"14.3.2 Using knn in R","text":"make confusion matrix model using pokemon data set, first need obtain predictions model. ’ll use class library fit knn model pokemon data. Note , instead 15 Pokemon training data set, now 70 pokemon give reasonable number. test set remaining 50 pokemon.following code chunk sets seed get training test samples, scales numeric variables pokemon data set, randomly selects 70 pokemon training sample.first knn model investigate HP, Attack, Defense, Speed predictors. class library can fit knn models knn() function requires training test data sets predictors want use fit model. knn() function also requires response variable, Type, given vector.Now data prepared knn() function class library, fit model 9 nearest neighbors. arguments knn() aretrain, data set training data contains predictors want use (predictors response).test, data set test data contains predictors want use (predictors response).cl, vector response variable training data.k, number nearest neighbors.output knn_mod gives predicted categories test sample. can compare predictions knn model actual pokemon Types test sample table(), makes confusion matrix:columns confusion matrix give actual Pokemon types test data rows give predicted types knn model. table tells us 0 pokemon Dark type knn model correctly classified Dark. 6 pokemon Dark type knn model incorrectly classified Fire. 5 pokemon Dark type knn model incorrectly classified Ice. words, correct predictions appear diagonal, incorrect predictions appear -diagonal.One common metric used assess overall model performance model’s classification rate, computed number correct classifications divided total number observations test data set. case, classification rate isCode automatically obtain classification rate confusion matrix isWhat diag() seem code ?","code":"\nlibrary(tidyverse)\nset.seed(11232020) ## run this line so that you get the same \n## results as I do!\n\n## scale the quantitative predictors\npokemon_scaled <- pokemon %>%\n    mutate(across(where(is.numeric), ~ (.x - min(.x)) /\n                                 (max(.x) - min(.x)))) \n\ntrain_sample_2 <- pokemon_scaled %>%\n  sample_n(70)\ntest_sample_2 <- anti_join(pokemon_scaled, train_sample_2)\n#> Joining, by = c(\"X1\", \"Name\", \"Type\", \"HP\", \"Attack\", \"Defense\", \"Speed\", \"SpAtk\", \"SpDef\", \"Generation\", \"Legendary\", \"height\", \"weight\", \"base_experience\")\n## install.packages(\"class\")\nlibrary(class)\n\n## create a data frame that only has the predictors\n## that we will use\ntrain_small <- train_sample_2 %>% select(HP, Attack, Defense, Speed)\ntest_small <- test_sample_2 %>% select(HP, Attack, Defense, Speed)\n\n## put our response variable into a vector\ntrain_cat <- train_sample_2$Type\ntest_cat <- test_sample_2$Type\n## fit the knn model with 9 nearest neighbors\nknn_mod <- knn(train = train_small, test = test_small,\n               cl = train_cat, k = 9)\nknn_mod\n#>  [1] Ice   Fire  Fire  Fire  Fire  Fire  Steel Fire  Ice  \n#> [10] Fire  Fire  Fire  Fire  Ice   Ice   Steel Ice   Dark \n#> [19] Ice   Fire  Steel Fire  Fire  Ice   Fire  Ice   Steel\n#> [28] Fire  Fire  Ice   Dark  Fire  Fire  Fire  Dark  Ice  \n#> [37] Ice   Fire  Ice   Fire  Fire  Fire  Fire  Fire  Fire \n#> [46] Fire  Fire  Fire  Ice   Fire \n#> Levels: Dark Fire Ice Steel\ntable(knn_mod, test_cat) \n#>        test_cat\n#> knn_mod Dark Fire Ice Steel\n#>   Dark     0    3   0     0\n#>   Fire     6   13   7     4\n#>   Ice      5    5   2     1\n#>   Steel    0    1   0     3\n(0 + 13 + 2 + 3) / 50\n#> [1] 0.36\ntab <- table(knn_mod, test_cat) \nsum(diag(tab)) / sum(tab)\n#> [1] 0.36"},{"path":"predictive-modeling-with-knn.html","id":"exercise-13-3","chapter":" 14 Predictive Modeling with knn","heading":"14.3.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 14.5.Change predictors used change k improve classification rate model k = 9 Attack, Defense, HP, Speed predictors.","code":""},{"path":"predictive-modeling-with-knn.html","id":"chapexercise-13","chapter":" 14 Predictive Modeling with knn","heading":"14.4 Chapter Exercises","text":"chapter exercises section. Instead, ’ll devote -class time begin work final project.","code":""},{"path":"predictive-modeling-with-knn.html","id":"solutions-13","chapter":" 14 Predictive Modeling with knn","heading":"14.5 Exercise Solutions","text":"","code":""},{"path":"predictive-modeling-with-knn.html","id":"introduction-to-classification-s","chapter":" 14 Predictive Modeling with knn","heading":"14.5.1 Introduction to Classification S","text":"","code":""},{"path":"predictive-modeling-with-knn.html","id":"knn-introduction-s","chapter":" 14 Predictive Modeling with knn","heading":"14.5.2 knn Introduction S","text":"* Consider toy example just two observations training data set unscaled weight height predictors.actual (height, weight) coordinates Fire pokemon (9, 250), actual coordinates Dark pokemon (15, 505), actual coordinates test pokemon (15, 350). mentioned , visually, pokemon looks “closer” Dark type pokemon. Verify case computing actual distances numerically.* scaling according formula section, coordinates (height, weight) Fire pokemon (0, 0) coordinates Dark pokemon (1, 1). (Since two observations, formula doesn’t give output 0 1 tiny example). scaled coordinates test pokemon (1, 0.39). Verify , scaling, test pokemon “closer” Dark type pokemon bu numerically computing distances.","code":"\nggplot(data = train_tiny, aes(x = height, y = weight, shape = Type)) +\n  geom_point(size = 5, aes(colour = Type)) + xlim(c(7, 17)) +\n  ylim(c(200, 550)) +\n  geom_point(data = newobs, shape = 4, size = 10)"},{"path":"predictive-modeling-with-knn.html","id":"choosing-predictors-and-k-s","chapter":" 14 Predictive Modeling with knn","heading":"14.5.3 Choosing Predictors and k S","text":"","code":""},{"path":"predictive-modeling-with-knn.html","id":"rcode-13","chapter":" 14 Predictive Modeling with knn","heading":"14.6 Non-Exercise R Code","text":"","code":"\nset.seed(1119)\nlibrary(tidyverse)\npokemon <- read_csv(\"data/pokemon_full.csv\") %>%\n  filter(Type %in% c(\"Steel\", \"Dark\", \"Fire\", \"Ice\"))\ntrain_sample <- pokemon %>%\n  sample_n(15)\ntest_sample <- anti_join(pokemon, train_sample)\n\ntrain_sample %>% head()\ntest_sample %>% head()\nggplot(data = train_sample, aes(x = Defense, y = 1, colour = Type, shape = Type)) +\n  geom_point(size = 4) +  theme(axis.title.y=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank())\ndialga <- test_sample %>% slice(63)\nggplot(data = train_sample, aes(x = Defense, y = 1, colour = Type, shape = Type)) +\n  geom_point(size = 4) +  theme(axis.title.y=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank()) +\n  geom_point(data = dialga, colour = \"black\", shape = 4, size = 7)\nggplot(data = train_sample, aes(x = Defense, y = Speed, colour = Type, shape = Type)) +\n  geom_point(size = 3) +\n  geom_point(data = dialga, colour = \"black\", shape = 4, size = 5)\ntrain_tiny <- train_sample %>% slice(1:2)\nnewobs <- tibble(height = 15, weight = 350, Type = \"Unknown\")\nggplot(data = train_tiny, aes(x = height, y = weight, shape = Type)) +\n  geom_point(size = 5, aes(colour = Type)) + xlim(c(7, 17)) + ylim(c(200, 550)) +\n  geom_point(data = newobs, shape = 4, size = 10)\ntrain_sample %>% select(weight) %>% head()\ntrain_sample %>% mutate(weight_s = (weight - min(weight)) / \n                          (max(weight) - min(weight))) %>%\n  select(weight_s) %>%\n  head()\n## ?across\nlibrary(pander)\ntrain_sample %>%\n  mutate(across(where(is.numeric), ~ (.x - min(.x)) /\n                                 (max(.x) - min(.x)))) %>%\n  slice(1:3)\nlibrary(tidyverse)\nset.seed(11232020) ## run this line so that you get the same \n## results as I do!\n\n## scale the quantitative predictors\npokemon_scaled <- pokemon %>%\n    mutate(across(where(is.numeric), ~ (.x - min(.x)) /\n                                 (max(.x) - min(.x)))) \n\ntrain_sample_2 <- pokemon_scaled %>%\n  sample_n(70)\ntest_sample_2 <- anti_join(pokemon_scaled, train_sample_2)\n## install.packages(\"class\")\nlibrary(class)\n\n## create a data frame that only has the predictors\n## that we will use\ntrain_small <- train_sample_2 %>% select(HP, Attack, Defense, Speed)\ntest_small <- test_sample_2 %>% select(HP, Attack, Defense, Speed)\n\n## put our response variable into a vector\ntrain_cat <- train_sample_2$Type\ntest_cat <- test_sample_2$Type\n## fit the knn model with 9 nearest neighbors\nknn_mod <- knn(train = train_small, test = test_small,\n               cl = train_cat, k = 9)\nknn_mod\ntable(knn_mod, test_cat) \n(0 + 13 + 2 + 3) / 50\ntab <- table(knn_mod, test_cat) \nsum(diag(tab)) / sum(tab)"}]
