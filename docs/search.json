[{"path":"index.html","id":"syllabus-and-course-information","chapter":" 1 Syllabus and Course Information","heading":" 1 Syllabus and Course Information","text":"","code":""},{"path":"index.html","id":"general-information","chapter":" 1 Syllabus and Course Information","heading":"1.1 General Information","text":"Instructor InformationProfessor: Matt HighamOffice: Bewkes 123Email: mhigham@stlawu.eduSemester: Fall 2022Sections:\nMW 2:30 - 4:00\nMW 2:30 - 4:00Office Hours: 15 minute slots bookable calendly page.\nNote must book time office hours least 12 hours advance guarantee present available time.\nNote must book time office hours least 12 hours advance guarantee present available time.Course MaterialsSTAT 234 Materials Bundle. primary source materials.Textbooks (used references):\nModern Data Science R Baumer, Kaplan, Horton, found free online version.\nR Data Science Grolemund Wickham, found free online version.\nModern Data Science R Baumer, Kaplan, Horton, found free online version.R Data Science Grolemund Wickham, found free online version.Computer Internet access.","code":""},{"path":"index.html","id":"course-information","chapter":" 1 Syllabus and Course Information","heading":"1.2 Course Information","text":"Welcome STAT 234! overall purpose course learn data science skills necessary complete large-scale data analysis projects. tool using achieve goal statistical software language R. work wide variety interesting data sets throughout semester build R skills. particular, focus Data Analysis Life Cycle (Grolemund Wickham 2020):put emphasis Import, Tidy, Transform, Visualize, Communicate parts cycle, introduction Modeling part covered STAT 213.","code":""},{"path":"index.html","id":"use-of-r-and-rstudio","chapter":" 1 Syllabus and Course Information","heading":"1.2.1 Use of R and RStudio","text":"use statistical software R construct graphs analyze data. notes:R RStudio free use.primarily using SLU R Studio server first: rstudio.stlawu.local:8787.Additionally, using RMarkdown data analysis reports. Note: ’s always nice start assignments projects early possible, particularly important assignments projects involving R. ’s fun try figure code working last minute. start early enough though, plenty time seek help therefore won’t waste lot time coding error.","code":""},{"path":"index.html","id":"general-course-outcomes","chapter":" 1 Syllabus and Course Information","heading":"1.3 General Course Outcomes","text":"Import data different types R analysis.Import data different types R analysis.Tidy data form can easily visualized, summarised, modeled.Tidy data form can easily visualized, summarised, modeled.Transform, Wrangle, Visualize variables data set assess patterns data.Transform, Wrangle, Visualize variables data set assess patterns data.Communicate results analysis target audience written report, , possibly oral presentation.Communicate results analysis target audience written report, , possibly oral presentation.Practice reproducible statistical practices use Quarto data analysis projects.Practice reproducible statistical practices use Quarto data analysis projects.Explain ethically important consider context data set comes .Explain ethically important consider context data set comes .Develop necessary skills able ask answer future data analysis questions , either using R another program, Python.Develop necessary skills able ask answer future data analysis questions , either using R another program, Python.paraphrase R Data Science textbook, 80% skills necessary complete data analysis project can learned coursework classes like one. , 20% particular project involve learning new things specific project. Achieving Goal # 6 allow learn extra 20% .","code":""},{"path":"index.html","id":"how-you-will-be-assessed","chapter":" 1 Syllabus and Course Information","heading":"1.4 How You Will Be Assessed","text":"components grade described :ModulesEach week, submit 60-point Module, consisting following:Exercise Set (10 points): Due Mondays usually STAT 234 Materials Bundle. Exercises graded completion solutions typically provided submit Canvas. Collaboration allowed.Take-Home Quiz (20 points): Due Wednesdays. Take-Home quizzes graded correctness. Collaboration allowed.-Class Quiz (30 points): Given Wednesdays start class. -Class quizzes graded correctness. Collaboration allowed. questions -class quiz based exercises complete class, exercise sets complete, take-home quiz questions.13 modules total. three modules, complete 50-point Project instead two quizzes. Project tasks complete particular data set. lowest module dropped grade total number points available 12 * 60 = 720 points.Additionally, one module, permitted take -class quiz take-home turn following Monday. quiz, must let know grades posted, permitted collaborate anyone.Finally, choose take (optional) -person final exam (described ), score earn final replace second third-lowest module scores.ClassClass participation assessed three times throughout semester 20 point rubric total 60 points. rubric used shared first day class.Final ProjectThere one final project, worth 100 points. primary purpose final project give opportunity assemble topics throughout course one coherent data analysis. able choose data set use final project, might begin thinking particular topic data set interested exploring. final project presented format decided later semester.Final ExamThere optional Final Exam, worth 120 points total, consisting 20 points Exercises (graded completeness), 40 points take-home portion, 60 points -class portion. must campus final exam time take final exam.two options final exam:Option 1: Skip final exam (skip components: exercises, take-home, -class) assign average percentage 12 highest modules percentage score 120 point final. example, suppose 13 module scores : 60, 60, 59, 58, 57, 53, 53, 53, 53, 45, 43, 30, 0. , drop lowest score (0) score final : (60 + 60 + 59 + 58 + 57 + 53 + 53 + 53 + 53 + 45 + 43 + 30 + 30) / 720 * 120 = 109 / 120 points.Option 1: Skip final exam (skip components: exercises, take-home, -class) assign average percentage 12 highest modules percentage score 120 point final. example, suppose 13 module scores : 60, 60, 59, 58, 57, 53, 53, 53, 53, 45, 43, 30, 0. , drop lowest score (0) score final : (60 + 60 + 59 + 58 + 57 + 53 + 53 + 53 + 53 + 45 + 43 + 30 + 30) / 720 * 120 = 109 / 120 points.Option 2: Take final exam, consists 20 points Exercises, 30 point Take-Home portion, 50 point -Class portion. score items used 100 points devoted final exam. Additionally, final exam score better 2nd 3rd lowest module grades, replaced final exam score. example, suppose 13 module scores : 60, 60, 59, 58, 57, 53, 53, 53, 53, 45, 43, 30, 0. take final exam score 110 / 120. , score final 110 / 120 points new module scores : 60, 60, 59, 58, 57, 53, 53, 53, 53, 45, 55, 55, 0. 0 still dropped lowest module score.Option 2: Take final exam, consists 20 points Exercises, 30 point Take-Home portion, 50 point -Class portion. score items used 100 points devoted final exam. Additionally, final exam score better 2nd 3rd lowest module grades, replaced final exam score. example, suppose 13 module scores : 60, 60, 59, 58, 57, 53, 53, 53, 53, 45, 43, 30, 0. take final exam score 110 / 120. , score final 110 / 120 points new module scores : 60, 60, 59, 58, 57, 53, 53, 53, 53, 45, 55, 55, 0. 0 still dropped lowest module score.","code":""},{"path":"index.html","id":"breakdown","chapter":" 1 Syllabus and Course Information","heading":"1.4.1 Breakdown","text":"720 points Modules60 points Class Participation100 points Final Project120 points (optional) -person Final ExamPoints add 1000 grade end semester number points ’ve earned across categories divided 1000.","code":""},{"path":"index.html","id":"grading-scale","chapter":" 1 Syllabus and Course Information","heading":"1.4.2 Grading Scale","text":"following rough grading scale. reserve right make changes scale necessary.","code":""},{"path":"index.html","id":"collaboration-diversity-accessibility-and-academic-integrity","chapter":" 1 Syllabus and Course Information","heading":"1.5 Collaboration, Diversity, Accessibility, and Academic Integrity","text":"","code":""},{"path":"index.html","id":"rules-for-collaboration","chapter":" 1 Syllabus and Course Information","heading":"1.5.1 Rules for Collaboration","text":"Collaboration classmates exercises, take-home quizzes, projects encouraged, must follow guidelines:must state name(s) collaborated top assessment.work must . means never send someone code via email let someone directly type code screen. Instead, can talk strategies solving problems help ask someone coding error.may use Internet StackExchange, also copy paste code directly website, without citing .isn’t rule, keep mind collaboration permitted quizzes, exams, limited collaboration permitted final project. Therefore, working someone, make sure really learning can success non-collaborative assessments.","code":""},{"path":"index.html","id":"diversity-statement","chapter":" 1 Syllabus and Course Information","heading":"1.5.2 Diversity Statement","text":"Diversity encompasses differences age, colour, ethnicity, national origin, gender, physical mental ability, religion, socioeconomic background, veteran status, sexual orientation, marginalized groups. interaction different human characteristics brings positive learning environment. Diversity respected valued classroom.","code":""},{"path":"index.html","id":"accessibility-statement","chapter":" 1 Syllabus and Course Information","heading":"1.5.3 Accessibility Statement","text":"specific learning profile, medical mental health condition need accommodations, please sure contact Student Accessibility Services Office right away can help get accommodations require. need use accommodations class, please meet instructor early provide Individualized Educational Accommodation Plan (IEAP) letter can best possible experience semester.Although required, instructor like know accommodations needed least 10 days quiz test. Please proactive set appointment meet someone Student Accessibility Services Office.Color-Vision Deficiency: Color-Vision Deficient, Student Accessibility Services office loan glasses students color vision deficient. Please contact office make appointment.specific information setting appointment Student Accessibility Services please see listed options :Telephone: 315.229.5537Email: studentaccessibility@stlawu.eduFor information Student Accessibility Services can check website : https://www.stlawu.edu/student-accessibility-services","code":""},{"path":"index.html","id":"academic-dishonesty","chapter":" 1 Syllabus and Course Information","heading":"1.5.4 Academic Dishonesty","text":"Academic dishonesty tolerated. specific policies course supplementary theHonor Code. According St. Lawrence University Academic Honor Policy,assumed work done student unless instructor/mentor/employer gives specific permission collaboration.Cheating examinations tests consists knowingly giving using attempting use unauthorized assistance examinations tests.Dishonesty work outside examinations tests consists handing presenting original work original, originality required.Claims ignorance academic personal pressure unacceptable excuses academic dishonesty. Students must learn constitutes one’s work work others must acknowledged.information, refer www.stlawu.edu/acadaffairs/academic_honor_policy.pdf.avoid academic dishonesty, important follow directions collaboration rules ask clarification questions acceptable particular assignment exam. suspect academic dishonesty, score zero given entire assignment academic dishonesty occurred individuals involved Academic Honor Council notified. pattern academic dishonesty found occurred, grade 0.0 entire course can given.important work way maximizes learning. aware students rely much others homework projects tend poorly quizzes exams.Please note addition , assignments score reduced due academic dishonesty dropped according quiz policy e.g., receive zero quiz academic dishonesty, dropped grade.","code":""},{"path":"index.html","id":"tentative-schedule","chapter":" 1 Syllabus and Course Information","heading":"1.6 Tentative Schedule","text":"three projects tentatively scheduled due September 28, October 19, November 2, though subject change.","code":""},{"path":"intro.html","id":"intro","chapter":" 2 Getting Started with R and R Studio","heading":" 2 Getting Started with R and R Studio","text":"Goals:Download R R StudioDownload R R StudioUse Quarto code chunksUse Quarto code chunksLoad data R StudioLoad data R StudioRun code change things within codeRun code change things within codeCorrect common errors running code RCorrect common errors running code R","code":""},{"path":"intro.html","id":"intro-to-r-and-r-studio","chapter":" 2 Getting Started with R and R Studio","heading":"2.1 Intro to R and R Studio","text":"R statistical computing software used many statisticians well professionals fields, biology, ecology, business, psychology. goal Week 0 provide basic familiarity R Quarto, using entire semester.","code":""},{"path":"intro.html","id":"installing-r-and-r-studio","chapter":" 2 Getting Started with R and R Studio","heading":"2.1.1 Installing R and R Studio","text":"R Studio server computer set-carry R-based analyses students remote access computer (case, SLU Login credentials). might helpful think server large machine keyboard screen: ’s purpose execute code. may used R Studio server different stats course. server benefits, asusing server ensures using version R. theory, one person gets error, everyone get error.using server ensures using version R. theory, one person gets error, everyone get error.installing R R Studio personal device much easier ’ve experience using server.installing R R Studio personal device much easier ’ve experience using server.don’t need computer capable running R use server (can use tablet Chromebook since server actual computation).don’t need computer capable running R use server (can use tablet Chromebook since server actual computation)., however, move away server install R R Studio devices. Though server advantages, also disadvantages:won’t SLU login forever, , wanted use R post graduation, ’d need know install .won’t SLU login forever, , wanted use R post graduation, ’d need know install .haven’t experience installing R packages. quite easy , ’ve installed necessary R packages server us haven’t worry step.haven’t experience installing R packages. quite easy , ’ve installed necessary R packages server us haven’t worry step.server requires good Internet access also potential crash.server requires good Internet access also potential crash.next section, work installing R R Studio personal laptop. following videos provide instructions install R R Studio laptop computer. easiest complete steps consecutively one sitting. Watch follow along video installing R.  Watch follow along video installing R Studio.  Watch follow along video installing R packages changing options. ","code":""},{"path":"intro.html","id":"relevant-websites","chapter":" 2 Getting Started with R and R Studio","heading":"2.1.2 Relevant Websites","text":"Install R: http://lib.stat.cmu.edu/R/CRAN/Install R: http://lib.stat.cmu.edu/R/CRAN/Install R Studio (free option): https://www.rstudio.com/products/rstudio/download/Install R Studio (free option): https://www.rstudio.com/products/rstudio/download/","code":""},{"path":"intro.html","id":"creating-an-r-project","chapter":" 2 Getting Started with R and R Studio","heading":"2.1.3 Creating an R Project","text":"R R Studio installed, open R Studio Applications. Create new folder Desktop (place easy access remember). Make sure folder name spaces ., R Studio, create R Project Clicking File -> New Project -> Existing Directory. Navigate DATA234 folder made, click Create Project. see new window R Studio open .Next, want put data folder folder newly created R Project. Download data.zip file Canvas (Resources) move zip file folder R project (can drag drop downloads, copy/paste downloads, move whatever method usually move files ). Clicking data.zip file (either window bottom-left window R Studio) created data folder data sets want use throughout semester.Finally, want create new Quarto file clicking File -> New File -> Quarto Document. can give new Quarto file title want, click okay.also going change one option routinely Quarto files. Change first lines file something like:Note self-contained: true option added. ensures figures, images, tables, etc. contained one .html file, important , quizzes exercises, typically turn .html file.moving , click Render button top-left window top menu bar. Make sure file renders pretty-looking .html file. newly rendered .html file can now found folder R project.","code":"---\ntitle: \"Your Title\"\nauthor: \"Your Name\"\nformat: \n  html:\n    self-contained: true\n---"},{"path":"intro.html","id":"what-are-r-r-studio-and-quarto","chapter":" 2 Getting Started with R and R Studio","heading":"2.2 What are R, R Studio, and Quarto?","text":"distinction 3 become clear later . now,R statistical coding software used heavily data analysis statistical procedures.R statistical coding software used heavily data analysis statistical procedures.R Studio nice IDE (Integrated Development Environment) R lot convenient features. Think just convenient User Interface.R Studio nice IDE (Integrated Development Environment) R lot convenient features. Think just convenient User Interface.Quarto allows users mix regular Microsoft-Word-style text code. .qmd file ending denotes Quarto file. Quarto many options use heavily throughout semester, ’s need worry now.Quarto allows users mix regular Microsoft-Word-style text code. .qmd file ending denotes Quarto file. Quarto many options use heavily throughout semester, ’s need worry now.","code":""},{"path":"intro.html","id":"r-packages-and-the-tidyverse","chapter":" 2 Getting Started with R and R Studio","heading":"2.2.1 R Packages and the tidyverse","text":"can think R packages add-ons R let things R able . ’re video games, can think R packages extra Downloadable Content (DLC). , unlike gaming DLC, R packages always free make heavy use R packages.tidyverse series R packages useful data science. order encounter class, core tidyverse packages :ggplot2 plotting datadplyr data wrangling summarizingtidyr data tidying reshapingreadr data importtibble data storedstringr text dataforcats factor (categorical) datapurrr, functional programming, one core 8 won’t get useWe use packages outside core tidyverse well, tidyverse main focus.","code":""},{"path":"intro.html","id":"installing-r-packages","chapter":" 2 Getting Started with R and R Studio","heading":"2.2.2 Installing R Packages","text":"R Studio server, either one statistics faculty members installed packages ’ve needed use server globally. However, want use package isn’t installed server, , want use package using R Studio personal computer, need install first.Installation needs happen (upgrade R, usually doesn’t happen often), whereas package needs loaded library() every time open R. analogy lightbulb might helpful. need screw lightbulb socket , , every time want lightbulb provide light, need flip light switch.lightbulb analogy, putting lightbulb socket correspond ? flipping light switch correspond ?Now R computer, ’ll need install packages want use (, remember just need install package ). Try installing tidyverse package, collection many useful data science packages, :","code":"\ninstall.packages(\"tidyverse\")"},{"path":"intro.html","id":"putting-code-in-a-.qmd-file","chapter":" 2 Getting Started with R and R Studio","heading":"2.3 Putting Code in a .qmd File","text":"first thing involves code load package R library() function. package just R add-lets just R . Load tidyverse package R typing running library(tidyverse) line. create code chunk, click Insert -> R. Within code chunk, type library(tidyverse) run code eitherClicking “Run” button menu bar top-left window R Studio orClicking “Run” button menu bar top-left window R Studio (Recommended) Clicking “Command + Enter” Mac “Control + Enter” PC.(Recommended) Clicking “Command + Enter” Mac “Control + Enter” PC.Note code appears grey boxes surrounded three backticks normal text different colour background backticks.run previous line, text appear bottom-left window. won’t worry much text means now, also won’t ignore completely. able spot 8 core tidyverse packages listed well numbers follow package. numbers correspond package version. ’s things , long text start “Error:”, ’re good go!Congrats running first line code class! particular code isn’t particularly exciting doesn’t really anything can see.run R code using R chunk. R chunk, new line, try typing basic calculation, like 71 + 9 4 / 3, run line observe result., still wasn’t super exciting. R can perform basic calculations, just use calculator Excel . order look things bit interesting, need data.","code":"\nlibrary(tidyverse)"},{"path":"intro.html","id":"alcohol-data-example","chapter":" 2 Getting Started with R and R Studio","heading":"2.4 Alcohol Data Example","text":"looking two data sets just get little bit preview things working rest semester. Important: worry understanding following code point. plenty time understand weeks ahead. purpose section just get used using R: detailed explanations exercises functions used various options coming weeks. particular, following code uses ggplot2, dplyr, tidyr packages, cover detail throughout first ~ 3-4 weeks course.Data first part obtained fivethirtyeight Five Thirty Eight GitHub page.first step read data set R. Though already downloaded alcohol.csv data zip, still need load R. Check make sure alcohol.csv data folder bottom-right hand window. following code can copied R code chunk read data:Note need full file extension data set R project.something show console window? , great! , make sure data set data folder R project set .like name data set something easily reference later, name data set using <- operator, inYou can name data set whatever want (restrictions). ’ve named alcohol_data. Now, run line code name data set, run alcohol_data, see data set appear:’s data set? see variables columns:country: name countrybeer_servings: average number beer servings per person per yearspirit_servings: average number spirit (hard alcohol) servings per person per yearwine_servings: average number wine servings per person per yeartotal_litres_of_pure_alcohol: average total litres pure alcohol consumed per person per year.One goal class able pose questions data set use tools learn answer questions. example, might want know distribution total litres alcohol consumed per person looks like across countries. , can make plot ggplot2 package, one packages automatically loads tidyverse. might start constructing following plot. Reminder: goal everyone understand code plot, don’t worry much .now want see United States (USA) falls distribution drawing red vertical line total litres alcohol consumed United States. , ’ll first use filter() function dplyr package (, learn function detail later). Copy paste following lines code new R chunk. , run lines.looks like countries consume little alcohol. might want know countries :looks like 13 countries data set consume alcohol. Note , chunk , use total_litres_of_pure_alcohol variable name name variable data set. Even something like spelling litres American English liters (total_liters_of_pure_alcohol) throw error isn’t exact name variable data set. something can aggravating first learning coding language.Now suppose want know 3 countries consume beer, 3 countries consume spirits, 3 countries consume wine per person. ’re trivia person, can form guesses. Without cheating, going guess (Germany, USA, UK) beer, (Spain, Italy, USA) wine, (Russia, Poland, Lithuania) spirits. Let’s beer first!Let’s thing Wine Spirits:Finally, suppose want know country consumes wine relative beer consumption? Let’s first look question graphically. need tidy data first pivot_longer() function tidyr package:x-axis corresponds beer servings y-axis corresponds wine servings. reference line given countries line consuming wine beer. get make plot like later: now, copy code chunk change labeled point corresponds country interests (Denmark).\nmight able better answer original question numerically computing wine beer ratio country ordering largest ratio smallest ratio:one ratios Inf?","code":"\nread_csv(\"data/alcohol.csv\")\nalcohol_data <- read_csv(\"data/alcohol.csv\")\nalcohol_data\n#> # A tibble: 193 × 5\n#>    country           beer_servings spirit_…¹ wine_…² total…³\n#>    <chr>                     <dbl>     <dbl>   <dbl>   <dbl>\n#>  1 Afghanistan                   0         0       0     0  \n#>  2 Albania                      89       132      54     4.9\n#>  3 Algeria                      25         0      14     0.7\n#>  4 Andorra                     245       138     312    12.4\n#>  5 Angola                      217        57      45     5.9\n#>  6 Antigua & Barbuda           102       128      45     4.9\n#>  7 Argentina                   193        25     221     8.3\n#>  8 Armenia                      21       179      11     3.8\n#>  9 Australia                   261        72     212    10.4\n#> 10 Austria                     279        75     191     9.7\n#> # … with 183 more rows, and abbreviated variable names\n#> #   ¹​spirit_servings, ²​wine_servings,\n#> #   ³​total_litres_of_pure_alcohol\n#> # ℹ Use `print(n = ...)` to see more rows\nggplot(data = alcohol_data,\n       mapping = aes(total_litres_of_pure_alcohol)) +\n  geom_histogram(colour = \"black\", fill = \"white\", bins = 15)\nsmall_df <- alcohol_data |> filter(country == \"USA\")\nggplot(data = alcohol_data,\n       mapping = aes(total_litres_of_pure_alcohol)) +\n  geom_histogram(colour = \"black\", fill = \"white\", bins = 15) +\n  geom_vline(data = small_df,\n             aes(xintercept = total_litres_of_pure_alcohol),\n             colour = \"red\")\nalcohol_data |> filter(total_litres_of_pure_alcohol == 0)\n#> # A tibble: 13 × 5\n#>    country          beer_servings spirit_s…¹ wine_…² total…³\n#>    <chr>                    <dbl>      <dbl>   <dbl>   <dbl>\n#>  1 Afghanistan                  0          0       0       0\n#>  2 Bangladesh                   0          0       0       0\n#>  3 North Korea                  0          0       0       0\n#>  4 Iran                         0          0       0       0\n#>  5 Kuwait                       0          0       0       0\n#>  6 Libya                        0          0       0       0\n#>  7 Maldives                     0          0       0       0\n#>  8 Marshall Islands             0          0       0       0\n#>  9 Mauritania                   0          0       0       0\n#> 10 Monaco                       0          0       0       0\n#> 11 Pakistan                     0          0       0       0\n#> 12 San Marino                   0          0       0       0\n#> 13 Somalia                      0          0       0       0\n#> # … with abbreviated variable names ¹​spirit_servings,\n#> #   ²​wine_servings, ³​total_litres_of_pure_alcohol\nalcohol_data |> mutate(rankbeer = rank(desc(beer_servings))) |>\n  arrange(rankbeer) |> \n  filter(rankbeer <= 3)\nalcohol_data |> mutate(rankwine = rank(desc(wine_servings))) |>\n  arrange(rankwine) |> \n  filter(rankwine <= 3)\n\nalcohol_data |> mutate(rankspirits = rank(desc(spirit_servings))) |>\n  arrange(rankspirits) |> \n  filter(rankspirits <= 3)\nonecountry_df <- alcohol_data |> \n  filter(country == \"Denmark\")\n\nlibrary(ggrepel)\nggplot(data = alcohol_data,\n       mapping = aes(x = beer_servings, y = wine_servings)) + \n  geom_point(alpha = 0.5) +\n  geom_label_repel(data = onecountry_df, aes(label = country),\n    colour = \"purple\") +\n  geom_point(data = onecountry_df, colour = \"purple\",\n             size = 2.5, shape = 1) +\n  geom_abline(aes(slope = 1, intercept = 0), alpha = 0.3)\nalcohol_data |>\n  mutate(wbratio = wine_servings / beer_servings) |>\n  arrange(desc(wbratio)) |>\n  select(country, beer_servings, wine_servings, wbratio)\n#> # A tibble: 193 × 4\n#>    country             beer_servings wine_servings wbratio\n#>    <chr>                       <dbl>         <dbl>   <dbl>\n#>  1 Cook Islands                    0            74  Inf   \n#>  2 Qatar                           1             7    7   \n#>  3 Montenegro                     31           128    4.13\n#>  4 Timor-Leste                     1             4    4   \n#>  5 Syria                           5            16    3.2 \n#>  6 France                        127           370    2.91\n#>  7 Georgia                        52           149    2.87\n#>  8 Italy                          85           237    2.79\n#>  9 Equatorial Guinea              92           233    2.53\n#> 10 Sao Tome & Principe            56           140    2.5 \n#> # … with 183 more rows\n#> # ℹ Use `print(n = ...)` to see more rows"},{"path":"intro.html","id":"exercise-1-1","chapter":" 2 Getting Started with R and R Studio","heading":"2.4.1 Exercises","text":"shape distribution total alcohol consumption? Left-skewed, right-skewed, approximately symmetric? Unimodal multimodal?shape distribution total alcohol consumption? Left-skewed, right-skewed, approximately symmetric? Unimodal multimodal?histogram total alcohol consumption, pick country USA interests . See can change code chunk made histogram red vertical line drawn country interests .histogram total alcohol consumption, pick country USA interests . See can change code chunk made histogram red vertical line drawn country interests .Hint: Use View() function look alcohol data set typing View(alcohol_data) bottom-left window help see countries data set.Note: careful capitalization: R case sensitive USA different usa.histogram total alcohol consumption, change fill colour bins histogram : changed code chunk?histogram total alcohol consumption, change fill colour bins histogram : changed code chunk?spirit rankings, think 2 countries showed instead 3? Can investigation case?spirit rankings, think 2 countries showed instead 3? Can investigation case?rankings code, wanted look top 5 countries instead top 3? See change code.rankings code, wanted look top 5 countries instead top 3? See change code.Change wine beer ratio code example find countries highest beer wine consumption (instead wine beer consumption).Change wine beer ratio code example find countries highest beer wine consumption (instead wine beer consumption).","code":"\nView(alcohol_data)"},{"path":"intro.html","id":"athlete-data-example","chapter":" 2 Getting Started with R and R Studio","heading":"2.5 Athlete Data Example","text":"Secondly, look data set top 100 highest paid athletes 2014. athletesdata obtained https://github.com/ali-ce/datasets data set information following variables 100 highest paid athletes 2014, according Forbes (pay includes salary endorsements):Name (name athlete)Rank (athlete ranks, 1 highest paid)Sport (sport athlete plays)endorsements (money sponsorships companies)totalpay (millions year 2014, salary + endorsements)salary (money tournaments contract salary)age athlete 2014Gender (Male Female)first read data set name athletes. can use head() function look first rows data set.many different interesting questions answer data set. First, might interested relationship athlete age salary top 100 athletes. Recall earlier stat course one appropriate graphic examine relationship scatterplot:see anything strange scatterplot? think y-axis tick labels 2.5e+07, 5.0e+07, etc. mean?Now let’s see can count number athletes Top 100 personal favourite sport, Tennis:looks like 6 athletes: can see sort Rank :Finally, let’s see can compare ratio endorsements (commercials products) salary professional athletes Top 100 2 sports: Football (referring American Football) Basketball. Recall earlier Stat class might want use side--side boxplots make comparison since one categorical variable (Sport Type) one quantitative variable (Ratio Endorsements Salary).graph endorsements / salary ratio 1 indicates person makes half overall pay endorsements half overall pay salary.sport looks like tends receive larger proportion overall pay endorsements athletes top 100?","code":"\nathletes <- read_csv(\"data/athletesdata.csv\")\nhead(athletes)\n#> # A tibble: 6 × 9\n#>    ...1 Name         Rank Sport endor…¹ total…² salary   age\n#>   <dbl> <chr>       <dbl> <chr>   <dbl>   <dbl>  <dbl> <dbl>\n#> 1     1 Aaron Rodg…    55 Foot… 7500000  2.2 e7 1.45e7    31\n#> 2     2 Adam Scott     95 Golf  9000000  1.77e7 8.7 e6    34\n#> 3     3 Adrian Gon…    60 Base…  400000  2.15e7 2.11e7    32\n#> 4     4 Alex Rodri…    48 Base…  300000  2.29e7 2.26e7    39\n#> 5     5 Alfonso So…    93 Base…   50000  1.80e7 1.8 e7    38\n#> 6     6 Amar'e Sto…    27 Bask… 5000000  2.67e7 2.17e7    32\n#> # … with 1 more variable: Gender <chr>, and abbreviated\n#> #   variable names ¹​endorsements, ²​totalpay\n#> # ℹ Use `colnames()` to see all variable names\nggplot(data = athletes, mapping = aes(x = age, y = salary)) + \n  geom_point() +\n  geom_smooth(se = FALSE)\nathletes |> group_by(Sport) |>\n  summarise(counts = n()) |>\n  filter(Sport == \"Tennis\")\n#> # A tibble: 1 × 2\n#>   Sport  counts\n#>   <chr>   <int>\n#> 1 Tennis      6\nathletes |>\n  filter(Sport == \"Tennis\") |>\n  arrange(Rank)\n#> # A tibble: 6 × 9\n#>    ...1 Name         Rank Sport endor…¹ total…² salary   age\n#>   <dbl> <chr>       <dbl> <chr>   <dbl>   <dbl>  <dbl> <dbl>\n#> 1    82 Roger Fede…     7 Tenn…   5.2e7  5.62e7 4.2 e6    33\n#> 2    78 Rafael Nad…     9 Tenn…   3  e7  4.45e7 1.45e7    28\n#> 3    72 Novak Djok…    17 Tenn…   2.1e7  3.31e7 1.21e7    27\n#> 4    64 Maria Shar…    34 Tenn…   2.2e7  2.44e7 2.4 e6    27\n#> 5    60 Li Na          41 Tenn…   1.8e7  2.36e7 5.6 e6    32\n#> 6    89 Serena Wil…    55 Tenn…   1.1e7  2.2 e7 1.1 e7    33\n#> # … with 1 more variable: Gender <chr>, and abbreviated\n#> #   variable names ¹​endorsements, ²​totalpay\n#> # ℹ Use `colnames()` to see all variable names\nfootball_basketball <- athletes |>\n  filter(Sport == \"Football\" | Sport == \"Basketball\")\n\nggplot(data = football_basketball,\n       aes(x = Sport, y = endorsements / salary)) + \n  geom_boxplot() +\n  labs(y = \"Endorsements / Salary\")"},{"path":"intro.html","id":"exercise-1-2","chapter":" 2 Getting Started with R and R Studio","heading":"2.5.1 Exercises","text":"Instead looking relationship age salary top 100 athletes 2014, change plot look relationship age endorsements. change code ? Try !Instead looking relationship age salary top 100 athletes 2014, change plot look relationship age endorsements. change code ? Try !Pick Sport Tennis see can count number athletes top 100 sport well sort Rank. Careful: sports athletes Top 100.Pick Sport Tennis see can count number athletes top 100 sport well sort Rank. Careful: sports athletes Top 100.many athletes top 100 sport chose?endorsements / salary example, change one sports sport choice make comparison. sport tends receive larger proportion overall pay endorsements.endorsements / salary example, change one sports sport choice make comparison. sport tends receive larger proportion overall pay endorsements.qualification might want make statement previous exercise? (random sample athletes sport? matter?).qualification might want make statement previous exercise? (random sample athletes sport? matter?).side--side boxplots comparing endorsements salary ratio two different sports, ’ve changed y-axis label Endorsements / Salary using labs(y = \"Endorsements / Salary\") statement. Try changing x-axis label something else. think need add plot?side--side boxplots comparing endorsements salary ratio two different sports, ’ve changed y-axis label Endorsements / Salary using labs(y = \"Endorsements / Salary\") statement. Try changing x-axis label something else. think need add plot?","code":""},{"path":"intro.html","id":"finishing-up-common-errors-in-r","chapter":" 2 Getting Started with R and R Studio","heading":"2.6 Finishing Up: Common Errors in R","text":"now talk little bit getting errors R can done correct common errors.may encountered errors point document. Let’s go common errors well discuss comment code.missing parenthesis: open parenthesis ( needs close ). Try running following code chunk without fixing anything.Notice bottom-left window > symbol starts line changes +. generally bad!! means forgot close parenthesis ) quote (' \"). code run since R thinks still trying type something function. fix issue, click cursor bottom-left window press Esc. , try find error code chunk.Can find missing closing parenthesis ?Missing Comma. Try running following code chunk without fixing anything.R gives “Error: unexpected symbol ….”. Oftentimes, means missing comma spelled variable name incorrectly.Can find missed comma ?Capitalization IssuesIn original data set, variable Sport capitalized. capitalizing means R won’t able find proclaims “object sport found”.Forgetting Quotes. Character strings need quotation marks around . discuss later, graph labels titles need quotes around since don’t directly refer columns rows data set:error forgetting quotes typically “Unexpected Symbol” though error also given issues.quotes missing code chunk ?Finally, can add comment code chunk # symbol (always use double ## reason though). allows type comment code chunk isn’t code:Comments useful longer code chunks, allow remember something. also tell someone ’ve shared code something.Save file clicking File -> Save using keyboard shortcut Command + s (Control + s PC). Render file clicking Render button top-left window. see .html file pop , errors code!","code":"ggplot(data = athletes, aes(x = Sport, y = salary) + \n  geom_boxplot()ggplot(data = athletes aes(x = Sport, y = salary)) + \n  geom_boxplot()\nathletes |> filter(sport == \"Tennis\")ggplot(data = athletes, aes(x = Sport, y = endorsements)) + \n  geom_boxplot() + xlab(Popularity Measure)\n## this is a comment\n## this calculation might be useful later\n7 * 42\n#> [1] 294"},{"path":"intro.html","id":"chapexercise-1","chapter":" 2 Getting Started with R and R Studio","heading":"2.7 Chapter Exercises","text":"Note: Usually, exercises ask write code using week’s chapter reference. However, initial chapter, something little different.Open new .qmd file (File -> New File -> Quarto Document -> OK) delete text explaining Quarto . Make sure Quarto document self-contained using something like following first lines file:, complete following exercises.Exercise 1. Read short paper https://joss.theoj.org/papers/10.21105/joss.01686 Introduction tidyverse, answer questions Quarto file. ’m imagining whole exercise take ~ 20-25 minutes.Answer following questions typing answers .qmd document. need make new code chunks, questions don’t ask coding!two major areas tidyverse doesn’t provide tools ?two major areas tidyverse doesn’t provide tools ?authors define “tidy”?authors define “tidy”?mean tidyverse “human-centred”?mean tidyverse “human-centred”?2 sentences, describe data science “cycle” given diagram top page 3.2 sentences, describe data science “cycle” given diagram top page 3.Exercise 2. may continue use .qmd file answer questions. question, type answer new line, line space answers. questions answered outside code chunks since answers text, code.name class year (first-year, sophomore, junior, senior)?name class year (first-year, sophomore, junior, senior)?/major(s) minor(s), either actual intended?/major(s) minor(s), either actual intended?taking course? (Major requirement?, Minor requirement?, recommended advisor student?, exploring field?, etc.). taking major minor requirement, decide major minor statistics data science?taking course? (Major requirement?, Minor requirement?, recommended advisor student?, exploring field?, etc.). taking major minor requirement, decide major minor statistics data science?semester year take STAT 113 professor?semester year take STAT 113 professor?taken STAT 213? taken CS 140?taken STAT 213? taken CS 140?hometown: city, state, country?hometown: city, state, country?play sport campus? , sport? , activity -campus?play sport campus? , sport? , activity -campus?favorite TV show movie band/musical artist?favorite TV show movie band/musical artist?Tell something .Tell something .Take look learning outcomes listed syllabus. excited ?Take look learning outcomes listed syllabus. excited ?expectations class /hope gain class?expectations class /hope gain class?Take moment scroll advice students took course Fall semester 2021. one piece advice hope apply course semester?Take moment scroll advice students took course Fall semester 2021. one piece advice hope apply course semester?Render .qmd file .html file submit rendered .html file Canvas. file won’t render, submit .qmd file instead. submit either file, first need get file server onto computer can upload Canvas.Nice work: dive ggplot() ggplot2 package next!","code":"---\ntitle: \"Your Title\"\nauthor: \"Your Name\"\nformat: \n  html:\n    self-contained: true\n---"},{"path":"intro.html","id":"solutions-1","chapter":" 2 Getting Started with R and R Studio","heading":"2.8 Exercise Solutions","text":"sections, exercise solutions posted end section. However, R brand new, coding exercises class first section.","code":""},{"path":"ggplot2.html","id":"ggplot2","chapter":" 3 Plotting with ggplot2","heading":" 3 Plotting with ggplot2","text":"Goals:Use ggplot2 package make exploratory plots STAT 113 single quantitative variable, two quantitative variables, quantitative categorical variable, single categorical variable, two categorical variables.Use ggplot2 package make exploratory plots STAT 113 single quantitative variable, two quantitative variables, quantitative categorical variable, single categorical variable, two categorical variables.Use plots produced answer questions Presidential election data set Fitness data set.Use plots produced answer questions Presidential election data set Fitness data set.practice running code R.practice running code R.","code":""},{"path":"ggplot2.html","id":"introduction-and-basic-terminology","chapter":" 3 Plotting with ggplot2","heading":"3.1 Introduction and Basic Terminology","text":"begin data science journey plotting ggplot2 package. starting plotting couple reasons:Plotting cool! get see immediate result coding efforts form nice--look-plot.Plotting cool! get see immediate result coding efforts form nice--look-plot.exploratory data analysis, typically start making plots data.exploratory data analysis, typically start making plots data.Plotting can lead us ask subsequently investigate interesting questions, see first example.Plotting can lead us ask subsequently investigate interesting questions, see first example.first use data set 2000 United States Presidential election former President George Bush Al Gore obtained http://www.econometrics.com/intro/votes.htm. unfamiliar U.S. political elections, enough know state allocated certain number “electoral votes” president: states award electoral votes candidate receives ballots state. can read strange system Wikipedia.Florida typically highly-contentious “battleground” state. data set following variables, recorded 67 counties Florida:Gore, number people voted Al Gore 2000Bush, number people voted George Bush 2000Buchanan, number people voted third-party candidate BuchananNader, number people voted third-party candidate NaderOther, number people voted candidate previous 4 listedCounty, name county FloridaTo get started exploring data, complete following steps learned Week 0:Open R Project double clicking .RProj icon folder desktop, , opening R Studio clicking File -> Open Project.Open R Project double clicking .RProj icon folder desktop, , opening R Studio clicking File -> Open Project.Create new .qmd file folder Notes R Project using File -> New File -> Quarto.Create new .qmd file folder Notes R Project using File -> New File -> Quarto.Finally, read name data set pres_df, take look data set running head(pres_df) line, shows first observations data set:Finally, read name data set pres_df, take look data set running head(pres_df) line, shows first observations data set:Pay special attention variable names: ’ll need use names make plots. , R case-sensitive, meaning , example, need use Gore, gore.trying go light technical code terminology start (come back things later semester). terminology make lot sense ’ve actually worked data. , three terms thrown around quite bit next weeks: function, argument, object.function R always* (*always class) followed open ( ended closed ). non-technical terms, function something inputs often analogous English verb. example, mean() function calculates mean, rank() functions ranks variable lowest highest, labs() used add labels plot. Every function help file can accessed typing ?name_of_function. Try typing ?mean lower left window.function R always* (*always class) followed open ( ended closed ). non-technical terms, function something inputs often analogous English verb. example, mean() function calculates mean, rank() functions ranks variable lowest highest, labs() used add labels plot. Every function help file can accessed typing ?name_of_function. Try typing ?mean lower left window.argument something goes inside parentheses function. Arguments include objects, might . bottom-left window, type ?mean view Help file R function. see mean() 3 arguments: x, R object, trim, na.rm. trim = 0 default, means , default, R trim numbers computing mean.argument something goes inside parentheses function. Arguments include objects, might . bottom-left window, type ?mean view Help file R function. see mean() 3 arguments: x, R object, trim, na.rm. trim = 0 default, means , default, R trim numbers computing mean.object something created R, usually <-. , looking code read data, pres_df R object.object something created R, usually <-. , looking code read data, pres_df R object.make sense go first couple weeks.","code":"\nlibrary(tidyverse)\npres_df <- read_table(\"data/PRES2000.txt\") \n## don't worry about the `read_table` function....yet\nhead(pres_df)\n#> # A tibble: 6 × 6\n#>     Gore   Bush Buchanan Nader Other County  \n#>    <dbl>  <dbl>    <dbl> <dbl> <dbl> <chr>   \n#> 1  47365  34124      263  3226   751 ALACHUA \n#> 2   2392   5610       73    53    26 BAKER   \n#> 3  18850  38637      248   828   242 BAY     \n#> 4   3075   5414       65    84    35 BRADFORD\n#> 5  97318 115185      570  4470   852 BREVARD \n#> 6 386561 177323      788  7101  1623 BROWAR"},{"path":"ggplot2.html","id":"basic-plot-structure","chapter":" 3 Plotting with ggplot2","heading":"3.2 Basic Plot Structure","text":"use ggplot() function ggplot2 package construct visualizations data. ggplot() function 3 basic components:data argument, specifying name data set (pres_df )mapping argument, specifying specifies aesthetics plot (aes()). Common aesthetics x position, y position, colour, size, shape, group, fill.geom_    () component, specifying geometric shape used display data.components combined following form:structure ggplot() plots based Grammar Graphics https://www.springer.com/gp/book/9780387245447. new things, components easier think examples.","code":"ggplot(data = name_of_data, aes(x = name_of_x_var, \n                                          y = name_of_y_var,\n                                          colour = name_of_colour_var,\n                                          etc.)) +\n  geom_nameofgeom() +\n  .....<other stuff>"},{"path":"ggplot2.html","id":"graphing-a-single-variable","chapter":" 3 Plotting with ggplot2","heading":"3.3 Graphing a Single Variable","text":"","code":""},{"path":"ggplot2.html","id":"histograms-and-frequency-plots-for-a-quantitative-variable","chapter":" 3 Plotting with ggplot2","heading":"3.3.1 Histograms and Frequency Plots for a Quantitative Variable","text":"Let’s go ahead begin exploration data making histogram number people voted Gore county. Recall histogram useful like graph single quantitative variable. Copy following code R chunk run code:1e+05, 2e+05, etc. labels x-axis mean?R gives us message “Pick better value binwidth” instead default bins = 30. Add , bins = 15 inside parentheses geom_histogram() change number bins histogram.Change colour inside bins “darkred”. think colour inside bins maps colour fill? Try !couple observations high vote values. explain large outliers?Another graph useful visualizing single quantitative variable frequency plot. code make frequency plot given . simply replacing geom_histogram() geom_freqpoly().frequency plot just like histogram counts connected line instead represented bins. can see relate including geom_freqpoly() geom_histogram() plot, though doesn’t make prettiest graph:","code":"\nggplot(data = pres_df, aes(x = Gore)) +\n  geom_histogram(colour = \"black\", fill = \"white\") +\n  xlab(\"Votes for Gore in Florida\")\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\nggplot(data = pres_df, aes(x = Gore)) +\n  geom_freqpoly(colour = \"black\") +\n  xlab(\"Votes for Gore in Florida\") \n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\nggplot(data = pres_df, aes(x = Gore)) +\n  geom_freqpoly(colour = \"black\") +\n  xlab(\"Votes for Gore in Florida\") +\n  geom_histogram() \n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`."},{"path":"ggplot2.html","id":"r-code-style","chapter":" 3 Plotting with ggplot2","heading":"3.3.2 R Code Style","text":"want code readable possible. benefits people may read code (like ), also benefits , particularly read code future. try follow Style Guide Advanced R book: http://adv-r..co.nz/Style.html. Feel free skim , don’t need worry much: able pick important elements just going course. might actually end better code style haven’t previous coding experience.quick example code style can important, consider following two code chunks, produce graph.code chunk want read two years now? code chunk want classmate/friend/coworker read? (assuming like classmate/friend/coworker….)","code":"\nggplot(data=pres_df,mapping=aes(x=Gore))+geom_histogram(colour=\"black\",fill=\"white\")+\n  xlab(\"Votes for Gore in Florida\")\nggplot(data = pres_df, aes(x = Gore)) +\n  geom_histogram(colour = \"black\", fill = \"white\") +\n  xlab(\"Votes for Gore in Florida\")"},{"path":"ggplot2.html","id":"bar-plots-for-a-categorical-variable","chapter":" 3 Plotting with ggplot2","heading":"3.3.3 Bar Plots for a Categorical Variable","text":"Recall STAT 113 bar plots useful want examine distribution one categorical variable. Side--side bar plots stacked bar plots plots useful looking relationship two categorical variables. actually aren’t categorical variables interesting plot data set, ’ll make one, called winner using code don’t need understand next week. winner \"Gore\" Gore won county \"Bush\" Bush won county. ’ll name new data set pres_cat.Using data set, can make bar plot geom_bar(). beauty ggplot() code super-similar used histograms frequency plots!Note , sometimes, data format one column contains levels categorical variable another column contains counts directly. example, can create data set using code learn next week:data set just two observations contains column two major presidential candidates column number counties candidate won. wanted make barplot showing number wins candidate, can’t use geom_bar(). Predict result running following code.Instead, can use geom_col(), takes x aesthetic giving column names levels categorical variable, y aesthetic giving column counts:","code":"\npres_cat <- pres_df |> mutate(winner = if_else(Gore > Bush,\n                                                true = \"Gore\",\n                                                false = \"Bush\"))\npres_cat\n#> # A tibble: 67 × 7\n#>      Gore   Bush Buchanan Nader Other County    winner\n#>     <dbl>  <dbl>    <dbl> <dbl> <dbl> <chr>     <chr> \n#>  1  47365  34124      263  3226   751 ALACHUA   Gore  \n#>  2   2392   5610       73    53    26 BAKER     Bush  \n#>  3  18850  38637      248   828   242 BAY       Bush  \n#>  4   3075   5414       65    84    35 BRADFORD  Bush  \n#>  5  97318 115185      570  4470   852 BREVARD   Bush  \n#>  6 386561 177323      788  7101  1623 BROWAR    Gore  \n#>  7   2155   2873       90    39    17 CALHOUN   Bush  \n#>  8  29645  35426      182  1462   181 CHARLOTTE Bush  \n#>  9  25525  29765      270  1379   261 CITRUS    Bush  \n#> 10  14632  41736      186   562   237 CLAY      Bush  \n#> # … with 57 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\nggplot(data = pres_cat, aes(x = winner)) +\n  geom_bar()\npres_cat2 <- pres_cat |> group_by(winner) |>\n  summarise(nwins = n())\npres_cat2\n#> # A tibble: 2 × 2\n#>   winner nwins\n#>   <chr>  <int>\n#> 1 Bush      51\n#> 2 Gore      16\nggplot(pres_cat2, aes(x = winner)) +\n  geom_bar()\nggplot(pres_cat2, aes(x = winner, y = nwins)) +\n  geom_col()"},{"path":"ggplot2.html","id":"exercise-2-1","chapter":" 3 Plotting with ggplot2","heading":"3.3.4 Exercises","text":"Exercises marked * indicate exercise solution end chapter 3.7.Change frequency plot plot number votes Bush instead number Gore. obvious outliers Bush frequency plot?Change frequency plot plot number votes Bush instead number Gore. obvious outliers Bush frequency plot?preference histograms preference frequency plots? Can think situation one desirable ?preference histograms preference frequency plots? Can think situation one desirable ?looks like Bush won lot ….necessarily mean Bush won votes total Florida? ?looks like Bush won lot ….necessarily mean Bush won votes total Florida? ?using survey data STAT 113 2018-2019 academic year many exercises section. may taken STAT 113 AP credit another reason, STAT 113 survey given students STAT 113 across sections. analyses Intro Stat carried using survey.data set contains following variables:Year, FirstYear, Sophomore, Junior, SeniorSex, M F (data set, Sex considered binary).Hgt, height, inches.Wgt, weight, pounds.Haircut, much paid haircut, typically.GPAExercise, amount hours exercise typical week.Sport, whether student plays varsity sport.TV, amount hours spent watching TV typical week.Award, Award preferred: choices Olympic Medal, Nobel Prize, Academy Award.Pulse, pulse rate, beats per minute.SocialMedia, used social media platform (Instagram, SnapChat, FaceBook, Twitter, , None).* Create histogram Exercise variable, change x-axis label “Exercise (hours per typical week)”, change number bins 14, change fill bins “lightpink2” outline colour bins black.* Create histogram Exercise variable, change x-axis label “Exercise (hours per typical week)”, change number bins 14, change fill bins “lightpink2” outline colour bins black.* can change y-axis histogram “density” instead raw count. means bar shows proportion cases instead raw count. Google something like “geom_histogram density” figure create y aes() show density instead count.* can change y-axis histogram “density” instead raw count. means bar shows proportion cases instead raw count. Google something like “geom_histogram density” figure create y aes() show density instead count.Construct histogram using quantitative variable choice. Change fill colour using http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf help choose colours.Construct histogram using quantitative variable choice. Change fill colour using http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf help choose colours.Construct bar plot variable choosing. find?Construct bar plot variable choosing. find?format STAT 113 data set need construct bar plot geom_col() instead geom_bar()?format STAT 113 data set need construct bar plot geom_col() instead geom_bar()?","code":"\nlibrary(tidyverse)\nstat113_df <- read_csv(\"data/stat113.csv\")\nhead(stat113_df)\n#> # A tibble: 6 × 12\n#>   Year   Sex     Hgt   Wgt Haircut   GPA Exerc…¹ Sport    TV\n#>   <chr>  <chr> <dbl> <dbl>   <dbl> <dbl>   <dbl> <chr> <dbl>\n#> 1 Sopho… M        66   155       0  2.9       15 Yes       8\n#> 2 First… F        69   170      17  3.87      14 Yes      12\n#> 3 First… F        64   130      40  3.3        5 No        5\n#> 4 First… M        68   157      35  3.21      10 Yes      15\n#> 5 First… M        72   175      20  3.1        2 No        5\n#> 6 Junior F        62   150      50  3.3        8 Yes       5\n#> # … with 3 more variables: Award <chr>, Pulse <dbl>,\n#> #   SocialMedia <chr>, and abbreviated variable name\n#> #   ¹​Exercise\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"ggplot2.html","id":"graphing-two-quantitative-variables-faceting-and-aes-options","chapter":" 3 Plotting with ggplot2","heading":"3.4 Graphing Two Quantitative Variables, Faceting, and aes() Options","text":"","code":""},{"path":"ggplot2.html","id":"scatterplots","chapter":" 3 Plotting with ggplot2","heading":"3.4.1 Scatterplots","text":"Moving back 2000 presidential election data set, thus far, ’ve figured couple counties large numbers votes Gore large number votes Bush. don’t know reason (counties democratic, republican, counties just populous). counties large number votes Bush also tend large number votes Gore? candidates: interesting patterns?Let’s start making scatterplot number votes Gore number votes Bush. Note geom_ making scatterplot called geom_point() adding layer points plot.patterns see scatterplot?Now, change x variable Gore Buchanan. notice something strange scatterplot. Try come one explanation outlying point many votes Buchanan.trying come explanation, nice figure Florida county outlying point nice knew something Florida counties. remedy first issue, recall can type View(pres_df) pull data set. new window open, click column heading Buchanan sort votes Buchanan high low figure county outlier.Use Google sleuthing skills find explanation: try search “2000 united states presidential election [name outlier county]”. Write sentence find. Hint: nothing useful pops , try adding term “butterfly ballot” search.used 2000 Presidential data set find something really interesting! particular, used exploratory data analysis examine data set, without specific question interest want answer. type exploring often really useful, drawbacks, discuss later semester.","code":"\nggplot(data = pres_df, aes(x = Gore, y = Bush)) +\n  geom_point()"},{"path":"ggplot2.html","id":"aesthetics-in-aes","chapter":" 3 Plotting with ggplot2","heading":"3.4.2 Aesthetics in aes()","text":"remainder chapter, work fitness data collected Apple Watch since November 2018. higham_fitness_clean.csv contains information following variables:Start, month, day, year fitness data recorded onmonth, monthweekday, day weekdayofyear, day year (304 corresponds 304th day year)distance, distance walked milessteps, number steps takenflights, number flights stairs climbedactive_cals, number calories burned activitystepgoal, whether reached 10,000 steps dayweekend_ind, variable whether day week weekend day (Saturday Sunday) weekday (Monday - Friday).First, let’s make basic scatterplot illustrate ’s important plot data. ’ll use variable distance x-variable active_cals y-variable.One aspect plot may notice observations burned 0 active calories, yet walked/jogged/ran/moved distance. possible burn calories move ~ 4 miles? Probably , let’s drop observations data set make note dropped observations. Unfortunately, don’t tools yet, just run following chunk code without worrying much syntax.Let’s make plot fitness data set instead fitness_full see outliers actually gone. time, put aes() geom_point() function:Putting aes() ggplot() putting aes() geom_point() results graph case. put aes() ggplot(), R perpetuates aes() aesthetics geom_s plotting command. However, put aes() geom_point(), future geoms use need re-specify different aes(). ’ll see example exercises.aes() OptionsIn addition x y, can also use aes() map variables things like colour, size, shape. example, might make scatterplot Start x-axis (date) active_cals y-axis, colouring whether day week weekend.anything useful notice plot? anything plot improved?Instead using colour, can also specify point shape. useful, example, printing something black white.prefer colour shape? ?Finally, another common aes() size. example, make size points scatterplot change depending many flights stairs climbed.don’t think previous three plots necessarily “best” need work, , part fun exploratory data analysis making trying different plots see “works.”Inside vs Outside aes()’ve changed colour points correspond weekend_ind, just wanted change colour points colour, \"purple\". Try running following code chunk:graph look like? expected?Putting colour = ____ inside aes() outside aes() achieves different things. general,want map something data set (fitness) something plot (x, y, colour, size, etc.), put inside aes() geom_point(aes(colour = weekend_ind)).want map something data set (fitness) something plot (x, y, colour, size, etc.), put inside aes() geom_point(aes(colour = weekend_ind)).assign fixed characteristics don’t come data, put outside aes(), geom_point(colour = \"purple\").assign fixed characteristics don’t come data, put outside aes(), geom_point(colour = \"purple\").can also change overall point size shape. standard size 1 following code chunk makes points bigger. standard shape 19: can try changing integers see shapes can get.","code":"\nlibrary(tidyverse)\nfitness_full <- read_csv(\"data/higham_fitness_clean.csv\") |> mutate(weekend_ind = case_when(weekday == \"Sat\" | weekday == \"Sun\" ~ \"weekend\",\n  TRUE ~ \"weekday\"))\n#> Rows: 993 Columns: 9\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (2): month, weekday\n#> dbl  (6): active_cals, distance, flights, steps, dayofye...\n#> date (1): Start\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nggplot(data = fitness_full, aes(x = distance, y = active_cals)) +\n  geom_point()\n## drop observations that have active calories < 50. \n## assuming that these are data errors or \n## days where the Apple Watch wasn't worn.\nfitness <- fitness_full |>\n  filter(active_cals > 50)\nggplot(data = fitness) +\n  geom_point(aes(x = distance, y = active_cals))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals, colour = weekend_ind))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals, shape = weekend_ind))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals, size = flights))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals, colour = \"purple\"))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals), size = 1.5, shape = 19)"},{"path":"ggplot2.html","id":"using-more-than-one-geom","chapter":" 3 Plotting with ggplot2","heading":"3.4.3 Using More Than One geom()","text":"might also interested fitting smooth curve scatterplot. want put one “geom” plot, can use multiple geoms. Since want aes() apply geom_point() geom_smooth(), going move aes() command overall ggplot() line code:Within geom_smooth(), can set se = FALSE get rid grey standard errors around lines, can setmethod = \"lm\" fit straight linear regression lines instead smooth curves:look like increasing overall trend? decreasing? make sense use line model relationship prefer smooth curve?","code":"\nggplot(data = fitness, aes(x = Start, y = active_cals)) +\n  geom_point() +\n  geom_smooth(span = 0.3)\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'\nggplot(data = fitness, aes(x = Start, y = active_cals)) +\n  geom_point() +\n  geom_smooth(se = FALSE, method = \"lm\")\n#> `geom_smooth()` using formula 'y ~ x'"},{"path":"ggplot2.html","id":"line-plots-with-geom_line","chapter":" 3 Plotting with ggplot2","heading":"3.4.4 Line Plots with geom_line()","text":"Line plots often useful quantitative variable ’d like explore time. y-axis quantitative variable x-axis typically time. generally, line plots often used x-axis variable one discrete value y-axis variable. example, suppose want explore step count changed time past couple years. Compare standard scatterplot following line plot: prefer?Can spot start pandemic graph? seemed happen step count?","code":"\nggplot(data = fitness, aes(x = Start, y = steps)) +\n  geom_point() + geom_smooth() + xlab(\"Date\")\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'\nggplot(data = fitness, aes(x = Start, y = steps)) +\n  geom_line() + geom_smooth() + xlab(\"Date\")\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'"},{"path":"ggplot2.html","id":"faceting","chapter":" 3 Plotting with ggplot2","heading":"3.4.5 Faceting","text":"Using colour colour points different levels categorical variable generally fine just couple levels /little overlap among levels. , lot two categories colour . example, let’s move back STAT 113 survey data set investigate relationship Pulse Exercise different class Year’s. might hypothesize students get exercise tend lower pulse rates.many different categories categorical variable (4 categories Year, particular plot still bit difficult read), can sometimes useful facet plot variable instead trying use different colours shapes.eliminated colour = argument added facet_wrap( ~ name_of_facet_variable). creates different scatterplot smooth line level name_of_facet_variable.can see plot harder see plot colour?data seem support hypothesis exercise associated lower pulse rates sample students?","code":"\nggplot(data = stat113_df, aes(x = Exercise, y = Pulse,\n                           colour = Year)) +\n  geom_point() +\n  geom_smooth(se = TRUE)\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'\nggplot(data = stat113_df, aes(x = Exercise, y = Pulse)) +\n  geom_point() +\n  geom_smooth(se = TRUE) +\n  facet_wrap(~ Year)\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'"},{"path":"ggplot2.html","id":"exercise-2-2","chapter":" 3 Plotting with ggplot2","heading":"3.4.6 Exercises","text":"Exercises marked * indicate exercise solution end chapter 3.7.Fix code chunk tried specify colour points purple actually make points “purple” moving colour = \"purple\" outside parentheses aes() (still inside geom_point()).Fix code chunk tried specify colour points purple actually make points “purple” moving colour = \"purple\" outside parentheses aes() (still inside geom_point()).console (bottom-left) window, type ?geom_smooth scroll “Arguments.” Find span, read , , within geom_smooth() argument line plot steps vs. date, add span argument make smooth line wigglier.console (bottom-left) window, type ?geom_smooth scroll “Arguments.” Find span, read , , within geom_smooth() argument line plot steps vs. date, add span argument make smooth line wigglier.Explain doesn’t make sense construct line plot Exercise vs. GPA.Explain doesn’t make sense construct line plot Exercise vs. GPA.* Make scatterplot Hgt y-axis Wgt x-axis, colouring Sport. Add smooth fitted curve scatterplot. , move colour = Sport aes() ggplot() function aes() geom_point() function. changes plot? Can give explanation change occurs?* Make scatterplot Hgt y-axis Wgt x-axis, colouring Sport. Add smooth fitted curve scatterplot. , move colour = Sport aes() ggplot() function aes() geom_point() function. changes plot? Can give explanation change occurs?* Faceting can used types plots ! Make pair faceted histograms quantitative variable choosing faceted categorical variable choosing.* Faceting can used types plots ! Make pair faceted histograms quantitative variable choosing faceted categorical variable choosing.","code":""},{"path":"ggplot2.html","id":"boxplots-stacked-barplots-and-others","chapter":" 3 Plotting with ggplot2","heading":"3.5 Boxplots, Stacked Barplots and Others","text":"common geoms useful throughout semester. skim surface: ’ll come back plotting weeks, ’re able data wrangling reshaping.","code":""},{"path":"ggplot2.html","id":"graphing-a-quant.-variable-vs.-a-cat.-variable","chapter":" 3 Plotting with ggplot2","heading":"3.5.1 Graphing a Quant. Variable vs. a Cat. Variable","text":"Another common plot used Intro Stat courses boxplot. Side--side boxplots particularly useful want compare quantitative response variable across two levels categorical variable. Let’s stick STAT 113 survey data examine relationship Exercise Award preference.can conclude plot?alternative side--side boxplots violin plots:Read Violin plots typing ?geom_violin console (bottom-left window). different boxplots?","code":"\nggplot(data = stat113_df, aes(x = Award, y = Exercise)) +\n  geom_boxplot()\nggplot(data = stat113_df, aes(x = Award, y = Exercise)) +\n  geom_violin()"},{"path":"ggplot2.html","id":"graphing-two-categorical-variables","chapter":" 3 Plotting with ggplot2","heading":"3.5.2 Graphing Two Categorical Variables","text":"combination two variables yet explore two variables categorical. Let’s look relationship Year SocialMedia first using stacked bar plot.make graph, specify position = \"fill\" bars “filled” stepgoal.patterns notice plot? anything plot improved?","code":"\nggplot(data = stat113_df, aes(x = Year, fill = SocialMedia)) +\n  geom_bar(position = \"fill\") +\n  ylab(\"Proportion\")"},{"path":"ggplot2.html","id":"exercise-2-3","chapter":" 3 Plotting with ggplot2","heading":"3.5.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 3.7.* Change colour inside boxplots Exercise vs. Award graph \"blue\". think ’ll use colour = \"blue\" fill = \"blue\"?* Change colour inside boxplots Exercise vs. Award graph \"blue\". think ’ll use colour = \"blue\" fill = \"blue\"?* Create side--side boxplot compares GPAs students prefer different Awards. change fill boxplot colour choice. notice plot?* Create side--side boxplot compares GPAs students prefer different Awards. change fill boxplot colour choice. notice plot?* making previous plot, R gives us warning message “Removed 70 rows containing non-finite values”. R’s robotic way telling us 70 GPA values missing data set. Use know data collected (Fall Spring semester 2018-2019 school-year) guess missing.* making previous plot, R gives us warning message “Removed 70 rows containing non-finite values”. R’s robotic way telling us 70 GPA values missing data set. Use know data collected (Fall Spring semester 2018-2019 school-year) guess missing.* Make stacked bar plot two variables choosing STAT 113 data set. Comment something notice plot.* Make stacked bar plot two variables choosing STAT 113 data set. Comment something notice plot.","code":""},{"path":"ggplot2.html","id":"chapexercise-2","chapter":" 3 Plotting with ggplot2","heading":"3.6 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 3.7.* default geom_smooth() use LOESS (locally estimated scatterplot smoothing). Read LOESS : . Write one two sentences explaining LOESS .* default geom_smooth() use LOESS (locally estimated scatterplot smoothing). Read LOESS : . Write one two sentences explaining LOESS .* Thus far, faceted single variable. Use Google figure facet two variables make plot shows relationship GPA (y-axis) Exercise (x-axis) four facets: one male students play sport, one female students play sport, one male students play sport, one female students play sport.* Thus far, faceted single variable. Use Google figure facet two variables make plot shows relationship GPA (y-axis) Exercise (x-axis) four facets: one male students play sport, one female students play sport, one male students play sport, one female students play sport.* Intro-Stat, boxplots typically introduced using * symbol identify outliers. Using combination help ?geom_boxplot Googling “R point shapes”, figure modify side--side boxplots outliers shown using *, default dots. , using Google, figure add mean boxplot “darkgreen” diamond-shaped symbol stat_summary().* Intro-Stat, boxplots typically introduced using * symbol identify outliers. Using combination help ?geom_boxplot Googling “R point shapes”, figure modify side--side boxplots outliers shown using *, default dots. , using Google, figure add mean boxplot “darkgreen” diamond-shaped symbol stat_summary().common theme ’ll see throughout course ’s advantageous know much background information possible data set analyzing. Data sets easier analyze pose questions ’re familiar subject matter.common theme ’ll see throughout course ’s advantageous know much background information possible data set analyzing. Data sets easier analyze pose questions ’re familiar subject matter.Give example something know STAT 113 survey data set helped answer pose question someone another university (therefore unfamiliar intro stat course) wouldn’t know.Give example something don’t know fitness data set person owns fitness data know. give advantage person familiar fitness data?","code":""},{"path":"ggplot2.html","id":"solutions-2","chapter":" 3 Plotting with ggplot2","heading":"3.7 Exercise Solutions","text":"","code":""},{"path":"ggplot2.html","id":"introduction-etc.-s","chapter":" 3 Plotting with ggplot2","heading":"3.7.1 Introduction etc. S","text":"","code":""},{"path":"ggplot2.html","id":"basic-plot-structure-s","chapter":" 3 Plotting with ggplot2","heading":"3.7.2 Basic Plot Structure S","text":"","code":""},{"path":"ggplot2.html","id":"graphing-a-single-variable-s","chapter":" 3 Plotting with ggplot2","heading":"3.7.3 Graphing a Single Variable S","text":"* Create histogram Exercise variable, change x-axis label “Exercise (hours per typical week)”, change number bins 14, change fill bins “lightpink2” outline colour bins black.* can change y-axis histogram “density” instead raw count. means bar shows proportion cases instead raw count. Google something like “geom_histogram density” figure create y aes() show density instead count.","code":"\nggplot(data = stat113_df, aes(x = Exercise)) +\n  geom_histogram(bins = 14, fill = \"lightpink2\", colour = \"black\") +\n  xlab(\"Exercise (hours per typical week)\")\nggplot(data = stat113_df, aes(x = Exercise, y = ..density..)) +\n  geom_histogram(bins = 14, fill = \"lightpink2\", colour = \"black\") +\n  xlab(\"Exercise (hours per typical week)\")"},{"path":"ggplot2.html","id":"graphing-two-quant.-etc.-s","chapter":" 3 Plotting with ggplot2","heading":"3.7.4 Graphing Two Quant. etc. S","text":"* Make scatterplot Hgt y-axis Wgt x-axis, colouring Sport. Add smooth fitted curve scatterplot. , move colour = Sport aes() ggplot() function aes() geom_point() function. changes plot? Can give explanation change occurs?points now coloured Sport one smooth fitted line. makes sense geom_point() now two global aesthetics x y, well colour aesthetic. geom_smooth() longer colour aesthetic still inherits two global aesthetics, x y.* Faceting can used types plots ! Make pair faceted histograms quantitative variable choosing faceted categorical variable choosing.Answers vary:","code":"\nggplot(data = stat113_df, aes(x = Wgt, y = Hgt, colour = Sport)) +\n  geom_point() +\n  geom_smooth()\n\nggplot(data = stat113_df, aes(x = Wgt, y = Hgt)) +\n  geom_point(aes(colour = Sport)) +\n  geom_smooth()\nggplot(data = stat113_df, aes(x = GPA)) + \n  geom_histogram(bins = 15) +\n  facet_wrap( ~ Sport)"},{"path":"ggplot2.html","id":"boxplots-stacked-etc.-s","chapter":" 3 Plotting with ggplot2","heading":"3.7.5 Boxplots, Stacked, etc. S","text":"* Change colour inside boxplots Exercise vs. Award graph \"blue\". think ’ll use colour = \"blue\" fill = \"blue\"?fill ’s inside boxplots want modify. colour modify outline colour.* Create side--side boxplot compares GPAs students prefer different Awards. change fill boxplot colour choice. notice plot?outlier students, three groups overall seem similar GPAs.* making previous plot, R gives us warning message “Removed 70 rows containing non-finite values”. R’s robotic way telling us 70 GPA values missing data set. Use know data collected (Fall Spring semeseter 2018-2019 school-year) guess missing.STAT 113 first-year students: first-years taking course fall GPA report. Additionally, another reason might student chose report GPA.* Make stacked bar plot two variables choosing STAT 113 data set. Comment something notice plot.Answers vary.might expect, seem like higher proportion students play sport prefer win Olympic medal, compared students play sport.","code":"\nggplot(data = stat113_df, aes(x = Award, y = Exercise)) +\n  geom_boxplot(fill = \"blue\")\nggplot(data = stat113_df, aes(x = Award, y = GPA)) +\n  geom_boxplot(fill = \"lightpink1\")\nggplot(data = stat113_df, aes(x = Sport, fill = Award)) +\n  geom_bar(position = \"fill\")"},{"path":"ggplot2.html","id":"chapexercise-2-S","chapter":" 3 Plotting with ggplot2","heading":"3.7.6 Chapter Exercises S","text":"* default geom_smooth() use LOESS (locally estimated scatterplot smoothing). Read LOESS : . Write one two sentences explaining LOESS .Loess uses bunch local regressions predict y-variable point, giving weight observations near point interest x-axis. done every point, predictions connected smooth curve.* Thus far, faceted single variable. Use Google figure facet two variables make plot shows relationship GPA (y-axis) Exercise (x-axis) four facets: one male students play sport, one female students play sport, one male students play sport, one female students play sport.* Intro-Stat, boxplots typically introduced using * symbol identify outliers. Using combination help ?geom_boxplot Googling “R point shapes”, figure modify side--side boxplots outliers shown using *, default dots., using Google, figure add mean boxplot “darkgreen” diamond-shaped symbol stat_summary().","code":"\nggplot(data = stat113_df |> filter(!is.na(Sport) & !is.na(Sex)),\n  aes(x = Exercise, y = GPA)) + \n  geom_point() + geom_smooth() +\n  facet_grid(Sex ~ Sport)\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'\nggplot(data = stat113_df, aes(x = Sex, y = GPA)) +\n  geom_boxplot(fill = \"lightpink1\", outlier.shape = 8) +\n  stat_summary(fun = mean, shape = 18, colour = \"darkgreen\")"},{"path":"ggplot2.html","id":"rcode-2","chapter":" 3 Plotting with ggplot2","heading":"3.8 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\npres_df <- read_table(\"data/PRES2000.txt\") \n## don't worry about the `read_table` function....yet\nhead(pres_df)\nggplot(data = pres_df, aes(x = Gore)) +\n  geom_histogram(colour = \"black\", fill = \"white\") +\n  xlab(\"Votes for Gore in Florida\")\nggplot(data = pres_df, aes(x = Gore)) +\n  geom_freqpoly(colour = \"black\") +\n  xlab(\"Votes for Gore in Florida\") \nggplot(data = pres_df, aes(x = Gore)) +\n  geom_freqpoly(colour = \"black\") +\n  xlab(\"Votes for Gore in Florida\") +\n  geom_histogram() \npres_cat <- pres_df |> mutate(winner = if_else(Gore > Bush,\n                                                true = \"Gore\",\n                                                false = \"Bush\"))\npres_cat\nggplot(data = pres_cat, aes(x = winner)) +\n  geom_bar()\npres_cat2 <- pres_cat |> group_by(winner) |>\n  summarise(nwins = n())\npres_cat2\nggplot(pres_cat2, aes(x = winner)) +\n  geom_bar()\nggplot(pres_cat2, aes(x = winner, y = nwins)) +\n  geom_col()\nggplot(data = pres_df, aes(x = Gore, y = Bush)) +\n  geom_point()\nlibrary(tidyverse)\nfitness_full <- read_csv(\"data/higham_fitness_clean.csv\") |> mutate(weekend_ind = case_when(weekday == \"Sat\" | weekday == \"Sun\" ~ \"weekend\",\n  TRUE ~ \"weekday\"))\nggplot(data = fitness_full, aes(x = distance, y = active_cals)) +\n  geom_point()\n## drop observations that have active calories < 50. \n## assuming that these are data errors or \n## days where the Apple Watch wasn't worn.\nfitness <- fitness_full |>\n  filter(active_cals > 50)\nggplot(data = fitness) +\n  geom_point(aes(x = distance, y = active_cals))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals, colour = weekend_ind))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals, shape = weekend_ind))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals, size = flights))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals, colour = \"purple\"))\nggplot(data = fitness) +\n  geom_point(aes(x = Start, y = active_cals), size = 1.5, shape = 19)\nggplot(data = fitness, aes(x = Start, y = active_cals)) +\n  geom_point() +\n  geom_smooth(span = 0.3)\nggplot(data = fitness, aes(x = Start, y = active_cals)) +\n  geom_point() +\n  geom_smooth(se = FALSE, method = \"lm\")\nggplot(data = fitness, aes(x = Start, y = steps)) +\n  geom_point() + geom_smooth() + xlab(\"Date\")\nggplot(data = fitness, aes(x = Start, y = steps)) +\n  geom_line() + geom_smooth() + xlab(\"Date\")\nggplot(data = stat113_df, aes(x = Exercise, y = Pulse,\n                           colour = Year)) +\n  geom_point() +\n  geom_smooth(se = TRUE)\nggplot(data = stat113_df, aes(x = Exercise, y = Pulse)) +\n  geom_point() +\n  geom_smooth(se = TRUE) +\n  facet_wrap(~ Year)\nggplot(data = stat113_df, aes(x = Award, y = Exercise)) +\n  geom_boxplot()\nggplot(data = stat113_df, aes(x = Award, y = Exercise)) +\n  geom_violin()\nggplot(data = stat113_df, aes(x = Year, fill = SocialMedia)) +\n  geom_bar(position = \"fill\") +\n  ylab(\"Proportion\")"},{"path":"dplyr.html","id":"dplyr","chapter":" 4 Wrangling with dplyr","heading":" 4 Wrangling with dplyr","text":"Goals:Use mutate(), if_else(), case_when() functions create new variables.Use mutate(), if_else(), case_when() functions create new variables.Use filter() slice(), select(), arrange() functions dplyr choose certain rows keep get rid , choose certain columns keep get rid , sort data, respectively.Use filter() slice(), select(), arrange() functions dplyr choose certain rows keep get rid , choose certain columns keep get rid , sort data, respectively.Use group_by() summarise() create useful summaries data set.Use group_by() summarise() create useful summaries data set.Combine goals plotting explore babynames data set data set SLU majors.Combine goals plotting explore babynames data set data set SLU majors.Explain pipe operator |> explain can use pipe operator.Explain pipe operator |> explain can use pipe operator.Throughout chapter, use babynames data set babynames R package. begin, install babynames package typing install.packages(\"babynames\") bottom-left console winow, read data set runningand typing ?babynames bottom-left window R Studio. see data set contains baby name data provided SSA United States dating back 1880:second data set use 27 observations, one SLU’s majors contains 3 variables:Major, name major.nfemales, number female graduates major 2015 - 2019.nmales, number male graduates major 2015 - 2019.data kindly provided Dr. Ramler. Notes R Project open, can read data set withThere many interesting informative plots make either data set, require data wrangling first. chapter provide foundation wrangling skills.","code":"\nlibrary(babynames)\nhead(babynames)\n#> # A tibble: 6 × 5\n#>    year sex   name          n   prop\n#>   <dbl> <chr> <chr>     <int>  <dbl>\n#> 1  1880 F     Mary       7065 0.0724\n#> 2  1880 F     Anna       2604 0.0267\n#> 3  1880 F     Emma       2003 0.0205\n#> 4  1880 F     Elizabeth  1939 0.0199\n#> 5  1880 F     Minnie     1746 0.0179\n#> 6  1880 F     Margaret   1578 0.0162\nlibrary(tidyverse)\nslumajors_df <- read_csv(\"data/SLU_Majors_15_19.csv\")\nslumajors_df\n#> # A tibble: 27 × 3\n#>    Major                        nfemales nmales\n#>    <chr>                           <dbl>  <dbl>\n#>  1 Anthropology                       34     15\n#>  2 Art & Art History                  65     11\n#>  3 Biochemistry                       14     11\n#>  4 Biology                           162     67\n#>  5 Business in the Liberal Arts      135    251\n#>  6 Chemistry                          26     14\n#>  7 Computer Science                   21     47\n#>  8 Conservation Biology               38     20\n#>  9 Economics                         128    349\n#> 10 English                           131     54\n#> # … with 17 more rows\n#> # ℹ Use `print(n = ...)` to see more rows"},{"path":"dplyr.html","id":"mutate-create-variables","chapter":" 4 Wrangling with dplyr","heading":"4.1 mutate(): Create Variables","text":"Sometimes, want create new variable ’s data set, oftentimes using if_else(), case_when(), basic algebraic operations one columns already present data set.R understands following symbols:+ addition, - subtraction* multiplication, / division^ raising something power (3 ^ 2 equal 9)R also order operations usual: parentheses, exponents, multiplication division, addition subtraction.example, suppose want create variable slumajors_df total number students graduating major. can mutate():’s lot break code chunk: importantly, ’re seeing first many, many, many, many, many, many, many instances using |> pipe! |> operator approximately reads take slumajors_df “” mutate() .Piping really convenient, easy--read way build sequence commands. can read code :Take slumajors_df slumajors_df,Take slumajors_df slumajors_df,perform mutate() step create new variable called ntotal, nfemales plus nmales.perform mutate() step create new variable called ntotal, nfemales plus nmales.Since first time using mutate(), let’s also delve function . general, mutate() reads:mutate(name_of_new_variable = operations_on_old_variables).R just automatically assumes want operation every single row data set, often quite convenient!might also want create variable percentage students identifying female major:happened ntotal? still printout? ’s : created variable ntotal, didn’t actually save new data set anything. R makes prints new variable, doesn’t get saved data set. want save new data set, can use <- operator. , ’re saving new data set name old data set: slumajors_df. , ’re thing percfemale variable. won’t always want give new data set name old one: ’ll talk chapter exercises., can pipe many things together want , ’s probably easier just create variables one go. following chunk says “Take slumajors_df create new variable ntotal. new data set, create new variable called percfemale.” Finally, slumajors_df <- beginning says “save new data set data set name, slumajors_df.”","code":"\nslumajors_df |> mutate(ntotal = nfemales + nmales)\n#> # A tibble: 27 × 4\n#>    Major                        nfemales nmales ntotal\n#>    <chr>                           <dbl>  <dbl>  <dbl>\n#>  1 Anthropology                       34     15     49\n#>  2 Art & Art History                  65     11     76\n#>  3 Biochemistry                       14     11     25\n#>  4 Biology                           162     67    229\n#>  5 Business in the Liberal Arts      135    251    386\n#>  6 Chemistry                          26     14     40\n#>  7 Computer Science                   21     47     68\n#>  8 Conservation Biology               38     20     58\n#>  9 Economics                         128    349    477\n#> 10 English                           131     54    185\n#> # … with 17 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\nslumajors_df |>\n  mutate(percfemale = 100 * nfemales / (nfemales + nmales))\n#> # A tibble: 27 × 4\n#>    Major                        nfemales nmales percfemale\n#>    <chr>                           <dbl>  <dbl>      <dbl>\n#>  1 Anthropology                       34     15       69.4\n#>  2 Art & Art History                  65     11       85.5\n#>  3 Biochemistry                       14     11       56  \n#>  4 Biology                           162     67       70.7\n#>  5 Business in the Liberal Arts      135    251       35.0\n#>  6 Chemistry                          26     14       65  \n#>  7 Computer Science                   21     47       30.9\n#>  8 Conservation Biology               38     20       65.5\n#>  9 Economics                         128    349       26.8\n#> 10 English                           131     54       70.8\n#> # … with 17 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\nslumajors_df <- slumajors_df |>\n  mutate(percfemale = 100 * nfemales / (nfemales + nmales))\nslumajors_df <- slumajors_df |> mutate(ntotal = nfemales + nmales)\nslumajors_df <- slumajors_df |>\n  mutate(ntotal = nfemales + nmales) |>\n  mutate(percfemale = 100 * nfemales / (nfemales + nmales))"},{"path":"dplyr.html","id":"if_else-and-case_when","chapter":" 4 Wrangling with dplyr","heading":"4.1.1 if_else() and case_when()","text":"Suppose want make new variable conditional another variable (one variable) data set. typically use mutate() coupled withif_else() new variable created one conditioncase_when() new variable created one conditionSuppose want create new variable tells us whether Major majority Women. , want new variable, morewomen \"Yes\" Major 50% women \"\" 50% less.mutate() statement reads: create new variable called morewomen equal \"Yes\" percfemale > 50 true equal \"\" perfemale > 0.5. first argument condition, second name new variable condition holds, third name variable condition hold.use conditions time every day life. example, New York quarantine order stating people coming 22 states July 2020 need quarantine. terms condition, read “traveling New York one 22 states, need quarantine 2 weeks. Else, , don’t need quarantine.” trick using conditions R getting used syntax code.can see set one condition, ’d need use different function (use nested if_else() statements, can nightmare read). one condition creating new variable, use case_when().example, looking output, see Biochemistry 56% female graduates. ’s “” 50/50 split, suppose want variable called large_majority “female” percent women 70 , “male” percent women 30 less, “none” percent female 30 70.case_when() function reads “percent female equal 70, assign new variable large_majority value ”female”, ’s less equal 30, assign 30 less 70, assign variable value “none” .” & boolean operator: ’ll talk later don’t worry much now.Let’s save two new variables slumajors_df:","code":"\nslumajors_df |> mutate(morewomen = if_else(percfemale > 50,\n                                            true = \"Yes\",\n                                            false = \"No\"))\n#> # A tibble: 27 × 6\n#>    Major               nfema…¹ nmales percf…² ntotal morew…³\n#>    <chr>                 <dbl>  <dbl>   <dbl>  <dbl> <chr>  \n#>  1 Anthropology             34     15    69.4     49 Yes    \n#>  2 Art & Art History        65     11    85.5     76 Yes    \n#>  3 Biochemistry             14     11    56       25 Yes    \n#>  4 Biology                 162     67    70.7    229 Yes    \n#>  5 Business in the Li…     135    251    35.0    386 No     \n#>  6 Chemistry                26     14    65       40 Yes    \n#>  7 Computer Science         21     47    30.9     68 No     \n#>  8 Conservation Biolo…      38     20    65.5     58 Yes    \n#>  9 Economics               128    349    26.8    477 No     \n#> 10 English                 131     54    70.8    185 Yes    \n#> # … with 17 more rows, and abbreviated variable names\n#> #   ¹​nfemales, ²​percfemale, ³​morewomen\n#> # ℹ Use `print(n = ...)` to see more rows\nslumajors_df |> mutate(large_majority =\n                          case_when(percfemale >= 70 ~ \"female\",\n                                    percfemale <= 30 ~ \"male\",\n                                    percfemale > 30 & percfemale < 70 ~ \"none\")) \n#> # A tibble: 27 × 6\n#>    Major               nfema…¹ nmales percf…² ntotal large…³\n#>    <chr>                 <dbl>  <dbl>   <dbl>  <dbl> <chr>  \n#>  1 Anthropology             34     15    69.4     49 none   \n#>  2 Art & Art History        65     11    85.5     76 female \n#>  3 Biochemistry             14     11    56       25 none   \n#>  4 Biology                 162     67    70.7    229 female \n#>  5 Business in the Li…     135    251    35.0    386 none   \n#>  6 Chemistry                26     14    65       40 none   \n#>  7 Computer Science         21     47    30.9     68 none   \n#>  8 Conservation Biolo…      38     20    65.5     58 none   \n#>  9 Economics               128    349    26.8    477 male   \n#> 10 English                 131     54    70.8    185 female \n#> # … with 17 more rows, and abbreviated variable names\n#> #   ¹​nfemales, ²​percfemale, ³​large_majority\n#> # ℹ Use `print(n = ...)` to see more rows\nslumajors_df <- slumajors_df |>\n  mutate(morewomen = if_else(percfemale > 50,\n                             true = \"Yes\",\n                             false = \"No\")) |>\n  mutate(large_majority =\n           case_when(percfemale >= 70 ~ \"female\",\n                     percfemale <= 30 ~ \"male\",\n                     percfemale > 30 & percfemale < 70 ~ \"none\")) "},{"path":"dplyr.html","id":"exercise-3-1","chapter":" 4 Wrangling with dplyr","heading":"4.1.2 Exercises","text":"Exercises marked * indicate exercise solution end chapter 4.7.think ethical exclude non-binary genders analyses graphs slumajors data set? ?think ethical exclude non-binary genders analyses graphs slumajors data set? ?* Create new variable called major_size “large” total number majors 100 “small” total number majors less 100.* Create new variable called major_size “large” total number majors 100 “small” total number majors less 100.Create new variable called major_size2 “large total number majors 150 ,”medium” total number majors 41 149, “small” total number majors 40 fewer.Create new variable called major_size2 “large total number majors 150 ,”medium” total number majors 41 149, “small” total number majors 40 fewer.55% SLU students identify female. , definition morewomen variable, make sense use 55% cutoff 50%?55% SLU students identify female. , definition morewomen variable, make sense use 55% cutoff 50%?* Investigate happens case_when() give overlapping conditions give conditions don’t cover observations. overlapping conditions, create variable testcase \"Yes\" percfemale greater equal 40 \"\" percfemale greater 60 conditions don’t cover observations, create variable testcase2 \"Yes\" percfemale greater equal 55 \"\" percfemale less 35.* Investigate happens case_when() give overlapping conditions give conditions don’t cover observations. overlapping conditions, create variable testcase \"Yes\" percfemale greater equal 40 \"\" percfemale greater 60 conditions don’t cover observations, create variable testcase2 \"Yes\" percfemale greater equal 55 \"\" percfemale less 35.one two newly created variables mutate(), create plot investigates question interest might data.one two newly created variables mutate(), create plot investigates question interest might data.","code":""},{"path":"dplyr.html","id":"arrange-ordering-rows-select-choosing-columns-and-slice-and-filter-choosing-rows","chapter":" 4 Wrangling with dplyr","heading":"4.2 arrange() (Ordering Rows), select() (Choosing Columns), and slice() and filter() (Choosing Rows)","text":"arrange() used order rows data set according variable, select() used choose columns keep (get rid ) filter() used keep (get rid ) observations (rows).","code":""},{"path":"dplyr.html","id":"arrange-ordering-rows","chapter":" 4 Wrangling with dplyr","heading":"4.2.1 arrange(): Ordering Rows","text":"arrange() function allows us order rows data set using one variables. function straightforward. Suppose want order rows majors lowest percfemale first:major lowest percentage female graduates?see , default, arrange() orders rows low high. order high low majors highest percfemale first, use desc() around variable ordering :major highest percentage women graduates?","code":"\nslumajors_df |> arrange(percfemale)\n#> # A tibble: 27 × 7\n#>    Major       nfema…¹ nmales percf…² ntotal morew…³ large…⁴\n#>    <chr>         <dbl>  <dbl>   <dbl>  <dbl> <chr>   <chr>  \n#>  1 Economics       128    349    26.8    477 No      male   \n#>  2 Physics           6     14    30       20 No      male   \n#>  3 Computer S…      21     47    30.9     68 No      none   \n#>  4 Business i…     135    251    35.0    386 No      none   \n#>  5 Music            13     21    38.2     34 No      none   \n#>  6 Geology          28     41    40.6     69 No      none   \n#>  7 History          62     82    43.1    144 No      none   \n#>  8 Philosophy       24     29    45.3     53 No      none   \n#>  9 Mathematics      74     83    47.1    157 No      none   \n#> 10 Government      127    116    52.3    243 Yes     none   \n#> # … with 17 more rows, and abbreviated variable names\n#> #   ¹​nfemales, ²​percfemale, ³​morewomen, ⁴​large_majority\n#> # ℹ Use `print(n = ...)` to see more rows\nslumajors_df |> arrange(desc(percfemale))\n#> # A tibble: 27 × 7\n#>    Major       nfema…¹ nmales percf…² ntotal morew…³ large…⁴\n#>    <chr>         <dbl>  <dbl>   <dbl>  <dbl> <chr>   <chr>  \n#>  1 Art & Art …      65     11    85.5     76 Yes     female \n#>  2 Psychology      278     61    82.0    339 Yes     female \n#>  3 French           27      7    79.4     34 Yes     female \n#>  4 Spanish          35     10    77.8     45 Yes     female \n#>  5 Statistics       28      9    75.7     37 Yes     female \n#>  6 Global Stu…      69     27    71.9     96 Yes     female \n#>  7 Neuroscien…      61     24    71.8     85 Yes     female \n#>  8 Performanc…     144     57    71.6    201 Yes     female \n#>  9 Religious …      10      4    71.4     14 Yes     female \n#> 10 English         131     54    70.8    185 Yes     female \n#> # … with 17 more rows, and abbreviated variable names\n#> #   ¹​nfemales, ²​percfemale, ³​morewomen, ⁴​large_majority\n#> # ℹ Use `print(n = ...)` to see more rows"},{"path":"dplyr.html","id":"select-choose-columns","chapter":" 4 Wrangling with dplyr","heading":"4.2.2 select() Choose Columns","text":"might also interested getting rid columns data set. One reason overwhelming (30+) columns data set, know just need . easiest way use select() just input names columns want keep. example, interested majors totals, doIf wanted use data set anything else, ’d also need name, rename, <-. probably want name something slumajors_df overwrite original data set, case want use variables later!might also want use select() get rid one two columns. case, denote column want get rid -. example, might want get rid ntotal column made get rid nmales nfemales columns:select() comes many useful helper functions, oftentimes needed. One helper functions actually often useful everything(). can, example, use using mutate() put variable just created front data set make sure weren’t unexpected issues:Verify propfemale now appears first data set. everything() tacks remaining variables propfemale. , case, ’s useful way re-order columns might interested appears first.","code":"\nslumajors_df |> select(Major, ntotal)\n#> # A tibble: 27 × 2\n#>    Major                        ntotal\n#>    <chr>                         <dbl>\n#>  1 Anthropology                     49\n#>  2 Art & Art History                76\n#>  3 Biochemistry                     25\n#>  4 Biology                         229\n#>  5 Business in the Liberal Arts    386\n#>  6 Chemistry                        40\n#>  7 Computer Science                 68\n#>  8 Conservation Biology             58\n#>  9 Economics                       477\n#> 10 English                         185\n#> # … with 17 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\nslumajors_df |> select(-ntotal, -nfemales, -nmales)\n#> # A tibble: 27 × 4\n#>    Major                        percfemale morewomen large…¹\n#>    <chr>                             <dbl> <chr>     <chr>  \n#>  1 Anthropology                       69.4 Yes       none   \n#>  2 Art & Art History                  85.5 Yes       female \n#>  3 Biochemistry                       56   Yes       none   \n#>  4 Biology                            70.7 Yes       female \n#>  5 Business in the Liberal Arts       35.0 No        none   \n#>  6 Chemistry                          65   Yes       none   \n#>  7 Computer Science                   30.9 No        none   \n#>  8 Conservation Biology               65.5 Yes       none   \n#>  9 Economics                          26.8 No        male   \n#> 10 English                            70.8 Yes       female \n#> # … with 17 more rows, and abbreviated variable name\n#> #   ¹​large_majority\n#> # ℹ Use `print(n = ...)` to see more rows\nslumajors_df |> mutate(propfemale = percfemale / 100) |>\n  select(propfemale, everything())\n#> # A tibble: 27 × 8\n#>    propfemale Major    nfema…¹ nmales percf…² ntotal morew…³\n#>         <dbl> <chr>      <dbl>  <dbl>   <dbl>  <dbl> <chr>  \n#>  1      0.694 Anthrop…      34     15    69.4     49 Yes    \n#>  2      0.855 Art & A…      65     11    85.5     76 Yes    \n#>  3      0.56  Biochem…      14     11    56       25 Yes    \n#>  4      0.707 Biology      162     67    70.7    229 Yes    \n#>  5      0.350 Busines…     135    251    35.0    386 No     \n#>  6      0.65  Chemist…      26     14    65       40 Yes    \n#>  7      0.309 Compute…      21     47    30.9     68 No     \n#>  8      0.655 Conserv…      38     20    65.5     58 Yes    \n#>  9      0.268 Economi…     128    349    26.8    477 No     \n#> 10      0.708 English      131     54    70.8    185 Yes    \n#> # … with 17 more rows, 1 more variable:\n#> #   large_majority <chr>, and abbreviated variable names\n#> #   ¹​nfemales, ²​percfemale, ³​morewomen\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names"},{"path":"dplyr.html","id":"slice-and-filter-choose-rows","chapter":" 4 Wrangling with dplyr","heading":"4.2.3 slice() and filter(): Choose Rows","text":"Instead choosing columns keep, can also choose certain rows keep using either slice() filter().slice() allows specify row numbers corresponding rows want keep. example, suppose want keep rows five popular majors:can alternatively use slice(1:5), shorthand slice(1, 2, 3, 4, 5). slice() useful, relatively simple. ’ll come back weeks well discuss subsetting base R.filter() way keep rows specifying condition related one variables data set. ’ve already seen conditions if_else() case_when() statements, ’ll now used “filter” rows data set.can keep rows based categorical variable quantitative variable combination number categorical quantitative variables. R uses following symbols make comparisons. ’ve already using intuitive symbols (like < >):< <= less less equal , respectively> >= greater greater equal , respectively== equal (careful: equal double equal sign ==)!= equal (general, ! denotes “”)’s probably time change data set ! ’ll working babynames data set rest chapter:needed, can remind babynames data set typing ?babynames console window.following statements ? See can guess running code.things put quotes, like \"Matthew\" things aren’t, like 2000? Can make pattern?can also combine conditions multiple variables filter() using Boolean operators. ’ve already seen one case_when() statement : & means “”.Look Venn diagrams R Data Science learn various Boolean operators can use R: https://r4ds..co.nz/transform.html#logical-operators. Boolean operators can used functions R well, ’ve already seen if_else() case_when().following gives examples. See can figure line code running .","code":"\nslumajors_df |> arrange(desc(ntotal)) |>\n  slice(1, 2, 3, 4, 5)\n#> # A tibble: 5 × 7\n#>   Major        nfema…¹ nmales percf…² ntotal morew…³ large…⁴\n#>   <chr>          <dbl>  <dbl>   <dbl>  <dbl> <chr>   <chr>  \n#> 1 Economics        128    349    26.8    477 No      male   \n#> 2 Business in…     135    251    35.0    386 No      none   \n#> 3 Psychology       278     61    82.0    339 Yes     female \n#> 4 Government       127    116    52.3    243 Yes     none   \n#> 5 Biology          162     67    70.7    229 Yes     female \n#> # … with abbreviated variable names ¹​nfemales, ²​percfemale,\n#> #   ³​morewomen, ⁴​large_majority\nlibrary(babynames)\nbabynames\n#> # A tibble: 1,924,665 × 5\n#>     year sex   name          n   prop\n#>    <dbl> <chr> <chr>     <int>  <dbl>\n#>  1  1880 F     Mary       7065 0.0724\n#>  2  1880 F     Anna       2604 0.0267\n#>  3  1880 F     Emma       2003 0.0205\n#>  4  1880 F     Elizabeth  1939 0.0199\n#>  5  1880 F     Minnie     1746 0.0179\n#>  6  1880 F     Margaret   1578 0.0162\n#>  7  1880 F     Ida        1472 0.0151\n#>  8  1880 F     Alice      1414 0.0145\n#>  9  1880 F     Bertha     1320 0.0135\n#> 10  1880 F     Sarah      1288 0.0132\n#> # … with 1,924,655 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\nbabynames |> filter(name == \"Matthew\")\nbabynames |> filter(year >= 2000)\nbabynames |> filter(sex != \"M\")\nbabynames |> filter(prop > 0.05)\nbabynames |> filter(year == max(year))\nbabynames |> filter(n > 20000 | prop > 0.05)\nbabynames |> filter(sex == \"F\" & name == \"Mary\")\nbabynames |> filter(sex == \"F\" & name == \"Mary\" & prop > 0.05)"},{"path":"dplyr.html","id":"exercise-3-2","chapter":" 4 Wrangling with dplyr","heading":"4.2.4 Exercises","text":"Exercises marked * indicate exercise solution end chapter 4.7.happens arrange() one categorical variables slumajors_df data set?happens arrange() one categorical variables slumajors_df data set?* Use select() everything() put large_majority variable first column slumajors_df data set.* Use select() everything() put large_majority variable first column slumajors_df data set.* babynames data set, use filter(), mutate() rank(), arrange() print 10 popular Male babynames 2017.* babynames data set, use filter(), mutate() rank(), arrange() print 10 popular Male babynames 2017.babynames data set, use filter() keep rows name (, another name interests ) one sex (either \"M\" \"F\"). Name new data set something construct line plot looks either n prop chosen name year.babynames data set, use filter() keep rows name (, another name interests ) one sex (either \"M\" \"F\"). Name new data set something construct line plot looks either n prop chosen name year.","code":""},{"path":"dplyr.html","id":"summarise-and-group_by-create-summaries","chapter":" 4 Wrangling with dplyr","heading":"4.3 summarise() and group_by(): Create Summaries","text":"summarise() function useful get summaries data. example, suppose want know average major size SLU across five year span total number majors across five years. can use summarise() summary function, like mean(), sum(), median(), max(), min(), n(), etc. ’ll notice format summarise() extremely similar format mutate(). Using slumajors_df data just one quick example,","code":"\nslumajors_df |>\n  summarise(meantotalmajor = mean(ntotal),\n            totalgrad = sum(ntotal))\n#> # A tibble: 1 × 2\n#>   meantotalmajor totalgrad\n#>            <dbl>     <dbl>\n#> 1           124.      3347"},{"path":"dplyr.html","id":"group_by-groups","chapter":" 4 Wrangling with dplyr","heading":"4.3.1 group_by(): Groups","text":"summarise() often useful paired group_by() statement. allows us get summaries across different groups.example, suppose wanted total number registered births per year babynames data set:group_by() takes grouping variable, , using summarise() computes given summary function group.summary functions intuitive ’ve intro stat. , ’re sure whether summary getting maximum maximum() max(), just try !n() function can used within summarise() obtain number observations. give total number rows, used without group_by()Note n() typically doesn’t inputs. ’s typically useful paired group_by(): allows us see number observations within year, instance:","code":"\nbabynames |> group_by(year) |>\n  summarise(totalbirths = sum(n))\n#> # A tibble: 138 × 2\n#>     year totalbirths\n#>    <dbl>       <int>\n#>  1  1880      201484\n#>  2  1881      192696\n#>  3  1882      221533\n#>  4  1883      216946\n#>  5  1884      243462\n#>  6  1885      240854\n#>  7  1886      255317\n#>  8  1887      247394\n#>  9  1888      299473\n#> 10  1889      288946\n#> # … with 128 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\nbabynames |> summarise(totalobs = n())\n#> # A tibble: 1 × 1\n#>   totalobs\n#>      <int>\n#> 1  1924665\nbabynames |> group_by(year) |>\n  summarise(ngroup = n())\n#> # A tibble: 138 × 2\n#>     year ngroup\n#>    <dbl>  <int>\n#>  1  1880   2000\n#>  2  1881   1935\n#>  3  1882   2127\n#>  4  1883   2084\n#>  5  1884   2297\n#>  6  1885   2294\n#>  7  1886   2392\n#>  8  1887   2373\n#>  9  1888   2651\n#> 10  1889   2590\n#> # … with 128 more rows\n#> # ℹ Use `print(n = ...)` to see more rows"},{"path":"dplyr.html","id":"exercise-3-3","chapter":" 4 Wrangling with dplyr","heading":"4.3.2 Exercises","text":"Exercises marked * indicate exercise solution end chapter 4.7.Compare summarise() mutate() using following code. ’s difference two functions?Using data set group_by() n() combination,make line plot ngroup x-axis year y-axis. interpret plot?* Create data set column name column shows total number births name across years sexes.* Create data set column name column shows total number births name across years sexes.* group_by() can also used functions, including mutate(). Use group_by() mutate() rank names least popular year-sex combination.* group_by() can also used functions, including mutate(). Use group_by() mutate() rank names least popular year-sex combination.* data set 4, filter() data keep popular name year-sex combination construct summary table showing many times name appears popular name.* data set 4, filter() data keep popular name year-sex combination construct summary table showing many times name appears popular name.* Run following code. Intuitively, slice(1, 2, 3, 4, 5) grab first five rows data set, , try run , get 1380 rows. Try figure issue using Google search something like “dplyr slicing correctly using group .” find?* Run following code. Intuitively, slice(1, 2, 3, 4, 5) grab first five rows data set, , try run , get 1380 rows. Try figure issue using Google search something like “dplyr slicing correctly using group .” find?","code":"\nslumajors_df |>\n  summarise(meantotalmajor = mean(ntotal),\n            totalgrad = sum(ntotal)) \nslumajors_df |>\n  mutate(meantotalmajor = mean(ntotal),\n            totalgrad = sum(ntotal)) |>\n  select(meantotalmajor, totalgrad, everything())\nbabynames |> group_by(year) |>\n  summarise(ngroup = n())\n#> # A tibble: 138 × 2\n#>     year ngroup\n#>    <dbl>  <int>\n#>  1  1880   2000\n#>  2  1881   1935\n#>  3  1882   2127\n#>  4  1883   2084\n#>  5  1884   2297\n#>  6  1885   2294\n#>  7  1886   2392\n#>  8  1887   2373\n#>  9  1888   2651\n#> 10  1889   2590\n#> # … with 128 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\nbabynames_test <- babynames |>\n  group_by(year, sex) |> mutate(ntest = n / prop)\nbabynames_test |> slice(1, 2, 3, 4, 5)\n#> # A tibble: 1,380 × 6\n#> # Groups:   year, sex [276]\n#>     year sex   name          n   prop   ntest\n#>    <dbl> <chr> <chr>     <int>  <dbl>   <dbl>\n#>  1  1880 F     Mary       7065 0.0724  97605.\n#>  2  1880 F     Anna       2604 0.0267  97605.\n#>  3  1880 F     Emma       2003 0.0205  97605.\n#>  4  1880 F     Elizabeth  1939 0.0199  97605.\n#>  5  1880 F     Minnie     1746 0.0179  97605.\n#>  6  1880 M     John       9655 0.0815 118400.\n#>  7  1880 M     William    9532 0.0805 118400.\n#>  8  1880 M     James      5927 0.0501 118400.\n#>  9  1880 M     Charles    5348 0.0452 118400.\n#> 10  1880 M     George     5126 0.0433 118400.\n#> # … with 1,370 more rows\n#> # ℹ Use `print(n = ...)` to see more rows"},{"path":"dplyr.html","id":"missing-values","chapter":" 4 Wrangling with dplyr","heading":"4.4 Missing Values","text":"data sets ’ve worked nice missing values. ’ll see plenty examples data sets missing values later, examine various functions ’ve talked far tackle missing values.Missing values R denoted NA “Available.” Run following code create toy data set missing values can see various functions ’ve used far deal NA values.","code":"\ntoy_df <- tibble(x = c(NA, 3, 4, 7),\n                 y = c(1, 4, 3, 2),\n                 z = c(\"A\", \"A\", \"B\", NA))\ntoy_df\n#> # A tibble: 4 × 3\n#>       x     y z    \n#>   <dbl> <dbl> <chr>\n#> 1    NA     1 A    \n#> 2     3     4 A    \n#> 3     4     3 B    \n#> 4     7     2 <NA>"},{"path":"dplyr.html","id":"exercise-3-4","chapter":" 4 Wrangling with dplyr","heading":"4.4.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 4.7.* mutate(). Try create new variable mutate() involving x. R missing value?* mutate(). Try create new variable mutate() involving x. R missing value?arrange(). Try arranging data set x. R missing value?arrange(). Try arranging data set x. R missing value?filter(). Try filtering observations x less 5 kept. R missing value?filter(). Try filtering observations x less 5 kept. R missing value?summarise(). Try using summarise() function involving x. R return?summarise(). Try using summarise() function involving x. R return?group_by() summarise(). statement 4, add group_by(z) statement summarise(). R return now?group_by() summarise(). statement 4, add group_by(z) statement summarise(). R return now?","code":""},{"path":"dplyr.html","id":"removing-missing-values","chapter":" 4 Wrangling with dplyr","heading":"4.4.2 Removing Missing Values","text":"Missing values removed without carefully examination note consequences might (e.g. values missing?). toy data set meaningless, aren’t asking questions now, data set missing values!investigated missing values comfortable removing , many functions use summarise() na.rm argument can set TRUE tell summarise() remove NAs taking mean(), median(), max(), etc.want remove missing values directly, can use .na() function combination filter(). variable NA (Available) observation, .na() evaluates TRUE; , .na() evaluates FALSE. Test using mutate() create new variable whether Median missing:missingx TRUE first observation. can use advantage filter() filter data set, without going extra step actually making new variable missingx:’ll commonly see written short-hand people’s code may come across :says “keep anything missing x value” (recall ! means “”).","code":"\ntoy_df |> summarise(meanx = mean(x, na.rm = TRUE))\n#> # A tibble: 1 × 1\n#>   meanx\n#>   <dbl>\n#> 1  4.67\ntoy_df |> mutate(missingx = is.na(x))\n#> # A tibble: 4 × 4\n#>       x     y z     missingx\n#>   <dbl> <dbl> <chr> <lgl>   \n#> 1    NA     1 A     TRUE    \n#> 2     3     4 A     FALSE   \n#> 3     4     3 B     FALSE   \n#> 4     7     2 <NA>  FALSE\ntoy_df |> filter(is.na(x) != TRUE)\n#> # A tibble: 3 × 3\n#>       x     y z    \n#>   <dbl> <dbl> <chr>\n#> 1     3     4 A    \n#> 2     4     3 B    \n#> 3     7     2 <NA>\ntoy_df |> filter(!is.na(x))\n#> # A tibble: 3 × 3\n#>       x     y z    \n#>   <dbl> <dbl> <chr>\n#> 1     3     4 A    \n#> 2     4     3 B    \n#> 3     7     2 <NA>"},{"path":"dplyr.html","id":"more-about-the-pipe","chapter":" 4 Wrangling with dplyr","heading":"4.5 More about the Pipe","text":"jumping straight using piping, want appreciation terrible life without . piping make whatever given |> pipe first argument whatever function follows |>. Sois equivalent toIt might also help use analogy thinking piping. Consider Ke$ha’s morning routine opening song Tik Tok. write morning routine terms piping,Kesha first wakes morning, Kesha woken grabs glasses, Kesha woken glasses brushes teeth, etc.pipe operator |> loaded automatically R. ’ve using pipe quite bit, let’s delve little deeper ’s actually . use videogame_clean.csv data file, contains variables video games 2004 - 2019, includinggame, name gamerelease_date, release date gamerelease_date2, second coding release dateprice, price dollars,owners, number owners (given range)median_playtime, median playtime gamemetascore, score website Metacriticprice_cat, 1 Low (less 10.00 dollars), 2 Moderate (10 29.99 dollars), 3 High (30.00 dollars)meta_cat, Metacritic’s review system, following categories: “Overwhelming Dislike”, “Generally Unfavorable”, “Mixed Reviews”, “Generally Favorable”, “Universal Acclaim”.playtime_miss, whether median play time missing (TRUE) (FALSE)Load data set withLet’s say want filter() data set include videogames metascore isn’t missing. ’ve using code likeWhat pipe putting videogame_df first argument filter() function piping statement chunk equivalent :want first filter games non-missing metascore, get rid observations median play time 0, obtain “median” median_playtime 3 price categories, typically useWe see summary , general, games tend give “bang buck”: expensive games tend larger median play time. Consecutive pipes build : can slowly build pipe step--step. Starting top, videogame_df first argument filter(!.na(metascore)) function:filter(videogame_df, !.na(metascore)) first argument filter(median_playtime > 0):filter(filter(videogame_df, !.na(metascore)), median_playtime > 0) first argument group_by(price_cat):group_by(filter(filter(videogame_df, !.na(metascore)), median_playtime > 0), price_cat) first argument summarise(avg_med_time = median(median_playtime, na.rm = TRUE)):obtain result without |> pipe. , use pipe? Compare code uses pipe operator find average median playtime code doesn’t. easier read? think easier write? example shows , purposes, pipe useful aiding readability code. ’s lot easier see ’s happening code chunk pipes previous code chunk without pipe , pipe, can read code left right top bottom. Without pipe, need read code “inside outside”, much challenging.","code":"\ndf |> mutate(x = y + 4)\nmutate(df, x = y + 4)kesha |> wake_up(time = \"morning\", feels_like = \"P-Diddy\") |>\n  grab(glasses) |>\n  brush(teeth, item = \"jack\", unit = \"bottle\") |> ....\nvideogame_df <- read_csv(\"data/videogame_clean.csv\")\n#> Rows: 26688 Columns: 15\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (7): game, release_date, owners, meta_cat, develope...\n#> dbl  (6): price, median_playtime, metascore, price_cat, ...\n#> lgl  (1): playtime_miss\n#> date (1): release_date2\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nhead(videogame_df)\n#> # A tibble: 6 × 15\n#>   game       relea…¹ release_…² price owners media…³ metas…⁴\n#>   <chr>      <chr>   <date>     <dbl> <chr>    <dbl>   <dbl>\n#> 1 Half-Life… Nov 16… 2004-11-16  9.99 10,00…      66      96\n#> 2 Counter-S… Nov 1,… 2004-11-01  9.99 10,00…     128      88\n#> 3 Counter-S… Mar 1,… 2004-03-01  9.99 10,00…       3      65\n#> 4 Half-Life… Nov 1,… 2004-11-01  4.99 5,000…       0      NA\n#> 5 Half-Life… Jun 1,… 2004-06-01  9.99 2,000…       0      NA\n#> 6 CS2D       Dec 24… 2004-12-24 NA    1,000…      10      NA\n#> # … with 8 more variables: price_cat <dbl>, meta_cat <chr>,\n#> #   playtime_miss <lgl>, number <dbl>, developer <chr>,\n#> #   publisher <chr>, average_playtime <dbl>,\n#> #   meta_cat_factor <chr>, and abbreviated variable names\n#> #   ¹​release_date, ²​release_date2, ³​median_playtime,\n#> #   ⁴​metascore\n#> # ℹ Use `colnames()` to see all variable names\nvideogame_df |> filter(!is.na(metascore))\nfilter(videogame_df, !is.na(metascore))\nvideogame_df |> filter(!is.na(metascore)) |>\n  filter(median_playtime > 0) |>\n  group_by(price_cat) |>\n  summarise(avg_med_time = median(median_playtime, na.rm = TRUE))\nfilter(videogame_df, !is.na(metascore))\nfilter(filter(videogame_df, !is.na(metascore)), median_playtime > 0)\ngroup_by(filter(filter(videogame_df, !is.na(metascore)),\n                median_playtime > 0), price_cat)\nsummarise(group_by(filter(filter(videogame_df, !is.na(metascore)),\n  median_playtime > 0), price_cat), \n  avg_med_time = median(median_playtime, na.rm = TRUE))"},{"path":"dplyr.html","id":"when-you-cant-use-the-pipe","chapter":" 4 Wrangling with dplyr","heading":"4.5.1 When You Can’t Use the Pipe","text":", pipe convenient way put precedes pipe first argument function follows pipe. ’s important understand learn R , functions tidyverse purposefully made make good use pipe, functions R utilize pipe. functions tidyverse first argument data set (can use pipes consecutively), isn’t case R functions.example, taken STAT 213, ’ve used lm() fit many different types linear models. haven’t taken STAT 213, lm(response ~ explanatory, data = name_of_data_set) stands “linear model” can used fit simple linear regression model learned STAT 113. might expect something like work:throws us error. Typing ?lm reveals first argument formula fit model, data set. function trying runwhich doesn’t work arguments function mixed (formula appear first data set appear second).one final note pipe, note pipe operator |> relatively new. Previously, primary pipe operator used %>% came magrittr package. almost cases, two operators equivalent. However, scanning Internet help code, probably see |> used many people’s responses sites like StackOverflow.","code":"\nvideogame_df |> lm(metascore ~ price)\n#> Error in as.data.frame.default(data): cannot coerce class '\"formula\"' to a data.frame\nlm(videogame_df, metascore ~ price)\n#> Error in as.data.frame.default(data): cannot coerce class '\"formula\"' to a data.frame"},{"path":"dplyr.html","id":"exercise-3-4","chapter":" 4 Wrangling with dplyr","heading":"4.5.2 Exercises","text":"Exercises marked * indicate exercise solution end chapter 4.7.* Recode following look cleaner using pipe |>.Explain following code gives warning message returns NA. Use list Arguments ?mean explanation.","code":"\nfitness_df <- read_csv(\"data/higham_fitness_clean.csv\")\n#> Rows: 993 Columns: 9\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (2): month, weekday\n#> dbl  (6): active_cals, distance, flights, steps, dayofye...\n#> date (1): Start\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nsummarise(group_by(filter(fitness_df, weekday == \"Sat\" | weekday == \"Sun\"),\n                   month),\n          meanweekend = mean(distance, na.rm = TRUE)) \n#> # A tibble: 12 × 2\n#>    month meanweekend\n#>    <chr>       <dbl>\n#>  1 Apr          5.30\n#>  2 Aug          5.52\n#>  3 Dec          3.30\n#>  4 Feb          4.87\n#>  5 Jan          3.89\n#>  6 Jul          4.85\n#>  7 Jun          4.18\n#>  8 Mar          4.86\n#>  9 May          5.00\n#> 10 Nov          3.06\n#> 11 Oct          3.82\n#> 12 Sep          4.02\nfitness_df |> mean(distance, na.rm = TRUE)\n#> [1] NA"},{"path":"dplyr.html","id":"chapexercise-3","chapter":" 4 Wrangling with dplyr","heading":"4.6 Chapter Exercises","text":"found SLU majors data set FiveThirtyEight majors data set Statistics higher proportion women almost STEM fields. Read first two sections article. Write 2-3 sentences article’s reasoning women statistics STEM fields.found SLU majors data set FiveThirtyEight majors data set Statistics higher proportion women almost STEM fields. Read first two sections article. Write 2-3 sentences article’s reasoning women statistics STEM fields.* . Choose 5 names interest create new data set data 5 names.* . Choose 5 names interest create new data set data 5 names.Use group_by() summarise() add together number Females Males name year. Hint: can group_by() one variable!Use group_by() summarise() add together number Females Males name year. Hint: can group_by() one variable!Make line plot showing popularity 5 names time.Make line plot showing popularity 5 names time.Choose year sex interests filter data set contain observations year sex.\nChoose year sex interests filter data set contain observations year sex.Create new variable ranks names popular least popular.Create new variable ranks names popular least popular.Create bar plot shows 10 popular names well count name.Create bar plot shows 10 popular names well count name.* cases throughout chapter, ’ve renamed data sets using <- name likeIn cases, ’ve given data set new name, likeFor functions generally “safe” name data set using name using function. ?mutate()mutate()arrange()arrange()filter()filter()summarise()summarise()select()select()Pose question babynames data set answer question either graphic data summary.","code":"\ntoy_df <- toy_df |> mutate(newvar = x / y)\ntoy_small <- toy_df |> filter(!is.na(x))"},{"path":"dplyr.html","id":"solutions-3","chapter":" 4 Wrangling with dplyr","heading":"4.7 Exercise Solutions","text":"","code":""},{"path":"dplyr.html","id":"mutate-s","chapter":" 4 Wrangling with dplyr","heading":"4.7.1 mutate() S","text":"* Create new variable called major_size “large” total number majors 100 “small” total number majors less 100.* Investigate happens case_when() give overlapping conditions give conditions don’t cover observations. overlapping conditions, create variable testcase \"Yes\" percfemale greater equal 40 \"\" percfemale greater 60 conditions don’t cover observations, create variable testcase2 \"Yes\" percefemale greater equal 55 \"\" percfemale less 35.overlapping cases, case_when prioritizes first case given.non-coverage, observation covered given NA.","code":"\nslumajors_df |> mutate(major_size = if_else(ntotal >= 100,\n                                             true = \"large\",\n                                             false = \"small\"))\n#> # A tibble: 27 × 8\n#>    Major       nfema…¹ nmales percf…² ntotal morew…³ large…⁴\n#>    <chr>         <dbl>  <dbl>   <dbl>  <dbl> <chr>   <chr>  \n#>  1 Anthropolo…      34     15    69.4     49 Yes     none   \n#>  2 Art & Art …      65     11    85.5     76 Yes     female \n#>  3 Biochemist…      14     11    56       25 Yes     none   \n#>  4 Biology         162     67    70.7    229 Yes     female \n#>  5 Business i…     135    251    35.0    386 No      none   \n#>  6 Chemistry        26     14    65       40 Yes     none   \n#>  7 Computer S…      21     47    30.9     68 No      none   \n#>  8 Conservati…      38     20    65.5     58 Yes     none   \n#>  9 Economics       128    349    26.8    477 No      male   \n#> 10 English         131     54    70.8    185 Yes     female \n#> # … with 17 more rows, 1 more variable: major_size <chr>,\n#> #   and abbreviated variable names ¹​nfemales, ²​percfemale,\n#> #   ³​morewomen, ⁴​large_majority\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n## OR\nslumajors_df |>\n  mutate(major_size = case_when(ntotal >= 100 ~ \"large\",\n                                ntotal < 100 ~ \"small\"))\n#> # A tibble: 27 × 8\n#>    Major       nfema…¹ nmales percf…² ntotal morew…³ large…⁴\n#>    <chr>         <dbl>  <dbl>   <dbl>  <dbl> <chr>   <chr>  \n#>  1 Anthropolo…      34     15    69.4     49 Yes     none   \n#>  2 Art & Art …      65     11    85.5     76 Yes     female \n#>  3 Biochemist…      14     11    56       25 Yes     none   \n#>  4 Biology         162     67    70.7    229 Yes     female \n#>  5 Business i…     135    251    35.0    386 No      none   \n#>  6 Chemistry        26     14    65       40 Yes     none   \n#>  7 Computer S…      21     47    30.9     68 No      none   \n#>  8 Conservati…      38     20    65.5     58 Yes     none   \n#>  9 Economics       128    349    26.8    477 No      male   \n#> 10 English         131     54    70.8    185 Yes     female \n#> # … with 17 more rows, 1 more variable: major_size <chr>,\n#> #   and abbreviated variable names ¹​nfemales, ²​percfemale,\n#> #   ³​morewomen, ⁴​large_majority\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names#> # A tibble: 27 × 9\n#>    Major       nfema…¹ nmales percf…² ntotal morew…³ large…⁴\n#>    <chr>         <dbl>  <dbl>   <dbl>  <dbl> <chr>   <chr>  \n#>  1 Anthropolo…      34     15    69.4     49 Yes     none   \n#>  2 Art & Art …      65     11    85.5     76 Yes     female \n#>  3 Biochemist…      14     11    56       25 Yes     none   \n#>  4 Biology         162     67    70.7    229 Yes     female \n#>  5 Business i…     135    251    35.0    386 No      none   \n#>  6 Chemistry        26     14    65       40 Yes     none   \n#>  7 Computer S…      21     47    30.9     68 No      none   \n#>  8 Conservati…      38     20    65.5     58 Yes     none   \n#>  9 Economics       128    349    26.8    477 No      male   \n#> 10 English         131     54    70.8    185 Yes     female \n#> # … with 17 more rows, 2 more variables: testcase <chr>,\n#> #   testcase2 <chr>, and abbreviated variable names\n#> #   ¹​nfemales, ²​percfemale, ³​morewomen, ⁴​large_majority\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names"},{"path":"dplyr.html","id":"arrange-select-.-s","chapter":" 4 Wrangling with dplyr","heading":"4.7.2 arrange(), select(), …. S","text":"* Use select() everything() put large_majority variable first column slumajors_df data set.* babynames data set, use filter(), mutate() rank(), arrange() print 10 popular Male babynames 2017.","code":"\nslumajors_df |> select(large_majority, everything())\n#> # A tibble: 27 × 7\n#>    large_major…¹ Major nfema…² nmales percf…³ ntotal morew…⁴\n#>    <chr>         <chr>   <dbl>  <dbl>   <dbl>  <dbl> <chr>  \n#>  1 none          Anth…      34     15    69.4     49 Yes    \n#>  2 female        Art …      65     11    85.5     76 Yes    \n#>  3 none          Bioc…      14     11    56       25 Yes    \n#>  4 female        Biol…     162     67    70.7    229 Yes    \n#>  5 none          Busi…     135    251    35.0    386 No     \n#>  6 none          Chem…      26     14    65       40 Yes    \n#>  7 none          Comp…      21     47    30.9     68 No     \n#>  8 none          Cons…      38     20    65.5     58 Yes    \n#>  9 male          Econ…     128    349    26.8    477 No     \n#> 10 female        Engl…     131     54    70.8    185 Yes    \n#> # … with 17 more rows, and abbreviated variable names\n#> #   ¹​large_majority, ²​nfemales, ³​percfemale, ⁴​morewomen\n#> # ℹ Use `print(n = ...)` to see more rows\nbabynames |> filter(sex == \"M\" & year == 2017) |>\n  mutate(rankname = rank(desc(n))) |>\n  filter(rankname <= 10)\n#> # A tibble: 10 × 6\n#>     year sex   name         n    prop rankname\n#>    <dbl> <chr> <chr>    <int>   <dbl>    <dbl>\n#>  1  2017 M     Liam     18728 0.00954        1\n#>  2  2017 M     Noah     18326 0.00933        2\n#>  3  2017 M     William  14904 0.00759        3\n#>  4  2017 M     James    14232 0.00725        4\n#>  5  2017 M     Logan    13974 0.00712        5\n#>  6  2017 M     Benjamin 13733 0.00699        6\n#>  7  2017 M     Mason    13502 0.00688        7\n#>  8  2017 M     Elijah   13268 0.00676        8\n#>  9  2017 M     Oliver   13141 0.00669        9\n#> 10  2017 M     Jacob    13106 0.00668       10"},{"path":"dplyr.html","id":"summarise-and-group_by-s","chapter":" 4 Wrangling with dplyr","heading":"4.7.3 summarise() and group_by() S","text":"* Create data set column name column shows total number births name across years sexes.* group_by() can also used functions, including mutate(). Use group_by() mutate() rank names least popular year-sex combination.* data set 4, filter() data keep popular name year-sex combination construct summary table showing many times name appears popular name.* Run following code. Intuitively, slice(1, 2, 3, 4, 5) grab first five rows data set, , try run , get 1380 rows. Try figure issue using Google search something like “dplyr slicing correctly using group .” find?Functions like slice() rank() operate defined groups data set using function like group_by() first. Sometimes feature quite convenient. , longer want slice() rank() functions account groups, need add ungroup() pipe, simply drops groups formed:","code":"\nbabynames |> group_by(name) |>\n  summarise(totalbirths = sum(n))\n#> # A tibble: 97,310 × 2\n#>    name      totalbirths\n#>    <chr>           <int>\n#>  1 Aaban             107\n#>  2 Aabha              35\n#>  3 Aabid              10\n#>  4 Aabir               5\n#>  5 Aabriella          32\n#>  6 Aada                5\n#>  7 Aadam             254\n#>  8 Aadan             130\n#>  9 Aadarsh           199\n#> 10 Aaden            4658\n#> # … with 97,300 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\nranked_babynames <- babynames |> group_by(year, sex) |>\n  mutate(rankname = rank((desc(n))))\nranked_babynames |> filter(rankname == 1) |>\n  group_by(name) |>\n  summarise(nappear = n()) |>\n  arrange(desc(nappear))\n#> # A tibble: 18 × 2\n#>    name     nappear\n#>    <chr>      <int>\n#>  1 Mary          76\n#>  2 John          44\n#>  3 Michael       44\n#>  4 Robert        17\n#>  5 Jennifer      15\n#>  6 Jacob         14\n#>  7 James         13\n#>  8 Emily         12\n#>  9 Jessica        9\n#> 10 Lisa           8\n#> 11 Linda          6\n#> 12 Emma           5\n#> 13 Noah           4\n#> 14 Sophia         3\n#> 15 Ashley         2\n#> 16 Isabella       2\n#> 17 David          1\n#> 18 Liam           1\nbabynames_test <- babynames |>\n  group_by(year, sex) |> mutate(ntest = n / prop)\nbabynames_test |> slice(1, 2, 3, 4, 5)\n#> # A tibble: 1,380 × 6\n#> # Groups:   year, sex [276]\n#>     year sex   name          n   prop   ntest\n#>    <dbl> <chr> <chr>     <int>  <dbl>   <dbl>\n#>  1  1880 F     Mary       7065 0.0724  97605.\n#>  2  1880 F     Anna       2604 0.0267  97605.\n#>  3  1880 F     Emma       2003 0.0205  97605.\n#>  4  1880 F     Elizabeth  1939 0.0199  97605.\n#>  5  1880 F     Minnie     1746 0.0179  97605.\n#>  6  1880 M     John       9655 0.0815 118400.\n#>  7  1880 M     William    9532 0.0805 118400.\n#>  8  1880 M     James      5927 0.0501 118400.\n#>  9  1880 M     Charles    5348 0.0452 118400.\n#> 10  1880 M     George     5126 0.0433 118400.\n#> # … with 1,370 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\nbabynames_test |> ungroup() |> slice(1:5)\n#> # A tibble: 5 × 6\n#>    year sex   name          n   prop  ntest\n#>   <dbl> <chr> <chr>     <int>  <dbl>  <dbl>\n#> 1  1880 F     Mary       7065 0.0724 97605.\n#> 2  1880 F     Anna       2604 0.0267 97605.\n#> 3  1880 F     Emma       2003 0.0205 97605.\n#> 4  1880 F     Elizabeth  1939 0.0199 97605.\n#> 5  1880 F     Minnie     1746 0.0179 97605."},{"path":"dplyr.html","id":"missing-values-s","chapter":" 4 Wrangling with dplyr","heading":"4.7.4 Missing Values S","text":"* mutate(). Try create new variable mutate() involving x. R missing value?R puts another NA place x times y observation missing x.","code":"\ntoy_df |> mutate(xy = x * y)\n#> # A tibble: 4 × 5\n#>       x     y z     newvar    xy\n#>   <dbl> <dbl> <chr>  <dbl> <dbl>\n#> 1    NA     1 A      NA       NA\n#> 2     3     4 A       0.75    12\n#> 3     4     3 B       1.33    12\n#> 4     7     2 <NA>    3.5     14"},{"path":"dplyr.html","id":"piping-s","chapter":" 4 Wrangling with dplyr","heading":"4.7.5 Piping S","text":"* Recode following look cleaner using pipe |>:","code":"\nfitness_df <- read_csv(\"data/higham_fitness_clean.csv\")\n#> Rows: 993 Columns: 9\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (2): month, weekday\n#> dbl  (6): active_cals, distance, flights, steps, dayofye...\n#> date (1): Start\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nsummarise(group_by(filter(fitness_df, weekday == 1 | weekday == 7),\n                   month),\n          meanweekend = mean(distance, na.rm = TRUE)) \n#> # A tibble: 0 × 2\n#> # … with 2 variables: month <chr>, meanweekend <dbl>\n#> # ℹ Use `colnames()` to see all variable names\nfitness_df |> filter(weekday == 1 | weekday == 7) |>\n  group_by(month) |>\n  summarise(meanweekend = mean(distance, na.rm = TRUE)) \n#> # A tibble: 0 × 2\n#> # … with 2 variables: month <chr>, meanweekend <dbl>\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"dplyr.html","id":"chapexercise-3-S","chapter":" 4 Wrangling with dplyr","heading":"4.7.6 Chapter Exercises S","text":"* . Choose 5 names interest create new data set data 5 names.Use group_by() summarise() add together number Females Males name year. Hint: can group_by() one variable!Use group_by() summarise() add together number Females Males name year. Hint: can group_by() one variable!Make line plot showing popularity 5 names time.Make line plot showing popularity 5 names time.* cases throughout chapter, ’ve renamed data sets using <- name likeIn cases, ’ve given data set new name, likeFor functions generally “safe” name data set using name using function. ?mutate()Usually fine: mutating creates new variable, doesn’t change variables data set, things get messed new variable.arrange()Usually fine: ordering rows certain way won’t change plots doesn’t change underlying data.filter()Usually best practice. Naming data set name filter means permanently lose data filtered , unless re-read data set beginning.summarise()Usually best practice. , naming summarized data set original data means lose original data, unless re-read beginning. example,means now way access original data toy_df.select()can sometimes okay ’re sure variables removing won’t ever used.","code":"\nbaby5 <- babynames |> filter(name == \"Matthew\" | name == \"Ivan\" |\n                                name == \"Jessica\" | name == \"Robin\" |\n                                name == \"Michael\")\nbaby5_tot <- baby5 |> group_by(year, name) |>\n  summarise(ntot = sum(n))\n#> `summarise()` has grouped output by 'year'. You can\n#> override using the `.groups` argument.\nggplot(data = baby5_tot, aes(x = year, y = ntot, colour = name)) +\n  geom_line()\ntoy_df <- toy_df |> mutate(newvar = x / y)\ntoy_small <- toy_df |> filter(!is.na(x))\ntoy_df <- toy_df |> summarise(meanx = mean(x))\ntoy_df\n#> # A tibble: 1 × 1\n#>   meanx\n#>   <dbl>\n#> 1    NA"},{"path":"dplyr.html","id":"rcode-3","chapter":" 4 Wrangling with dplyr","heading":"4.8 Non-Exercise R Code","text":"","code":"\nlibrary(babynames)\nhead(babynames)\nlibrary(tidyverse)\nslumajors_df <- read_csv(\"data/SLU_Majors_15_19.csv\")\nslumajors_df\nslumajors_df |> mutate(ntotal = nfemales + nmales)\nslumajors_df |>\n  mutate(percfemale = 100 * nfemales / (nfemales + nmales))\nslumajors_df <- slumajors_df |>\n  mutate(percfemale = 100 * nfemales / (nfemales + nmales))\nslumajors_df <- slumajors_df |> mutate(ntotal = nfemales + nmales)\nslumajors_df <- slumajors_df |>\n  mutate(ntotal = nfemales + nmales) |>\n  mutate(percfemale = 100 * nfemales / (nfemales + nmales))\nslumajors_df |> mutate(morewomen = if_else(percfemale > 50,\n                                            true = \"Yes\",\n                                            false = \"No\"))\nslumajors_df |> mutate(large_majority =\n                          case_when(percfemale >= 70 ~ \"female\",\n                                    percfemale <= 30 ~ \"male\",\n                                    percfemale > 30 & percfemale < 70 ~ \"none\")) \nslumajors_df <- slumajors_df |>\n  mutate(morewomen = if_else(percfemale > 50,\n                             true = \"Yes\",\n                             false = \"No\")) |>\n  mutate(large_majority =\n           case_when(percfemale >= 70 ~ \"female\",\n                     percfemale <= 30 ~ \"male\",\n                     percfemale > 30 & percfemale < 70 ~ \"none\")) \nslumajors_df |> arrange(percfemale)\nslumajors_df |> arrange(desc(percfemale))\nslumajors_df |> select(Major, ntotal)\nslumajors_df |> select(-ntotal, -nfemales, -nmales)\nslumajors_df |> mutate(propfemale = percfemale / 100) |>\n  select(propfemale, everything())\nslumajors_df |> arrange(desc(ntotal)) |>\n  slice(1, 2, 3, 4, 5)\nlibrary(babynames)\nbabynames\nbabynames |> filter(name == \"Matthew\")\nbabynames |> filter(year >= 2000)\nbabynames |> filter(sex != \"M\")\nbabynames |> filter(prop > 0.05)\nbabynames |> filter(year == max(year))\nbabynames |> filter(n > 20000 | prop > 0.05)\nbabynames |> filter(sex == \"F\" & name == \"Mary\")\nbabynames |> filter(sex == \"F\" & name == \"Mary\" & prop > 0.05)\nslumajors_df |>\n  summarise(meantotalmajor = mean(ntotal),\n            totalgrad = sum(ntotal))\nbabynames |> group_by(year) |>\n  summarise(totalbirths = sum(n))\nbabynames |> summarise(totalobs = n())\nbabynames |> group_by(year) |>\n  summarise(ngroup = n())\ntoy_df <- tibble(x = c(NA, 3, 4, 7),\n                 y = c(1, 4, 3, 2),\n                 z = c(\"A\", \"A\", \"B\", NA))\ntoy_df\ntoy_df |> summarise(meanx = mean(x, na.rm = TRUE))\ntoy_df |> mutate(missingx = is.na(x))\ntoy_df |> filter(is.na(x) != TRUE)\ntoy_df |> filter(!is.na(x))\nvideogame_df |> filter(!is.na(metascore))\nfilter(videogame_df, !is.na(metascore))\nvideogame_df |> filter(!is.na(metascore)) |>\n  filter(median_playtime > 0) |>\n  group_by(price_cat) |>\n  summarise(avg_med_time = median(median_playtime, na.rm = TRUE))\nfilter(videogame_df, !is.na(metascore))\nfilter(filter(videogame_df, !is.na(metascore)), median_playtime > 0)\ngroup_by(filter(filter(videogame_df, !is.na(metascore)),\n                median_playtime > 0), price_cat)\nsummarise(group_by(filter(filter(videogame_df, !is.na(metascore)),\n  median_playtime > 0), price_cat), \n  avg_med_time = median(median_playtime, na.rm = TRUE))"},{"path":"communication-with-quarto.html","id":"communication-with-quarto","chapter":" 5 Communication with Quarto","heading":" 5 Communication with Quarto","text":"Special Note: Quarto .qmd files R Markdown .qmd files extremely similar. previous version section, used R Markdown. Quarto advantage .qmd files also work Python Julia, generally better -purpose data scientist. spot references R Markdown .qmd file, just mentally convert R Markdown Quarto .rmd qmd.Goals:Explain reproducibility means explain ’s important analyses reproducible.Explain reproducibility means explain ’s important analyses reproducible.Explain Quarto provides tools making analyses reproducible base R Microsoft Word Microsoft Excel.Explain Quarto provides tools making analyses reproducible base R Microsoft Word Microsoft Excel.Use Code Options Quarto Text Options modify Quarto file renders readable, professional .html file.Use Code Options Quarto Text Options modify Quarto file renders readable, professional .html file.Use titles, labels, colour scales, annotations, themes make plots easy read, including people Colour Vision Deficiency.Use titles, labels, colour scales, annotations, themes make plots easy read, including people Colour Vision Deficiency.Overall: ’re making quick plots just , things communication won’t apply. , ’re planning sharing results (usually , eventually), communication tools become much important.","code":""},{"path":"communication-with-quarto.html","id":"reproducibility","chapter":" 5 Communication with Quarto","heading":"5.1 Reproducibility","text":"’ve using Quarto now, yet talked features anything except insert new code chunk. end section, want able use Quarto options make nice-looking document (can implement options first mini-project).Reproducibility concept recently gained popularity sciences describing analyses another researcher able repeat. , analysis reproducible provide enough information person sitting next can obtain identical results long follow procedures. analysis reproducible isn’t case.\nQuarto makes easy make analysis reproducible couple reasons:Quarto file render unless code runs, meaning won’t accidentally give someone code doesn’t work.Quarto file render unless code runs, meaning won’t accidentally give someone code doesn’t work.Quarto combines “coding” steps “write-” steps one coherent document contains code, figures tables, explanations.Quarto combines “coding” steps “write-” steps one coherent document contains code, figures tables, explanations.","code":""},{"path":"communication-with-quarto.html","id":"r-scripts-vs.-quarto","chapter":" 5 Communication with Quarto","heading":"5.1.1 R Scripts vs. Quarto","text":"’ve using Quarto entirety course. , may noticed go File -> New File open new Quarto Document file, ton options. first option R Script. Go ahead open new R Script file now.file open completely blank. R Script file reads R code. text , unless text commented #. example, copy paste code inside code chunk .qmd file .R file run line line., advantages disadvantages using R Script file compared using Quarto file? Let’s start advantages Quarto. Quarto allows fully integrate text explanations code results, actual tables figures , code make tables figures one cohesive document. see, using R Scripts write-analysis Word, lot copy-pasting involved results. reason, using Quarto often results reproducible analyses.advantage R Script situation really aren’t presenting results anyone also don’t need text explanations. often occurs two situations. (1) lot data preparation steps. case, typically complete data prep steps R script write resulting clean data .csv ’d import Quarto file. (2) ’re complicated statistically. case, code much focus text creating figures ’d use R Script.“demo” reproducible analysis class.","code":""},{"path":"communication-with-quarto.html","id":"spell-checking","chapter":" 5 Communication with Quarto","heading":"5.1.2 Spell-Checking","text":"using Quarto communication, probably want utilize spell-check feature. Go Edit -> Check Spelling, ’ll presented spell-checker lets change spelling words may misspelled.","code":""},{"path":"communication-with-quarto.html","id":"exercise-5-1","chapter":" 5 Communication with Quarto","heading":"5.1.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 5.5.’s difference R Quarto?’s difference R Quarto?Quarto analysis reproducible base R script analysis?Quarto analysis reproducible base R script analysis?Quarto analysis easier make reproducible analysis Excel?Quarto analysis easier make reproducible analysis Excel?friend Chaz data analysis project Excel compare average GPA student athletes average GPA non-student athletes. two variables: whether student student athlete GPA. decides two-sample t-test appropriate procedure data (recall Intro Stat procedure appropriate comparing quantitative response (GPA) across two groups). steps analysis.friend Chaz data analysis project Excel compare average GPA student athletes average GPA non-student athletes. two variables: whether student student athlete GPA. decides two-sample t-test appropriate procedure data (recall Intro Stat procedure appropriate comparing quantitative response (GPA) across two groups). steps analysis.writes null alternative hypotheses words statistical notation.writes null alternative hypotheses words statistical notation.uses Excel make set side--side boxplots. changes labels limits y-axis using Point--Click Excel operations.uses Excel make set side--side boxplots. changes labels limits y-axis using Point--Click Excel operations.boxplots, see 3 outliers non-athlete group. three students GPAs 0 suspended repeatedly refusing wear masks indoors. Chaz decides 3 students removed analysis , stayed enrolled, GPAs different 0. deletes 3 rows Excel.boxplots, see 3 outliers non-athlete group. three students GPAs 0 suspended repeatedly refusing wear masks indoors. Chaz decides 3 students removed analysis , stayed enrolled, GPAs different 0. deletes 3 rows Excel.Chaz uses t.test function Excel run test. writes degrees freedom, T-stat, p-value.Chaz uses t.test function Excel run test. writes degrees freedom, T-stat, p-value.Chaz copies graph Word writes conclusion context problem.Chaz copies graph Word writes conclusion context problem.State 2 aspects Chaz’s analysis reproducible.","code":""},{"path":"communication-with-quarto.html","id":"quarto-files","chapter":" 5 Communication with Quarto","heading":"5.2 Quarto Files","text":"Let’s talk bit components Quarto file used make reproducible analysis shown class.First, open new Quarto file clicking File -> New File -> Quarto Document keep new file renders HTML now.first four five lines top file make YAML (Yet Another Markup Language) header. ’ll come back end, ’s frustrating part learn.Delete code YAML header paste following code chunks clean .qmd file:cars data set built R ’s need anything read (already exists R ).","code":"\nlibrary(tidyverse)\nhead(cars)\nggplot(data = cars, aes(x = speed, y = dist)) +\n  geom_point()\nsummary(cars)"},{"path":"communication-with-quarto.html","id":"code-chunk-options","chapter":" 5 Communication with Quarto","heading":"5.2.1 Code Chunk Options","text":"First, render new file (give name, prompted). see code, couple results tables, scatterplot.Chunk options allow control gets printed file render. example, may may want: code printed, figure printed, tables printed, tidyverse message printed, etc. ton chunk options give us control code output shown! going just focus commonly used.options common execute options Quarto.echo. set either true print code false print code. blank line ```{r}, insert following, tells Quarto print code chunk: #| echo: false. , re-render document make sure code making plot actually hidden .html output.can keep adding options new lines. options include:warning. set either true print warnings messages false print warnings messages. example, load tidyverse, message automatically prints . code chunk, add new line #| warning: false get rid message. Re-render make sure message actually gone.warning. set either true print warnings messages false print warnings messages. example, load tidyverse, message automatically prints . code chunk, add new line #| warning: false get rid message. Re-render make sure message actually gone.output. default, set true shows output tables figures. Change false print output running code. Practice adding #| output: false code chunk Quarto file summary(cars) re-render make sure output summary(cars) gone.output. default, set true shows output tables figures. Change false print output running code. Practice adding #| output: false code chunk Quarto file summary(cars) re-render make sure output summary(cars) gone.eval. eval set true code evaluated false .eval. eval set true code evaluated false .Besides execute options, also options pertaining size figures figure captions. common examples includefig-height fig-width control height width figures. default, 7, can change fig-height fig-width make figures take less space rendered .html document (fig-height: 5, example).fig-height fig-width control height width figures. default, 7, can change fig-height fig-width make figures take less space rendered .html document (fig-height: 5, example).fig-cap adds figure caption figure. Try inserting #| fig-cap: \"Figure 1: caption text blah blah blah\" chunk options chunk plot.fig-cap adds figure caption figure. Try inserting #| fig-cap: \"Figure 1: caption text blah blah blah\" chunk options chunk plot.","code":""},{"path":"communication-with-quarto.html","id":"global-options","chapter":" 5 Communication with Quarto","heading":"5.2.2 Global Options","text":"discussed far change code output options individual chunks code. , can pain add certain option every single chunk code want option apply . can instead change global option code /output options apply code chunks, unless specifically overwritten chunk.can change execute options (echo, warning, eval, output, ) globally adding line YAML header top Quarto file. Try addingas two new lines title format lines YAML header. tells Quarto echo code code chunk. However, note can change local code chunk #| echo: true override global setting chunk.Additional global execute options go new lines:non-execute options pertaining figure size can changed globally specifying option html part YAML header. following changes figure heights 2, unless chunk overrides global setting:Important Note: need pay particular attention spacing things YAML header. Notice, example, echo: false indented exactly two spaces. Try adding space deleting space, ’ll get error!","code":"execute: \n  echo: falseexecute: \n  echo: false\n  warning: false---\ntitle: \"Quarto Test\"\nexecute: \n  echo: false\nformat: \n  html:\n    fig-height: 2\n---"},{"path":"communication-with-quarto.html","id":"figures-and-tables","chapter":" 5 Communication with Quarto","heading":"5.2.3 Figures and Tables","text":"’ve already seen Figures pop automatically (unless set output: false), quite convenient. Making tables look nice requires one extra step.Delete output: false option added earlier chunk summary(cars). render .qmd file now, results tables head(cars) summary(cars) look kind ugly. focus using kable() function knitr package make tables much aesthetically pleasing. Another option use pander() function pander package. pander() kable() simple functions generate tables sufficient purposes. generate complicated tables, see xtable package.use functions, simply add |> pipe name table function want use. head(cars) |> kable() make nice-looking table kable head(cars) |> pander() use pander(). using kable() knitr package, ’ll need install knitr package install.packages(\"knitr\") load library adding line library(knitr) head(cars) |> kable(). using pander(), ’ll need install pander package install.packages(\"pander\") load library adding line library(pander) head(cars) |> pander(). Try Quarto file.table like better case?plenty options making tables look presentable, discuss Exercises. Keep mind probably wouldn’t use making tables . ’re much useful ’re writing report want share others.","code":""},{"path":"communication-with-quarto.html","id":"non-code-options","chapter":" 5 Communication with Quarto","heading":"5.2.4 Non-Code Options","text":"Quarto combines R (code chunks, ’ve already discussed) Markdown syntax, comprises stuff outside code chunks, like ’re reading right now!many Markdown options, time, want something specific, can just Google . purpose follows just get us familiar basics things probably use often.Bullet Points Sub-bullet Points: Denoted * -, respectively. sub bullets indented 4 spaces. Note bullet points code appear code chunk.Note: Everything Markdown particular spacing. Things often precise. personally just love , can frustrating sometimes. example, indenting sub-bullet 3 spaces instead 4 spaces make sub-bullet.Numbered Lists bulleted ones, except * replaced numbers 1., 2., etc.Bold, Italics, Code. Surround text __bold text__ make text bold, _italic text_ make text Italics, backticks make text look like Code.Links: simplest way create link something web surround < > <https://www.youtube.com/watch?v=gJf_DDAfDXs>want name link something web address, use [name link](https://www.youtube.com/watch?v=gJf_DDAfDXs), show rendered document “name link” , clicked , take youtube video.Headers: Headers created ## fewer hashtags resulting bigger Header. Typing #Big Header beginning line make big header, ### Medium Header make medium header, ##### Small Header make small header. Headers important get mapped table contents.’s lot stuff explore: <href=“https://rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf” target=“blank> https://rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf ., want something basics, Google definitely help.","code":"* Bullet 1\n* Bullet 2\n    - Sub bullet 1\n    - Sub bullet 2\n    - Sub bullet 3* Bullet 1\n   - Sub bullet 1"},{"path":"communication-with-quarto.html","id":"yaml","chapter":" 5 Communication with Quarto","heading":"5.2.5 YAML","text":"briefly discussed ’s given top every .qmd file: YAML header. YAML header frustrating part change ’s particular spacing.addition controlling global chunk options, can also use YAML header specify theme  Bootswatch.25 themes Bootswatch project. YAML header uses darkly theme. Try pasting YAML header rendering document see outputted theme.can also add table contents, create table contents based headers created ##.many options available theming, , know css, can provide .css file customize theme.","code":"---\ntitle: \"Quarto Test\"\nexecute: \n  echo: false\n  warning: false\nformat: \n  html:\n    fig-height: 2\n    theme: darkly\n    self-contained: true\n------\ntitle: \"Quarto Test\"\nexecute: \n  echo: false\n  warning: false\nformat: \n  html:\n    fig-height: 2\n    theme: darkly\n    toc: true\n    self-contained: true\n---"},{"path":"communication-with-quarto.html","id":"exercise-5-2","chapter":" 5 Communication with Quarto","heading":"5.2.6 Exercises","text":"Exercises marked * indicate exercise solution end chapter 7.5.rest section, use built-R data set mtcars, observations makes models cars. variables using :cyl, number cylinders car hasmpg, mileage car, miles per gallonBecause data set loaded every time R started , need line reads data set. can examine first observations * Create table showing mean mpg cyl group (cyl stands cylinder can 4-cylinder, 6-cylinder, 8-cylinder) kable() pander(). Hint: remember call knitr library pander library.* Create table showing mean mpg cyl group (cyl stands cylinder can 4-cylinder, 6-cylinder, 8-cylinder) kable() pander(). Hint: remember call knitr library pander library.* Type ?kable console window scroll Help file. Change rounding mean displays one number decimal. , add caption table says “First Table Caption!!”* Type ?kable console window scroll Help file. Change rounding mean displays one number decimal. , add caption table says “First Table Caption!!”* Google “Change Column Names kable” replace column names “Cylinder Numb.” “Mean Mileage”.* Google “Change Column Names kable” replace column names “Cylinder Numb.” “Mean Mileage”.Find table plan use first mini-project. Use column names, caption, digits options make table look nicer kable() function.Find table plan use first mini-project. Use column names, caption, digits options make table look nicer kable() function.Create new R chunk copy paste following new R chunk. Don’t worry factor() : cover next week!Create new R chunk copy paste following new R chunk. Don’t worry factor() : cover next week!Modify R chunk : () figure height 3, (b) code R chunk shows .html file, (c) table running head(cars) hidden .html file. Make (b) (c) local chunk option, set () global option applies R chunks.Change global options first project () hide messages loading tidyverse (b) show code.Change global options first project () hide messages loading tidyverse (b) show code.Use bullet points Introduction first mini-project explains important variables . , add header project marks Introduction.Use bullet points Introduction first mini-project explains important variables . , add header project marks Introduction.Change YAML header project Author (something like author: \"Name\" file uses theme Bootswatch default theme.Change YAML header project Author (something like author: \"Name\" file uses theme Bootswatch default theme.","code":"\nhead(mtcars)\n#>                    mpg cyl disp  hp drat    wt  qsec vs am\n#> Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1\n#> Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1\n#> Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1\n#> Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0\n#> Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0\n#> Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0\n#>                   gear carb\n#> Mazda RX4            4    4\n#> Mazda RX4 Wag        4    4\n#> Datsun 710           4    1\n#> Hornet 4 Drive       3    1\n#> Hornet Sportabout    3    2\n#> Valiant              3    1\nlibrary(tidyverse)\nhead(mtcars)\nggplot(data = mtcars, aes(x = factor(cyl), y = mpg)) +\n  geom_boxplot()"},{"path":"communication-with-quarto.html","id":"ggplot2-communication","chapter":" 5 Communication with Quarto","heading":"5.3 ggplot2 Communication","text":"first introduced plotting, used histograms, boxplots, frequency plots, bar plots, scatterplots, line plots, help us explore data set. probably make many different plots single analysis, , exploring, ’s fine keep plots unlabeled untitled default colour scheme theme. ’re just , typically understand data variable means.However, ’ve finished exploring ’d like communicate results, graphically numerically, ’ll likely want tweak plots look aesthetically pleasing. certainly wouldn’t presenting every exploratory plot made tweaking needs done plots. might consider:changing x-axis y-axis labels, changing legend title, adding title, adding subtitle, adding caption + labs()changing x-axis y-axis labels, changing legend title, adding title, adding subtitle, adding caption + labs()changing limits x-axis y-axis + xlim() + ylim()changing limits x-axis y-axis + xlim() + ylim()changing colour scheme visually appealing easy see people colour-vision-deficiency (CVD)changing colour scheme visually appealing easy see people colour-vision-deficiency (CVD)labeling certain points lines + geom_label() + geom_text()labeling certain points lines + geom_label() + geom_text()changing default theme + theme_<name_of_theme>()changing default theme + theme_<name_of_theme>()bullet labeling certain points data set one reason second ggplot2 section now, opposed immediately first ggplot2 section. see, ’ll make use combining ’ve learned dplyr help us label interesting observations plots.DataThe Happy Planet Index (HPI) measure efficiently country uses ecological resources give citizens long “happy” lives. can read data :  ., basic idea HPI metric computes happy healthy country’s citizens , adjusts country’s ecological footprint (much “damage” country planet Earth). data set obtained  https://github.com/aepoetry/happy_planet_index_2016. Variables data set :HPIRank, rank country’s Happy Planet Index (lower better)Country, name countryLifeExpectancy, average life expectancy citizen (years)Wellbeing, average well score (scale 1 - 10). See ladder question documentation calculated.HappyLifeYears, combination LifeExpectancy WellbeingFootprint, ecological footprint per person (higher footprint means average person country less ecologically friendly)Read data set withLet’s look relationship HappyLifeYears Footprint countries different Regions world.region seems variability Ecological Footprint?","code":"\nlibrary(tidyverse)\nhpi_df <- read_csv(\"data/hpi-tidy.csv\")\nhead(hpi_df)\n#> # A tibble: 6 × 11\n#>   HPIRank Country    LifeE…¹ Wellb…² Happy…³ Footp…⁴ Happy…⁵\n#>     <dbl> <chr>        <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n#> 1     109 Afghanist…    48.7    4.76    29.0   0.540    36.8\n#> 2      18 Albania       76.9    5.27    48.8   1.81     54.1\n#> 3      26 Algeria       73.1    5.24    46.2   1.65     52.2\n#> 4     127 Angola        51.1    4.21    28.2   0.891    33.2\n#> 5      17 Argentina     75.9    6.44    55.0   2.71     54.1\n#> 6      53 Armenia       74.2    4.37    41.9   1.73     46.0\n#> # … with 4 more variables: Population <dbl>,\n#> #   GDPcapita <dbl>, GovernanceRank <chr>, Region <chr>,\n#> #   and abbreviated variable names ¹​LifeExpectancy,\n#> #   ²​Wellbeing, ³​HappyLifeYears, ⁴​Footprint,\n#> #   ⁵​HappyPlanetIndex\n#> # ℹ Use `colnames()` to see all variable names\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point()"},{"path":"communication-with-quarto.html","id":"change-labels-and-titles","chapter":" 5 Communication with Quarto","heading":"5.3.1 Change Labels and Titles","text":"can add + labs() change various labels titles throughout plot:aes() use plot gets label can changed name_of_aethetic = \"Label\". example , changed three aes() labels: x, y, colour.text plot aren’t able change labs()?","code":"\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  labs(title = \"Countries with a Higher Ecological Footprint Tend to Have Citizens with Longer, Happier Lives\", \n       ## add title\n       subtitle = \"HappyLifeYears is a Combination of Life Expectancy and Citizen Well-Being\", \n       ## add subtitle (smaller text size than the title)\n       caption = \"Data Source: http://happyplanetindex.org/countries\", \n       ## add caption to the bottom of the figure\n       x = \"Ecological Footprint\", ## change x axis label\n       y = \"Happy Life Years\", ## change y axis label\n       colour = \"World Region\") ## change label of colour legend"},{"path":"communication-with-quarto.html","id":"changing-x-and-y-axis-limits","chapter":" 5 Communication with Quarto","heading":"5.3.2 Changing x and y axis Limits","text":"can also change x-axis limits y-axis limits , example, start 0 y-axis:case, makes points plot bit harder see. can also change often tick marks appear x y-axes. special things like , think ’s best just resort Google (“ggplot change x-axis breaks tick marks” help).","code":"\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  ylim(c(0, 70))"},{"path":"communication-with-quarto.html","id":"changing-a-colour-scale","chapter":" 5 Communication with Quarto","heading":"5.3.3 Changing A Colour Scale","text":"want use graphics communicate others clearly possible. also want inclusive possible communications. means , choose use colour, graphics made colour-vision-deficient (CVD) person can read graphs. 4.5% people colour vision deficient, ’s actually quite likely CVD person view graphics make (depending many people share ) Information CVD.colour scales R Colour Brewer readable common types CVD. list scales can found .typically use top scales variable colouring ordered sequentially (called seq sequential, like grades course: , B, C, D, F), bottom scales variable diverging (called div diverging, like Republican / Democrat lean middle colourless), middle set scales variable unordered categorical (called qual qualitative like names different treatment drugs medical experiment).3 situations World Region graph?want use one colour scales, just need add scale_colour_brewer() name scale want use.Try changing palette something else besides \"Accent\". like new palette better worse?One option easily change colour scale use viridis package. base viridis functions automatically load ggplot2 ’s need call package library(viridis). viridis colour scales made aesthetically pleasing CVD-friendly.drawback viridis package yellow can really hard see (least ).Read examples section Help file ?scale_colour_viridis_d. ’s difference scale_colour_viridis_d(), ?scale_colour_viridis_c(), scale_colour_viridis_b()?like better: Colour Brewer scale Viridis scale?","code":"\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Accent\")\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_viridis_d(option = \"plasma\")"},{"path":"communication-with-quarto.html","id":"labeling-points-or-lines-of-interest","chapter":" 5 Communication with Quarto","heading":"5.3.4 Labeling Points or Lines of Interest","text":"One goal might communication highlighting particular points data set show something interesting. example, might want label points graph corresponding countries highest HPI region: countries best terms using resources efficiently maximize citizen happiness. , might want highlight “bad” example countries least efficient region. , might want label country graph.can done geom_label(). Let’s start labeling points. geom_label() needs one aesthetic called label name column data set labels want use.Yikes! ’s quite uncommon want label points. Let’s see can instead label country best HPI country’s region. , first need use dplyr skills create new data set 7 “best” countries. used group_by(), typically used summarise() afterward. , group_by() works filter() well!code previous chunk ?Now new data set, can use within geom_label(). Recall data = argument ggplot() carries geoms unless specify otherwise. Now chance “specify otherwise” including another data = argument within geom_label():think colour legend changed showing letter “” region?code chunk change “”’s back points?common issue, even labels, labels overlap. ggrepel package solves problem including geom_label_repel() geom automatically repels overlapping labels:final issue plot ’s always clear point plot labeled. trick used R Data Science book surround points labeled open circle using extra geom_point() function:code , shape = 1 says new point open circle size = 3 makes point bigger, ensuring goes around original point. show.legend = FALSE ensures larger open circles don’t become part legend.can use strategy label specific countries. ’m interested United States America falls graph ’m U.S. ’m also interested Denmark falls ’s country ’m interested visiting. Feel free replace countries ’re interested !","code":"\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label(aes(label = Country))\nplot_df <- hpi_df |> group_by(Region) |>\n  filter(HPIRank == min(HPIRank))\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label(data = plot_df, aes(label = Country))\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point(aes(colour = Region)) +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label(data = plot_df, aes(label = Country), show.legend = FALSE)\nlibrary(ggrepel)\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label_repel(data = plot_df, aes(label = Country),\n                   show.legend = FALSE) \nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears, colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label_repel(data = plot_df, aes(label = Country), show.legend = FALSE) +\n  geom_point(data = plot_df, size = 3, shape = 1, show.legend = FALSE) \nplot_df_us <- hpi_df |>\n  filter(Country == \"United States of America\" | Country == \"Denmark\")\n\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_point(data = plot_df_us, size = 3, shape = 1,\n             show.legend = FALSE) +\n  geom_label_repel(data = plot_df_us, aes(label = Country),\n                   show.legend = FALSE)"},{"path":"communication-with-quarto.html","id":"plot-themes","chapter":" 5 Communication with Quarto","heading":"5.3.5 Plot Themes","text":"Plot themes easy way change many aspects plot overall theme someone developed. default theme ggplot2 graphs theme_grey(), graph grey background ’ve using entirety class. 7 themes given R Data Science Figure 28.3.However, many choices ggthemes package. Load package library(ggthemes) check https://yutannihilation.github.io/allYourFigureAreBelongToUs/ggthemes/ themes package. personal favorites, given , theme_solarized(), theme_fivethirtyeight(), theme_economist(), choosing theme mostly matter personal taste.’s still much can ggplot2. fact, entire books . , specializations, can usually use Google help !","code":"\nlibrary(ggthemes)\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_point(data = plot_df_us, size = 3, shape = 1, show.legend = FALSE) +\n  geom_label_repel(data = plot_df_us, aes(label = Country), show.legend = FALSE) +\n  theme_solarized()\n\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_point(data = plot_df_us, size = 3, shape = 1, show.legend = FALSE) +\n  geom_label_repel(data = plot_df_us, aes(label = Country), show.legend = FALSE) +\n  theme_fivethirtyeight()\n\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_point(data = plot_df_us, size = 3, shape = 1, show.legend = FALSE) +\n  geom_label_repel(data = plot_df_us, aes(label = Country), show.legend = FALSE) +\n  theme_economist()"},{"path":"communication-with-quarto.html","id":"exercise-5-3","chapter":" 5 Communication with Quarto","heading":"5.3.6 Exercises","text":"Exercises marked * indicate exercise solution end chapter 5.5.theme() function way really specialise plot. explore exercise .Using options theme() options change colours, shapes, sizes, etc., create ugliest possible ggplot2 graph can make. may change underlying data graph, goal investigate options given theme(). list theme options given link.practice communicating plots chapter exercises.","code":"\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point()"},{"path":"communication-with-quarto.html","id":"chapexercise-5","chapter":" 5 Communication with Quarto","heading":"5.4 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 5.5.data sets exist within specific R packages. example, Jenny Bryan, quite famous stats/data science community, put together gapminder package users R access specific data set countries throughout world. https://github.com/jennybc/gapminder.load data set within specific R package, first need install package install.packages(\"gapminder\") load package :, name data set something. case, name data set gapminder, ’s always name package . name data set country_df.Explore data set head(country_df) ?gapminder proceeding following exercises.* Make line graph shows relationship lifeExp year countries data set, faceting graph continent also colouring continent (though redundant). Add x-axis label, y-axis label, legend label, title graph.* Make line graph shows relationship lifeExp year countries data set, faceting graph continent also colouring continent (though redundant). Add x-axis label, y-axis label, legend label, title graph.* Change colour palette CVD-friendly using either scale_colour_brewer() scale_colour_viridis_d().* Change colour palette CVD-friendly using either scale_colour_brewer() scale_colour_viridis_d().* can see couple interesting trends life expectancy. one country Africa one country Asia sees sharp decline life expectancy one point. Europe, one country substantially lower life expectancy rest 1950s catches European countries 2000s. Use filter() create data set 3 countries. , use geom_label() label three countries plot.* can see couple interesting trends life expectancy. one country Africa one country Asia sees sharp decline life expectancy one point. Europe, one country substantially lower life expectancy rest 1950s catches European countries 2000s. Use filter() create data set 3 countries. , use geom_label() label three countries plot.Google history countries Africa Asia just labeled. Add short description country experienced dip life expectancy caption graph.Google history countries Africa Asia just labeled. Add short description country experienced dip life expectancy caption graph.Read help file ?annotate. different geom_label(). one allows finer tuning? one takes code use? One functions (annotate() geom_label()) becomes pain use many labels. one becomes harder use ?Read help file ?annotate. different geom_label(). one allows finer tuning? one takes code use? One functions (annotate() geom_label()) becomes pain use many labels. one becomes harder use ?Suppose want legend appear bottom graph. Without using entirely different theme, use Google figure move legend right-hand side bottom.Suppose want legend appear bottom graph. Without using entirely different theme, use Google figure move legend right-hand side bottom.lot overlapping points overlapping lines, can use alpha control transparency lines. Google “change transparency lines ggplot” change alpha lines transparent.lot overlapping points overlapping lines, can use alpha control transparency lines. Google “change transparency lines ggplot” change alpha lines transparent.Change theme plot theme ggthemes package. , change order two commands change legend position change overall theme. happens?Change theme plot theme ggthemes package. , change order two commands change legend position change overall theme. happens?Modify .qmd file :Modify .qmd file :figure made Exercise 8 prints .html file. (Hint: use global options help ).figure made Exercise 8 prints .html file. (Hint: use global options help ).none code gets printed.none code gets printed.warnings/messages R prints default hidden code chunks.warnings/messages R prints default hidden code chunks.figure height 5 instead default 7.figure height 5 instead default 7.Read following “can software tools make research reproducible?” https://ropensci.github.io/reproducibility-guide/sections/introduction/. discussed article related Quarto?","code":"\nlibrary(gapminder)\ncountry_df <- gapminder"},{"path":"communication-with-quarto.html","id":"solutions-5","chapter":" 5 Communication with Quarto","heading":"5.5 Exercise Solutions","text":"","code":""},{"path":"communication-with-quarto.html","id":"reproducibility-s","chapter":" 5 Communication with Quarto","heading":"5.5.1 Reproducibility S","text":"","code":""},{"path":"communication-with-quarto.html","id":"quarto-files-s","chapter":" 5 Communication with Quarto","heading":"5.5.2 Quarto Files S","text":"* Create table showing mean mpg cyl group (cyl stands cylinder can 4-cylinder, 6-cylinder, 8-cylinder) kable() pander(). Hint: remember call knitr library pander library.* Type ?kable console window scroll Help file. Change rounding mean displays one number decimal. , add caption table says “First Table Caption!!”Table 5.1: First Table Caption!!* Google “Change Column Names kable” replace column names “Cylinder Numb.” “Mean Mileage”.Table 5.2: First Table Caption!!","code":"\nlibrary(knitr)\nlibrary(pander)\nlibrary(tidyverse)\nmpg_df <- mtcars |> group_by(cyl) |>\n  summarise(meanmpg = mean(mpg))\nmpg_df |> kable()\nmpg_df |> pander()\nmpg_df |> kable(digits = 1, caption = \"My First Table Caption!!\")\nmpg_df |> kable(digits = 1, caption = \"My First Table Caption!!\",\n  col.names = c(\"Cylinder Numb.\", \"Mean Mileage\"))"},{"path":"communication-with-quarto.html","id":"ggplot2-communication-s","chapter":" 5 Communication with Quarto","heading":"5.5.3 ggplot2 Communication S","text":"","code":""},{"path":"communication-with-quarto.html","id":"chapexercise-5-S","chapter":" 5 Communication with Quarto","heading":"5.5.4 Chapter Exercises S","text":"* Make line graph shows relationship lifeExp year countries data set, faceting graph continent also colouring continent (though redundant). Add x-axis label, y-axis label, legend label, title graph.* Make line graph shows relationship lifeExp year countries data set, faceting graph continent also colouring continent (though redundant). Add x-axis label, y-axis label, legend label, title graph.* Change colour palette CVD-friendly using either scale_colour_brewer() scale_colour_viridis_d().* Change colour palette CVD-friendly using either scale_colour_brewer() scale_colour_viridis_d().* can see couple interesting trends life expectancy. one country Africa one country Asia sees sharp decline life expxectancy one point. Europe, one country substantially lower life expectancy rest 1950s catches European countries 2000s. Use filter() create data set 3 countries. , use geom_label() label three countries plot.* can see couple interesting trends life expectancy. one country Africa one country Asia sees sharp decline life expxectancy one point. Europe, one country substantially lower life expectancy rest 1950s catches European countries 2000s. Use filter() create data set 3 countries. , use geom_label() label three countries plot.","code":"\ninterest_countries <- country_df |> filter((year == 1952 & continent == \"Europe\" &\n    lifeExp < 50) | (year == 1992 & continent == \"Africa\" &\n    lifeExp < 30) | (year == 1977 & continent == \"Asia\" & \n    lifeExp < 35))\nggplot(data = country_df, aes(x = year, y = lifeExp, group = country,\n  colour = continent)) +\n  geom_line() +\n  facet_wrap( ~ continent) +\n  scale_colour_brewer(palette = \"Set2\") +\n  labs(x = \"Year\", y = \"Life Expectancy (Years)\", colour = \"Continent\",\n    title = \"Life Expectancy Increases Across time for nearly every country\") +\n  geom_label(data = interest_countries, aes(label = country),\n    nudge_x = 7)"},{"path":"communication-with-quarto.html","id":"rcode-5","chapter":" 5 Communication with Quarto","heading":"5.6 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\nhpi_df <- read_csv(\"data/hpi-tidy.csv\")\nhead(hpi_df)\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point()\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  labs(title = \"Countries with a Higher Ecological Footprint Tend to Have Citizens with Longer, Happier Lives\", \n       ## add title\n       subtitle = \"HappyLifeYears is a Combination of Life Expectancy and Citizen Well-Being\", \n       ## add subtitle (smaller text size than the title)\n       caption = \"Data Source: http://happyplanetindex.org/countries\", \n       ## add caption to the bottom of the figure\n       x = \"Ecological Footprint\", ## change x axis label\n       y = \"Happy Life Years\", ## change y axis label\n       colour = \"World Region\") ## change label of colour legend\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  ylim(c(0, 70))\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Accent\")\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_viridis_d(option = \"plasma\")\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label(aes(label = Country))\nplot_df <- hpi_df |> group_by(Region) |>\n  filter(HPIRank == min(HPIRank))\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label(data = plot_df, aes(label = Country))\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point(aes(colour = Region)) +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label(data = plot_df, aes(label = Country), show.legend = FALSE)\nlibrary(ggrepel)\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label_repel(data = plot_df, aes(label = Country),\n                   show.legend = FALSE) \nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears, colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_label_repel(data = plot_df, aes(label = Country), show.legend = FALSE) +\n  geom_point(data = plot_df, size = 3, shape = 1, show.legend = FALSE) \nplot_df_us <- hpi_df |>\n  filter(Country == \"United States of America\" | Country == \"Denmark\")\n\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_point(data = plot_df_us, size = 3, shape = 1,\n             show.legend = FALSE) +\n  geom_label_repel(data = plot_df_us, aes(label = Country),\n                   show.legend = FALSE)\nlibrary(ggthemes)\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_point(data = plot_df_us, size = 3, shape = 1, show.legend = FALSE) +\n  geom_label_repel(data = plot_df_us, aes(label = Country), show.legend = FALSE) +\n  theme_solarized()\n\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_point(data = plot_df_us, size = 3, shape = 1, show.legend = FALSE) +\n  geom_label_repel(data = plot_df_us, aes(label = Country), show.legend = FALSE) +\n  theme_fivethirtyeight()\n\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") +\n  geom_point(data = plot_df_us, size = 3, shape = 1, show.legend = FALSE) +\n  geom_label_repel(data = plot_df_us, aes(label = Country), show.legend = FALSE) +\n  theme_economist()\nggplot(data = hpi_df, aes(x = Footprint, y = HappyLifeYears,\n                          colour = Region)) +\n  geom_point()"},{"path":"workflow.html","id":"workflow","chapter":" 6 Workflow and Other Skills","heading":" 6 Workflow and Other Skills","text":"Goals:Describe files organized R project, describe advantage common working directory R Project, use package assist accessing reading files.Describe files organized R project, describe advantage common working directory R Project, use package assist accessing reading files.Use strategies debug code working correctly.Use strategies debug code working correctly.Explain context data set comes informs analysis data.Explain context data set comes informs analysis data.Find missing values outliers, explain might affect conclusions data analysis.Find missing values outliers, explain might affect conclusions data analysis.Use tibble create data sets R, describe benefits reprexes.Use tibble create data sets R, describe benefits reprexes.","code":""},{"path":"workflow.html","id":"r-projects-and-file-organization","chapter":" 6 Workflow and Other Skills","heading":"6.1 R Projects and File Organization","text":"R Projects convenient way keep related code, data sets, analyses together. Read short introduction R Data Science : https://r4ds..co.nz/workflow-projects.html#paths--directories https://r4ds..co.nz/workflow-projects.html#rstudio-projects.rarely use absolute directory?Look top bottom-left terminal window. ’ve made R project (!), see file path current folder ’re working . R Studio look files default.package can help keep track files reading files. Install package install.packages(\"\"). , load package run () function withhere() prints directory current R project . reading data set read_csv(), useR can read data set successfully: starts path given console printed (), looks folder called data path looks file called athletesdata.csv data folder., zipped project sent someone else, ’d able open read data file without needing change directory code!() function package can used just printing current working directory. see usefulness, suppose , folder current R project, want make folder called Quizzes .qmd files quizzes class. Make folder, create new .qmd file, paste R chunk reads athletesdata.csv data set, save file, try render file.get error athletesdata.csv data file found. rendering .qmd file, R looks data/ folder within folder contains .qmd file. Since data/ folder folder R Project, folder .qmd file, R can’t find .fix issue, specify entire file path data/ file. , better fix use () function, tells R start looking folders files folder R Project:allows us Quarto files within folders R project.","code":"\nlibrary(here)\n#> here() starts at /Users/highamm/Desktop/datascience234\nhere()\nlibrary(tidyverse)\n#> ── Attaching packages ─────────────────── tidyverse 1.3.2 ──\n#> ✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n#> ✔ tibble  3.1.8     ✔ dplyr   1.0.9\n#> ✔ tidyr   1.2.0     ✔ stringr 1.4.0\n#> ✔ readr   2.1.2     ✔ forcats 0.5.1\n#> ── Conflicts ────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\nathletes_df <- read_csv(\"data/athletesdata.csv\")\n#> New names:\n#> Rows: 100 Columns: 9\n#> ── Column specification\n#> ──────────────────────────────────── Delimiter: \",\" chr\n#> (3): Name, Sport, Gender dbl (6): ...1, Rank, endorsements,\n#> totalpay, salary, age\n#> ℹ Use `spec()` to retrieve the full column specification\n#> for this data. ℹ Specify the column types or set\n#> `show_col_types = FALSE` to quiet this message.\n#> • `` -> `...1`\nathletes_test_read <- read_csv(here(\"data/athletesdata.csv\"))\n#> New names:\n#> Rows: 100 Columns: 9\n#> ── Column specification\n#> ──────────────────────────────────── Delimiter: \",\" chr\n#> (3): Name, Sport, Gender dbl (6): ...1, Rank, endorsements,\n#> totalpay, salary, age\n#> ℹ Use `spec()` to retrieve the full column specification\n#> for this data. ℹ Specify the column types or set\n#> `show_col_types = FALSE` to quiet this message.\n#> • `` -> `...1`"},{"path":"workflow.html","id":"exercise-14-1","chapter":" 6 Workflow and Other Skills","heading":"6.1.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 6.7.Take time modify files course creating folders help keep things bit organized. might consider making Quizzes folder Projects folder, example. Move relevant files folders modify file load package use () function read relevant data sets. ’ve using () function quite bit already may already !Take time modify files course creating folders help keep things bit organized. might consider making Quizzes folder Projects folder, example. Move relevant files folders modify file load package use () function read relevant data sets. ’ve using () function quite bit already may already !Click “Packages” button lower-right hand window bring packages menu. Instead using library(name_of_package), can click check-box package name load R. Try un-checking re-checking tidyverse. Explain, reproducibility perspective, loading packages way good practice.Click “Packages” button lower-right hand window bring packages menu. Instead using library(name_of_package), can click check-box package name load R. Try un-checking re-checking tidyverse. Explain, reproducibility perspective, loading packages way good practice.","code":""},{"path":"workflow.html","id":"code-style","chapter":" 6 Workflow and Other Skills","heading":"6.2 Code Style","text":"Writing code “readable” helpful others also , especially project working long-term. constitutes “readable” code varies bit, general principles widely accepted “good” code. Much coding “style” seen far imposed : style writing code naturally, use style code write course materials.","code":""},{"path":"workflow.html","id":"names","chapter":" 6 Workflow and Other Skills","heading":"6.2.1 Names","text":"Names objects create descriptive yet short. Sometimes, thinking name makes sense can challenging! examples “bad” names objects include names generic won’t able distinguish later:Better names data frames cyl4_df, cyl6_df, cyl8_df, respectively, names tell us data frame.“bad” names objects names long:Long names descriptive can pain type read.may noticed coding “style” separate words names _: cyl4_df. Others may choose separate words names .: cyl4.df others may use capitalization second word: cyl4Df. important thing consistent choice. words, using _ instead . isn’t necessarily better, poor practice mix naming notation.mixed, always keep track whether object named _ . capitalization.Finally, may noticed data frames named suffix _df. worked coding style like keeping track dataframe (tibble) isn’t. generally helpful encounter different types objects (model output, lists, matrices, vectors, etc.).","code":"\ndf1 <- mtcars |> filter(cyl == 4)\ndf2 <- mtcars |> filter(cyl == 6)\ndf3 <- mtcars |> filter(cyl == 8)\ncars_with_4_cylinders_data_set <- mtcars |> filter(cyl == 4)\ncyl4_df <- mtcars |> filter(cyl == 4)\ncyl6.df <- mtcars |> filter(cyl == 6)"},{"path":"workflow.html","id":"code-readability","chapter":" 6 Workflow and Other Skills","heading":"6.2.2 Code Readability","text":"can also follow general practices make code “readable.” already employing practices throughout semester: R Studio generally makes code readable indenting appropriately.Appropriately using spacing can make code much readable. Consider following ggplot() code. example, following code chunk executes scatterplot fitted regression line ’s generally tough read.couple conventions can help: (1) spaces around equal sign, plus sign, comma (2) putting code plus sign different line.Indenting subsequent lines ggplot2 code dplyr pipeline shows subsequent lines “go ” first line:concepts using multiple lines holds piping statement well. general,easier read ","code":"\nggplot(data=mtcars,aes(x=wt,y=drat))+geom_point()+geom_smooth(method=\"lm\",se=FALSE)\n#> `geom_smooth()` using formula 'y ~ x'\nggplot(data = mtcars, aes(x = wt, y = drat)) +\ngeom_point() +\ngeom_smooth(method = \"lm\", se = FALSE)\n#> `geom_smooth()` using formula 'y ~ x'\nggplot(data = mtcars, aes(x = wt, y = drat)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n#> `geom_smooth()` using formula 'y ~ x'\nmtcars |> filter(cyl == 4) |>\n  group_by(vs) |>\n  summarise(mean_mpg = mean(mpg, na.rm = TRUE))\n#> # A tibble: 2 × 2\n#>      vs mean_mpg\n#>   <dbl>    <dbl>\n#> 1     0     26  \n#> 2     1     26.7\nmtcars |> filter(cyl == 4) |> group_by(vs) |> summarise(mean_mpg = mean(mpg, na.rm = TRUE))\n#> # A tibble: 2 × 2\n#>      vs mean_mpg\n#>   <dbl>    <dbl>\n#> 1     0     26  \n#> 2     1     26.7"},{"path":"workflow.html","id":"exercise-14-2","chapter":" 6 Workflow and Other Skills","heading":"6.2.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 6.7.Change following object names “better:”Change style following code make code readable.","code":"\ncars_where_wt_is_larger_than_3_tons <- mtcars |> filter(wt > 3)\ndataset <- mtcars |> group_by(am) |>\n  summarise(mean_disp = mean(disp),\n            med_disp = median(disp),\n            sd_disp = sd(disp))\nggplot(data=mtcars,aes(x = mpg))+geom_histogram(colour=\"black\",fill=\"white\",bins=15) + facet_wrap(~cyl, ncol=1)"},{"path":"workflow.html","id":"debugging-code","chapter":" 6 Workflow and Other Skills","heading":"6.3 Debugging Code","text":"previous section code readability can seen one step helping code debugging: code easier read code easier spot errors . Additionally, strategies can take code working figure issue .","code":""},{"path":"workflow.html","id":"identify-the-problem","chapter":" 6 Workflow and Other Skills","heading":"6.3.1 Identify the Problem","text":"run R code data analyses “top bottom,” makes bit easier identify problem code occurring. can run code top .qmd file, line line, see red Error message.Often Error message occur ggplot statement piping statement. case, strategy run ggplot statement + sign + sign run piping statement pipe pipe isolate error. example, take following ggplot code, generates somewhat cryptic error.case, error message help us locate issue, always case. sure error , can runto see get error. don’t, move code next + sign:still don’t get error move code next + sign:error. now, instead isolating error particular chunk code, isolated error particular line code: know issue something using geom_smooth(). (missing aes() refer variable disp).strategy can used piping. following code, used figure average bill length bill depth ratio Adelie penguins, give error instead outputs something might expect: tibble NaN (Number) value (note must install palmerpenguins package install.packages(\"palmerpenguins\") loading palmerpenguins library.can troubleshoot running code “pipe pipe,” starting code first filter() pipe:Right away, see problem: get tibble data misspelled Adelie:correcting issue, can continue pipes:doesn’t seem issues mutate() statement can go next pipe.get NA value, isolated issue something summarise(), , possibly something mutate() set something quite right summarise(). Can figure issue?addition isolating coding issue, couple basic strategies trying fix problematic code use search engine like google see anyone else similar error message one may restart R make sure working clean slate.“restart R” strategy can particularly helpful code run .qmd file render. can happen , example, created data set use later chunk code since deleted code created data set. example, suppose create cyl4_df make plot:, later delete line creating cyl4_df. plot still work cyl4_df already environment file render missing crucial line code. Restarting R can help us identify issue plot longer work get sensible error message like cyl4_df found.","code":"\nggplot(data = mtcars, aes(x = wt, y = mpg)) +\n  geom_point() +\n  geom_smooth(colour = disp) +\n  facet_wrap(~ cyl) \nggplot(data = mtcars, aes(x = wt, y = mpg))\nggplot(data = mtcars, aes(x = wt, y = mpg)) +\n  geom_point()\nggplot(data = mtcars, aes(x = wt, y = mpg)) +\n  geom_point() +\n  geom_smooth(colour = disp)\nlibrary(palmerpenguins)\npenguins |> filter(species == \"Adeie\") |>\n  mutate(bill_ratio = bill_length_mm / bill_depth_mm) |>\n  summarise(mean_ratio = mean(bill_ratio))\npenguins |> filter(species == \"Adeie\")\npenguins |> filter(species == \"Adelie\")\npenguins |> filter(species == \"Adelie\") |>\n  mutate(bill_ratio = bill_length_mm / bill_depth_mm)\npenguins |> filter(species == \"Adelie\") |>\n  mutate(bill_ratio = bill_length_mm / bill_depth_mm) |>\n  summarise(mean_ratio = mean(bill_ratio))\ncyl4_df <- mtcars |> filter(cyl == 4)\n\nggplot(data = cyl4_df, aes(x = mpg)) +\n  geom_histogram()\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`."},{"path":"workflow.html","id":"exercise-14-3","chapter":" 6 Workflow and Other Skills","heading":"6.3.2 Exercises","text":"Exercises marked * indicate exercise solution end chapter 6.7.Find error following code chunk running code “+ sign + sign).Find error following code chunk running code “pipe pipe.”Find error following code chunk running code “pipe pipe.”","code":"\nggplot(data = mtcars, aes(x = hp, y = drat)) +\n  geom_point(aes(colour = factor(gear))) +\n  facet_wrap(cyl) +\n  geom_smooth()\npenguins |> mutate(flipper_ratio = flipper_length_mm / body_mass_g) |>\n  group_by(species, island) |>\n  summarise(mean_flipper = mean(flipper_ratio, na.rm = TRUE)) |>\n  arrange(flipper_ratio) |>\n  pivot_wider(names_from = c(\"species\"), values_from = \"mean_flipper\")\npenguins |> mutate(flipper_ratio = flipper_length_mm / body_mass_g) |>\n  filter(flipper_ratio > median(flipper_ratio)) |>\n  group_by(species) |>\n  summarise(count_var = n())"},{"path":"workflow.html","id":"context-outliers-and-missing-values","chapter":" 6 Workflow and Other Skills","heading":"6.4 Context, Outliers, and Missing Values","text":"primary purpose section explore always think critically data set analyzing opposed simply making summary tables without thinking interpreted. words, need examine data set see things like missing values outliers affect interpretation well consider context data set comes .","code":""},{"path":"workflow.html","id":"context","chapter":" 6 Workflow and Other Skills","heading":"6.4.1 Context","text":"Considering context includes thinking questions like:data set come ? collected ?data set come ? collected ?missing values coded NAs data set. affect analysis missing “random.” Missing values coded NA referred explicitly missing values.missing values coded NAs data set. affect analysis missing “random.” Missing values coded NA referred explicitly missing values.missing values data set actually observations ? implicitly missing. example might collecting data students attending class. Students present time data collected implicitly missing.missing values data set actually observations ? implicitly missing. example might collecting data students attending class. Students present time data collected implicitly missing.data come observational study experiment?data come observational study experiment?many questions ask pertaining context, many questions depend particular data collected. example, consider data set majors SLU 2015 2020. now, can ignore extra code given read data: pivoting functions variable types topics learn upcoming weeks.data, n_majors variable represents number students graduating particular major particular year. example, year 2005, just 2 students graduating Biochemistry major.Suppose interested trends among majors Estudios Hispanicos (Spanish). United States, many people speak Spanish might expect somewhat popular major. particular, want see increase decrease number majors since 2005. can make line chart :conclude based plot?topic subsection context data set arises . , might guess conclusion one make based line graph (spanish major SLU seems decline) tell full story. fact, decade ago, International Economics Combined major introduced, students complete courses Economics well foreign language studies. popular choice foreign language Spanish.can make graph number International Economics Combined majors:new contextual information International Economics major influence conclusions popularity Spanish studies SLU?find throughout semester data sets topics familiar easier analyze data sets topics familiar . large part reasoning much contextual information data topics prior knowledge . extra contextual information generally allows us pose deeper questions, identify potentially erroneous data, write subtle conclusions. discuss context throughout semester also another focus context discuss data ethics.","code":"\nmajors_df <- read_csv(here(\"data/majors.csv\")) |>\n  pivot_longer(-1, names_to = \"year\", values_to = \"n_majors\") |>\n  mutate(year = as.numeric(year)) |>\n  rename(major = `...1`)\n#> New names:\n#> Rows: 63 Columns: 17\n#> ── Column specification\n#> ──────────────────────────────────── Delimiter: \",\" chr\n#> (1): ...1 dbl (16): 2005, 2006, 2007, 2008, 2009, 2010,\n#> 2011, 2012...\n#> ℹ Use `spec()` to retrieve the full column specification\n#> for this data. ℹ Specify the column types or set\n#> `show_col_types = FALSE` to quiet this message.\n#> • `` -> `...1`\nhead(majors_df)\n#> # A tibble: 6 × 3\n#>   major         year n_majors\n#>   <chr>        <dbl>    <dbl>\n#> 1 Biochemistry  2005        2\n#> 2 Biochemistry  2006        6\n#> 3 Biochemistry  2007        5\n#> 4 Biochemistry  2008        8\n#> 5 Biochemistry  2009        3\n#> 6 Biochemistry  2010        7\nspanish_df <- majors_df |> filter(major == \"Estudios Hispanicos (Spanish)\")\nggplot(data = spanish_df, aes(x = year, y = n_majors)) +\n  geom_line() +\n  geom_smooth(se = FALSE)\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'\nint_econ_df <- majors_df |> filter(major == \"Int'l Economics (Combined)\")\nggplot(data = int_econ_df, aes(x = year, y = n_majors)) +\n  geom_line() +\n  geom_smooth(se = FALSE)\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'"},{"path":"workflow.html","id":"outliers-and-missing-values","chapter":" 6 Workflow and Other Skills","heading":"6.4.2 Outliers and Missing Values","text":"Outliers data analysis can affect certain summary statistics, like mean standard deviation (learned STAT 113). also observations warrant investigation interested particular point outlier.Missing values can also cause us reach potentially misleading conclusion carefully consider values missing.talk consequences outliers missing values next, first, discuss determine outliers missing values data set. easy function use purpose skim() function skimr package. Install skimr package use skim() function thevideogame_clean.csv file, contains variables video games 2004 - 2019, includinggame, name gamerelease_date, release date gamerelease_date2, second coding release dateprice, price dollars,owners, number owners (given range)median_playtime, median playtime gamemetascore, score website Metacriticprice_cat, 1 Low (less 10.00 dollars), 2 Moderate (10 29.99 dollars), 3 High (30.00 dollars)meta_cat, Metacritic’s review system, following categories: “Overwhelming Dislike”, “Generally Unfavorable”, “Mixed Reviews”, “Generally Favorable”, “Universal Acclaim”.playtime_miss, whether median play time missing (TRUE) (FALSE)data set modified https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-07-30.See can find output following:number rows data set number columnsthe number missing values variablethe number unique values character variablethe completion rate (proportion values non-missing).particular, number missing values given nmissing complete_rate gives proportion values non-missing. give us idea missing values exist certain variables, , , many exist variable.Also, bottom output, see tiny histograms numeric variable summary statistics. Looking min, max, histograms variable can inform us whether variable outliers. example, see histograms price, median_playtime, average_playtime look extremely skewed right outlier(s) upper end., now know outliers missing values certain variables videogame data set. might affect tables graphs make?First, let’s focus metascore variable, gives Metacritic’s overall aggregated review score videogames. Note complete_rate metascore variable 0.107: almost 90% videogames metascore., suppose interested exploring “typical” metascore . can figure average metascore median metascore non-missing videogames :Ignoring missing values, say , average, videogames receive metascores around 72 points. question need ask : “reasonable assume missing games receive similar reviews non-missing games can thin 71.9 average review score games?”answer might depend understand videogames review process. argue missing games reviewed worse non-missing games. Major games usually get reviews also usually funding many minor games little funding, get reviewed, , get reviewed, may get lower rating.can certainly make different argument: don’t know argument correct without data. important thing least think make clear possible limitations conclusions data analysis.second example, consider exploration relationship median_playtime game metascore. can make scatterplot relationship, ignoring missing values, withWe see clear outliers, talk next, missing values metascore affect conclusions draw graph? answer “yes” think videogames missing metascores follow different overall trend non-missing metascores “” think , videogames missing metascores rated, follow similar trend already graph.question, make argument games follow similar trend. , assumption need make need explicit .also mentioned idea implicit missing values. videogames appear data set . words, set videogames sample videogames ever published United States? sample, selected, , convenience sample, types games left ?Outliers can also pose interesting challenges data analysis. example, consider graph median_playtime vs. metascore. focus outliers now, ignore missing values metascore.see clear outliers median_playtime: games median playtime thousands hours. , knowledge videogames can help us determine outliers.important thing dealing outliers explicit , analyst, choose keep graph summary table choose remove. choose remove values, give reasoning, , space, can also give second graph data without removing outliers.example, median playtime 3000+ hours seems bit excessive, ’s challenging determine reasonable cutoff “excessive” . reasonable game median playtime 1000 hours? aobut 2000 hours? 500 hours? Choosing points keep affect fit smoother. may learned STAT 113 STAT 213, observations high control fit smoother regression line influential.","code":"\nlibrary(skimr)\nlibrary(here)\nvideogame_df <- read_csv(here(\"data/videogame_clean.csv\"))\n#> Rows: 26688 Columns: 15\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (7): game, release_date, owners, meta_cat, develope...\n#> dbl  (6): price, median_playtime, metascore, price_cat, ...\n#> lgl  (1): playtime_miss\n#> date (1): release_date2\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n## skim(videogame_df)\nvideogame_df |> summarise(mean_meta = mean(metascore, na.rm = TRUE),\n                          med_meta = median(metascore, na.rm = TRUE))\n#> # A tibble: 1 × 2\n#>   mean_meta med_meta\n#>       <dbl>    <dbl>\n#> 1      71.9       73\nggplot(data = videogame_df, aes(x = metascore, y = median_playtime)) +\n  geom_point() +\n  geom_smooth()\n#> `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\nggplot(data = videogame_df, aes(x = metascore, y = median_playtime)) +\n  geom_point() +\n  geom_smooth()\n#> `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'"},{"path":"workflow.html","id":"exercise-14-4","chapter":" 6 Workflow and Other Skills","heading":"6.4.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 6.7.STAT 113 survey data set contains responses 397 STAT 113 students survey students take beginning semester. 5 categorical variables 7 numeric variables. categorical variables, many variables 0 missing values? numeric variables, many variables 0 missing values?Choose variable missing values feel comfortable ignoring missing values table graph. Give one two sentence reason.Choose variable missing values feel comfortable ignoring missing values table graph. Give one two sentence reason.Choose variable missing values feel comfortable ignoring missing values table graph. Give one two sentence reason.Choose variable missing values feel comfortable ignoring missing values table graph. Give one two sentence reason.Find mean median median_playtime videogames metacritic videogame data set. , remove games median_playtime 1000 hours. Compute mean median median_playtime data set without games. measure, mean median affected outliers present?Find mean median median_playtime videogames metacritic videogame data set. , remove games median_playtime 1000 hours. Compute mean median median_playtime data set without games. measure, mean median affected outliers present?","code":"\nlibrary(tidyverse)\nstat113_df <- read_csv(here(\"data/stat113.csv\"))\n#> Rows: 397 Columns: 12\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> chr (5): Year, Sex, Sport, Award, SocialMedia\n#> dbl (7): Hgt, Wgt, Haircut, GPA, Exercise, TV, Pulse\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."},{"path":"workflow.html","id":"reprexes-and-tibble","chapter":" 6 Workflow and Other Skills","heading":"6.5 Reprexes and tibble","text":"reproducible example, reprex, chunk code can give someone else runs without outside data. used often StackExchange. can create data set directly within R tibble() function tibble package. useful want make small reproducible example someone else may help code.following code chunk reprex people necessarily data set parsedf.csv.Suppose want post StackExchange someone ask friend help us convert variable character vector units numeric vector without units. want able give possible helpers small example data set work isolate problem question . , can create tiny data set tibble():library(tidyverse) necessary code chunk reprex?can copy paste code chunk question: ’s code anyone can run long tidyverse package installed, really encourages people help.second example, might question find mean many numeric variables. example, stat113.csv file, many numeric variables. can compute mean numeric variable writing separate summarise() statement variable. also may interested quicker way. , since helper might stat113.csv file, can create reprex problem:Note included categorical variables reprex data set. want code work even categorical variables data set, must include reprex example general possible.reference, across() function can used answer question (though ’s point section). code reads summarise() across() variables numeric (.numeric) summary measure mean.","code":"\n## Hello! How do I get rid of the units from the values in\n## my variable `x`? Thanks!\nlibrary(tidyverse)\ntest_df <- read_csv(here(\"data/parsedf.csv\"))\nhead(test_df)\n#> # A tibble: 3 × 2\n#>   x                   y\n#>   <chr>           <dbl>\n#> 1 20,000 dollars      1\n#> 2 40 dollars          2\n#> 3 only 13 dollars     3\n## Hello! How do I get rid of the units from the values in\n## my variable `xvar`? Thanks!\nlibrary(tidyverse)\ntest_df2 <- tibble(xvar = c(\"20,000 dollars\", \"40 dollars\"),\n                   yvar = c(1, 2))\ntest_df2\n#> # A tibble: 2 × 2\n#>   xvar            yvar\n#>   <chr>          <dbl>\n#> 1 20,000 dollars     1\n#> 2 40 dollars         2\n## is there a way to get a summary measure, like the mean, for \n## all numeric variables in a data set without writing a separate\n## summarise() statement for each variable?\n\nlibrary(tidyverse)\nsum_df <- tibble(xvar = c(\"A\", \"B\"), yvar = c(1, 4), zvar = c(-1, 4),\n                 svar = c(\"G\", \"g\"), tvar = c(99, 100000))\nsum_df |> summarise(across(where(is.numeric), mean))\n#> # A tibble: 1 × 3\n#>    yvar  zvar   tvar\n#>   <dbl> <dbl>  <dbl>\n#> 1   2.5   1.5 50050."},{"path":"workflow.html","id":"exercise-14-5","chapter":" 6 Workflow and Other Skills","heading":"6.5.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 6.7.Project 2, work course evaluation data professor SLU. Overall, ’ll answer questions professor can improve courses SLU looking course evaluation data. variables data set described detail project description.* Suppose can’t figure create semester variable year variable Term evals_prof_S21.csv. (want split Term variable two variables: Semester levels F S Year levels 19, 20, 21).Put together reprex using tibble() someone able run help figure question.","code":"\nlibrary(tidyverse)\nevals_df <- read_csv(here(\"data/evals_prof_S21.csv\"))\nhead(evals_df)\n#> # A tibble: 6 × 10\n#>   Term  Course Quest…¹ Agree…² Agree Agree…³ Neutral Disag…⁴\n#>   <chr> <chr>  <chr>     <dbl> <dbl>   <dbl>   <dbl>   <dbl>\n#> 1 F19   113-02 1. Cou…       9     9       1       5       0\n#> 2 F19   113-02 2. Eff…      12     8       1       2       1\n#> 3 F19   113-02 3. Env…      11     8       2       3       0\n#> 4 F19   113-02 5a. Fa…       5    13       3       1       1\n#> 5 F19   113-02 5b. Ti…       8    12       1       2       1\n#> 6 F19   113-02 5c. Co…       5     8       4       6       1\n#> # … with 2 more variables: Disagree <dbl>,\n#> #   `Disagree Strongly` <dbl>, and abbreviated variable\n#> #   names ¹​Question, ²​`Agree strongly`, ³​`Agree Somewhat`,\n#> #   ⁴​`Disagree Somewhat`\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"workflow.html","id":"chapexercise-14","chapter":" 6 Workflow and Other Skills","heading":"6.6 Chapter Exercises","text":"chapter exercises section workflow.","code":""},{"path":"workflow.html","id":"solutions-14","chapter":" 6 Workflow and Other Skills","heading":"6.7 Exercise Solutions","text":"","code":""},{"path":"workflow.html","id":"r-projects-and-file-organization-s","chapter":" 6 Workflow and Other Skills","heading":"6.7.1 R Projects and File Organization S","text":"","code":""},{"path":"workflow.html","id":"code-style-s","chapter":" 6 Workflow and Other Skills","heading":"6.7.2 Code Style S","text":"","code":""},{"path":"workflow.html","id":"debugging-code-s","chapter":" 6 Workflow and Other Skills","heading":"6.7.3 Debugging Code S","text":"","code":""},{"path":"workflow.html","id":"context-outliers-and-missing-values-s","chapter":" 6 Workflow and Other Skills","heading":"6.7.4 Context, Outliers, and Missing Values S","text":"","code":""},{"path":"workflow.html","id":"reprexes-and-tibble-s","chapter":" 6 Workflow and Other Skills","heading":"6.7.5 Reprexes and tibble S","text":"* Suppose can’t figure create semester variable year variable Term evals_prof_S21.csv. (want split Term variable two variables: Semester levels F S Year levels 19, 20, 21).Put together reprex using tibble() someone able run help figure question.","code":"\nlibrary(tidyverse)\nevals_df <- read_csv(here(\"data/evals_prof_S21.csv\"))\nhead(evals_df)\n#> # A tibble: 6 × 10\n#>   Term  Course Quest…¹ Agree…² Agree Agree…³ Neutral Disag…⁴\n#>   <chr> <chr>  <chr>     <dbl> <dbl>   <dbl>   <dbl>   <dbl>\n#> 1 F19   113-02 1. Cou…       9     9       1       5       0\n#> 2 F19   113-02 2. Eff…      12     8       1       2       1\n#> 3 F19   113-02 3. Env…      11     8       2       3       0\n#> 4 F19   113-02 5a. Fa…       5    13       3       1       1\n#> 5 F19   113-02 5b. Ti…       8    12       1       2       1\n#> 6 F19   113-02 5c. Co…       5     8       4       6       1\n#> # … with 2 more variables: Disagree <dbl>,\n#> #   `Disagree Strongly` <dbl>, and abbreviated variable\n#> #   names ¹​Question, ²​`Agree strongly`, ³​`Agree Somewhat`,\n#> #   ⁴​`Disagree Somewhat`\n#> # ℹ Use `colnames()` to see all variable names\nlibrary(tidyverse)\ndf <- tibble(Term = c(\"F19\", \"S20\"), x = c(1, 2))\n## Hello! I need help creating a variable that has F/S and \n## a separate year variable that has 19 and 20 from the data set above.\n## Thanks!"},{"path":"workflow.html","id":"rcode-14","chapter":" 6 Workflow and Other Skills","heading":"6.8 Non-Exercise R Code","text":"","code":"\nlibrary(here)\nhere()\nlibrary(tidyverse)\nathletes_df <- read_csv(\"data/athletesdata.csv\")\nathletes_test_read <- read_csv(here(\"data/athletesdata.csv\"))\ndf1 <- mtcars |> filter(cyl == 4)\ndf2 <- mtcars |> filter(cyl == 6)\ndf3 <- mtcars |> filter(cyl == 8)\ncars_with_4_cylinders_data_set <- mtcars |> filter(cyl == 4)\ncyl4_df <- mtcars |> filter(cyl == 4)\ncyl6.df <- mtcars |> filter(cyl == 6)\nggplot(data=mtcars,aes(x=wt,y=drat))+geom_point()+geom_smooth(method=\"lm\",se=FALSE)\nggplot(data = mtcars, aes(x = wt, y = drat)) +\ngeom_point() +\ngeom_smooth(method = \"lm\", se = FALSE)\nggplot(data = mtcars, aes(x = wt, y = drat)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\nmtcars |> filter(cyl == 4) |>\n  group_by(vs) |>\n  summarise(mean_mpg = mean(mpg, na.rm = TRUE))\nmtcars |> filter(cyl == 4) |> group_by(vs) |> summarise(mean_mpg = mean(mpg, na.rm = TRUE))\ncyl4_df <- mtcars |> filter(cyl == 4)\n\nggplot(data = cyl4_df, aes(x = mpg)) +\n  geom_histogram()\nmajors_df <- read_csv(here(\"data/majors.csv\")) |>\n  pivot_longer(-1, names_to = \"year\", values_to = \"n_majors\") |>\n  mutate(year = as.numeric(year)) |>\n  rename(major = `...1`)\nhead(majors_df)\nspanish_df <- majors_df |> filter(major == \"Estudios Hispanicos (Spanish)\")\nggplot(data = spanish_df, aes(x = year, y = n_majors)) +\n  geom_line() +\n  geom_smooth(se = FALSE)\nint_econ_df <- majors_df |> filter(major == \"Int'l Economics (Combined)\")\nggplot(data = int_econ_df, aes(x = year, y = n_majors)) +\n  geom_line() +\n  geom_smooth(se = FALSE)\nlibrary(skimr)\nlibrary(here)\nvideogame_df <- read_csv(here(\"data/videogame_clean.csv\"))\n## skim(videogame_df)\nvideogame_df |> summarise(mean_meta = mean(metascore, na.rm = TRUE),\n                          med_meta = median(metascore, na.rm = TRUE))\nggplot(data = videogame_df, aes(x = metascore, y = median_playtime)) +\n  geom_point() +\n  geom_smooth()\nggplot(data = videogame_df, aes(x = metascore, y = median_playtime)) +\n  geom_point() +\n  geom_smooth()\n## Hello! How do I get rid of the units from the values in\n## my variable `x`? Thanks!\nlibrary(tidyverse)\ntest_df <- read_csv(here(\"data/parsedf.csv\"))\nhead(test_df)\n## Hello! How do I get rid of the units from the values in\n## my variable `xvar`? Thanks!\nlibrary(tidyverse)\ntest_df2 <- tibble(xvar = c(\"20,000 dollars\", \"40 dollars\"),\n                   yvar = c(1, 2))\ntest_df2"},{"path":"tidying-with-tidyr.html","id":"tidying-with-tidyr","chapter":" 7 Tidying with tidyr","heading":" 7 Tidying with tidyr","text":"Goals:describe means data set tidy.describe means data set tidy.use separate() unite() transform data set tidy form.use separate() unite() transform data set tidy form.use pivot_longer() pivot_wider() transform data set tidy form.use pivot_longer() pivot_wider() transform data set tidy form.combine tidyr functions dplyr ggplot2 functions form complete workflow.combine tidyr functions dplyr ggplot2 functions form complete workflow.Data: first use polling data set contains variables collected different polls July 2016 U.S. presidential election. data set scraped RealClear politics https://www.realclearpolitics.com/epolls/latest_polls/president/ Dr. Ramler. variables :Poll, name pollDate, date range poll conductedSample, contains sample size poll whether poll Likely Voters Registered VotersMoE, margin error poll (recall term IntroStat)Clinton (D), percentage people poll voting ClintonTrump (R), percentage people poll voting TrumpJohnson (L), percentage people poll voting JohnsonSteing (G), percentage people poll voting Stein","code":""},{"path":"tidying-with-tidyr.html","id":"what-is-tidy-data","chapter":" 7 Tidying with tidyr","heading":"7.1 What is Tidy Data?","text":"R usually (always) works best data tidy form. tidy data set characteristics. Note already quite familiar tidy data , point, data sets used class (probably data sets see STAT 113 data sets may seen STAT 213) tidy. definition tidy data taken R Data Science:every variable data set stored columnevery case data set stored roweach value variable stored one cellvalues data set contain unitsthere table headers footnotesWe begin focusing first characteristic: every variable data set stored column (correspondingly, number 3: value variable stored one cell).","code":""},{"path":"tidying-with-tidyr.html","id":"separate-and-unite-columns","chapter":" 7 Tidying with tidyr","heading":"7.2 separate() and unite() Columns","text":"fresh .qmd file (File -> New File -> Quarto) Notes project, copy paste following code R chunk:Suppose wanted know average sample size polls . Using dplyr functions,warning get? ?get similar warning (sometimes error) time want try use Sample size plotting summaries. issue Sample column actually contains two variables data set tidy.","code":"\nlibrary(tidyverse)\nlibrary(here)\npolls <- read_csv(here(\"data/rcp-polls.csv\"), na = \"--\")\npolls\n#> # A tibble: 7 × 8\n#>   Poll    Date  Sample   MoE Clint…¹ Trump…² Johns…³ Stein…⁴\n#>   <chr>   <chr> <chr>  <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n#> 1 Monmou… 7/14… 688 LV   3.7      45      43       5       1\n#> 2 CNN/ORC 7/13… 872 RV   3.5      42      37      13       5\n#> 3 ABC Ne… 7/11… 816 RV   4        42      38       8       5\n#> 4 NBC Ne… 7/9 … 1000 …   3.1      41      35      11       6\n#> 5 Econom… 7/9 … 932 RV   4.5      40      37       5       2\n#> 6 Associ… 7/7 … 837 RV  NA        40      36       6       2\n#> 7 McClat… 7/5 … 1053 …   3        40      35      10       5\n#> # … with abbreviated variable names ¹​`Clinton (D)`,\n#> #   ²​`Trump (R)`, ³​`Johnson (L)`, ⁴​`Stein (G)`\npolls |> summarise(meansample = mean(Sample))"},{"path":"tidying-with-tidyr.html","id":"separate-a-column","chapter":" 7 Tidying with tidyr","heading":"7.2.1 separate() a Column","text":"Let’s separate() two variables Sample_size Sample_type:arguments separate() fairly easy learn:col name column data set want separate.col name column data set want separate.name new columns. anything want, entered vector (c() separate names)name new columns. anything want, entered vector (c() separate names)sep character want separate column . case, sample size sample type separated whitespace, sep = \" \", white space.sep character want separate column . case, sample size sample type separated whitespace, sep = \" \", white space.sep argument newest piece information . Note even using sep = \"\" produce error (space now, R doesn’t know separate ).Similarly, like Date column separated poll start date poll end date:use \" - \" separator instead \"-\"? Try using \"-\" aren’t sure: shouldn’t get error something look .happened Sample? back un-separated form?","code":"\npolls |>\n  separate(col = Sample, into = c(\"Sample_size\", \"Sample_type\"), \n           sep = \" \")\n#> # A tibble: 7 × 9\n#>   Poll   Date  Sampl…¹ Sampl…²   MoE Clint…³ Trump…⁴ Johns…⁵\n#>   <chr>  <chr> <chr>   <chr>   <dbl>   <dbl>   <dbl>   <dbl>\n#> 1 Monmo… 7/14… 688     LV        3.7      45      43       5\n#> 2 CNN/O… 7/13… 872     RV        3.5      42      37      13\n#> 3 ABC N… 7/11… 816     RV        4        42      38       8\n#> 4 NBC N… 7/9 … 1000    RV        3.1      41      35      11\n#> 5 Econo… 7/9 … 932     RV        4.5      40      37       5\n#> 6 Assoc… 7/7 … 837     RV       NA        40      36       6\n#> 7 McCla… 7/5 … 1053    RV        3        40      35      10\n#> # … with 1 more variable: `Stein (G)` <dbl>, and\n#> #   abbreviated variable names ¹​Sample_size, ²​Sample_type,\n#> #   ³​`Clinton (D)`, ⁴​`Trump (R)`, ⁵​`Johnson (L)`\n#> # ℹ Use `colnames()` to see all variable names\npolls |>\n  separate(col = Sample, into = c(\"Sample_size\", \"Sample_type\"), \n           sep = \"\")\npolls_sep <- polls |>\n  separate(col = Date, into = c(\"Start\", \"End\"),\n           sep = \" - \")"},{"path":"tidying-with-tidyr.html","id":"unite-columns","chapter":" 7 Tidying with tidyr","heading":"7.2.2 unite() Columns","text":"unite() “opposite” separate(): use one variable stored across multiple columns, row still represents single case. need use unite() less common separate(). current data set, need use . , sake seeing example, let’s separate Start date month day use unite() re-unite columns:situation occur practice: date variable multiple columns: one month one day (multiple years, third year). use unite() combine two columns single Date, called New_start_date:Note unite() just switches around first two arguments separate(). Argument 1 now name new column Argument 2 names columns data set want combine.also used c() function separate() unite(). c() general R function isn’t specific tidy data, first time ’re seeing course. c() officially stands concatenate, , simpler terms, c() combines two “things”, separated comma.useful function argument expects two “things”: example, separate(), argument requires two column names example. column names must specified combining names together c().","code":"\npolls_sillytest <- polls_sep |>\n  separate(col = Start, into = c(\"Start_month\", \"Start_day\"), \n           sep = \"/\")\npolls_sillytest\n#> # A tibble: 7 × 10\n#>   Poll    Start…¹ Start…² End   Sample   MoE Clint…³ Trump…⁴\n#>   <chr>   <chr>   <chr>   <chr> <chr>  <dbl>   <dbl>   <dbl>\n#> 1 Monmou… 7       14      7/16  688 LV   3.7      45      43\n#> 2 CNN/ORC 7       13      7/16  872 RV   3.5      42      37\n#> 3 ABC Ne… 7       11      7/14  816 RV   4        42      38\n#> 4 NBC Ne… 7       9       7/13  1000 …   3.1      41      35\n#> 5 Econom… 7       9       7/11  932 RV   4.5      40      37\n#> 6 Associ… 7       7       7/11  837 RV  NA        40      36\n#> 7 McClat… 7       5       7/9   1053 …   3        40      35\n#> # … with 2 more variables: `Johnson (L)` <dbl>,\n#> #   `Stein (G)` <dbl>, and abbreviated variable names\n#> #   ¹​Start_month, ²​Start_day, ³​`Clinton (D)`, ⁴​`Trump (R)`\n#> # ℹ Use `colnames()` to see all variable names\npolls_sillytest |>\n  unite(\"New_start_date\", c(Start_month, Start_day),\n        sep = \"/\")\n#> # A tibble: 7 × 9\n#>   Poll    New_s…¹ End   Sample   MoE Clint…² Trump…³ Johns…⁴\n#>   <chr>   <chr>   <chr> <chr>  <dbl>   <dbl>   <dbl>   <dbl>\n#> 1 Monmou… 7/14    7/16  688 LV   3.7      45      43       5\n#> 2 CNN/ORC 7/13    7/16  872 RV   3.5      42      37      13\n#> 3 ABC Ne… 7/11    7/14  816 RV   4        42      38       8\n#> 4 NBC Ne… 7/9     7/13  1000 …   3.1      41      35      11\n#> 5 Econom… 7/9     7/11  932 RV   4.5      40      37       5\n#> 6 Associ… 7/7     7/11  837 RV  NA        40      36       6\n#> 7 McClat… 7/5     7/9   1053 …   3        40      35      10\n#> # … with 1 more variable: `Stein (G)` <dbl>, and\n#> #   abbreviated variable names ¹​New_start_date,\n#> #   ²​`Clinton (D)`, ³​`Trump (R)`, ⁴​`Johnson (L)`\n#> # ℹ Use `colnames()` to see all variable names\nc(1, 4, 2)\n#> [1] 1 4 2\nc(\"A\", \"A\", \"D\")\n#> [1] \"A\" \"A\" \"D\""},{"path":"tidying-with-tidyr.html","id":"column-names-and-rename","chapter":" 7 Tidying with tidyr","heading":"7.2.3 Column Names and rename()","text":"might noticed columns percentage votes Clinton, Trump, etc. surrounded backticks ` ` print polls polls_sep:happens column names space (also occur columns started number odd special characters ). , time want reference variable, need include backticks:variable names spaces doesn’t technically violate principle tidy data, can quite annoying. Always using backticks can huge pain. can rename variables easily rename(), just takes series new_name = old_name arguments.rename() can also useful variable names long type . rename() actually dplyr, tidyr, didn’t need dplyr data sets.","code":"\npolls_sep\n#> # A tibble: 7 × 9\n#>   Poll      Start End   Sample   MoE Clint…¹ Trump…² Johns…³\n#>   <chr>     <chr> <chr> <chr>  <dbl>   <dbl>   <dbl>   <dbl>\n#> 1 Monmouth  7/14  7/16  688 LV   3.7      45      43       5\n#> 2 CNN/ORC   7/13  7/16  872 RV   3.5      42      37      13\n#> 3 ABC News… 7/11  7/14  816 RV   4        42      38       8\n#> 4 NBC News… 7/9   7/13  1000 …   3.1      41      35      11\n#> 5 Economis… 7/9   7/11  932 RV   4.5      40      37       5\n#> 6 Associat… 7/7   7/11  837 RV  NA        40      36       6\n#> 7 McClatch… 7/5   7/9   1053 …   3        40      35      10\n#> # … with 1 more variable: `Stein (G)` <dbl>, and\n#> #   abbreviated variable names ¹​`Clinton (D)`,\n#> #   ²​`Trump (R)`, ³​`Johnson (L)`\n#> # ℹ Use `colnames()` to see all variable names\npolls_sep |>\n  summarise(meanclinton = mean(Clinton (D))) ## throws an error\npolls_sep |>\n  summarise(meanclinton = mean(`Clinton (D)`)) ## backticks save the day!\npolls_new <- polls_sep |>\n  rename(Clinton_D = `Clinton (D)`, Trump_R = `Trump (R)`,\n         Johnson_L = `Johnson (L)`, Stein_G = `Stein (G)`)\npolls_new\n#> # A tibble: 7 × 9\n#>   Poll      Start End   Sample   MoE Clint…¹ Trump_R Johns…²\n#>   <chr>     <chr> <chr> <chr>  <dbl>   <dbl>   <dbl>   <dbl>\n#> 1 Monmouth  7/14  7/16  688 LV   3.7      45      43       5\n#> 2 CNN/ORC   7/13  7/16  872 RV   3.5      42      37      13\n#> 3 ABC News… 7/11  7/14  816 RV   4        42      38       8\n#> 4 NBC News… 7/9   7/13  1000 …   3.1      41      35      11\n#> 5 Economis… 7/9   7/11  932 RV   4.5      40      37       5\n#> 6 Associat… 7/7   7/11  837 RV  NA        40      36       6\n#> 7 McClatch… 7/5   7/9   1053 …   3        40      35      10\n#> # … with 1 more variable: Stein_G <dbl>, and abbreviated\n#> #   variable names ¹​Clinton_D, ²​Johnson_L\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"tidying-with-tidyr.html","id":"exercise-4-1","chapter":" 7 Tidying with tidyr","heading":"7.2.4 Exercises","text":"Exercises marked * indicate exercise solution end chapter 7.5.MLB salary data set contains salaries 862 players Major League Baseball 2016. data set obtained http://www.usatoday.com/sports/mlb/salaries/2016/player//Read data using following code chunk write sentence two explains data set tidy.* Tidy data set just thatDuration salary contract (currently given Year column) columnthe year range (also currently given Year column) split variable called Start variable called End year give start end years contract. can still special characters now (like ( )) start end year.received warning message. message mean? See can figure typing View(baseball_df) console window scrolling rows warning mentions: 48, 59, 60, etc.received warning message. message mean? See can figure typing View(baseball_df) console window scrolling rows warning mentions: 48, 59, 60, etc.won’t learn parse_number() readr, function straightforward enough mention . ’s useful extra characters values numeric variable (like $ (), just want grab actual number:won’t learn parse_number() readr, function straightforward enough mention . ’s useful extra characters values numeric variable (like $ (), just want grab actual number:Run code parsing saved baseball_df.* Using function dplyr. fix End variable created , example, first observation 2020 instead just 20.* Using function dplyr. fix End variable created , example, first observation 2020 instead just 20.* tidyr extremely useful, ’s glamorous. end data set ggplot2 dplyr can use cool things. , let’s something tidy data set make tidying little worth moving . Make graphic investigates player Salary compares different POS.* tidyr extremely useful, ’s glamorous. end data set ggplot2 dplyr can use cool things. , let’s something tidy data set make tidying little worth moving . Make graphic investigates player Salary compares different POS.* State reason making plot worked tidied data set.* State reason making plot worked tidied data set.","code":"\nlibrary(tidyverse)\nlibrary(here)\nbaseball_df <- read_csv(here(\"data/mlb2016.csv\"))\nhead(baseball_df)\n#> # A tibble: 6 × 7\n#>   Name             Team  POS   Salary  Years Total…¹ Avg.A…²\n#>   <chr>            <chr> <chr> <chr>   <chr> <chr>   <chr>  \n#> 1 Clayton Kershaw  LAD   SP    $ 33,0… 7 (2… $ 215,… $ 30,7…\n#> 2 Zack Greinke     ARI   SP    $ 31,7… 6 (2… $ 206,… $ 34,4…\n#> 3 David Price      BOS   SP    $ 30,0… 7 (2… $ 217,… $ 31,0…\n#> 4 Miguel Cabrera   DET   1B    $ 28,0… 10 (… $ 292,… $ 29,2…\n#> 5 Justin Verlander DET   SP    $ 28,0… 7 (2… $ 180,… $ 25,7…\n#> 6 Yoenis Cespedes  NYM   CF    $ 27,3… 3 (2… $ 75,0… $ 25,0…\n#> # … with abbreviated variable names ¹​Total.Value,\n#> #   ²​Avg.Annual\nbaseball_df <- baseball_df |>\n  mutate(Salary = parse_number(Salary),\n         Total.Value = parse_number(Total.Value),\n         Avg.Annual = parse_number(Avg.Annual),\n         Start = parse_number(Start),\n         End = parse_number(End))"},{"path":"tidying-with-tidyr.html","id":"reshaping-with-pivot_","chapter":" 7 Tidying with tidyr","heading":"7.3 Reshaping with pivot_()","text":"continue use polling data set introduce pivoting functions data reshaping. make sure working data set, run following line code:data set polls_clean still isn’t tidy!! candidate variable spread 4 different columns values 4 columns actually represent 1 variable: poll percentage.Thinking data “tidyness” using definitions can sometimes little bit confusing. practice, oftentimes usually realize data set untidy go something super simple something turns super simple data current form.example, one thing might want make plot poll Start time x-axis, polling numbers y-axis, candidates represented different colours. small data set, might see trends time, imagine graph quite useful polling numbers June, July, August, September, etc.Take moment think make graph ggplot2: x-axis variable? variable specifying y-axis? colours?first attempt making graph :’re stuck. ’s certainly impossible make graph data current form (keep adding geom_point() re-specifying aesthetics, manually specify colours, manually specify legend), ’s definitely huge pain.pivot_longer() can help! https://www.youtube.com/watch?v=8w3wmQAMoxQ","code":"\npolls_clean <- polls |>\n  separate(col = Sample, into = c(\"Sample_size\", \"Sample_type\"), \n           sep = \" \")  |>\n  separate(col = Date, into = c(\"Start\", \"End\"),\n           sep = \" - \") |> \n  rename(Clinton_D = `Clinton (D)`, Trump_R = `Trump (R)`,\n         Johnson_L = `Johnson (L)`, Stein_G = `Stein (G)`)\npolls_clean\n#> # A tibble: 7 × 10\n#>   Poll     Start End   Sampl…¹ Sampl…²   MoE Clint…³ Trump_R\n#>   <chr>    <chr> <chr> <chr>   <chr>   <dbl>   <dbl>   <dbl>\n#> 1 Monmouth 7/14  7/16  688     LV        3.7      45      43\n#> 2 CNN/ORC  7/13  7/16  872     RV        3.5      42      37\n#> 3 ABC New… 7/11  7/14  816     RV        4        42      38\n#> 4 NBC New… 7/9   7/13  1000    RV        3.1      41      35\n#> 5 Economi… 7/9   7/11  932     RV        4.5      40      37\n#> 6 Associa… 7/7   7/11  837     RV       NA        40      36\n#> 7 McClatc… 7/5   7/9   1053    RV        3        40      35\n#> # … with 2 more variables: Johnson_L <dbl>, Stein_G <dbl>,\n#> #   and abbreviated variable names ¹​Sample_size,\n#> #   ²​Sample_type, ³​Clinton_D\n#> # ℹ Use `colnames()` to see all variable namesggplot(data = polls_clean, aes(x = Start, y = Clinton_D)) + \n  geom_point(aes(colour = ....??????????))"},{"path":"tidying-with-tidyr.html","id":"pivot_longer-to-gather-columns","chapter":" 7 Tidying with tidyr","heading":"7.3.1 pivot_longer() to Gather Columns","text":"pivot_longer() “pivots” data set rows (hence “longer”) collapsing multiple columns two columns. One new column “key” column, new variable containing old data set’s column names. second new column “value” column, new variable containing old data set’s values old data set’s column names. ’s easier see example. know plotting exercise ’d really like candidate variable colour poll_percent variable y-axis plot. , can use pivot_longer() make two columns:pivot_longer() three important arguments:cols, names columns want PIVOT!names_to, name new variable old column names (anything want !)values_to, name new variable old column values (anything want !)happens omit names_to values_to arguments? Give try!Now can make plot using Week 1 ggplot functions. don’t forget give name new “long” data set first!","code":"\npolls_clean |>\n  pivot_longer(cols = c(Clinton_D, Trump_R, Johnson_L, Stein_G),\n               names_to = \"candidate\", values_to = \"poll_percent\")\n#> # A tibble: 28 × 8\n#>    Poll    Start End   Sampl…¹ Sampl…²   MoE candi…³ poll_…⁴\n#>    <chr>   <chr> <chr> <chr>   <chr>   <dbl> <chr>     <dbl>\n#>  1 Monmou… 7/14  7/16  688     LV        3.7 Clinto…      45\n#>  2 Monmou… 7/14  7/16  688     LV        3.7 Trump_R      43\n#>  3 Monmou… 7/14  7/16  688     LV        3.7 Johnso…       5\n#>  4 Monmou… 7/14  7/16  688     LV        3.7 Stein_G       1\n#>  5 CNN/ORC 7/13  7/16  872     RV        3.5 Clinto…      42\n#>  6 CNN/ORC 7/13  7/16  872     RV        3.5 Trump_R      37\n#>  7 CNN/ORC 7/13  7/16  872     RV        3.5 Johnso…      13\n#>  8 CNN/ORC 7/13  7/16  872     RV        3.5 Stein_G       5\n#>  9 ABC Ne… 7/11  7/14  816     RV        4   Clinto…      42\n#> 10 ABC Ne… 7/11  7/14  816     RV        4   Trump_R      38\n#> # … with 18 more rows, and abbreviated variable names\n#> #   ¹​Sample_size, ²​Sample_type, ³​candidate, ⁴​poll_percent\n#> # ℹ Use `print(n = ...)` to see more rows\npolls_long <- polls_clean |>\n  pivot_longer(cols = c(Clinton_D, Trump_R, Johnson_L, Stein_G),\n               names_to = \"candidate\", values_to = \"poll_percent\")\n\n## ignore as.Date for now....we will get to dates later!\nggplot(data = polls_long,\n       aes(x = as.Date(Start, \"%m/%d\"), y = poll_percent,\n           colour = candidate)) +\n  geom_point() + xlab(\"Poll Start Date\")"},{"path":"tidying-with-tidyr.html","id":"pivot_wider-to-spread-to-multiple-columns","chapter":" 7 Tidying with tidyr","heading":"7.3.2 pivot_wider() to Spread to Multiple Columns","text":"“opposite” pivot_longer() pivot_wider(). need use pivot_wider() one case actually spread across multiple rows. , typically realize issue untidy data go something simple ’s .Let’s examine airline safety data fivethirtyeight used Travelers Avoid Flying Airlines Crashes Past? story: https://fivethirtyeight.com/features/-travelers-avoid-flying-airlines----crashes---past/\n. raw data can found .data set contains following columns:airline, name airlineavail_seat_km_per_week, available seat kilometers flown weekincidents 1985_1999, number incidents 1985 1999fatal_accidents 1985_1999, number fatal accidents 1985 1999fatalities 1985_1999, number fatalities 1985 1999incidents 2000_2014fatal_accidents 2000_2014fatalities 2000_2014There’s whole lot mess data set: really want variable year two values (1985-1999 2000-2014). Sometimes ’s tough know even start, one strategy draw sketch data frame ’d like end . example, think want data set following columns: airline, available seat km, years, incidents, fatal accidents, fatalities. , sketch might look something like:etc.Let’s start pivot_longer() see can get year variable (know year variable, want, make rows pivot_longer() seems like good place start):Instead giving pivot_longer() names variables, gave column numbers instead. c(3, 4, 5, 6, 7, 8) corresponds 3rd, 4th, …., 8th columns data set. didn’t quite give us year variable, excited see opportunity take advantage separate():format want data set ? Depending task, . , also might want accident types variable. , might want collapse data set variable incidents, variable fatal_accidents, variable fatalities. , want add columns data set, need use pivot_wider().pivot_wider() two main arguments:names_from, column old data set provide names new columns andnames_from, column old data set provide names new columns andvalues_from, column old data set provide values fill new columnsvalues_from, column old data set provide values fill new columnsWe see examples pivot_wider() pivot_longer() Exercises. Note tidy data isn’t necessarily always better: might find cases need “untidy” data using pivot_longer() pivot_wider(). However, functions R (languages) work best tidy data.topics discuss tidying data. yet discussed 4th 5th characteristics tidy data (cells contain units headers footers), usually dealt read data. Therefore, issues covered discuss readr.","code":"\nlibrary(here)\nairlines <- read_csv(here(\"data/airline-safety.csv\"))\nhead(airlines)\n#> # A tibble: 6 × 8\n#>   airline    avail…¹ incid…² fatal…³ fatal…⁴ incid…⁵ fatal…⁶\n#>   <chr>        <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n#> 1 Aer Lingus  3.21e8       2       0       0       0       0\n#> 2 Aeroflot*   1.20e9      76      14     128       6       1\n#> 3 Aerolinea…  3.86e8       6       0       0       1       0\n#> 4 Aeromexic…  5.97e8       3       1      64       5       0\n#> 5 Air Canada  1.87e9       2       0       0       2       0\n#> 6 Air France  3.00e9      14       4      79       6       2\n#> # … with 1 more variable: `fatalities 2000_2014` <dbl>, and\n#> #   abbreviated variable names ¹​avail_seat_km_per_week,\n#> #   ²​`incidents 1985_1999`, ³​`fatal_accidents 1985_1999`,\n#> #   ⁴​`fatalities 1985_1999`, ⁵​`incidents 2000_2014`,\n#> #   ⁶​`fatal_accidents 2000_2014`\n#> # ℹ Use `colnames()` to see all variable names\nairlines |>\n  pivot_longer(c(3, 4, 5, 6, 7, 8), names_to = \"type_year\",\n  values_to = \"total_num\") \n#> # A tibble: 336 × 4\n#>    airline    avail_seat_km_per_week type_year       total…¹\n#>    <chr>                       <dbl> <chr>             <dbl>\n#>  1 Aer Lingus              320906734 incidents 1985…       2\n#>  2 Aer Lingus              320906734 fatal_accident…       0\n#>  3 Aer Lingus              320906734 fatalities 198…       0\n#>  4 Aer Lingus              320906734 incidents 2000…       0\n#>  5 Aer Lingus              320906734 fatal_accident…       0\n#>  6 Aer Lingus              320906734 fatalities 200…       0\n#>  7 Aeroflot*              1197672318 incidents 1985…      76\n#>  8 Aeroflot*              1197672318 fatal_accident…      14\n#>  9 Aeroflot*              1197672318 fatalities 198…     128\n#> 10 Aeroflot*              1197672318 incidents 2000…       6\n#> # … with 326 more rows, and abbreviated variable name\n#> #   ¹​total_num\n#> # ℹ Use `print(n = ...)` to see more rows\nairlines |> pivot_longer(c(3, 4, 5, 6, 7, 8), names_to = \"type_year\",\n                          values_to = \"total_num\") |>\n  separate(type_year, into = c(\"type\", \"year\"), sep = \" \")\n#> # A tibble: 336 × 5\n#>    airline    avail_seat_km_per_week type      year  total…¹\n#>    <chr>                       <dbl> <chr>     <chr>   <dbl>\n#>  1 Aer Lingus              320906734 incidents 1985…       2\n#>  2 Aer Lingus              320906734 fatal_ac… 1985…       0\n#>  3 Aer Lingus              320906734 fataliti… 1985…       0\n#>  4 Aer Lingus              320906734 incidents 2000…       0\n#>  5 Aer Lingus              320906734 fatal_ac… 2000…       0\n#>  6 Aer Lingus              320906734 fataliti… 2000…       0\n#>  7 Aeroflot*              1197672318 incidents 1985…      76\n#>  8 Aeroflot*              1197672318 fatal_ac… 1985…      14\n#>  9 Aeroflot*              1197672318 fataliti… 1985…     128\n#> 10 Aeroflot*              1197672318 incidents 2000…       6\n#> # … with 326 more rows, and abbreviated variable name\n#> #   ¹​total_num\n#> # ℹ Use `print(n = ...)` to see more rows\n## name the long data set\nairlines_long <- airlines |>\n  pivot_longer(c(3, 4, 5, 6, 7, 8), names_to = \"type_year\",\n               values_to = \"total_num\") |>\n  separate(type_year, into = c(\"type\", \"year\"), sep = \" \")\n\n## use pivot_wider() to create variables for incidents, fatalities, and\n## fatal_accidents:\nairlines_long |> pivot_wider(names_from = type,\n                              values_from = total_num)\n#> # A tibble: 112 × 6\n#>    airline             avail…¹ year  incid…² fatal…³ fatal…⁴\n#>    <chr>                 <dbl> <chr>   <dbl>   <dbl>   <dbl>\n#>  1 Aer Lingus           3.21e8 1985…       2       0       0\n#>  2 Aer Lingus           3.21e8 2000…       0       0       0\n#>  3 Aeroflot*            1.20e9 1985…      76      14     128\n#>  4 Aeroflot*            1.20e9 2000…       6       1      88\n#>  5 Aerolineas Argenti…  3.86e8 1985…       6       0       0\n#>  6 Aerolineas Argenti…  3.86e8 2000…       1       0       0\n#>  7 Aeromexico*          5.97e8 1985…       3       1      64\n#>  8 Aeromexico*          5.97e8 2000…       5       0       0\n#>  9 Air Canada           1.87e9 1985…       2       0       0\n#> 10 Air Canada           1.87e9 2000…       2       0       0\n#> # … with 102 more rows, and abbreviated variable names\n#> #   ¹​avail_seat_km_per_week, ²​incidents, ³​fatal_accidents,\n#> #   ⁴​fatalities\n#> # ℹ Use `print(n = ...)` to see more rows"},{"path":"tidying-with-tidyr.html","id":"exercise-4-2","chapter":" 7 Tidying with tidyr","heading":"7.3.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 7.5.handle data science terminology, ’s difficult transfer ’ve learned different language. example, students computer science might familiar Python. Google something like “pivot wide long python” find help achieving equivalent pivot_longer() Python.UBSprices2 data set contains information prices common commodities cities throughout world years 2003 2009. three commodities data set Rice (1 kg worth), Bread (1 kg worth), Big Mac https://media1.giphy.com/media/Fw5LicDKem6nC/source.gif* Convert data set tidier form year variable commodity variable 3 values: \"bigmac\", \"bread\", \"rice\"Hint: point, need separate commodity year , example, bread2009. , ’ll notice different uses separate() “-” ” ” “/” use separating character. Look help separate() scroll sep argument see can figure issue. first code chunk shows solution particular issue case get stuck part second code chunk shows entire solution.* Convert data set previous exercise commodity split 3 variables: bigmac price, rice price bread price.* Convert data set previous exercise commodity split 3 variables: bigmac price, rice price bread price.data set easiest make line plot year x-axis price rice y-axis lines city? data set easiest make line chart 3 lines, one type commodity, city Amsterdam?data set easiest make line plot year x-axis price rice y-axis lines city? data set easiest make line chart 3 lines, one type commodity, city Amsterdam?time, make plots!New Data:under5mortality.csv file contains data mortality people age 5 countries around world (mortality deaths per 1000 people). data come https://www.gapminder.org/data/. data set extremely wide current form, column year data set. Read data set * Notice 217 columns (top print header, 217 second number). use tidyr, aren’t going want type c(2, 3, 4, 5, .....) way 217! R short-hand notation can use :. example, type 4:9 console window. Use notation tidy mortality_df data set.Note: ’ll need add something pivot_longer() function convert variable Year numeric. haven’t talked much variable types yet , values_to = \"Mortality\" statement, add , names_transform = list(Year = .numeric), making sure second ) close pivot_longer() function.Make line plot look overall 5 mortality trends country.Make line plot look overall 5 mortality trends country.overall trend 5 mortality? every single country follow trend? looks strange plot, specifically data collected 1900?overall trend 5 mortality? every single country follow trend? looks strange plot, specifically data collected 1900?Write two short paragraphs article found https://www.r-bloggers.com/. important thing exercise pick article interests . many choose , multiple posts put day. purposes assignment though, find article author actually provides code (“big-picture” views certain topics).Write two short paragraphs article found https://www.r-bloggers.com/. important thing exercise pick article interests . many choose , multiple posts put day. purposes assignment though, find article author actually provides code (“big-picture” views certain topics).first paragraph, answer following: () main purpose blog post? (b) data /author(s) using? (c) main findings? (d) important author data main findings?second paragraph, discuss () code see explicitly seen class, (b) code see explicitly seen class, (c) anything else find interesting article. , copy paste URL.","code":"\nprices_df <- read_csv(here(\"data/UBSprices2.csv\"))\nseparate(name_of_variable, into = c(\"newname1\", \"newname2\"), sep = -4)\nmortality_df <- read_csv(here(\"data/under5mortality.csv\"))\nhead(mortality_df)\n#> # A tibble: 6 × 217\n#>   Under f…¹ `1800` `1801` `1802` `1803` `1804` `1805` `1806`\n#>   <chr>      <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n#> 1 Abkhazia     NA     NA     NA     NA     NA     NA     NA \n#> 2 Afghanis…   469.   469.   469.   469.   469.   469.   470.\n#> 3 Akrotiri…    NA     NA     NA     NA     NA     NA     NA \n#> 4 Albania     375.   375.   375.   375.   375.   375.   375.\n#> 5 Algeria     460.   460.   460.   460.   460.   460.   460.\n#> 6 American…    NA     NA     NA     NA     NA     NA     NA \n#> # … with 209 more variables: `1807` <dbl>, `1808` <dbl>,\n#> #   `1809` <dbl>, `1810` <dbl>, `1811` <dbl>, `1812` <dbl>,\n#> #   `1813` <dbl>, `1814` <dbl>, `1815` <dbl>, `1816` <dbl>,\n#> #   `1817` <dbl>, `1818` <dbl>, `1819` <dbl>, `1820` <dbl>,\n#> #   `1821` <dbl>, `1822` <dbl>, `1823` <dbl>, `1824` <dbl>,\n#> #   `1825` <dbl>, `1826` <dbl>, `1827` <dbl>, `1828` <dbl>,\n#> #   `1829` <dbl>, `1830` <dbl>, `1831` <dbl>, …\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"tidying-with-tidyr.html","id":"chapexercise-4","chapter":" 7 Tidying with tidyr","heading":"7.4 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 7.5.use nfl salary data obtained FiveThirtyEight originally obtained Spotrac.com.data set top 100 paid players year position 2011 2018, broken player position. unfamiliar American football, positions data set Quarterback, Running Back, Wide Receiver, Tight End, Offensive Lineman offense, Cornerback, Defensive Lineman, Linebacker, Safety Defense, separate category Special Teams players includes punters kickers. can review summary player positions  .interested salaries compare top 100 players position salaries changed time position.Read data set withUse head() functions look data, explain data set tidy form.Use head() functions look data, explain data set tidy form.* Use function tidyr make data tidy, give tidy data set new name.* Use function tidyr make data tidy, give tidy data set new name.* data set previous exercise, add ranking variable ranks salaries within player position highest paid players position receive 1, second highest paid players receive 2, etc. Compare results default way R uses break ties two salaries using ties.method = \"first\".* data set previous exercise, add ranking variable ranks salaries within player position highest paid players position receive 1, second highest paid players receive 2, etc. Compare results default way R uses break ties two salaries using ties.method = \"first\".Hint: See Exercise 4 4.3.2 another example .* Find maximum salary player position year. , create two different line graphs shows maximum salary changed 2011 2018 position. one line graph, make colours lines different position. second line graph, facet position. graph like better?* Find maximum salary player position year. , create two different line graphs shows maximum salary changed 2011 2018 position. one line graph, make colours lines different position. second line graph, facet position. graph like better?* maximum salary dependent one specific player. Make graph, plot average salary top 20 players position year. notice? interesting patterns positions? ’re fan football, provide guess one positions salary plateau recent years.* maximum salary dependent one specific player. Make graph, plot average salary top 20 players position year. notice? interesting patterns positions? ’re fan football, provide guess one positions salary plateau recent years.* Sometimes graphs involving cost salary, want take account inflation rate. Google inflation rate 2011 2018 (Google something like “inflation rate 2011 2018” able find something). Adjust 2011 salaries inflation comparable 2018 salaries. , make similar line plot ignore years 2012 2017 (line plot just 2 points per position).* Sometimes graphs involving cost salary, want take account inflation rate. Google inflation rate 2011 2018 (Google something like “inflation rate 2011 2018” able find something). Adjust 2011 salaries inflation comparable 2018 salaries. , make similar line plot ignore years 2012 2017 (line plot just 2 points per position).adjusting inflation, many positions average higher salaries top 20 players position?Construct graph shows much salary decreases moving higher ranked players lower ranked players position year 2018. think depreciation large Quarterbacks?","code":"\nnfl_df <- read_csv(here(\"data/nfl_salary.csv\"))"},{"path":"tidying-with-tidyr.html","id":"solutions-4","chapter":" 7 Tidying with tidyr","heading":"7.5 Exercise Solutions","text":"","code":""},{"path":"tidying-with-tidyr.html","id":"what-is-tidy-data-s","chapter":" 7 Tidying with tidyr","heading":"7.5.1 What is Tidy Data? S","text":"","code":""},{"path":"tidying-with-tidyr.html","id":"separate-and-unite-s","chapter":" 7 Tidying with tidyr","heading":"7.5.2 separate() and unite() S","text":"* Tidy data set just thatDuration salary contract (currently given Year column) columnthe year range (also currently given Year column) split variable called Start variable called End year give start end years contract. can still special characters now (like ( )) start end year.* Using function dplyr. fix End variable created , example, first observation 2020 instead just 20.somewhat lazy way get trouble (one years 1990s?) , ’s safe particular data set.* tidyr extremely useful, ’s glamorous. end data set ggplot2 dplyr can use cool things. , let’s something tidy data set make tidying little worth moving . Make graphic investigates player Salary compares different POS.* State reason making plot worked tidied data set.Salary variable dollar sign ggplot known plot .","code":"\nbaseball_df <- baseball_df |>\n  separate(Years, into = c(\"Duration\", \"Range\"), sep = \" \") |>\n  separate(Range, into = c(\"Start\", \"End\"), sep = \"-\")\nbaseball_df <- baseball_df |> mutate(End = End + 2000)\nggplot(data = baseball_df, aes(x = POS, y = Salary)) +\n  geom_boxplot()\nggplot(data = baseball_df, aes(x = Salary, colour = POS)) + \n  geom_freqpoly() ## boxplots look better in this case"},{"path":"tidying-with-tidyr.html","id":"pivot_-s","chapter":" 7 Tidying with tidyr","heading":"7.5.3 pivot_() S","text":"* Convert data set tidier form year variable commodity variable 3 values: \"bigmac\", \"bread\", \"rice\"Hint: point, need separate commodity year , example, bread2009. , ’ll notice different uses separate() “-” ” ” “/” use separating character. Look help separate() scroll sep argument see can figure issue. first code chunk shows solution particular issue case get stuck part second code chunk shows entire solution.* Convert data set previous exercise commodity split 3 variables: bigmac price, rice price bread price.* Notice 217 columns (top print header, 217 second number). use tidyr, aren’t going want type c(2, 3, 4, 5, .....) way 217! R short-hand notation can use :. example, type 4:9 console window. Use notation tidy mortality_df data set.’ll need add something pivot_longer() function convert variable Year numeric. haven’t talked much variable types yet , values_to = \"Mortality\" statement, add , names_transform = list(Year = .numeric), making sure second ) close pivot_longer() function.","code":"\nseparate(name_of_variable, into = c(\"newname1\", \"newname2\"), sep = -4)\nprices_long <- prices_df |> pivot_longer(cols = c(2, 3, 4, 5, 6, 7),\n  names_to = \"commod_year\", values_to = \"price\") |>\n  separate(col = \"commod_year\", into = c(\"commodity\", \"year\"), sep = -4)\nhead(prices_long)\n#> # A tibble: 6 × 4\n#>   city      commodity year  price\n#>   <chr>     <chr>     <chr> <dbl>\n#> 1 Amsterdam bigmac    2009     19\n#> 2 Amsterdam bread     2009     10\n#> 3 Amsterdam rice      2009     11\n#> 4 Amsterdam bigmac    2003     16\n#> 5 Amsterdam bread     2003      9\n#> 6 Amsterdam rice      2003      9\nprices_wide <- prices_long |>\n  pivot_wider(names_from = commodity, values_from = price)\nhead(prices_wide)\n#> # A tibble: 6 × 5\n#>   city      year  bigmac bread  rice\n#>   <chr>     <chr>  <dbl> <dbl> <dbl>\n#> 1 Amsterdam 2009      19    10    11\n#> 2 Amsterdam 2003      16     9     9\n#> 3 Athens    2009      30    13    27\n#> 4 Athens    2003      21    12    19\n#> 5 Auckland  2009      19    19    13\n#> 6 Auckland  2003      19    19     9\nmortality_long <- mortality_df |>\n  pivot_longer(cols = 2:217, names_to = \"Year\",\n               values_to = \"Mortality\",\n               names_transform = list(Year = as.numeric))"},{"path":"tidying-with-tidyr.html","id":"chapexercise-4-S","chapter":" 7 Tidying with tidyr","heading":"7.5.4 Chapter Exercises S","text":"* Use function tidyr make data tidy, give tidy data set new name.* data set previous exercise, add ranking variable ranks salaries within player position year highest paid players position year receive 1, second highest paid players receive 2, etc. Compare results default way R uses break ties two salaries using ties.method = \"first\".Hint: See Exercise 4 4.3.2 another example .first ranking code allows observations ranking get rankings averaged together (e.g. two observations tied 5th get ranking (5 + 6) / 2 = 5.5).second ranking method, first observation data set gets “higher” rank.* Find maximum salary player position year. , create two different line graphs shows maximum salary changed 2011 2018 position. one line graph, make colours lines different position. second line graph, facet position. graph like better?number levels, personally prefer faceted graph cleaner look.* maximum salary dependent one specific player. Make graph, plot average salary top 20 players position year. notice? interesting patterns positions? ’re fan football, provide guess one positions salary plateau recent years.Running backs haven’t much salary increase whereas offensive positions large salary increase. many plausible explanations case. One NFL much “passing league” now decades ago.* Sometimes graphs involving cost salary, want take account inflation rate. Google inflation rate 2011 2018 (Google something like “inflation rate 2011 2018” able find something). Adjust 2011 salaries inflation comparable 2018 salaries. , make similar line plot ignore years 2012 2017 (line plot just 2 points per position).adjusting inflation, many positions average higher salaries top 20 players position?positions higher salaries, even adjusting inflation, except perhaps running backs (’s hard tell graph).","code":"\nnfl_long <- nfl_df |>\n  pivot_longer(c(2, 3, 4, 5, 6, 7, 8, 9, 10, 11),\n               names_to = \"position\", values_to = \"salary\")\nnfl_long\n#> # A tibble: 8,000 × 3\n#>     year position            salary\n#>    <dbl> <chr>                <dbl>\n#>  1  2011 Cornerback        11265916\n#>  2  2011 Defensive Lineman 17818000\n#>  3  2011 Linebacker        16420000\n#>  4  2011 Offensive Lineman 15960000\n#>  5  2011 Quarterback       17228125\n#>  6  2011 Running Back      12955000\n#>  7  2011 Safety             8871428\n#>  8  2011 Special Teamer     4300000\n#>  9  2011 Tight End          8734375\n#> 10  2011 Wide Receiver     16250000\n#> # … with 7,990 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\nnfl_long_default <- nfl_long |> group_by(position, year) |>\n  mutate(rank = rank(desc(salary)))\n\nnfl_long <- nfl_long |> group_by(position, year) |>\n  mutate(rank = rank(desc(salary), ties.method = \"first\"))\nnfl_max <- nfl_long |> group_by(position, year) |>\n  summarise(maxsal = max(salary, na.rm = TRUE))\n#> `summarise()` has grouped output by 'position'. You can\n#> override using the `.groups` argument.\n\nggplot(data = nfl_max,\n  aes(x = year, y = maxsal, group = position, colour = position)) +\n  geom_line()\n\nggplot(data = nfl_max, aes(x = year, y = maxsal)) +\n  geom_line() +\n  facet_wrap( ~ position)\nnfl_rank <- nfl_long |> filter(rank <= 20) |>\n  group_by(position, year) |>\n  summarise(mean20 = mean(salary, na.rm = TRUE))\n#> `summarise()` has grouped output by 'position'. You can\n#> override using the `.groups` argument.\n\nggplot(data = nfl_rank, aes(x = year, y = mean20)) +\n  geom_line() + \n  facet_wrap( ~ position)\n## 11.6% from 2011 to 2018.\nnfl_inf <- nfl_long |>\n  mutate(salary_inf = if_else(year == 2011,\n                              true = salary * 1.116,\n                              false = salary)) |> \n  filter(year == 2011 | year == 2018) |> \n  filter(rank <= 20) |> group_by(position, year) |>\n  summarise(mean20 = mean(salary, na.rm = TRUE)) \n#> `summarise()` has grouped output by 'position'. You can\n#> override using the `.groups` argument.\n\nggplot(data = nfl_inf, aes(x = year, y = mean20)) +\n  geom_line() +\n  geom_point() +\n  facet_wrap( ~ position)"},{"path":"tidying-with-tidyr.html","id":"rcode-4","chapter":" 7 Tidying with tidyr","heading":"7.6 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\nlibrary(here)\npolls <- read_csv(here(\"data/rcp-polls.csv\"), na = \"--\")\npolls\npolls |> summarise(meansample = mean(Sample))\npolls |>\n  separate(col = Sample, into = c(\"Sample_size\", \"Sample_type\"), \n           sep = \" \")\npolls_sep <- polls |>\n  separate(col = Date, into = c(\"Start\", \"End\"),\n           sep = \" - \")\npolls_sillytest <- polls_sep |>\n  separate(col = Start, into = c(\"Start_month\", \"Start_day\"), \n           sep = \"/\")\npolls_sillytest\npolls_sillytest |>\n  unite(\"New_start_date\", c(Start_month, Start_day),\n        sep = \"/\")\nc(1, 4, 2)\nc(\"A\", \"A\", \"D\")\npolls_sep\npolls_new <- polls_sep |>\n  rename(Clinton_D = `Clinton (D)`, Trump_R = `Trump (R)`,\n         Johnson_L = `Johnson (L)`, Stein_G = `Stein (G)`)\npolls_new\npolls_clean <- polls |>\n  separate(col = Sample, into = c(\"Sample_size\", \"Sample_type\"), \n           sep = \" \")  |>\n  separate(col = Date, into = c(\"Start\", \"End\"),\n           sep = \" - \") |> \n  rename(Clinton_D = `Clinton (D)`, Trump_R = `Trump (R)`,\n         Johnson_L = `Johnson (L)`, Stein_G = `Stein (G)`)\npolls_clean\npolls_clean |>\n  pivot_longer(cols = c(Clinton_D, Trump_R, Johnson_L, Stein_G),\n               names_to = \"candidate\", values_to = \"poll_percent\")\npolls_long <- polls_clean |>\n  pivot_longer(cols = c(Clinton_D, Trump_R, Johnson_L, Stein_G),\n               names_to = \"candidate\", values_to = \"poll_percent\")\n\n## ignore as.Date for now....we will get to dates later!\nggplot(data = polls_long,\n       aes(x = as.Date(Start, \"%m/%d\"), y = poll_percent,\n           colour = candidate)) +\n  geom_point() + xlab(\"Poll Start Date\")\nlibrary(here)\nairlines <- read_csv(here(\"data/airline-safety.csv\"))\nhead(airlines)\nairlines |>\n  pivot_longer(c(3, 4, 5, 6, 7, 8), names_to = \"type_year\",\n  values_to = \"total_num\") \nairlines |> pivot_longer(c(3, 4, 5, 6, 7, 8), names_to = \"type_year\",\n                          values_to = \"total_num\") |>\n  separate(type_year, into = c(\"type\", \"year\"), sep = \" \")\n## name the long data set\nairlines_long <- airlines |>\n  pivot_longer(c(3, 4, 5, 6, 7, 8), names_to = \"type_year\",\n               values_to = \"total_num\") |>\n  separate(type_year, into = c(\"type\", \"year\"), sep = \" \")\n\n## use pivot_wider() to create variables for incidents, fatalities, and\n## fatal_accidents:\nairlines_long |> pivot_wider(names_from = type,\n                              values_from = total_num)"},{"path":"coding-in-base-r.html","id":"coding-in-base-r","chapter":" 8 Coding in Base R","heading":" 8 Coding in Base R","text":"Goals:describe common classes variables data set.explain R errors come class misspecifications.use indexing reference rows, columns, specific observations tibble data set.Motivation“Base R” generally refers R code can use without loading outside packages (code tidyverse family packages). chapter R basics first chapter discuss? certainly advantages things way, also advantages starting something like “classes variables R.”First, ’s inherently interesting thing look . ’s lot fun make plots wrangle data. long someone makes sure variables already “correct” class, ’s need talk .Second, much discuss make sense, previous four chapters belt. ’ll able see misspecified variable classes cause issues certain summaries plots already know make plots get summaries.","code":""},{"path":"coding-in-base-r.html","id":"variable-classes-in-r","chapter":" 8 Coding in Base R","heading":"8.1 Variable Classes in R","text":"R different classes variables take, including numeric, factor, character Date, logical. delve specifics classes mean, let’s try make plots illustrate care classes mean.videogame_clean.csv file contains variables video games 2004 - 2019, includinggame, name gamerelease_date, release date gamerelease_date2, second coding release dateprice, price dollars,owners, number owners (given range)median_playtime, median playtime gamemetascore, score website Metacriticprice_cat, 1 Low (less 10.00 dollars), 2 Moderate (10 29.99 dollars), 3 High (30.00 dollars)meta_cat, Metacritic’s review system, following categories: “Overwhelming Dislike”, “Generally Unfavorable”, “Mixed Reviews”, “Generally Favorable”, “Universal Acclaim”.playtime_miss, whether median play time missing (TRUE) (FALSE)data set modified https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-07-30.Run code following R chunk read data.data frame tibble holds variables allowed different classes. variable different class expect, ’ll get strange errors results trying wrangle data make graphics.Run following lines code. cases, using first 100 observations videogame_small. Otherwise, code take long time run.first plot, release_date isn’t ordered according expect (date). Instead, R orders alphabetically.second plot, expect get plot 3 different colours, one level price_cat. Instead, get continuous colour scale, doesn’t make sense, given price_cat can 1, 2, 3.plots rendered correctly variable classes correct underlying data set. point, data provided almost always correct variable classes, default, won’t always case!’ve actually seen issues well (Date issue exercise data continuous colour scale cars data), , instances, code provided “fix” problem. section, ’ll tools fix many class issues !examine output following line codeyou’ll see , top output, right variable names, R provides classes variables tibble.<chr> character, used strings text.<fct> used variables factors, typically used character variables finite number possible values variable can take .<date> used dates.<dbl> stands double used numeric class.<int> numbers integers. practice, much difference class class dbl.<lgl> logical, variables either TRUE FALSE.","code":"\nlibrary(tidyverse)\nlibrary(here)\nvideogame_df <- read_csv(here(\"data/videogame_clean.csv\"))\nhead(videogame_df)\n#> # A tibble: 6 × 15\n#>   game       relea…¹ release_…² price owners media…³ metas…⁴\n#>   <chr>      <chr>   <date>     <dbl> <chr>    <dbl>   <dbl>\n#> 1 Half-Life… Nov 16… 2004-11-16  9.99 10,00…      66      96\n#> 2 Counter-S… Nov 1,… 2004-11-01  9.99 10,00…     128      88\n#> 3 Counter-S… Mar 1,… 2004-03-01  9.99 10,00…       3      65\n#> 4 Half-Life… Nov 1,… 2004-11-01  4.99 5,000…       0      NA\n#> 5 Half-Life… Jun 1,… 2004-06-01  9.99 2,000…       0      NA\n#> 6 CS2D       Dec 24… 2004-12-24 NA    1,000…      10      NA\n#> # … with 8 more variables: price_cat <dbl>, meta_cat <chr>,\n#> #   playtime_miss <lgl>, number <dbl>, developer <chr>,\n#> #   publisher <chr>, average_playtime <dbl>,\n#> #   meta_cat_factor <chr>, and abbreviated variable names\n#> #   ¹​release_date, ²​release_date2, ³​median_playtime,\n#> #   ⁴​metascore\n#> # ℹ Use `colnames()` to see all variable names\nvideogame_small <- videogame_df |> slice(1:100)\nggplot(data = videogame_small, aes(x = release_date, y = price)) +\n  geom_point() \n\nggplot(data = videogame_small, aes(x = release_date2, y = metascore)) +\n  geom_point(aes(colour = price_cat))\nhead(videogame_df)\n#> # A tibble: 6 × 15\n#>   game       relea…¹ release_…² price owners media…³ metas…⁴\n#>   <chr>      <chr>   <date>     <dbl> <chr>    <dbl>   <dbl>\n#> 1 Half-Life… Nov 16… 2004-11-16  9.99 10,00…      66      96\n#> 2 Counter-S… Nov 1,… 2004-11-01  9.99 10,00…     128      88\n#> 3 Counter-S… Mar 1,… 2004-03-01  9.99 10,00…       3      65\n#> 4 Half-Life… Nov 1,… 2004-11-01  4.99 5,000…       0      NA\n#> 5 Half-Life… Jun 1,… 2004-06-01  9.99 2,000…       0      NA\n#> 6 CS2D       Dec 24… 2004-12-24 NA    1,000…      10      NA\n#> # … with 8 more variables: price_cat <dbl>, meta_cat <chr>,\n#> #   playtime_miss <lgl>, number <dbl>, developer <chr>,\n#> #   publisher <chr>, average_playtime <dbl>,\n#> #   meta_cat_factor <chr>, and abbreviated variable names\n#> #   ¹​release_date, ²​release_date2, ³​median_playtime,\n#> #   ⁴​metascore\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"coding-in-base-r.html","id":"referencing-variables-and-using-str","chapter":" 8 Coding in Base R","heading":"8.1.1 Referencing Variables and Using str()","text":"can use name_of_dataset$name_of_variable look specific variable data set:prints first thousand entries variable game. ways get class variable: way use often str(), stands “structure”, gives class variable, number observations (26688), well first couple observations:can also get variable’s class directly class()","code":"\nvideogame_df$game\nstr(videogame_df$game)\n#>  chr [1:26688] \"Half-Life 2\" \"Counter-Strike: Source\" ...\nclass(videogame_df$game)\n#> [1] \"character\""},{"path":"coding-in-base-r.html","id":"classes-in-detail","chapter":" 8 Coding in Base R","heading":"8.2 Classes in Detail","text":"following gives summary information class variables R:","code":""},{"path":"coding-in-base-r.html","id":"chr-and-fct-class","chapter":" 8 Coding in Base R","heading":"8.2.1 <chr> and <fct> Class","text":"character class, R give warning /missing value try perform numerical operations:also can’t convert character class numeric. can, however, convert character class <fct> class, using .factor(). <fct> class useful discuss forcats package, isn’t particularly useful now.general, ._____ lets convert classes. Note, however, aren’t saving converted variable anywhere. wanted conversion factor saved data set, can use mutate():R functions, won’t matter whether variable class character class factor. general, though, character classes variables ton different levels, like name videogame, whereas factors reserved categorical variables finite number levels.","code":"\nmean(videogame_df$game)\n#> [1] NA\nvideogame_df |> summarise(maxgame = max(game))\n#> # A tibble: 1 × 1\n#>   maxgame\n#>   <chr>  \n#> 1 <NA>\nclass(videogame_df$meta_cat)\n#> [1] \"character\"\nclass(as.factor(videogame_df$meta_cat))\n#> [1] \"factor\"\nvideogame_df <- videogame_df |>\n  mutate(meta_cat_factor = as.factor(meta_cat))\nstr(videogame_df$meta_cat_factor)\n#>  Factor w/ 4 levels \"Generally Favorable\",..: 4 1 3 NA NA NA 4 1 3 NA ..."},{"path":"coding-in-base-r.html","id":"date-class","chapter":" 8 Coding in Base R","heading":"8.2.2 <date> Class","text":"<date> class used dates, <datetime> class used Dates times. R requires specific format dates times. Note , human eye, following variables contain dates, one class <date>:release_date class character, issue odd ordering dates earlier. can try converting using .Date, function doesn’t always work:Dates times can pretty complicated. fact, spend entire week covering using lubridate package.variables Date format, like release_date2, can use numerical operations:think taking median taking mean date class means?","code":"\nstr(videogame_df$release_date)\n#>  chr [1:26688] \"Nov 16, 2004\" \"Nov 1, 2004\" ...\nstr(videogame_df$release_date2)\n#>  Date[1:26688], format: \"2004-11-16\" \"2004-11-01\" \"2004-03-01\" ...\nas.Date(videogame_df$release_date)\n#> Error in charToDate(x): character string is not in a standard unambiguous format\nmedian(videogame_df$release_date2, na.rm = TRUE)\n#> [1] \"2017-06-09\"\nmean(videogame_df$release_date2, na.rm = TRUE)\n#> [1] \"2016-09-15\""},{"path":"coding-in-base-r.html","id":"dbl-and-int-class","chapter":" 8 Coding in Base R","heading":"8.2.3 <dbl> and <int> Class","text":"Class <dbl> <int> probably self-explanatory classes. <dbl>, numeric class, just variables numbers <int> integers (…, -2, -1, 0, 1, 2, ….). can numerical operations either classes (’ve throughout semester). purposes, two classes interchangeable.Problems arise numeric variables coded something non-numeric, non-numeric variables coded numeric. example, examine:price_cat categorical coded 1 cheap games, 2 moderately priced games, 3 expensive games. Therefore, R thinks variable numeric, , ’s actually factor.cause odd colour scale encountered earlier can fixed converting price_cat factor:","code":"\nstr(videogame_df$price)\n#>  num [1:26688] 9.99 9.99 9.99 4.99 9.99 ...\nstr(videogame_df$price_cat)\n#>  num [1:26688] 1 1 1 1 1 NA 2 1 1 1 ...\nstr(as.factor(videogame_df$price_cat))\n#>  Factor w/ 3 levels \"1\",\"2\",\"3\": 1 1 1 1 1 NA 2 1 1 1 ...\nvideogame_df <- videogame_df |>\n  mutate(price_factor = as.factor(price_cat)) \nggplot(data = videogame_df, aes(x = release_date2, y = metascore)) +\n  geom_point(aes(colour = price_factor))"},{"path":"coding-in-base-r.html","id":"lgl-class","chapter":" 8 Coding in Base R","heading":"8.2.4 <lgl> Class","text":"Finally, class variables called logical. variables can take 2 values: TRUE FALSE. example, playtime_miss, variable whether median_playtime variable missing , logical:’s little strange first, R can perform numeric operations logical classes. R treat every TRUE 1 every FALSE 0. Therefore, sum() gives total number TRUEs mean() gives proportion TRUEs. , can find number proportion games missing median_playtime :’s lot games missing information!’ve actually used ideas logical variables quite time now, particularly statements involving if_else(), case_when(), filter(), mutate().primary purpose section able identify variable classes able convert different variable types mutate() “fix” variables incorrect class.","code":"\nstr(videogame_df$playtime_miss)\n#>  logi [1:26688] FALSE FALSE FALSE TRUE TRUE FALSE ...\nsum(videogame_df$playtime_miss)\n#> [1] 25837\nmean(videogame_df$playtime_miss)\n#> [1] 0.968113"},{"path":"coding-in-base-r.html","id":"exercise-6-2","chapter":" 8 Coding in Base R","heading":"8.2.5 Exercises","text":"Exercises marked * indicate exercise solution end chapter 8.6.use fitness data set set exercises, data set issues variable class discussed. However, week 1, work work fix issues already done saw data. Now, ’ll get fix couple issues! Read data set :* issue following plot? figure issue, use mutate() create new variable fixes issue reconstruct graph.* another variable data set incorrect class?* another variable data set incorrect class?Create new variable, called step_goal 1 TRUE least 10000 steps walked 0 FALSE fewer 10000 steps walked. Using variable, find total number days goal met proportion days goal met.Create new variable, called step_goal 1 TRUE least 10000 steps walked 0 FALSE fewer 10000 steps walked. Using variable, find total number days goal met proportion days goal met.","code":"\nlibrary(tidyverse)\nfitness_df <- read_csv(here(\"data/higham_fitness_notclean.csv\"))\nggplot(data = fitness_df, aes(x = active_cals)) +\n  geom_freqpoly(aes(group = weekday, colour = weekday))\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`."},{"path":"coding-in-base-r.html","id":"object-types-and-subsetting","chapter":" 8 Coding in Base R","heading":"8.3 Object Types and Subsetting","text":"Variables different classes can stored variety different objects R. almost exclusively used tibble object type. tidy tibbleis “rectangular” specific number rows columns.columns variableseach column must elements class, different columns can different classes. allows us character numeric variables tibble.","code":""},{"path":"coding-in-base-r.html","id":"tibble-and-data.frame","chapter":" 8 Coding in Base R","heading":"8.3.1 tibble and data.frame","text":"tibble object similar data.frame object. can also check type object ’re working using str() command:small section tibbles coming weeks won’t focus . , take note , reference specific element tibble, called indexing, can use [# , #]. , example, videogame_df[5, 3] grabs value fifth row third column:often, ’d want grab entire row (range rows) entire column. can leaving row number blank (grab entire column) leaving column number blank (grab entire row):can also grab range columns rows using : operator:can grab different columns rows using c():get rid entire row column, use -: videogame_df[ ,-c(1, 2)] drops first second columns videogame_df[-c(1, 2), ] drops first second rows.","code":"\nstr(videogame_df) ## look at the beginning to see \"tibble\"\nvideogame_df[5, 3]\n#> # A tibble: 1 × 1\n#>   release_date2\n#>   <date>       \n#> 1 2004-06-01\nvideogame_df[ ,3] ## grab the third column\n\nvideogame_df[5, ] ## grab the fifth row\n3:7\n\nvideogame_df[ ,3:7] ## grab columns 3 through 7\n\nvideogame_df[3:7, ] ## grab rows 3 through 7\nvideogame_df[ ,c(1, 3, 4)] ## grab columns 1, 3, and 4\n\nvideogame_df[c(1, 3, 4), ] ## grab rows 1, 3, and 4"},{"path":"coding-in-base-r.html","id":"vectors","chapter":" 8 Coding in Base R","heading":"8.3.2 Vectors","text":"vector object holds “things”, elements, class. can create vector R using c() function, stands “concatenate”. ’ve used c() function bind things together; just hadn’t yet discussed context creating vector.Notice vec2 character class. R requires elements vector one class; since R knows b can’t numeric, makes numbers characters well.Using dataset$variable draws vector tibble data.frame:wanted make vector “hand”, ’d need lot patience: c(96, 88, 65, NA, NA, NA, 93, .........)Just like tibbles, can save vectors something later use:get mean metascore using dplyr functions?Vectors one-dimensional: want grab 100th element vector just use name_of_vector[100]:aware , ’re coming math perspective, “vector” R doesn’t correspond “vector” mathematics physics.","code":"\nvec1 <- c(1, 3, 2)\nvec2 <- c(\"b\", 1, 2)\nvec3 <- c(FALSE, FALSE, TRUE)\nstr(vec1); str(vec2); str(vec3)\n#>  num [1:3] 1 3 2\n#>  chr [1:3] \"b\" \"1\" \"2\"\n#>  logi [1:3] FALSE FALSE TRUE\nvideogame_df$metascore\nmetavec <- videogame_df$metascore\nmean(metavec, na.rm = TRUE)\n#> [1] 71.89544\nmetavec[100] ## 100th element is missing\n#> [1] NA"},{"path":"coding-in-base-r.html","id":"lists","chapter":" 8 Coding in Base R","heading":"8.3.3 Lists","text":"Lists one flexible objects R: can put objects different classes list lists aren’t required rectangular (like tibbles ). Lists extremely useful flexibility, , won’t use much class. Therefore, just see example list moving :testlist four elements: single character \"\", single number 4, vector 1, 4, 2, 6, tibble couple variables. Lists can therefore used store complex information wouldn’t easily stored vector tibble.","code":"\ntestlist <- list(\"a\", 4, c(1, 4, 2, 6),\n                 tibble(x = c(1, 2), y = c(3, 2)))\ntestlist\n#> [[1]]\n#> [1] \"a\"\n#> \n#> [[2]]\n#> [1] 4\n#> \n#> [[3]]\n#> [1] 1 4 2 6\n#> \n#> [[4]]\n#> # A tibble: 2 × 2\n#>       x     y\n#>   <dbl> <dbl>\n#> 1     1     3\n#> 2     2     2"},{"path":"coding-in-base-r.html","id":"exercise-6-3","chapter":" 8 Coding in Base R","heading":"8.3.4 Exercises","text":"Exercises marked * indicate exercise solution end chapter 8.6.* Look subsetting commands [ , ]. dplyr functions can use thing?* Look subsetting commands [ , ]. dplyr functions can use thing?Create tibble called last100 last 100 days data set using (1) indexing [ , ] (2) dplyr function.Create tibble called last100 last 100 days data set using (1) indexing [ , ] (2) dplyr function.Create tibble doesn’t flights variable using (1) indexing [ , ] (2) dplyr function.Create tibble doesn’t flights variable using (1) indexing [ , ] (2) dplyr function.* Use following steps create new variable weekend_ind, “weekend” day week Saturday Sunday “weekday” day week day. current weekday variable coded 1 represents Sunday, 2 represents Monday, …., 7 represents Saturday.* Use following steps create new variable weekend_ind, “weekend” day week Saturday Sunday “weekday” day week day. current weekday variable coded 1 represents Sunday, 2 represents Monday, …., 7 represents Saturday.Create vector numbers corresponding two weekend days. Name vector create second vector numbers corresponding five weekday days.Create vector numbers corresponding two weekend days. Name vector create second vector numbers corresponding five weekday days.Use dplyr functions %% operator create new weekend_ind variable. can use following code chunk help %% :Use dplyr functions %% operator create new weekend_ind variable. can use following code chunk help %% :","code":"\n1 %in% c(1, 2, 3, 4)\n2 %in% c(1, 2, 3, 4)\n\n2 %in% c(3, 4, 5, 6)"},{"path":"coding-in-base-r.html","id":"other-useful-base-r-functions","chapter":" 8 Coding in Base R","heading":"8.4 Other Useful Base R Functions","text":"addition functions like %% previous exercise, many useful base R functions. following give functions think useful data science.Generating Data: rnorm(), sample(), set.seed()rnorm() can used generate certain number normal random variables given mean standard deviation. three arguments: sample size, mean, standard deviation.sample() can used obtain sample vector, either without replacement: two required arguments: vector want sample size, size sample.set.seed() can used fix R’s random seed. can set , example, person class can get random sample long set seed.can combined quickly generate toy data. example, generating two quantitative variables (normally distributed) two categorical variables:Tables: can use table() function $ operator quickly generate tables categorical variables:Others: quite useful base R functions. nrow() can used data frame quickly look number rows data frame summary() can used get quick summary vector:also useful functions viewing data frame. View() function can used console window data frame: View(toy_df) pull spreadsheet-like view data set different window within R Studio.Options print() allow us view rows columns console printout:stop , surely encounter base R functions run different types problems.","code":"\nset.seed(15125141)\ntoy_df <- tibble(xvar = rnorm(100, 3, 4),\n                 yvar = rnorm(100, -5, 10),\n                 group1 = sample(c(\"A\", \"B\", \"C\"), size = 100, replace = TRUE),\n                 group2 = sample(c(\"Place1\", \"Place2\", \"Place3\"), size = 100,\n                                 replace = TRUE))\ntoy_df\n#> # A tibble: 100 × 4\n#>      xvar   yvar group1 group2\n#>     <dbl>  <dbl> <chr>  <chr> \n#>  1  0.516 -13.5  B      Place2\n#>  2 -0.891 -13.3  A      Place2\n#>  3  5.58  -14.3  B      Place2\n#>  4  2.42   -4.91 C      Place1\n#>  5  1.43   -5.86 B      Place2\n#>  6  6.61   12.7  B      Place2\n#>  7 -2.04   -9.28 A      Place1\n#>  8  7.56    1.89 A      Place3\n#>  9 -0.425 -30.1  C      Place1\n#> 10  4.14    2.65 C      Place2\n#> # … with 90 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\ntable(toy_df$group1)\n#> \n#>  A  B  C \n#> 27 39 34\n\ntable(toy_df$group1, toy_df$group2)\n#>    \n#>     Place1 Place2 Place3\n#>   A     10      8      9\n#>   B      9     20     10\n#>   C     10     10     14\nnrow(toy_df)\n#> [1] 100\nsummary(toy_df$yvar)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#> -30.123 -12.938  -5.380  -6.630  -1.298  13.858\ntoy_df |>\n  print(n = 60) ## print out 60 rows\n#> # A tibble: 100 × 4\n#>      xvar    yvar group1 group2\n#>     <dbl>   <dbl> <chr>  <chr> \n#>  1  0.516 -13.5   B      Place2\n#>  2 -0.891 -13.3   A      Place2\n#>  3  5.58  -14.3   B      Place2\n#>  4  2.42   -4.91  C      Place1\n#>  5  1.43   -5.86  B      Place2\n#>  6  6.61   12.7   B      Place2\n#>  7 -2.04   -9.28  A      Place1\n#>  8  7.56    1.89  A      Place3\n#>  9 -0.425 -30.1   C      Place1\n#> 10  4.14    2.65  C      Place2\n#> 11  5.03   -8.82  C      Place1\n#> 12  2.98  -22.7   C      Place1\n#> 13  5.97   -2.67  B      Place3\n#> 14  0.882   1.59  A      Place1\n#> 15  2.14   -5.63  B      Place3\n#> 16  7.74    5.79  C      Place3\n#> 17  5.20   -3.17  B      Place2\n#> 18  2.89   -0.697 A      Place1\n#> 19  2.71    1.09  B      Place2\n#> 20  5.87   -4.87  C      Place1\n#> 21  5.65  -10.3   B      Place2\n#> 22 -0.520  -4.77  B      Place3\n#> 23 -0.130 -18.3   B      Place3\n#> 24 -0.174 -18.9   A      Place3\n#> 25  4.33    4.63  A      Place3\n#> 26  0.462 -12.8   A      Place3\n#> 27  5.53   -3.36  C      Place1\n#> 28  1.66   -5.34  A      Place1\n#> 29 -0.469 -13.2   C      Place2\n#> 30  7.51  -13.4   B      Place1\n#> 31 -1.82   -6.47  C      Place3\n#> 32 -2.44   -2.17  C      Place3\n#> 33  1.52  -12.6   C      Place2\n#> 34  4.60   -6.69  A      Place2\n#> 35  3.10  -25.5   A      Place2\n#> 36 -0.682 -20.4   A      Place1\n#> 37 -5.72    2.65  B      Place3\n#> 38  0.976 -12.1   B      Place3\n#> 39  1.39    2.78  B      Place2\n#> 40  6.67  -14.6   A      Place1\n#> 41  3.09  -10.4   B      Place2\n#> 42 -1.98  -12.8   A      Place3\n#> 43  0.225  13.9   C      Place1\n#> 44  5.71   -3.50  A      Place3\n#> 45  5.57   -2.02  B      Place3\n#> 46  8.96   -1.86  B      Place2\n#> 47  3.80  -11.3   C      Place1\n#> 48  7.40   -1.32  C      Place2\n#> 49  0.988   4.04  B      Place2\n#> 50  1.93   -5.24  A      Place2\n#> 51  5.23   13.2   C      Place2\n#> 52 -2.13  -19.6   A      Place2\n#> 53  6.05   -4.42  A      Place3\n#> 54  0.865  -9.47  A      Place1\n#> 55  4.16  -16.4   B      Place1\n#> 56 -2.73   -4.09  B      Place2\n#> 57 -0.532   7.70  C      Place3\n#> 58 -2.96  -11.6   C      Place3\n#> 59  4.34   -5.99  B      Place2\n#> 60  6.72  -13.6   B      Place2\n#> # … with 40 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\ntoy_df |>\n  print(width = Inf) ## print out all of the columns\n#> # A tibble: 100 × 4\n#>      xvar   yvar group1 group2\n#>     <dbl>  <dbl> <chr>  <chr> \n#>  1  0.516 -13.5  B      Place2\n#>  2 -0.891 -13.3  A      Place2\n#>  3  5.58  -14.3  B      Place2\n#>  4  2.42   -4.91 C      Place1\n#>  5  1.43   -5.86 B      Place2\n#>  6  6.61   12.7  B      Place2\n#>  7 -2.04   -9.28 A      Place1\n#>  8  7.56    1.89 A      Place3\n#>  9 -0.425 -30.1  C      Place1\n#> 10  4.14    2.65 C      Place2\n#> # … with 90 more rows\n#> # ℹ Use `print(n = ...)` to see more rows"},{"path":"coding-in-base-r.html","id":"exercise-6-4","chapter":" 8 Coding in Base R","heading":"8.4.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 8.6.Use dplyr tidyr functions re-create tables generated ","code":"\ntable(toy_df$group1)\n#> \n#>  A  B  C \n#> 27 39 34\n\ntable(toy_df$group1, toy_df$group2)\n#>    \n#>     Place1 Place2 Place3\n#>   A     10      8      9\n#>   B      9     20     10\n#>   C     10     10     14"},{"path":"coding-in-base-r.html","id":"chapexercise-6","chapter":" 8 Coding in Base R","heading":"8.5 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 8.6.Work following exercises pertaining video game data set.* Read data set use filter() remove rows missing metascores, missing median playtime, median playtime 0 hours.Note: usually don’t want remove missing values without valid reason. case, missing metascore means game wasn’t “major” enough get enough critic reviews, missing 0 hour median playtime means weren’t enough users uploaded playtime database. Therefore, analyses constructed games popular enough get enough reviews metacritic enough users upload median playtimes.* Make scatterplot median_playtime y-axis metascore x-axis filtered data set.* Make scatterplot median_playtime y-axis metascore x-axis filtered data set.* Something may notice many points directly overlap one another. common least one variables scatterplot discrete: metascore can take integer values case. Change geom_point() previous plot geom_jitter(). , use help write sentence geom_jitter() .* Something may notice many points directly overlap one another. common least one variables scatterplot discrete: metascore can take integer values case. Change geom_point() previous plot geom_jitter(). , use help write sentence geom_jitter() .* Another option control point transparency alpha. geom_jitter() statement, change alpha can still see points, can tell plot lot points overlapping.* Another option control point transparency alpha. geom_jitter() statement, change alpha can still see points, can tell plot lot points overlapping.* Label points median playtimes 1500 hours. may want use ggrepel package labels don’t overlap.* Label points median playtimes 1500 hours. may want use ggrepel package labels don’t overlap.Choose one games got labeled Google game’s median, possibly average, play time. vicinity median_playtime recorded data set?Choose one games got labeled Google game’s median, possibly average, play time. vicinity median_playtime recorded data set?done outliers? discuss investigate issue class.done outliers? discuss investigate issue class.","code":"\nvideogame_df <- read_csv(here(\"data/videogame_clean.csv\"))"},{"path":"coding-in-base-r.html","id":"solutions-6","chapter":" 8 Coding in Base R","heading":"8.6 Exercise Solutions","text":"","code":""},{"path":"coding-in-base-r.html","id":"variable-classes-s","chapter":" 8 Coding in Base R","heading":"8.6.1 Variable Classes S","text":"","code":""},{"path":"coding-in-base-r.html","id":"classes-in-detail-s","chapter":" 8 Coding in Base R","heading":"8.6.2 Classes in Detail S","text":"* issue following plot? figure issue, use mutate() create new variable fixes issue reconstruct graph.issue weekday factor, numeric.* another variable data set incorrect class?Month ordered factor, numeric.","code":"\nggplot(data = fitness_df, aes(x = active_cals)) +\n  geom_freqpoly(aes(group = weekday, colour = weekday))\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\nfitness_df <- fitness_df |> mutate(weekday_cat = as.factor(weekday))\nggplot(data = fitness_df, aes(x = active_cals)) +\n  geom_freqpoly(aes(group = weekday_cat, colour = weekday_cat)) +\n  scale_colour_viridis_d()\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`."},{"path":"coding-in-base-r.html","id":"object-types-s","chapter":" 8 Coding in Base R","heading":"8.6.3 Object Types S","text":"* Look subsetting commands [ , ]. dplyr functions can use thing?slice() can used row indexing select() can used column indexing.* Use following steps create new variable weekend_ind, “weekend” day week Saturday Sunday “weekday” day week day. current weekday variable coded 1 represents Sunday, 2 represents Monday, …., 7 represents Saturday.Create vector numbers corresponding two weekend days. Name vector create second vector numbers corresponding five weekday days.Use dplyr functions %% operator create new weekend_ind variable. can use following code chunk help %% :","code":"\nvecweekend <- c(1, 7)\nvecweekday <- 2:6 ## or c(2, 3, 4, 5, 6)\n1 %in% c(1, 2, 3, 4)\n#> [1] TRUE\n2 %in% c(1, 2, 3, 4)\n#> [1] TRUE\n\n2 %in% c(3, 4, 5, 6)\n#> [1] FALSE\nfitness_df |>\n  mutate(weekend_ind = case_when(weekday %in% vecweekend ~ \"weekend\",\n                                 weekday %in% vecweekday ~ \"weekday\")) |>\n  select(weekend_ind, everything())\n#> # A tibble: 993 × 11\n#>    weekend…¹ Start      activ…² dista…³ flights  steps month\n#>    <chr>     <date>       <dbl>   <dbl>   <dbl>  <dbl> <dbl>\n#>  1 weekday   2018-11-28    57.8   0.930       0  1885.    11\n#>  2 weekday   2018-11-29   509.    4.64       18  8953.    11\n#>  3 weekday   2018-11-30   599.    6.05       12 11665     11\n#>  4 weekend   2018-12-01   661.    6.80        6 12117     12\n#>  5 weekend   2018-12-02   527.    4.61        1  8925.    12\n#>  6 weekday   2018-12-03   550.    3.96        2  7205     12\n#>  7 weekday   2018-12-04   670.    6.60        5 12483.    12\n#>  8 weekday   2018-12-05   557.    4.91        6  9258.    12\n#>  9 weekday   2018-12-06   997.    7.50       13 14208     12\n#> 10 weekday   2018-12-07   533.    4.27        8  8269.    12\n#> # … with 983 more rows, 4 more variables: weekday <dbl>,\n#> #   dayofyear <dbl>, stepgoal <dbl>, weekday_cat <fct>, and\n#> #   abbreviated variable names ¹​weekend_ind, ²​active_cals,\n#> #   ³​distance\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n## can also use if_else, which is actually a little simpler in this case:\nfitness_df |> mutate(weekend_ind = if_else(weekday %in% vecweekend,\n  true = \"weekend\", false = \"weekday\")) |>\n  select(weekend_ind, everything())\n#> # A tibble: 993 × 11\n#>    weekend…¹ Start      activ…² dista…³ flights  steps month\n#>    <chr>     <date>       <dbl>   <dbl>   <dbl>  <dbl> <dbl>\n#>  1 weekday   2018-11-28    57.8   0.930       0  1885.    11\n#>  2 weekday   2018-11-29   509.    4.64       18  8953.    11\n#>  3 weekday   2018-11-30   599.    6.05       12 11665     11\n#>  4 weekend   2018-12-01   661.    6.80        6 12117     12\n#>  5 weekend   2018-12-02   527.    4.61        1  8925.    12\n#>  6 weekday   2018-12-03   550.    3.96        2  7205     12\n#>  7 weekday   2018-12-04   670.    6.60        5 12483.    12\n#>  8 weekday   2018-12-05   557.    4.91        6  9258.    12\n#>  9 weekday   2018-12-06   997.    7.50       13 14208     12\n#> 10 weekday   2018-12-07   533.    4.27        8  8269.    12\n#> # … with 983 more rows, 4 more variables: weekday <dbl>,\n#> #   dayofyear <dbl>, stepgoal <dbl>, weekday_cat <fct>, and\n#> #   abbreviated variable names ¹​weekend_ind, ²​active_cals,\n#> #   ³​distance\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names"},{"path":"coding-in-base-r.html","id":"chapexercise-6-S","chapter":" 8 Coding in Base R","heading":"8.6.4 Chapter Exercises S","text":"* Read data set use filter() remove rows missing metascores, missing median playtime, median playtime 0 hours.Note: usually don’t want remove missing values without valid reason. case, missing metascore means game wasn’t “major” enough get enough critic reviews, missing 0 hour median playtime means weren’t enough users uploaded playtime database. Therefore, analyses constructed games popular enough get enough reviews metacritic enough users upload median playtimes.* Make scatterplot median_playtime y-axis metascore x-axis filtered data set.* Something may notice many points directly overlap one another. common least one variables scatterplot discrete: metascore can take integer values case. Change geom_point() previous plot geom_jitter(). , use help write sentence geom_jitter() .geom_jitter() adds small amount “noise” data point points don’t overlap quite much.* Another option control point transparency alpha. geom_jitter() statement, change alpha can still see points, can tell plot lot points overlapping.* Label points median playtimes 1500 hours. may want use ggrepel package labels don’t overlap.","code":"\nvideogame_df <- read_csv(here(\"data/videogame_clean.csv\"))\nvideogame_nomiss <- videogame_df |>\n  filter(!is.na(median_playtime) &\n           !is.na(metascore) &\n           median_playtime != 0)\nggplot(data = videogame_nomiss, aes(x = metascore,\n                                    y = median_playtime)) + \n  geom_point()\nggplot(data = videogame_nomiss, aes(x = metascore,\n                                    y = median_playtime)) + \n  geom_jitter()\nggplot(data = videogame_nomiss, aes(x = metascore,\n                                    y = median_playtime)) + \n  geom_jitter(alpha = 0.4)\n## can see a lot of ponits have median playtimes close to 0\nlibrary(ggrepel)\nvideogame_long <- videogame_nomiss |> filter(median_playtime > 1500)\nggplot(data = videogame_nomiss,\n       aes(x = metascore, y = median_playtime)) + \n  geom_jitter(alpha = 0.4) +\n  geom_label_repel(data = videogame_long, aes(label = game))"},{"path":"coding-in-base-r.html","id":"rcode-6","chapter":" 8 Coding in Base R","heading":"8.7 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\nlibrary(here)\nvideogame_df <- read_csv(here(\"data/videogame_clean.csv\"))\nhead(videogame_df)\nvideogame_small <- videogame_df |> slice(1:100)\nggplot(data = videogame_small, aes(x = release_date, y = price)) +\n  geom_point() \n\nggplot(data = videogame_small, aes(x = release_date2, y = metascore)) +\n  geom_point(aes(colour = price_cat))\nhead(videogame_df)\nvideogame_df$game\nstr(videogame_df$game)\nclass(videogame_df$game)\nmean(videogame_df$game)\nvideogame_df |> summarise(maxgame = max(game))\nclass(videogame_df$meta_cat)\nclass(as.factor(videogame_df$meta_cat))\nvideogame_df <- videogame_df |>\n  mutate(meta_cat_factor = as.factor(meta_cat))\nstr(videogame_df$meta_cat_factor)\nstr(videogame_df$release_date)\nstr(videogame_df$release_date2)\nmedian(videogame_df$release_date2, na.rm = TRUE)\nmean(videogame_df$release_date2, na.rm = TRUE)\nstr(videogame_df$price)\nstr(videogame_df$price_cat)\nstr(as.factor(videogame_df$price_cat))\nvideogame_df <- videogame_df |>\n  mutate(price_factor = as.factor(price_cat)) \nggplot(data = videogame_df, aes(x = release_date2, y = metascore)) +\n  geom_point(aes(colour = price_factor))\nstr(videogame_df$playtime_miss)\nsum(videogame_df$playtime_miss)\nmean(videogame_df$playtime_miss)\nstr(videogame_df) ## look at the beginning to see \"tibble\"\nvideogame_df[5, 3]\nvideogame_df[ ,3] ## grab the third column\n\nvideogame_df[5, ] ## grab the fifth row\n3:7\n\nvideogame_df[ ,3:7] ## grab columns 3 through 7\n\nvideogame_df[3:7, ] ## grab rows 3 through 7\nvideogame_df[ ,c(1, 3, 4)] ## grab columns 1, 3, and 4\n\nvideogame_df[c(1, 3, 4), ] ## grab rows 1, 3, and 4\nvec1 <- c(1, 3, 2)\nvec2 <- c(\"b\", 1, 2)\nvec3 <- c(FALSE, FALSE, TRUE)\nstr(vec1); str(vec2); str(vec3)\nvideogame_df$metascore\nmetavec <- videogame_df$metascore\nmean(metavec, na.rm = TRUE)\nmetavec[100] ## 100th element is missing\ntestlist <- list(\"a\", 4, c(1, 4, 2, 6),\n                 tibble(x = c(1, 2), y = c(3, 2)))\ntestlist\nset.seed(15125141)\ntoy_df <- tibble(xvar = rnorm(100, 3, 4),\n                 yvar = rnorm(100, -5, 10),\n                 group1 = sample(c(\"A\", \"B\", \"C\"), size = 100, replace = TRUE),\n                 group2 = sample(c(\"Place1\", \"Place2\", \"Place3\"), size = 100,\n                                 replace = TRUE))\ntoy_df\ntable(toy_df$group1)\n\ntable(toy_df$group1, toy_df$group2)\nnrow(toy_df)\nsummary(toy_df$yvar)\ntoy_df |>\n  print(n = 60) ## print out 60 rows\ntoy_df |>\n  print(width = Inf) ## print out all of the columns"},{"path":"factors-with-forcats.html","id":"factors-with-forcats","chapter":" 9 Factors with forcats","heading":" 9 Factors with forcats","text":"Goals:Use forcats package change levels factors, re-order levels factors way makes tables graphs easier read.","code":""},{"path":"factors-with-forcats.html","id":"change-factor-levels","chapter":" 9 Factors with forcats","heading":"9.1 Change Factor Levels","text":"Data: pokemon_allgen.csv data set contains observations Pokemon first 6 Generations (first 6 games). 20 variable data set, , particular interest chapter areType 1, first Type characteristic Pokemon (factor 13 levels)Type 2, second Type characteristic Pokemon (factor 13 levels, NA Pokemon one type)Generation, generation Pokemon first appeared (factor 6 levels)Read data set read_csv(). , use mutate() statement make Generation_cat variable factor.One easy way get quick summary factor variable use group_by() n() within summarise() statement:","code":"\nlibrary(tidyverse)\nlibrary(here)\npokemon_df <- read_csv(here(\"data/pokemon_allgen.csv\")) |>\n  mutate(Generation_cat = factor(Generation))\npokemon_df |> group_by(`Type 1`) |>\n  summarise(counttype = n())\n#> # A tibble: 18 × 2\n#>    `Type 1` counttype\n#>    <chr>        <int>\n#>  1 Bug             75\n#>  2 Dark            31\n#>  3 Dragon          41\n#>  4 Electric        90\n#>  5 Fairy           18\n#>  6 Fighting        27\n#>  7 Fire            56\n#>  8 Flying           6\n#>  9 Ghost           58\n#> 10 Grass           73\n#> 11 Ground          42\n#> 12 Ice             24\n#> 13 Normal         108\n#> 14 Poison          30\n#> 15 Psychic         73\n#> 16 Rock            47\n#> 17 Steel           29\n#> 18 Water          119"},{"path":"factors-with-forcats.html","id":"fct_recode-to-rename-levels","chapter":" 9 Factors with forcats","heading":"9.1.1 fct_recode() to Rename Levels","text":"Now, let’s make bar plot examines many Legendary Pokemon first appear generation, using dplyr commands ’ve used simple geom_col():’ve discussed change many aspects ggplot2 graphs, haven’t discussed rename labels levels categorical variable, whether appear x-axis separate legend. easiest way rename levels factor using fct_recode(). Suppose, example, want relabel Generation number actual region corresponding game (Kanto, Johto, Hoenn, Sinnoh, Unova, Kalos). function fct_recode() takes name factor already present data set first argument series renaming schemes (new_name = “old_name”) remaining arguments.","code":"\npokemon_legend <- pokemon_df |> filter(Legendary == TRUE) |>\n  group_by(Generation_cat) |>\n  summarise(nlegend = n())\nggplot(data = pokemon_legend, aes(x = Generation_cat, y = nlegend)) +\n  geom_col()\npokemon_legend <- pokemon_legend |>\n  mutate(Generation_cat2 = fct_recode(Generation_cat, Kanto = \"1\",\n                                      Johto = \"2\", Hoenn = \"3\",\n                                      Sinnoh = \"4\", Unova = \"5\",\n                                      Kalos = \"6\")) |>\n  select(Generation_cat2, everything())\nhead(pokemon_legend)\n#> # A tibble: 6 × 3\n#>   Generation_cat2 Generation_cat nlegend\n#>   <fct>           <fct>            <int>\n#> 1 Kanto           1                    6\n#> 2 Johto           2                    5\n#> 3 Hoenn           3                   34\n#> 4 Sinnoh          4                   17\n#> 5 Unova           5                   27\n#> 6 Kalos           6                   13\nggplot(data = pokemon_legend,\n       aes(x = Generation_cat2, y = nlegend)) +\n  geom_col()"},{"path":"factors-with-forcats.html","id":"collapsing-many-levels-into-fewer-levels-with-fct_collapse","chapter":" 9 Factors with forcats","heading":"9.1.2 Collapsing Many Levels Into Fewer Levels with fct_collapse()","text":"Sometimes, might want collapse levels two factors single level. Pokemon data set, isn’t example really makes sense, , exercises, ’ll see good use function social survey data set. practice, can collapse Ice Dark type Pokemon new level called Coolest can collapse Poison, Fighting, Fire type Pokemon new level called Least_Cool.happens levels aren’t re-specified?","code":"\npokemon_long <- pokemon_df |> pivot_longer(c(`Type 1`, `Type 2`),\n                            names_to = \"Number\",\n                            values_to = \"Type\")\npokemon_long |>\n  mutate(new_type = fct_collapse(Type, Coolest = c(\"Ice\", \"Dark\"),\n                                 Least_Cool = c(\"Fire\", \"Fighting\", \"Poison\"))) |>\n  select(new_type, Type, everything())\n#> # A tibble: 1,894 × 22\n#>    new_type   Type     `#` Name   Total    HP Attack Defense\n#>    <fct>      <chr>  <dbl> <chr>  <dbl> <dbl>  <dbl>   <dbl>\n#>  1 Grass      Grass      1 Bulba…   318    45     49      49\n#>  2 Least_Cool Poison     1 Bulba…   318    45     49      49\n#>  3 Grass      Grass      2 Ivysa…   405    60     62      63\n#>  4 Least_Cool Poison     2 Ivysa…   405    60     62      63\n#>  5 Grass      Grass      3 Venus…   525    80     82      83\n#>  6 Least_Cool Poison     3 Venus…   525    80     82      83\n#>  7 Grass      Grass      3 Venus…   525    80     82      83\n#>  8 Least_Cool Poison     3 Venus…   525    80     82      83\n#>  9 Least_Cool Fire       4 Charm…   309    39     52      43\n#> 10 <NA>       <NA>       4 Charm…   309    39     52      43\n#> # … with 1,884 more rows, and 14 more variables:\n#> #   `Sp. Atk` <dbl>, `Sp. Def` <dbl>, Speed <dbl>,\n#> #   Generation <dbl>, Legendary <lgl>, id <chr>,\n#> #   identifier <chr>, height <dbl>, weight <dbl>,\n#> #   base_experience <dbl>, order <dbl>, is_default <dbl>,\n#> #   Generation_cat <fct>, Number <chr>\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names"},{"path":"factors-with-forcats.html","id":"exercise-7-1","chapter":" 9 Factors with forcats","heading":"9.1.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 9.4.dplyr function(s) also use create new levels created fct_collapse()? might little easier use fct_collapse()?dplyr function(s) also use create new levels created fct_collapse()? might little easier use fct_collapse()?* properly explore data set making graphs , , fact, double counting Pokemon data set (another example familiar data set ’re working advantageous: people familiar Pokemon know fewer 947 Pokemon Generations 1 6).* properly explore data set making graphs , , fact, double counting Pokemon data set (another example familiar data set ’re working advantageous: people familiar Pokemon know fewer 947 Pokemon Generations 1 6).Figure Pokemon double counted. , create new data set keeps one observation per Pokemon #.Create bar plot non-duplicated data set. results significantly changed?","code":""},{"path":"factors-with-forcats.html","id":"reorder-factor-levels","chapter":" 9 Factors with forcats","heading":"9.2 Reorder Factor Levels","text":"","code":""},{"path":"factors-with-forcats.html","id":"change-the-order-of-levels-by-a-quantitative-variable-with-fct_reorder","chapter":" 9 Factors with forcats","heading":"9.2.1 Change the Order of Levels by a Quantitative Variable with fct_reorder()","text":"might also interested re-ordering x y-axis particular graph order factors correspond , example, median quantitative variable level. reason want easiest see example. example, suppose want look common Pokemon types across first 6 generations. use non-duplicated data set previous section’s exercises, pivot data type one column, remove observations missing Type, correspond second Type Pokemon single Type:R order levels Type factor, default? might like ordered make graph readable?following code creates new factor variable called Type_ordered orders type count_type variable. fct_reorder() takes factor first argument numeric variable re-order factor second argument. bar plot reconstructed new variable.","code":"\npokemon_nodup <- pokemon_df |> group_by(`#`) |> slice(1) |>\n  ungroup()\npokemon_long <- pokemon_nodup |>\n  pivot_longer(c(`Type 1`, `Type 2`),\n               names_to = \"Number\",\n               values_to = \"Type\")\npokemon_sum <- pokemon_long |>\n  group_by(Type) |>\n  summarise(count_type = n()) |>\n  filter(!is.na(Type))\nggplot(data = pokemon_sum, aes(x = Type,\n                               y = count_type)) +\n  geom_col() +\n  coord_flip()  ## flips the x and y axes\npokemon_sum <- pokemon_sum |> \n  mutate(Type_ordered = fct_reorder(.f = Type, .x = count_type))\nggplot(data = pokemon_sum, aes(x = Type_ordered,\n                               y = count_type)) +\n  geom_col() +\n  coord_flip()"},{"path":"factors-with-forcats.html","id":"lollipop-plots","chapter":" 9 Factors with forcats","heading":"9.2.2 Lollipop Plots","text":"Lollipop plots popular alternative bar plots often look cleaner less ink. make lollipop plot R, specify two different geoms: geom_segment() form stick lollipop geom_point() form pop part lollipop. geom_segment() requires 4 aesthetics: x, xend, y, yend.fct_reorder() also works boxplots simple point plots show, example, median response level factor. following set plots investigate Defense stat changes different Pokemon typesThe following code makes point plot shows median defense type instead boxplots.Finally, can make lollipop plot median defense.preference boxplot graph, point plot, lollipop plot?New Data. gun_violence_us.csv data set obtained https://www.openintro.org/book/statdata/index.php?data=gun_violence_us contains following variables gun violence 2014:state, name U.S. statemortality_rate, number deaths gun violence per 100,000 peopleownership_rate, proportion adults gunregion, region U.S. (South, West, NE, MW)","code":"\nggplot(data = pokemon_sum, aes(x = Type_ordered,\n                               y = count_type)) +\n  geom_segment(aes(x = Type_ordered, xend = Type_ordered,\n                   y = 0, yend = count_type)) +\n  geom_point() +\n  coord_flip()\npokemon_long <- pokemon_long |>\n  filter(!is.na(Type)) |>\n  mutate(Type_Deford = fct_reorder(.f = Type, .x = Defense,\n                                   .fun = median))\nggplot(data = pokemon_long, aes(x = Type_Deford,\n                               y = Defense)) +\n  geom_boxplot() + \n  coord_flip()\npokemon_med <- pokemon_long |> group_by(Type_Deford) |>\n  summarise(med_def = median(Defense)) |>\n  mutate(Type_Deford = fct_reorder(.f = Type_Deford, .x = med_def,\n                                   .fun = median))\n\nggplot(data = pokemon_med, aes(x = med_def, y = Type_Deford)) +\n  geom_point()\nggplot(data = pokemon_med, aes(x = Type_Deford, y = med_def)) +\n  geom_segment(aes(xend = Type_Deford, y = 0, yend = med_def)) +\n  geom_point() +\n  coord_flip()\nmortality_df <- read_csv(here(\"data/gun_violence_us.csv\")) |>\n  mutate(region = factor(region))"},{"path":"factors-with-forcats.html","id":"re-leveling-by-two-quantitative-variables-with-fct_reorder2","chapter":" 9 Factors with forcats","heading":"9.2.3 Re-Leveling By Two Quantitative Variables with fct_reorder2()","text":"Suppose want investigate relationship mortality_rate ownership_rate using data set. Run following code create scatterplot mortality_rate vs. ownership_rate fitted linear regression lines region United States:Notice order levels legend. people prefer order actually match lines plot end, order alphabetical. achieve , can use fct_reorder2() change order factor levels:change order levels expect? fct_reorder2() actually looks points, lines, determining ordering. want levels match exactly, ’ll reorder levels manually fct_relevel():","code":"\nggplot(data = mortality_df,\n       aes(x = ownership_rate, y = mortality_rate, colour = region)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\nmortality_df <- mortality_df |>\n  mutate(region_2 = fct_reorder2(region,\n                                 .x = ownership_rate,\n                                 .y = mortality_rate))\nggplot(data = mortality_df,\n       aes(x = ownership_rate, y = mortality_rate, colour = region_2)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")"},{"path":"factors-with-forcats.html","id":"reordering-levels-manually-with-fct_relevel","chapter":" 9 Factors with forcats","heading":"9.2.4 Reordering Levels Manually with fct_relevel()","text":"Factors ordered alphabetically default. want precise control order levels factor, can use fct_relevel(), takes factor vector new levels inputs:Reordering levels factor manually might also useful fitting linear models. Recall , default, R makes reference group linear model first level alphabetically. ’d like different reference group, can reorder levels factor:","code":"\nmortality_df <- mortality_df |>\n  mutate(region_3 = fct_relevel(region, c(\"South\", \"West\", \"MW\", \"NE\")))\nggplot(data = mortality_df,\n       aes(x = ownership_rate, y = mortality_rate, colour = region_3)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\nmod <- lm(mortality_rate ~ ownership_rate + region, data = mortality_df)\nmod2 <- lm(mortality_rate ~ ownership_rate + region_2, data = mortality_df)\nmod3 <- lm(mortality_rate ~ ownership_rate + region_3, data = mortality_df)\nsummary(mod)\nsummary(mod2)\nsummary(mod3)"},{"path":"factors-with-forcats.html","id":"exercise-7-2","chapter":" 9 Factors with forcats","heading":"9.2.5 Exercises","text":"Make side--side boxplots pokemon data use ungroup() running following code.aren’t types ordered median defense anymore?.fun argument fct_reorder() controls Type factor ordered. Change specify ordering mean, max, min. ordering makes sense? ?","code":"\npokemon_nodup <- pokemon_df |> group_by(`#`) |> slice(1) ## |>\n  ## ungroup()\npokemon_long <- pokemon_nodup |>\n  pivot_longer(c(`Type 1`, `Type 2`),\n               names_to = \"Number\",\n               values_to = \"Type\")\n\npokemon_long <- pokemon_long |>\n  filter(!is.na(Type)) |>\n  mutate(Type_Deford = fct_reorder(.f = Type, .x = Defense,\n                                   .fun = median))\nggplot(data = pokemon_long, aes(x = Type_Deford,\n                               y = Defense)) +\n  geom_boxplot() + \n  coord_flip()"},{"path":"factors-with-forcats.html","id":"chapexercise-7","chapter":" 9 Factors with forcats","heading":"9.3 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 9.4.chapter exercises, use data set National Football League standings 2000 2020. Read data set :important variables use include:team, city team based inteam_name, name teamplayoffs, whether team made playoffs yearsb_winner, whether team won superbowl yearUse table() function table(name_of_data_frame$name_of_variable) make table team_name. useful use categorical variables give quick summary levels many times level appears data set.Use table() function table(name_of_data_frame$name_of_variable) make table team_name. useful use categorical variables give quick summary levels many times level appears data set.couple years ago, Washington Commanders team used known Washington Redskins. obvious racism name conveys, 2022, name changed Redskins Commanders. Use forcats function rename Redskins team_name Commanders. Note , usually, renaming new variable use forcats function, , oftentimes, makes sense just overwrite old variable using name mutate() statement.couple years ago, Washington Commanders team used known Washington Redskins. obvious racism name conveys, 2022, name changed Redskins Commanders. Use forcats function rename Redskins team_name Commanders. Note , usually, renaming new variable use forcats function, , oftentimes, makes sense just overwrite old variable using name mutate() statement.Use function tidyr combine team team_name single variable called franchise. may want specify sep = \" \" consistency city names.Use function tidyr combine team team_name single variable called franchise. may want specify sep = \" \" consistency city names.couple franchises national football league moved cities late 2010s. particular, San Diego Chargers became Los Angeles Chargers St. Louis Rams became Los Angeles Rams (another instance familiar context helpful : may taken much longer figure , known much NFL). Use forcats function put San Diego Chargers Los Angeles Chargers single level, San Diego LA Chargers, put St. Louis Rams Los Angeles Rams single level, St. Louis LA Rams.couple franchises national football league moved cities late 2010s. particular, San Diego Chargers became Los Angeles Chargers St. Louis Rams became Los Angeles Rams (another instance familiar context helpful : may taken much longer figure , known much NFL). Use forcats function put San Diego Chargers Los Angeles Chargers single level, San Diego LA Chargers, put St. Louis Rams Los Angeles Rams single level, St. Louis LA Rams.Using updated data set, create lollipop plot ten franchises made playoffs often. need work dplyr making plot.Using updated data set, create lollipop plot ten franchises made playoffs often. need work dplyr making plot.Customize lollipop plot changing way points look end / way “stems” lollipops look. may use https://r-graph-gallery.com/301-custom-lollipop-chart.html inspiration.Customize lollipop plot changing way points look end / way “stems” lollipops look. may use https://r-graph-gallery.com/301-custom-lollipop-chart.html inspiration.following old chapter exercises forcats: ’ve left case want extra practice!\nuse general social survey data set, forcats library R. Wikipedia page better understand data comes Wikipedia.variables self-explanatory, couple aren’t :partyid, political leaning anddenom, religious denomination (unfamiliar , can think “specific” subset particular religion).Note exercises R Data Science textbook.Load data set * Using forcats function, change name level str republican Weak republican change name level str democrat Weak democrat. names closely match levels Strong republican Strong democrat. , create table counts shows number respondents political party partyid.Note: Levels aren’t specified forcats function change.Note 2: naming something Weak republican, ’ll need use backticks since space level name.* Use forcats function partyid just 4 categories: (corresponding answer, Don’t know, party), Ind (corresponding Ind,near rep, Independent, Ind, near dem), Rep (corresponding Strong republican str republican), Dem (corresponding str democrat Strong democrat).* Use forcats function partyid just 4 categories: (corresponding answer, Don’t know, party), Ind (corresponding Ind,near rep, Independent, Ind, near dem), Rep (corresponding Strong republican str republican), Dem (corresponding str democrat Strong democrat).* Run code create following plot shows average number hours television people watch various religions.* Run code create following plot shows average number hours television people watch various religions., use forcats function create new variable data set reorders religion factor levels make lollipop plot religion watches television, average, top, religion watches least television, average, bottom.* Run code make following line plot shows age x-axis, proportion y-axis, coloured various marital statuses (married, divorced, widowed, etc.):, use forcats function make plot legend labels line better different coloured marital status lines (e.g. label widowed first appears legend, label married second, etc.).haven’t talked much creating two-way tables (contingency tables). generally quite difficult make tidyverse functions, can use base R table() prop.table() functions make .Using data year 2014, run following code make 4 two-way tables party_small variable constructed earlier race:Use help ?prop.table figure three tables constructed.table think informative? conclusions help draw?","code":"\nlibrary(tidyverse)\nlibrary(here)\nstandings_df <- read_csv(here(\"data/standings.csv\"))\n#> Rows: 638 Columns: 15\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (4): team, team_name, playoffs, sb_winner\n#> dbl (11): year, wins, loss, points_for, points_against, ...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nstandings_df\n#> # A tibble: 638 × 15\n#>    team    team_…¹  year  wins  loss point…² point…³ point…⁴\n#>    <chr>   <chr>   <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>\n#>  1 Miami   Dolphi…  2000    11     5     323     226      97\n#>  2 Indian… Colts    2000    10     6     429     326     103\n#>  3 New Yo… Jets     2000     9     7     321     321       0\n#>  4 Buffalo Bills    2000     8     8     315     350     -35\n#>  5 New En… Patrio…  2000     5    11     276     338     -62\n#>  6 Tennes… Titans   2000    13     3     346     191     155\n#>  7 Baltim… Ravens   2000    12     4     333     165     168\n#>  8 Pittsb… Steele…  2000     9     7     321     255      66\n#>  9 Jackso… Jaguars  2000     7     9     367     327      40\n#> 10 Cincin… Bengals  2000     4    12     185     359    -174\n#> # … with 628 more rows, 7 more variables:\n#> #   margin_of_victory <dbl>, strength_of_schedule <dbl>,\n#> #   simple_rating <dbl>, offensive_ranking <dbl>,\n#> #   defensive_ranking <dbl>, playoffs <chr>,\n#> #   sb_winner <chr>, and abbreviated variable names\n#> #   ¹​team_name, ²​points_for, ³​points_against,\n#> #   ⁴​points_differential\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\nlibrary(tidyverse)\ngss_cat\nrelig_summary <- gss_cat |>\n  group_by(relig) |>\n  summarise(\n    age = mean(age, na.rm = TRUE),\n    tvhours = mean(tvhours, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(data = relig_summary, aes(tvhours, relig)) +\n  geom_point()\nby_age <- gss_cat |>\n  filter(!is.na(age)) |>\n  count(age, marital) |>\n  group_by(age) |>\n  mutate(prop = n / sum(n))\n\nggplot(by_age, aes(age, prop,\n                  colour = marital)) +\n  geom_line(na.rm = TRUE) +\n  labs(colour = \"marital\")\ngss_cat <- gss_cat |> mutate(party_small = fct_collapse(partyid,\n                                              Other = c(\"No answer\", \"Don't know\", \"Other party\"),\n                                              Ind = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n                                              Rep = c(\"Strong republican\", \"Not str republican\"),\n                                              Dem = c(\"Not str democrat\", \"Strong democrat\")))\n\ngss_recent <- gss_cat |> filter(year == 2014)\n\ntab1 <- table(gss_recent$party_small, gss_recent$race)\ntab1\n#>        \n#>         Other Black White Not applicable\n#>   Other     8    12    68              0\n#>   Rep      22    17   498              0\n#>   Ind     152   108   828              0\n#>   Dem      80   249   496              0\nprop.table(tab1)\n#>        \n#>               Other       Black       White Not applicable\n#>   Other 0.003152088 0.004728132 0.026792750    0.000000000\n#>   Rep   0.008668243 0.006698188 0.196217494    0.000000000\n#>   Ind   0.059889677 0.042553191 0.326241135    0.000000000\n#>   Dem   0.031520883 0.098108747 0.195429472    0.000000000\nprop.table(tab1, margin = 1)\n#>        \n#>              Other      Black      White Not applicable\n#>   Other 0.09090909 0.13636364 0.77272727     0.00000000\n#>   Rep   0.04096834 0.03165736 0.92737430     0.00000000\n#>   Ind   0.13970588 0.09926471 0.76102941     0.00000000\n#>   Dem   0.09696970 0.30181818 0.60121212     0.00000000\nprop.table(tab1, margin = 2)\n#>        \n#>              Other      Black      White Not applicable\n#>   Other 0.03053435 0.03108808 0.03597884               \n#>   Rep   0.08396947 0.04404145 0.26349206               \n#>   Ind   0.58015267 0.27979275 0.43809524               \n#>   Dem   0.30534351 0.64507772 0.26243386"},{"path":"factors-with-forcats.html","id":"solutions-7","chapter":" 9 Factors with forcats","heading":"9.4 Exercise Solutions","text":"","code":""},{"path":"factors-with-forcats.html","id":"change-factor-levels-s","chapter":" 9 Factors with forcats","heading":"9.4.1 Change Factor Levels S","text":"* properly explore data set making graphs , , fact, double counting Pokemon data set (another example familiar data set ’re working advantageous: people familiar Pokemon know fewer 947 Pokemon Generations 1 6).Figure Pokemon double counted. , create new data set keeps one observation per Pokemon #.","code":"\npokemon_nodup <- pokemon_df |> group_by(`#`) |> slice(1) |>\n  ungroup()"},{"path":"factors-with-forcats.html","id":"reorder-factor-levels-s","chapter":" 9 Factors with forcats","heading":"9.4.2 Reorder Factor Levels S","text":"","code":""},{"path":"factors-with-forcats.html","id":"chapexercise-7-S","chapter":" 9 Factors with forcats","heading":"9.4.3 Chapter Exercises S","text":"* Using forcats function, change name level str republican Weak republican change name level str democrat Weak democrat. names closely match levels Strong republican Strong democrat. , create table counts shows number respondents political party partyid.Note: Levels aren’t specified forcats function change.Note 2: naming something Weak republican, ’ll need use backticks since space level name.* Use forcats function partyid just 4 categories: (corresponding answer, Don’t know, party), Ind (corresponding Ind,near rep, Independent, Ind, near dem), Rep (corresponding Strong republican str republican), Dem (corresponding str democrat Strong democrat).* Run code create following plot shows average number hours television people watch various religions., use forcats function create new variable data set reorders religion factor levels remake barplot religion watches television, average, top, religion watches least television, average, bottom.* Run code make following line plot shows age x-axis, proportion y-axis, coloured various marital statuses (married, divorced, widowed, etc.):, use forcats function make plot legend labels line better different coloured marital status lines (e.g. label widowed first appears legend, label married second, etc.).","code":"\ngss_cat |>\n  mutate(partyid_new = fct_recode(partyid,\n                                  `Weak republican` = \"Not str republican\",\n                                  `Weak democrat` = \"Not str democrat\")) |> group_by(partyid_new) |>\n  summarise(ncount = n())\ngss_cat <- gss_cat |> mutate(party_small = fct_collapse(partyid,\n                                              Other = c(\"No answer\", \"Don't know\", \"Other party\"),\n                                              Ind = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n                                              Rep = c(\"Strong republican\", \"Not str republican\"),\n                                              Dem = c(\"Not str democrat\", \"Strong democrat\")))\nrelig_summary <- gss_cat |>\n  group_by(relig) |>\n  summarise(\n    age = mean(age, na.rm = TRUE),\n    tvhours = mean(tvhours, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(data = relig_summary, aes(tvhours, relig)) +\n  geom_point()\nrelig_summary <- relig_summary |>\n  mutate(relig = fct_reorder(relig, tvhours))\nggplot(data = relig_summary, aes(x = relig, y = tvhours)) +\n  geom_segment(aes(x = relig, xend = relig, y = 0, yend = tvhours)) +\n  geom_point() +\n  coord_flip()\nby_age <- gss_cat |>\n  filter(!is.na(age)) |>\n  count(age, marital) |>\n  group_by(age) |>\n  mutate(prop = n / sum(n))\n\nggplot(by_age, aes(age, prop,\n                  colour = marital)) +\n  geom_line(na.rm = TRUE) +\n  labs(colour = \"marital\")\nby_age2 <- by_age |> ungroup() |>\n  mutate(marital2 = fct_reorder2(marital, .x = age, .y = prop))\nggplot(by_age2, aes(age, prop,\n                  colour = marital2)) +\n  geom_line(na.rm = TRUE) +\n  labs(colour = \"marital\") +\n  scale_colour_viridis_d()"},{"path":"factors-with-forcats.html","id":"rcode-7","chapter":" 9 Factors with forcats","heading":"9.5 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\nlibrary(here)\npokemon_df <- read_csv(here(\"data/pokemon_allgen.csv\")) |>\n  mutate(Generation_cat = factor(Generation))\npokemon_df |> group_by(`Type 1`) |>\n  summarise(counttype = n())\npokemon_legend <- pokemon_df |> filter(Legendary == TRUE) |>\n  group_by(Generation_cat) |>\n  summarise(nlegend = n())\nggplot(data = pokemon_legend, aes(x = Generation_cat, y = nlegend)) +\n  geom_col()\npokemon_legend <- pokemon_legend |>\n  mutate(Generation_cat2 = fct_recode(Generation_cat, Kanto = \"1\",\n                                      Johto = \"2\", Hoenn = \"3\",\n                                      Sinnoh = \"4\", Unova = \"5\",\n                                      Kalos = \"6\")) |>\n  select(Generation_cat2, everything())\nhead(pokemon_legend)\nggplot(data = pokemon_legend,\n       aes(x = Generation_cat2, y = nlegend)) +\n  geom_col()\npokemon_long <- pokemon_df |> pivot_longer(c(`Type 1`, `Type 2`),\n                            names_to = \"Number\",\n                            values_to = \"Type\")\npokemon_long |>\n  mutate(new_type = fct_collapse(Type, Coolest = c(\"Ice\", \"Dark\"),\n                                 Least_Cool = c(\"Fire\", \"Fighting\", \"Poison\"))) |>\n  select(new_type, Type, everything())\npokemon_nodup <- pokemon_df |> group_by(`#`) |> slice(1) |>\n  ungroup()\npokemon_long <- pokemon_nodup |>\n  pivot_longer(c(`Type 1`, `Type 2`),\n               names_to = \"Number\",\n               values_to = \"Type\")\npokemon_sum <- pokemon_long |>\n  group_by(Type) |>\n  summarise(count_type = n()) |>\n  filter(!is.na(Type))\nggplot(data = pokemon_sum, aes(x = Type,\n                               y = count_type)) +\n  geom_col() +\n  coord_flip()  ## flips the x and y axes\npokemon_sum <- pokemon_sum |> \n  mutate(Type_ordered = fct_reorder(.f = Type, .x = count_type))\nggplot(data = pokemon_sum, aes(x = Type_ordered,\n                               y = count_type)) +\n  geom_col() +\n  coord_flip()\nggplot(data = pokemon_sum, aes(x = Type_ordered,\n                               y = count_type)) +\n  geom_segment(aes(x = Type_ordered, xend = Type_ordered,\n                   y = 0, yend = count_type)) +\n  geom_point() +\n  coord_flip()\npokemon_long <- pokemon_long |>\n  filter(!is.na(Type)) |>\n  mutate(Type_Deford = fct_reorder(.f = Type, .x = Defense,\n                                   .fun = median))\nggplot(data = pokemon_long, aes(x = Type_Deford,\n                               y = Defense)) +\n  geom_boxplot() + \n  coord_flip()\npokemon_med <- pokemon_long |> group_by(Type_Deford) |>\n  summarise(med_def = median(Defense)) |>\n  mutate(Type_Deford = fct_reorder(.f = Type_Deford, .x = med_def,\n                                   .fun = median))\n\nggplot(data = pokemon_med, aes(x = med_def, y = Type_Deford)) +\n  geom_point()\nggplot(data = pokemon_med, aes(x = Type_Deford, y = med_def)) +\n  geom_segment(aes(xend = Type_Deford, y = 0, yend = med_def)) +\n  geom_point() +\n  coord_flip()\nmortality_df <- read_csv(here(\"data/gun_violence_us.csv\")) |>\n  mutate(region = factor(region))\nggplot(data = mortality_df,\n       aes(x = ownership_rate, y = mortality_rate, colour = region)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\nmortality_df <- mortality_df |>\n  mutate(region_2 = fct_reorder2(region,\n                                 .x = ownership_rate,\n                                 .y = mortality_rate))\nggplot(data = mortality_df,\n       aes(x = ownership_rate, y = mortality_rate, colour = region_2)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\nmortality_df <- mortality_df |>\n  mutate(region_3 = fct_relevel(region, c(\"South\", \"West\", \"MW\", \"NE\")))\nggplot(data = mortality_df,\n       aes(x = ownership_rate, y = mortality_rate, colour = region_3)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\nmod <- lm(mortality_rate ~ ownership_rate + region, data = mortality_df)\nmod2 <- lm(mortality_rate ~ ownership_rate + region_2, data = mortality_df)\nmod3 <- lm(mortality_rate ~ ownership_rate + region_3, data = mortality_df)\nsummary(mod)\nsummary(mod2)\nsummary(mod3)"},{"path":"data-ethics.html","id":"data-ethics","chapter":" 10 Data Ethics","heading":" 10 Data Ethics","text":"Goals:explain data ethics important issue data science using couple examples.describe issues data privacy explain , just data doesn’t individual’s name doesn’t necessarily make data truly anonymous.explain difference hypothesis confirmation hypothesis exploration distinction matters.","code":""},{"path":"data-ethics.html","id":"ethical-examples","chapter":" 10 Data Ethics","heading":"10.1 Ethical Examples","text":"’ve tried interweave issues ethics throughout many examples used already course, purpose section put data ethics direct focus.questions consider data collected, especially data collected human subjects:gets use data purposes?gets use data purposes?collected data organization conflicts interest?collected data organization conflicts interest?presentation analysis harmful particular person group people? benefits analysis?presentation analysis harmful particular person group people? benefits analysis?subjects data collection procedure treated respectfully given consent information collected?\nconsent needed ? example, looked data professional athletes. need provide consent consent inherent spotlight?\n’ve also scraped data SLU’s athletics website look data pertaining ! ethical? line wouldn’t cross pertaining data collected named, individual people?\nsubjects data collection procedure treated respectfully given consent information collected?consent needed ? example, looked data professional athletes. need provide consent consent inherent spotlight?consent needed ? example, looked data professional athletes. need provide consent consent inherent spotlight?’ve also scraped data SLU’s athletics website look data pertaining ! ethical? line wouldn’t cross pertaining data collected named, individual people?’ve also scraped data SLU’s athletics website look data pertaining ! ethical? line wouldn’t cross pertaining data collected named, individual people?","code":""},{"path":"data-ethics.html","id":"exercise-9-1","chapter":" 10 Data Ethics","heading":"10.1.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 10.5.Read Sections 8.1 - 8.3 Modern Data Science R. , write one paragraph summary reading might pertain way use interpret data.Read Sections 8.1 - 8.3 Modern Data Science R. , write one paragraph summary reading might pertain way use interpret data.Data Feminism related data ethics, though two terms certainly synonymous. Recently, Catherine D’Ignazio Lauren F. Klein published book called Data Feminism https://datafeminism.io/ Data Feminism related data ethics, though two terms certainly synonymous. Recently, Catherine D’Ignazio Lauren F. Klein published book called Data Feminism https://datafeminism.io/ Read following blog post Data Feminism, focusing section Missing Data. https://teachdatascience.com/datafem/ .Pick one example bulleted list write 2 sentence explanation explains might important acknowledge missing data analysis.Choose 1 following two articles readhttps://www.theguardian.com/world/2017/sep/08/ai-gay-gaydar-algorithm-facial-recognition-criticism-stanford  use data LGBTQIA+ communityhttps://towardsdatascience.com/5-steps--take---antiracist-data-scientist-89712877c214  anti-racist data practices.LGBTQIA+ article, write two sentence summary side argument research facial recognition software identify members LGBTQ+ community occur, even viewpoint isn’t ., write two sentence summary side argument research facial recognition software identify members LGBTQ+ community okay long results used responsibly, even viewpoint isn’t .anti-racist data science article, Step 2, pick News Article read first paragraphs. Describe, 2-3 sentences, article’s example bias incidence bias matters.","code":""},{"path":"data-ethics.html","id":"data-privacy","chapter":" 10 Data Ethics","heading":"10.2 Data Privacy","text":"Related data ethics idea data privacy.data private data public? examples, may seem obvious, others (e.g. data government agency collects data people), answer might clear cut.anonymous data truly anonymous?type consent provided collecting data someone?explore issues following exercises.","code":""},{"path":"data-ethics.html","id":"exercise-9-2","chapter":" 10 Data Ethics","heading":"10.2.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 10.5.anonymous SLU’s course evaluations? -class activity investigate .anonymous SLU’s course evaluations? -class activity investigate .Suppose collect data students Data Science class. setting () (d), suppose give data set following variables collected student class. option, , ethically okay share data students class.Suppose collect data students Data Science class. setting () (d), suppose give data set following variables collected student class. option, , ethically okay share data students class.current grade time spent Canvas.current grade time spent Canvas.current grade, class year, whether student stat majorcurrent grade, class year, whether student stat majorfavorite R package, whether student took STAT 213, whether student took CS 140, Majorfavorite R package, whether student took STAT 213, whether student took CS 140, Majorfavorite R package, whether student took STAT 213, whether student took CS 140, current grade coursefavorite R package, whether student took STAT 213, whether student took CS 140, current grade course","code":""},{"path":"data-ethics.html","id":"hypothesis-generation-vs.-confirmation","chapter":" 10 Data Ethics","heading":"10.3 Hypothesis Generation vs. Confirmation","text":"focused hypothesis generation data sets particular course. Read following two articles explain difference hypothesis generation hypothesis confirmation:Read following two short articles, one textbook one another source:https://r4ds..co.nz/model-intro.html#hypothesis-generation-vs.-hypothesis-confirmationhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC6718169/","code":""},{"path":"data-ethics.html","id":"exercise-9-3","chapter":" 10 Data Ethics","heading":"10.3.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 10.5.Explain difference hypothesis generation hypothesis confirmation.Explain difference hypothesis generation hypothesis confirmation.many times can use single observation hypothesis generation? hypothesis confirmation?many times can use single observation hypothesis generation? hypothesis confirmation?following questions, pertaining someone’s fitness, sound suitable answered Hypothesis Exploration? Hypothesis Confirmation?following questions, pertaining someone’s fitness, sound suitable answered Hypothesis Exploration? Hypothesis Confirmation?want know , average, person exercises weekends weekdays, questions interest.want know , average, person exercises weekends weekdays, questions interest.want look general trends person’s step count try determine various events influenced step count.want look general trends person’s step count try determine various events influenced step count.want know person exercises winter summer, also like investigate seasonal trends.want know person exercises winter summer, also like investigate seasonal trends.Note: Prediction different hypothesis confirmation, typically don’t really care variables associated response. want model gives “best” predictions. , goal prediction, typically lot freedom many times can “use” single observation. talk little prediction later semester.","code":""},{"path":"data-ethics.html","id":"chapexercise-9","chapter":" 10 Data Ethics","heading":"10.4 Chapter Exercises","text":"chapter exercises chapter.","code":""},{"path":"data-ethics.html","id":"solutions-9","chapter":" 10 Data Ethics","heading":"10.5 Exercise Solutions","text":"exercise solutions chapter.","code":""},{"path":"data-import.html","id":"data-import","chapter":" 11 Data Import","heading":" 11 Data Import","text":"Goals:Use readr read data R .csv, .txt, .tsv files.Use readr read data R .csv, .txt, .tsv files.Use rvest scrape data public websites.Use rvest scrape data public websites.Use jsonlite read data JSON (Java Script Object Notation) files.Use jsonlite read data JSON (Java Script Object Notation) files.","code":""},{"path":"data-import.html","id":"readr-to-read-in-data","chapter":" 11 Data Import","heading":"11.1 readr to Read in Data","text":"now, mostly worked data “R Ready”: meaning nice .csv file read R easily read_csv() readr package. begin looking options read_csv() function move formats .csv data commonly stored .","code":""},{"path":"data-import.html","id":"read_csv-options","chapter":" 11 Data Import","heading":"11.1.1 read_csv() Options","text":"mtcarsex.csv observations different car models variables include things like gas mileage, number cylinders, etc. Read mtcarsex.csv data set following code. , examine data set head().notice data set seems odd? Open .csv file Excel program examine data set outside R.Type ?read_csv bottom-left window look options read_csv(). particular, use na skip arguments fix reading.Let’s start skip aren’t reading first two rows data set:looks better, still couple problems. notice?Go help read na argument. Let’s add option fix missing value issue.Now look classes variable. classes look like incorrect?’ve talked re-specify classes variables using mutate() .factor() .Date() .numeric() functions, sometimes ’s easier just respecify class reading data. Notice , use read_csv(), R gives us message column types. actually argument read_csv() called col_types. can add |> spec() piping statement read_csv() statement tell R print col_types ’s easy us copy paste read_csv() change classes.example, notice cyl = col_double() changed cyl = col_factor() code chunk :Finally, two rows missing values. aren’t providing anything useful can slice() :many possible file formats data storage. example, data set called oscars.tsv, tab-separated file. can read read_tsv() instead read_csv().’ll able work .txt files Excel files Exercises. Check https://rawgit.com/rstudio/cheatsheets/master/data-import.pdf data import cheatsheet.final issue discuss section occurs data set units within cells. Consider earlier example used reprex section:parse_number() function really useful just want number (commas, units, etc.). function often paired mutate() since creating new variable:","code":"\nlibrary(tidyverse)\nlibrary(here)\ncars_df <- read_csv(here(\"data/mtcarsex.csv\"))\nhead(cars_df)\n#> # A tibble: 6 × 11\n#>   This is …¹ ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9 \n#>   <chr>      <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr>\n#> 1 \"I'm a na… <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n#> 2 \"mpg\"      cyl   disp  hp    drat  wt    qsec  vs    am   \n#> 3  <NA>      <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n#> 4  <NA>      <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n#> 5 \"-999\"     6     160   110   3.9   2.62  16.46 0     1    \n#> 6 \"21\"       6     160   110   3.9   2.875 17.02 0     1    \n#> # … with 2 more variables: ...10 <chr>, ...11 <chr>, and\n#> #   abbreviated variable name\n#> #   ¹​`This is a data set about cars.`\n#> # ℹ Use `colnames()` to see all variable names\ncars_df <- read_csv(here(\"data/mtcarsex.csv\"), skip = 2)\n## first two lines will be skipped\nhead(cars_df)\n#> # A tibble: 6 × 11\n#>      mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n#>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n#> 1   NA      NA    NA    NA NA    NA     NA      NA    NA\n#> 2   NA      NA    NA    NA NA    NA     NA      NA    NA\n#> 3 -999       6   160   110  3.9   2.62  16.5     0     1\n#> 4   21       6   160   110  3.9   2.88  17.0     0     1\n#> 5   22.8     4   108    93  3.85  2.32  18.6     1     1\n#> 6   21.4     6   258   110  3.08  3.22  19.4     1     0\n#> # … with 2 more variables: gear <dbl>, carb <dbl>\n#> # ℹ Use `colnames()` to see all variable names\ncars_df <- read_csv(here(\"data/mtcarsex.csv\"), na = c(\"NA\", \"-999\"), skip = 2)\nhead(cars_df)\n#> # A tibble: 6 × 11\n#>     mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n#>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n#> 1  NA      NA    NA    NA NA    NA     NA      NA    NA\n#> 2  NA      NA    NA    NA NA    NA     NA      NA    NA\n#> 3  NA       6   160   110  3.9   2.62  16.5     0     1\n#> 4  21       6   160   110  3.9   2.88  17.0     0     1\n#> 5  22.8     4   108    93  3.85  2.32  18.6     1     1\n#> 6  21.4     6   258   110  3.08  3.22  19.4     1     0\n#> # … with 2 more variables: gear <dbl>, carb <dbl>\n#> # ℹ Use `colnames()` to see all variable names\nread_csv(here(\"data/mtcarsex.csv\"), na = c(\"NA\", \"-999\"), skip = 2) |>\n  spec()\n#> Rows: 34 Columns: 11\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> dbl (11): mpg, cyl, disp, hp, drat, wt, qsec, vs, am, ge...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n#> cols(\n#>   mpg = col_double(),\n#>   cyl = col_double(),\n#>   disp = col_double(),\n#>   hp = col_double(),\n#>   drat = col_double(),\n#>   wt = col_double(),\n#>   qsec = col_double(),\n#>   vs = col_double(),\n#>   am = col_double(),\n#>   gear = col_double(),\n#>   carb = col_double()\n#> )\ncars_df <- read_csv(here(\"data/mtcarsex.csv\"), na = c(NA, \"-999\"), skip = 2,\n  col_types = cols(\n  mpg = col_double(),\n  cyl = col_factor(),\n  disp = col_double(),\n  hp = col_double(),\n  drat = col_double(),\n  wt = col_double(),\n  qsec = col_double(),\n  vs = col_factor(),\n  am = col_double(),\n  gear = col_double(),\n  carb = col_double()\n))\ncars_df <- read_csv(here(\"data/mtcarsex.csv\"), na = c(\"NA\", \"-999\"), skip = 2,\n  col_types = cols(\n  mpg = col_double(),\n  cyl = col_factor(),\n  disp = col_double(),\n  hp = col_double(),\n  drat = col_double(),\n  wt = col_double(),\n  qsec = col_double(),\n  vs = col_factor(),\n  am = col_double(),\n  gear = col_double(),\n  carb = col_double()\n)) |>\n  slice(-(1:2))\nhead(cars_df)\n#> # A tibble: 6 × 11\n#>     mpg cyl    disp    hp  drat    wt  qsec vs       am\n#>   <dbl> <fct> <dbl> <dbl> <dbl> <dbl> <dbl> <fct> <dbl>\n#> 1  NA   6       160   110  3.9   2.62  16.5 0         1\n#> 2  21   6       160   110  3.9   2.88  17.0 0         1\n#> 3  22.8 4       108    93  3.85  2.32  18.6 1         1\n#> 4  21.4 6       258   110  3.08  3.22  19.4 1         0\n#> 5  NA   8       360   175  3.15  3.44  17.0 0         0\n#> 6  18.1 6       225   105  2.76  3.46  20.2 1         0\n#> # … with 2 more variables: gear <dbl>, carb <dbl>\n#> # ℹ Use `colnames()` to see all variable names\noscars_df <- read_tsv(here(\"data/oscars.tsv\"))\nhead(oscars_df)\n#> # A tibble: 6 × 51\n#>   FilmName    Oscar…¹ Durat…² Rating Direc…³ Direc…⁴ Oscar…⁵\n#>   <chr>         <dbl>   <dbl>  <dbl> <chr>     <dbl>   <dbl>\n#> 1 Crash          2006     113      4 Haggis        0       1\n#> 2 Brokeback …    2006     134      4 Lee           0       0\n#> 3 Capote         2006     114      4 Miller        0       0\n#> 4 Good Night…    2006      93      2 Clooney       0       0\n#> 5 Munich         2006     164      4 Spielb…       0       0\n#> 6 The Depart…    2007     151      4 Scorse…       0       1\n#> # … with 44 more variables: GenreName <chr>,\n#> #   Genre_Drama <dbl>, Genre_Bio <dbl>, CountryName <chr>,\n#> #   ForeignandUSA <dbl>, ProductionName <chr>,\n#> #   ProductionCompany <dbl>, BudgetRevised <chr>,\n#> #   Budget <chr>, DomesticBoxOffice <dbl>,\n#> #   WorldwideRevised <dbl>, WorldwideBoxOffice <dbl>,\n#> #   DomesticPercent <dbl>, LimitedOpeningWnd <dbl>, …\n#> # ℹ Use `colnames()` to see all variable names\ntest_df <- read_csv(here(\"data/parsedf.csv\"))\nhead(test_df)\n#> # A tibble: 3 × 2\n#>   x                   y\n#>   <chr>           <dbl>\n#> 1 20,000 dollars      1\n#> 2 40 dollars          2\n#> 3 only 13 dollars     3\ntest_df |> mutate(x2 = parse_number(x))\n#> # A tibble: 3 × 3\n#>   x                   y    x2\n#>   <chr>           <dbl> <dbl>\n#> 1 20,000 dollars      1 20000\n#> 2 40 dollars          2    40\n#> 3 only 13 dollars     3    13"},{"path":"data-import.html","id":"exercise-8-2","chapter":" 11 Data Import","heading":"11.1.2 Exercises","text":"Exercises marked * indicate exercise solution end chapter 11.5.* birthdays.txt file information birthdays various animals Animal Crossing island. also columns Animal’s Name, Animal Type, long animal lived island (weeks). Click file open look format data.Start following code chunk use options read_delim() read data (?read_delim). delim argument ’s already provided specifies delimiter (separator) ’ll use -, opposed , example, , .csv file. Arguments may need change includeskipcol_namesnatrim_wscol_types* Another common format data stored Excel file. Often, ’s easiest just save Excel file .csv file read using read_csv(). , sometimes route can difficult (example, Excel file thousands sheets). read directly Excel, ’ll need install readxl install.packages(\"readxl\"). installed, load package library(readxl), read first sheet evals_prof.xlsx data set, similar data set one used Project 2, read_excel() function.* Another common format data stored Excel file. Often, ’s easiest just save Excel file .csv file read using read_csv(). , sometimes route can difficult (example, Excel file thousands sheets). read directly Excel, ’ll need install readxl install.packages(\"readxl\"). installed, load package library(readxl), read first sheet evals_prof.xlsx data set, similar data set one used Project 2, read_excel() function.* Now, read second sheet Excel file, using help file ?read_excel change one arguments.* Now, read second sheet Excel file, using help file ?read_excel change one arguments.","code":"\nlibrary(tidyverse)\ndf <- read_delim(here(\"data/birthdays.txt\"), delim = \" - \")\nhead(df)"},{"path":"data-import.html","id":"data-scraping-with-rvest","chapter":" 11 Data Import","heading":"11.2 Data Scraping with rvest","text":"Sometimes, might want data public website isn’t provided file format. obtain data, ’ll need use web scraping, term just means “getting data website.” easiest way R rvest package. Note spend entire semester talking web scraping, focus websites scraping data “easy” won’t give us major errors.Go following website suppose wanted table gun violence statistics R: https://en.wikipedia.org/wiki/Gun_violence_in_the_United_States_by_state. try copy-pasting table Excel reading data set read_excel(). Depending format table, strategy may work may . Another way scrape directly rvest. Additionally, website continually updates (standings sports league, enrollment data school, best-selling products company, etc.), scraping much convenient, don’t need continually copy-paste updated data.following code chunk, read_html() reads entire html file url provided html_nodes() extracts tables website.’ll see , example, 3 tables provided. tables stored list can reference first table using [[1]], second table using [[2]], etc. purposes class, figure 3 tables one actually want using trial error.html_table() function converts table data.frame object.3 tables one want use analysis gun violence United States?another example, consider scraping data SLU’s athletics page. particular, suppose want analysis SLU’s baseball team.Go following website look table data want scrape: https://saintsathletics.com/sports/baseball/stats/2021.looking website, use following code scrape data set.’s now 72 different tables! See can figure first tables coming website.","code":"\nlibrary(tidyverse)\nlibrary(rvest)\n\n## provide the URL and name it something (in this case, url).\nurl <- \"https://en.wikipedia.org/wiki/Gun_violence_in_the_United_States_by_state\"\n\n## convert the html code into something R can read\nh <- read_html(url)\n\n## grabs the tables\ntab <- h |> html_nodes(\"table\")\ntest1 <- tab[[1]] |> html_table()\ntest2 <- tab[[2]] |> html_table()\ntest3 <- tab[[3]] |> html_table()\n\nhead(test1)\nhead(test2)\nhead(test3)\nurl <- \"https://saintsathletics.com/sports/baseball/stats/2021\"\nh <- read_html(url)\ntab <- h |> html_nodes(\"table\")\ntab\nobj <- tab[[1]] |> html_table(fill = TRUE)\nhead(obj)\ntail(obj)\nobj2 <- tab[[2]] |> html_table(fill = TRUE)\nhead(obj2)\ntail(obj2)"},{"path":"data-import.html","id":"exercise-8-3","chapter":" 11 Data Import","heading":"11.2.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 11.5.Choose topic/person/place/etc. interests tables Wikipedia scrape table related topic.Choose topic/person/place/etc. interests tables Wikipedia scrape table related topic.* SLU keeps track diversity faculty time makes data public following website: https://www.stlawu.edu/offices/institutional-research/faculty-diversity. Use rvest scrape data tables R.* SLU keeps track diversity faculty time makes data public following website: https://www.stlawu.edu/offices/institutional-research/faculty-diversity. Use rvest scrape data tables R.Hint: may need use extra argument html_table() like fill.","code":""},{"path":"data-import.html","id":"json-files-with-jsonlite","chapter":" 11 Data Import","heading":"11.3 JSON Files with jsonlite","text":"final common data format discuss JSON (JavaScript Object Notation). cover basics JSON data use jsonlite package R read .json files. JSON files read R list object.","code":""},{"path":"data-import.html","id":"everything-working-well","chapter":" 11 Data Import","heading":"11.3.1 Everything Working Well","text":"First, consider data mobile game Clash Royale. Install jsonlite package use read json file function fromJSON():get warning message, investigate class.Next, type View(cr_cards) console (bottom-left) window look data. See can pull data set clicking things View() window.following give couple ways grab data using code. as_tibble() function converts rectangular object familiar tibble.first option specifies name table ’s JSON file (case, name \"cards\"):second method uses flatten() function purrr package, package core tidyverse talk detail class. also different flatten() function jsonlite package. code , specify want use flatten() purrr purrr::flatten(). wanted use flatten() jsonlite, ’d use jsonlite::flatten()methods give tibble can use usual tidyverse tools ggplot2, dplyr, tidyr, etc. .","code":"\n## install.packages(\"jsonlite\")\nlibrary(jsonlite)\ncr_cards <- fromJSON(here(\"data/clash_royale_card_info.json\"))\nlibrary(tidyverse)\ncr_cards_flat <- cr_cards[[\"cards\"]]\ncr_cards_df <- as_tibble(cr_cards_flat)\nhead(cr_cards_df)\n#> # A tibble: 6 × 8\n#>   key     name      elixir type  rarity arena descr…¹     id\n#>   <chr>   <chr>      <int> <chr> <chr>  <int> <chr>    <int>\n#> 1 knight  Knight         3 Troop Common     0 A toug… 2.6 e7\n#> 2 archers Archers        3 Troop Common     0 A pair… 2.60e7\n#> 3 goblins Goblins        2 Troop Common     1 Three … 2.60e7\n#> 4 giant   Giant          5 Troop Rare       0 Slow b… 2.60e7\n#> 5 pekka   P.E.K.K.A      7 Troop Epic       4 A heav… 2.60e7\n#> 6 minions Minions        3 Troop Common     0 Three … 2.60e7\n#> # … with abbreviated variable name ¹​description\ncr_cards_flat2 <- purrr::flatten(cr_cards)\ncr_cards_df2 <- as_tibble(cr_cards_flat2)\nhead(cr_cards_df2)\n#> # A tibble: 6 × 8\n#>   key     name      elixir type  rarity arena descr…¹     id\n#>   <chr>   <chr>      <int> <chr> <chr>  <int> <chr>    <int>\n#> 1 knight  Knight         3 Troop Common     0 A toug… 2.6 e7\n#> 2 archers Archers        3 Troop Common     0 A pair… 2.60e7\n#> 3 goblins Goblins        2 Troop Common     1 Three … 2.60e7\n#> 4 giant   Giant          5 Troop Rare       0 Slow b… 2.60e7\n#> 5 pekka   P.E.K.K.A      7 Troop Epic       4 A heav… 2.60e7\n#> 6 minions Minions        3 Troop Common     0 Three … 2.60e7\n#> # … with abbreviated variable name ¹​description"},{"path":"data-import.html","id":"things-arent-always-so-easy","chapter":" 11 Data Import","heading":"11.3.2 Things Aren’t Always So Easy","text":"Now let’s try look animal crossing data obtained https://github.com/jefflomacy/villagerdb. first just want look data one individual villager (ace) file ace.json.Things now….complicated. example just show ’s always easy working JSON data. Lists can nested creates problems trying convert deeply nested list “rectangular” format ’s easy work .’s also added problem reading .json files villagers time loop mapping function purrr download read JSON files villagers. won’t delve deeply , ’s lot file formats ’ve discussed week, particularly web scraping .json files.","code":"\nacedata <- fromJSON(here(\"data/ace.json\"))\naceflat <- purrr::flatten(acedata)\nhead(aceflat)\n#> $gender\n#> [1] \"male\"\n#> \n#> $species\n#> [1] \"bird\"\n#> \n#> $birthday\n#> [1] \"3-13\"\n#> \n#> $ac\n#> $ac$personality\n#> [1] \"jock\"\n#> \n#> $ac$clothes\n#> [1] \"spade-shirt\"\n#> \n#> $ac$song\n#> [1] \"K.K. Parade\"\n#> \n#> $ac$phrase\n#> [1] \"ace\"\n#> \n#> \n#> $`afe+`\n#> $`afe+`$personality\n#> [1] \"jock\"\n#> \n#> $`afe+`$clothes\n#> [1] \"spade-shirt\"\n#> \n#> $`afe+`$song\n#> [1] \"K.K. Parade\"\n#> \n#> \n#> $name\n#> [1] \"Ace\""},{"path":"data-import.html","id":"exercise-8-4","chapter":" 11 Data Import","heading":"11.3.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 11.5.* Read pokedex.json file, data set information 151 original Pokemon. , use flatten() function purrr flatten list.* Read pokedex.json file, data set information 151 original Pokemon. , use flatten() function purrr flatten list.* Use as_tibble() convert flattened list tibble.* Use as_tibble() convert flattened list tibble.* Use parse_number() mutate() tidy two variables data set.* Use parse_number() mutate() tidy two variables data set.* Look type variable. looks odd ? happens try use , either plot, using dplyr function?* Look type variable. looks odd ? happens try use , either plot, using dplyr function?can unnest() Type variable unnest() function tidyr. didn’t discuss function feel free read ?unnestThere 6 pokemon spawn_chance 0. Figure 6 pokemon .6 pokemon spawn_chance 0. Figure 6 pokemon .Figure 5 common Pokemon types first generation (’ll need use unnest()-ed data set : ?).Figure 5 common Pokemon types first generation (’ll need use unnest()-ed data set : ?).","code":"\npokemon_unnest <- unnest(pokemon_df, cols = c(type))"},{"path":"data-import.html","id":"chapexercise-8","chapter":" 11 Data Import","heading":"11.4 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 11.5.Choose sports team SLU, go team’s website (simply googling SLU name_of_sport). Scrape data tables “Results” “Statistics” section sport. scrape data, tidy data set. , choose one following options (different options might make /less sense different sports)(). Summarise different team statistics, either numerically graphically. Perhaps make graphs showing different statistics time.(b). Summarise different individual statistics, either numerically graphically.(c). Ask answer questions make sense particular sport looking !Note: sports (men’s women’s golf, example), give results PDF format. PDF format generally horrible way record share data, ’s difficult read almost program. Therefore, avoid sports PDF results purposes exercise.","code":""},{"path":"data-import.html","id":"solutions-8","chapter":" 11 Data Import","heading":"11.5 Exercise Solutions","text":"","code":""},{"path":"data-import.html","id":"readr-s","chapter":" 11 Data Import","heading":"11.5.1 readr S","text":"* birthdays.txt file information birthdays various animals Animal Crossing island. also columns Animal’s Name, Animal Type, long animal lived island (weeks). Click file open look format data.Start following code chunk use options read_delim() read data (?read_delim). delim argument ’s already provided specifies delimiter (separator) ’ll use -, opposed , example, , .csv file. Arguments may change includeskipcol_namesnatrim_wscol_types* Another common format data stored Excel file. Often, ’s easiest just save Excel file .csv file read using read_csv(). , sometimes route can difficult (example, Excel file thousands sheets). read directly Excel, ’ll need install readxl install.packages(\"readxl\"). installed, load package library(readxl), read first sheet evals_prof.xlsx data set read_excel() function.* Now, read second sheet, using help file ?read_excel change one arguments.","code":"\nlibrary(tidyverse)\ndf <- read_delim(here(\"data/birthdays.txt\"), delim = \" - \")\nhead(df)\nread_delim(here(\"data/birthdays.txt\"), delim = \"-\", skip = 4,\n  col_names = c(\"Birthday\", \"Name\",\n    \"Animal\", \"Island\"),\n  trim_ws = TRUE,\n  col_types = list(\n    col_character(), col_character(), col_character(), col_number()\n  ), na = c(\"N/A\", \"?\"))\n## install.packages(\"readxl\")\nlibrary(readxl)\nread_excel(here(\"data/evals_prof.xlsx\"))\nread_excel(here(\"data/evals_prof.xlsx\"), sheet = 2)"},{"path":"data-import.html","id":"rvest-and-data-scraping-s","chapter":" 11 Data Import","heading":"11.5.2 rvest and Data Scraping S","text":"* SLU keeps track diversity faculty time makes data public following website: https://www.stlawu.edu/ir/diversity/faculty. Use rvest scrape data tables R.","code":"\nurl <- \"https://www.stlawu.edu/ir/diversity/faculty\"\nh <- read_html(url)\ntab <- h |> html_nodes(\"table\")\nobj <- tab[[1]] |> html_table(fill = TRUE)\nobj"},{"path":"data-import.html","id":"json-with-jsonlite-s","chapter":" 11 Data Import","heading":"11.5.3 JSON with jsonlite S","text":"* Read pokedex.json file, data set information 151 original Pokemon. , use flatten() function purrr flatten list.* Use as_tibble() convert flattened list tibble.* Use parse_number() mutate() tidy two variables data set.* Look type variable. looks odd ? happens try use , either plot, using dplyr function?can unnest() Type variable unnest() function tidyr. didn’t discuss function feel free read ?unnest","code":"\nlibrary(jsonlite)\npokedex <- fromJSON(here(\"data/pokedex.json\"))\ndf <- purrr::flatten(pokedex)\npokemon_df <- as_tibble(df)\npokemon_df <- pokemon_df |> mutate(height = parse_number(height),\n                                    weight = parse_number(weight))\n## it's a variable of lists....this is happening because some \n## pokemon have more than one type.\n\n## most ggplot() and dplyr() functions won't work, or\n## won't work as you'd expect\npokemon_unnest <- unnest(pokemon_df, cols = c(type))"},{"path":"data-import.html","id":"chapexercise-8-S","chapter":" 11 Data Import","heading":"11.5.4 Chapter Exercises S","text":"","code":""},{"path":"data-import.html","id":"rcode-8","chapter":" 11 Data Import","heading":"11.6 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\nlibrary(here)\ncars_df <- read_csv(here(\"data/mtcarsex.csv\"))\nhead(cars_df)\ncars_df <- read_csv(here(\"data/mtcarsex.csv\"), skip = 2)\n## first two lines will be skipped\nhead(cars_df)\ncars_df <- read_csv(here(\"data/mtcarsex.csv\"), na = c(\"NA\", \"-999\"), skip = 2)\nhead(cars_df)\ncars_df <- read_csv(here(\"data/mtcarsex.csv\"), na = c(NA, \"-999\"), skip = 2,\n  col_types = cols(\n  mpg = col_double(),\n  cyl = col_factor(),\n  disp = col_double(),\n  hp = col_double(),\n  drat = col_double(),\n  wt = col_double(),\n  qsec = col_double(),\n  vs = col_factor(),\n  am = col_double(),\n  gear = col_double(),\n  carb = col_double()\n))\ncars_df <- read_csv(here(\"data/mtcarsex.csv\"), na = c(\"NA\", \"-999\"), skip = 2,\n  col_types = cols(\n  mpg = col_double(),\n  cyl = col_factor(),\n  disp = col_double(),\n  hp = col_double(),\n  drat = col_double(),\n  wt = col_double(),\n  qsec = col_double(),\n  vs = col_factor(),\n  am = col_double(),\n  gear = col_double(),\n  carb = col_double()\n)) |>\n  slice(-(1:2))\nhead(cars_df)\noscars_df <- read_tsv(here(\"data/oscars.tsv\"))\nhead(oscars_df)\ntest_df <- read_csv(here(\"data/parsedf.csv\"))\nhead(test_df)\ntest_df |> mutate(x2 = parse_number(x))\nlibrary(tidyverse)\nlibrary(rvest)\n\n## provide the URL and name it something (in this case, url).\nurl <- \"https://en.wikipedia.org/wiki/Gun_violence_in_the_United_States_by_state\"\n\n## convert the html code into something R can read\nh <- read_html(url)\n\n## grabs the tables\ntab <- h |> html_nodes(\"table\")\ntest1 <- tab[[1]] |> html_table()\ntest2 <- tab[[2]] |> html_table()\ntest3 <- tab[[3]] |> html_table()\n\nhead(test1)\nhead(test2)\nhead(test3)\nurl <- \"https://saintsathletics.com/sports/baseball/stats/2021\"\nh <- read_html(url)\ntab <- h |> html_nodes(\"table\")\ntab\nobj <- tab[[1]] |> html_table(fill = TRUE)\nhead(obj)\ntail(obj)\nobj2 <- tab[[2]] |> html_table(fill = TRUE)\nhead(obj2)\ntail(obj2)\n## install.packages(\"jsonlite\")\nlibrary(jsonlite)\ncr_cards <- fromJSON(here(\"data/clash_royale_card_info.json\"))\nlibrary(tidyverse)\ncr_cards_flat <- cr_cards[[\"cards\"]]\ncr_cards_df <- as_tibble(cr_cards_flat)\nhead(cr_cards_df)\ncr_cards_flat2 <- purrr::flatten(cr_cards)\ncr_cards_df2 <- as_tibble(cr_cards_flat2)\nhead(cr_cards_df2)\nacedata <- fromJSON(here(\"data/ace.json\"))\naceflat <- purrr::flatten(acedata)\nhead(aceflat)"},{"path":"merging-with-dplyr.html","id":"merging-with-dplyr","chapter":" 12 Merging with dplyr","heading":" 12 Merging with dplyr","text":"Goals:use bind_rows() stack two data sets bind_cols() merge two data sets.use bind_rows() stack two data sets bind_cols() merge two data sets.identify keys two related data sets.identify keys two related data sets.use mutating join functions dplyr merge two data sets key.use mutating join functions dplyr merge two data sets key.use filtering join functions dplyr filter one data set values another data set.use filtering join functions dplyr filter one data set values another data set.apply appropriate join() function given problem context.apply appropriate join() function given problem context.","code":""},{"path":"merging-with-dplyr.html","id":"stacking-rows-and-appending-columns","chapter":" 12 Merging with dplyr","heading":"12.1 Stacking Rows and Appending Columns","text":"","code":""},{"path":"merging-with-dplyr.html","id":"stacking-with-bind_rows","chapter":" 12 Merging with dplyr","heading":"12.1.1 Stacking with bind_rows()","text":"First, talk combining two data sets “stacking” top form one new data set. bind_rows() function can used purpose two data sets identical column names.common instance useful two data sets come source different locations years, exact column names.example, examine following website notice .csv files given year matches ATP (Association (men’s) Tennis Professionals). https://github.com/JeffSackmann/tennis_atp., read data sets, look many columns .combine results data sets,happens? Can fix error? Hint: runto get full column specifications use readr knowledge change couple column types. also discuss , , using col_type argument read_csv(), don’t need specify column types. Just specifying ones want change works . following code forces seed variables 2018 data set characters.can try combining data sets now.quick check make sure number rows atp_2018 plus number rows atp_2019 equals number rows atp_df.might seem little annoying, , default bind_rows() combine two data sets stacking rows data sets identical column names identical column classes, saw previous example.Now run following look output.behavior expect?","code":"\nlibrary(tidyverse)\nlibrary(here)\natp_2019 <- read_csv(here(\"data/atp_matches_2019.csv\"))\natp_2018 <- read_csv(here(\"data/atp_matches_2018.csv\"))\nhead(atp_2019) \nhead(atp_2018)\natp_df <- bind_rows(atp_2018, atp_2019)\n#> Error in `bind_rows()`:\n#> ! Can't combine `winner_seed` <double> and `winner_seed` <character>.\nspec(atp_2018)\natp_2018 <- read_csv(here(\"data/atp_matches_2018.csv\"),\n                     col_types = cols(winner_seed = col_character(),\n                                      loser_seed = col_character()))\natp_df <- bind_rows(atp_2018, atp_2019)\natp_df\ndf_test2a <- tibble(xvar = c(1, 2))\ndf_test2b <- tibble(xvar = c(1, 2), y = c(5, 1))\nbind_rows(df_test2a, df_test2b)\n#> # A tibble: 4 × 2\n#>    xvar     y\n#>   <dbl> <dbl>\n#> 1     1    NA\n#> 2     2    NA\n#> 3     1     5\n#> 4     2     1"},{"path":"merging-with-dplyr.html","id":"binding-columns-with-bind_cols","chapter":" 12 Merging with dplyr","heading":"12.1.2 Binding Columns with bind_cols()","text":"won’t spend much time talking bind together columns ’s generally little dangerous.use couple test data sets, df_test1a df_test1b, see action:larger data set, might dangerous way combine data? must sure way data collected order combine data way?","code":"\ndf_test1a <- tibble(xvar = c(1, 2), yvar = c(5, 1))\ndf_test1b <- tibble(x = c(1, 2), y = c(5, 1))\nbind_cols(df_test1a, df_test1b)\n#> # A tibble: 2 × 4\n#>    xvar  yvar     x     y\n#>   <dbl> <dbl> <dbl> <dbl>\n#> 1     1     5     1     5\n#> 2     2     1     2     1"},{"path":"merging-with-dplyr.html","id":"exercise-10-1","chapter":" 12 Merging with dplyr","heading":"12.1.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 12.5.* Run following explain R simply stack rows. , fix issue rename() function.","code":"\ndf_test1a <- tibble(xvar = c(1, 2), yvar = c(5, 1))\ndf_test1b <- tibble(x = c(1, 2), y = c(5, 1))\nbind_rows(df_test1a, df_test1b)\n#> # A tibble: 4 × 4\n#>    xvar  yvar     x     y\n#>   <dbl> <dbl> <dbl> <dbl>\n#> 1     1     5    NA    NA\n#> 2     2     1    NA    NA\n#> 3    NA    NA     1     5\n#> 4    NA    NA     2     1"},{"path":"merging-with-dplyr.html","id":"mutating-joins","chapter":" 12 Merging with dplyr","heading":"12.2 Mutating Joins","text":"goal combine two data sets using common variable(s) data sets , need different tools simply stacking rows appending columns. merging together two data sets, need matching identification variable data set. variable commonly called key. key can identification number, name, date, etc, must present data sets.simple first example, considerOur goal combine two data sets people’s favorite sports favorite colours one data set.Identify key example . can longer use bind_cols() ?","code":"\nlibrary(tidyverse)\ndf1 <- tibble(name = c(\"Emily\", \"Miguel\", \"Tonya\"), fav_sport = c(\"Swimming\", \"Football\", \"Tennis\"))\ndf2 <- tibble(name = c(\"Tonya\", \"Miguel\", \"Emily\"),\n              fav_colour = c(\"Robin's Egg Blue\", \"Tickle Me Pink\", \"Goldenrod\"))"},{"path":"merging-with-dplyr.html","id":"keep-all-rows-of-data-set-1-with-left_join","chapter":" 12 Merging with dplyr","heading":"12.2.1 Keep All Rows of Data Set 1 with left_join()","text":"Consider babynames R package, following data sets:lifetables: cohort life tables different sex different year variables, starting year 1900.births: number births United States year, since 1909babynames: popularity different baby names per year sex since year 1880.Read data set ?babynames, ?births ?lifetables.Suppose want combine births data set babynames data set, row babynames now total number births year. first need identify key data set use joining. case, data set year variable, can use left_join() keep observations babynames_df, even years births_df data set.births missing head(combined_left) tail(combined_left)?","code":"\n##install.packages(\"babynames\")\nlibrary(babynames)\nlife_df <- babynames::lifetables\nbirth_df <- babynames::births\nbabynames_df <- babynames::babynames\nhead(babynames)\nhead(births)\nhead(lifetables)\ncombined_left <- left_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))\nhead(combined_left)\n#> # A tibble: 6 × 6\n#>    year sex   name          n   prop births\n#>   <dbl> <chr> <chr>     <int>  <dbl>  <int>\n#> 1  1880 F     Mary       7065 0.0724     NA\n#> 2  1880 F     Anna       2604 0.0267     NA\n#> 3  1880 F     Emma       2003 0.0205     NA\n#> 4  1880 F     Elizabeth  1939 0.0199     NA\n#> 5  1880 F     Minnie     1746 0.0179     NA\n#> 6  1880 F     Margaret   1578 0.0162     NA\ntail(combined_left)\n#> # A tibble: 6 × 6\n#>    year sex   name       n       prop  births\n#>   <dbl> <chr> <chr>  <int>      <dbl>   <int>\n#> 1  2017 M     Zyhier     5 0.00000255 3855500\n#> 2  2017 M     Zykai      5 0.00000255 3855500\n#> 3  2017 M     Zykeem     5 0.00000255 3855500\n#> 4  2017 M     Zylin      5 0.00000255 3855500\n#> 5  2017 M     Zylis      5 0.00000255 3855500\n#> 6  2017 M     Zyrie      5 0.00000255 3855500"},{"path":"merging-with-dplyr.html","id":"keep-all-rows-of-data-set-2-with-right_join","chapter":" 12 Merging with dplyr","heading":"12.2.2 Keep All Rows of Data Set 2 with right_join()","text":"Recall accompanying handout need ever use right_join() using left_join() first two data set arguments switched:Therefore, ’s usually easier just always use left_join() ignore right_join() completely.","code":"\n## these will always do the same exact thing\nright_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))\n#> # A tibble: 1,839,952 × 6\n#>     year sex   name          n   prop  births\n#>    <dbl> <chr> <chr>     <int>  <dbl>   <int>\n#>  1  1909 F     Mary      19259 0.0523 2718000\n#>  2  1909 F     Helen      9250 0.0251 2718000\n#>  3  1909 F     Margaret   7359 0.0200 2718000\n#>  4  1909 F     Ruth       6509 0.0177 2718000\n#>  5  1909 F     Dorothy    6253 0.0170 2718000\n#>  6  1909 F     Anna       5804 0.0158 2718000\n#>  7  1909 F     Elizabeth  5176 0.0141 2718000\n#>  8  1909 F     Mildred    5054 0.0137 2718000\n#>  9  1909 F     Marie      4301 0.0117 2718000\n#> 10  1909 F     Alice      4170 0.0113 2718000\n#> # … with 1,839,942 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\nleft_join(birth_df, babynames_df, by = c(\"year\" = \"year\"))\n#> # A tibble: 1,839,952 × 6\n#>     year  births sex   name          n   prop\n#>    <dbl>   <int> <chr> <chr>     <int>  <dbl>\n#>  1  1909 2718000 F     Mary      19259 0.0523\n#>  2  1909 2718000 F     Helen      9250 0.0251\n#>  3  1909 2718000 F     Margaret   7359 0.0200\n#>  4  1909 2718000 F     Ruth       6509 0.0177\n#>  5  1909 2718000 F     Dorothy    6253 0.0170\n#>  6  1909 2718000 F     Anna       5804 0.0158\n#>  7  1909 2718000 F     Elizabeth  5176 0.0141\n#>  8  1909 2718000 F     Mildred    5054 0.0137\n#>  9  1909 2718000 F     Marie      4301 0.0117\n#> 10  1909 2718000 F     Alice      4170 0.0113\n#> # … with 1,839,942 more rows\n#> # ℹ Use `print(n = ...)` to see more rows"},{"path":"merging-with-dplyr.html","id":"keep-all-rows-of-both-data-sets-with-full_join","chapter":" 12 Merging with dplyr","heading":"12.2.3 Keep All Rows of Both Data Sets with full_join()","text":"full_join() keep rows data set 1 don’t matching key data set 2, also keep rows data set 2 don’t matching key data set 1, filling NA missing values necessary. example merging babynames_df birth_df,","code":"\nfull_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))"},{"path":"merging-with-dplyr.html","id":"keep-only-rows-with-matching-keys-with-inner_join","chapter":" 12 Merging with dplyr","heading":"12.2.4 Keep Only Rows with Matching Keys with inner_join()","text":"can also keep rows matching keys inner_join(). join, row data set 1 without matching key data set 2 dropped, row data set 2 without matching key data set 1 also dropped.","code":"\ninner_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))\n#> # A tibble: 1,839,952 × 6\n#>     year sex   name          n   prop  births\n#>    <dbl> <chr> <chr>     <int>  <dbl>   <int>\n#>  1  1909 F     Mary      19259 0.0523 2718000\n#>  2  1909 F     Helen      9250 0.0251 2718000\n#>  3  1909 F     Margaret   7359 0.0200 2718000\n#>  4  1909 F     Ruth       6509 0.0177 2718000\n#>  5  1909 F     Dorothy    6253 0.0170 2718000\n#>  6  1909 F     Anna       5804 0.0158 2718000\n#>  7  1909 F     Elizabeth  5176 0.0141 2718000\n#>  8  1909 F     Mildred    5054 0.0137 2718000\n#>  9  1909 F     Marie      4301 0.0117 2718000\n#> 10  1909 F     Alice      4170 0.0113 2718000\n#> # … with 1,839,942 more rows\n#> # ℹ Use `print(n = ...)` to see more rows"},{"path":"merging-with-dplyr.html","id":"which-xxxx_join","chapter":" 12 Merging with dplyr","heading":"12.2.5 Which xxxx_join()?","text":"join function use depend context data questions answering analysis. importantly, ’re using left_join(), right_join() inner_join(), ’re potentially cutting data. ’s important aware data ’re omitting. example, babynames births data, want keep note left_join() removed observations 1909 joined data set.","code":""},{"path":"merging-with-dplyr.html","id":"the-importance-of-a-good-key","chapter":" 12 Merging with dplyr","heading":"12.2.6 The Importance of a Good Key","text":"key variable important joining always available “perfect” form. Recall college majors data sets , called slumajors_df, information majors SLU. Another data set, collegemajors_df, different statistics college majors nationwide. ’s lots interesting variables data sets, ’ll focus Major variable . Read examine two data sets :logical key joining two data sets Major, joining data sets won’t actually work. following attempt using Major key.collegemajors_df give NA values tried merge major?example underscores importance key matches exactly. , , issues involved joining two data sets can solved functions stringr package (discussed weeks). example, capitalization issue can solved str_to_title() function, converts -caps majors collegemajors_df majors first letter word capitalized:can see, solves issue majors others still different naming conventions two data sets.","code":"\nslumajors_df <- read_csv(here(\"data/SLU_Majors_15_19.csv\"))\ncollegemajors_df <- read_csv(here(\"data/college-majors.csv\"))\nhead(slumajors_df)\n#> # A tibble: 6 × 3\n#>   Major                        nfemales nmales\n#>   <chr>                           <dbl>  <dbl>\n#> 1 Anthropology                       34     15\n#> 2 Art & Art History                  65     11\n#> 3 Biochemistry                       14     11\n#> 4 Biology                           162     67\n#> 5 Business in the Liberal Arts      135    251\n#> 6 Chemistry                          26     14\nhead(collegemajors_df)\n#> # A tibble: 6 × 12\n#>   Major    Total   Men Women Major…¹ Emplo…² Full_…³ Part_…⁴\n#>   <chr>    <dbl> <dbl> <dbl> <chr>     <dbl>   <dbl>   <dbl>\n#> 1 PETROLE…  2339  2057   282 Engine…    1976    1849     270\n#> 2 MINING …   756   679    77 Engine…     640     556     170\n#> 3 METALLU…   856   725   131 Engine…     648     558     133\n#> 4 NAVAL A…  1258  1123   135 Engine…     758    1069     150\n#> 5 CHEMICA… 32260 21239 11021 Engine…   25694   23170    5180\n#> 6 NUCLEAR…  2573  2200   373 Engine…    1857    2038     264\n#> # … with 4 more variables: Unemployed <dbl>, Median <dbl>,\n#> #   P25th <dbl>, P75th <dbl>, and abbreviated variable\n#> #   names ¹​Major_category, ²​Employed, ³​Full_time,\n#> #   ⁴​Part_time\n#> # ℹ Use `colnames()` to see all variable names\nleft_join(slumajors_df, collegemajors_df, by = c(\"Major\" = \"Major\"))\n#> # A tibble: 27 × 14\n#>    Major    nfema…¹ nmales Total   Men Women Major…² Emplo…³\n#>    <chr>      <dbl>  <dbl> <dbl> <dbl> <dbl> <chr>     <dbl>\n#>  1 Anthrop…      34     15    NA    NA    NA <NA>         NA\n#>  2 Art & A…      65     11    NA    NA    NA <NA>         NA\n#>  3 Biochem…      14     11    NA    NA    NA <NA>         NA\n#>  4 Biology      162     67    NA    NA    NA <NA>         NA\n#>  5 Busines…     135    251    NA    NA    NA <NA>         NA\n#>  6 Chemist…      26     14    NA    NA    NA <NA>         NA\n#>  7 Compute…      21     47    NA    NA    NA <NA>         NA\n#>  8 Conserv…      38     20    NA    NA    NA <NA>         NA\n#>  9 Economi…     128    349    NA    NA    NA <NA>         NA\n#> 10 English      131     54    NA    NA    NA <NA>         NA\n#> # … with 17 more rows, 6 more variables: Full_time <dbl>,\n#> #   Part_time <dbl>, Unemployed <dbl>, Median <dbl>,\n#> #   P25th <dbl>, P75th <dbl>, and abbreviated variable\n#> #   names ¹​nfemales, ²​Major_category, ³​Employed\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\ncollegemajors_df <- collegemajors_df |>\n  mutate(Major = str_to_title(Major))\nleft_join(slumajors_df, collegemajors_df)\n#> Joining, by = \"Major\"\n#> # A tibble: 27 × 14\n#>    Major nfema…¹ nmales  Total    Men  Women Major…² Emplo…³\n#>    <chr>   <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <chr>     <dbl>\n#>  1 Anth…      34     15     NA     NA     NA <NA>         NA\n#>  2 Art …      65     11     NA     NA     NA <NA>         NA\n#>  3 Bioc…      14     11     NA     NA     NA <NA>         NA\n#>  4 Biol…     162     67 280709 111762 168947 Biolog…  182295\n#>  5 Busi…     135    251     NA     NA     NA <NA>         NA\n#>  6 Chem…      26     14  66530  32923  33607 Physic…   48535\n#>  7 Comp…      21     47 128319  99743  28576 Comput…  102087\n#>  8 Cons…      38     20     NA     NA     NA <NA>         NA\n#>  9 Econ…     128    349 139247  89749  49498 Social…  104117\n#> 10 Engl…     131     54     NA     NA     NA <NA>         NA\n#> # … with 17 more rows, 6 more variables: Full_time <dbl>,\n#> #   Part_time <dbl>, Unemployed <dbl>, Median <dbl>,\n#> #   P25th <dbl>, P75th <dbl>, and abbreviated variable\n#> #   names ¹​nfemales, ²​Major_category, ³​Employed\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names"},{"path":"merging-with-dplyr.html","id":"exercise-10-2","chapter":" 12 Merging with dplyr","heading":"12.2.7 Exercises","text":"Exercises marked * indicate exercise solution end chapter 12.5.Examine following two joins ’ve done, explain one resulting data set fewer observations (rows) .Evaluate whether following statement true false: inner_join() always result data set fewer rows full_join().Evaluate whether following statement true false: inner_join() always result data set fewer rows full_join().Evaluate whether following statement true false: inner_join() always result data set fewer rows left_join().Evaluate whether following statement true false: inner_join() always result data set fewer rows left_join().Evaluate whether following statement true false: left_join() always result data set number rows semi_join() two data sets.Evaluate whether following statement true false: left_join() always result data set number rows semi_join() two data sets.","code":"\nleft_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))\n#> # A tibble: 1,924,665 × 6\n#>     year sex   name          n   prop births\n#>    <dbl> <chr> <chr>     <int>  <dbl>  <int>\n#>  1  1880 F     Mary       7065 0.0724     NA\n#>  2  1880 F     Anna       2604 0.0267     NA\n#>  3  1880 F     Emma       2003 0.0205     NA\n#>  4  1880 F     Elizabeth  1939 0.0199     NA\n#>  5  1880 F     Minnie     1746 0.0179     NA\n#>  6  1880 F     Margaret   1578 0.0162     NA\n#>  7  1880 F     Ida        1472 0.0151     NA\n#>  8  1880 F     Alice      1414 0.0145     NA\n#>  9  1880 F     Bertha     1320 0.0135     NA\n#> 10  1880 F     Sarah      1288 0.0132     NA\n#> # … with 1,924,655 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\nleft_join(birth_df, babynames_df, by = c(\"year\" = \"year\"))\n#> # A tibble: 1,839,952 × 6\n#>     year  births sex   name          n   prop\n#>    <dbl>   <int> <chr> <chr>     <int>  <dbl>\n#>  1  1909 2718000 F     Mary      19259 0.0523\n#>  2  1909 2718000 F     Helen      9250 0.0251\n#>  3  1909 2718000 F     Margaret   7359 0.0200\n#>  4  1909 2718000 F     Ruth       6509 0.0177\n#>  5  1909 2718000 F     Dorothy    6253 0.0170\n#>  6  1909 2718000 F     Anna       5804 0.0158\n#>  7  1909 2718000 F     Elizabeth  5176 0.0141\n#>  8  1909 2718000 F     Mildred    5054 0.0137\n#>  9  1909 2718000 F     Marie      4301 0.0117\n#> 10  1909 2718000 F     Alice      4170 0.0113\n#> # … with 1,839,942 more rows\n#> # ℹ Use `print(n = ...)` to see more rows"},{"path":"merging-with-dplyr.html","id":"filtering-joins","chapter":" 12 Merging with dplyr","heading":"12.3 Filtering Joins","text":"Filtering joins (semi_join() anti_join()) useful like keep variables one data set, want filter observations variable second data set.Consider two data sets men’s tennis matches 2018 2019.","code":"\natp_2019 <- read_csv(here(\"data/atp_matches_2019.csv\"))\natp_2018 <- read_csv(here(\"data/atp_matches_2018.csv\"))\natp_2019\n#> # A tibble: 2,781 × 49\n#>    tourney…¹ tourn…² surface draw_…³ tourn…⁴ tourn…⁵ match…⁶\n#>    <chr>     <chr>   <chr>     <dbl> <chr>     <dbl>   <dbl>\n#>  1 2019-M020 Brisba… Hard         32 A        2.02e7     300\n#>  2 2019-M020 Brisba… Hard         32 A        2.02e7     299\n#>  3 2019-M020 Brisba… Hard         32 A        2.02e7     298\n#>  4 2019-M020 Brisba… Hard         32 A        2.02e7     297\n#>  5 2019-M020 Brisba… Hard         32 A        2.02e7     296\n#>  6 2019-M020 Brisba… Hard         32 A        2.02e7     295\n#>  7 2019-M020 Brisba… Hard         32 A        2.02e7     294\n#>  8 2019-M020 Brisba… Hard         32 A        2.02e7     293\n#>  9 2019-M020 Brisba… Hard         32 A        2.02e7     292\n#> 10 2019-M020 Brisba… Hard         32 A        2.02e7     291\n#> # … with 2,771 more rows, 42 more variables:\n#> #   winner_id <dbl>, winner_seed <chr>, winner_entry <chr>,\n#> #   winner_name <chr>, winner_hand <chr>, winner_ht <dbl>,\n#> #   winner_ioc <chr>, winner_age <dbl>, loser_id <dbl>,\n#> #   loser_seed <chr>, loser_entry <chr>, loser_name <chr>,\n#> #   loser_hand <chr>, loser_ht <dbl>, loser_ioc <chr>,\n#> #   loser_age <dbl>, score <chr>, best_of <dbl>, …\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\natp_2018\n#> # A tibble: 2,889 × 49\n#>    tourney…¹ tourn…² surface draw_…³ tourn…⁴ tourn…⁵ match…⁶\n#>    <chr>     <chr>   <chr>     <dbl> <chr>     <dbl>   <dbl>\n#>  1 2018-M020 Brisba… Hard         32 A        2.02e7     271\n#>  2 2018-M020 Brisba… Hard         32 A        2.02e7     272\n#>  3 2018-M020 Brisba… Hard         32 A        2.02e7     273\n#>  4 2018-M020 Brisba… Hard         32 A        2.02e7     275\n#>  5 2018-M020 Brisba… Hard         32 A        2.02e7     276\n#>  6 2018-M020 Brisba… Hard         32 A        2.02e7     277\n#>  7 2018-M020 Brisba… Hard         32 A        2.02e7     278\n#>  8 2018-M020 Brisba… Hard         32 A        2.02e7     279\n#>  9 2018-M020 Brisba… Hard         32 A        2.02e7     280\n#> 10 2018-M020 Brisba… Hard         32 A        2.02e7     282\n#> # … with 2,879 more rows, 42 more variables:\n#> #   winner_id <dbl>, winner_seed <dbl>, winner_entry <chr>,\n#> #   winner_name <chr>, winner_hand <chr>, winner_ht <dbl>,\n#> #   winner_ioc <chr>, winner_age <dbl>, loser_id <dbl>,\n#> #   loser_seed <dbl>, loser_entry <chr>, loser_name <chr>,\n#> #   loser_hand <chr>, loser_ht <dbl>, loser_ioc <chr>,\n#> #   loser_age <dbl>, score <chr>, best_of <dbl>, …\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names"},{"path":"merging-with-dplyr.html","id":"filtering-with-semi_join","chapter":" 12 Merging with dplyr","heading":"12.3.1 Filtering with semi_join()","text":"Suppose want keep matches 2019 winning player 10 wins 2018. might useful want consider players 2018 played couple matches, perhaps got injured perhaps received special wildcard draw one event.accomplish , can first create data set names players won 10 matches 2018, using functions learned dplyr earlier semester:Next, apply semi_join(), takes names two data sets (second one contains information first “filtered”). third argument gives name key (winner_name) case.Note keeps matches 2019 winner 10 match wins 2018. drops matches loser lost someone 10 match wins 2018. isn’t yet perfect take little thought matches actually want keep particular analysis.","code":"\nwin10 <- atp_2018 |> group_by(winner_name) |>\n  summarise(nwin = n()) |> \n  filter(nwin >= 10)\nwin10\n#> # A tibble: 93 × 2\n#>    winner_name       nwin\n#>    <chr>            <int>\n#>  1 Adrian Mannarino    26\n#>  2 Albert Ramos        21\n#>  3 Alex De Minaur      29\n#>  4 Alexander Zverev    58\n#>  5 Aljaz Bedene        19\n#>  6 Andreas Seppi       24\n#>  7 Andrey Rublev       20\n#>  8 Benoit Paire        27\n#>  9 Borna Coric         40\n#> 10 Cameron Norrie      19\n#> # … with 83 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\ntennis_2019_10 <- semi_join(atp_2019, win10,\n                            by = c(\"winner_name\" = \"winner_name\"))\ntennis_2019_10$winner_name"},{"path":"merging-with-dplyr.html","id":"filtering-with-anti_join","chapter":" 12 Merging with dplyr","heading":"12.3.2 Filtering with anti_join()","text":"Now suppose want keep matches 2019 winning player wins 2018. might think players “emerging players” 2019, players coming back injury, etc.. , can use anti_join(), keeps rows first data set match second data set.can examine many wins “new” (perhaps previously injured) players 2019:filtering join functions useful want filter observations criterion different data set.","code":"\nnew_winners <- anti_join(atp_2019, atp_2018,\n                         by = c(\"winner_name\" = \"winner_name\")) \nnew_winners$winner_name\nnew_winners |> group_by(winner_name) |>\n  summarise(nwin = n()) |>\n  arrange(desc(nwin))\n#> # A tibble: 59 × 2\n#>    winner_name           nwin\n#>    <chr>                <int>\n#>  1 Christian Garin         32\n#>  2 Juan Ignacio Londero    22\n#>  3 Miomir Kecmanovic       22\n#>  4 Hugo Dellien            12\n#>  5 Attila Balazs            7\n#>  6 Cedrik Marcel Stebe      7\n#>  7 Janko Tipsarevic         7\n#>  8 Jannik Sinner            7\n#>  9 Soon Woo Kwon            7\n#> 10 Gregoire Barrere         6\n#> # … with 49 more rows\n#> # ℹ Use `print(n = ...)` to see more rows"},{"path":"merging-with-dplyr.html","id":"exercise-10-3","chapter":" 12 Merging with dplyr","heading":"12.3.3 Exercises","text":"Examine following data sets (first df1 second df2) , without running code, answer following questions.many rows data set left_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set left_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set left_join(df2, df1, = c(\"id\" = \"id\"))?many rows data set left_join(df2, df1, = c(\"id\" = \"id\"))?many rows data set full_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set full_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set inner_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set inner_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set semi_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set semi_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set anti_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set anti_join(df1, df2, = c(\"id\" = \"id\"))?Examine following data sets (first df3 second df4) , without running code, answer following questions. question step challenge Exercise 9 levels id key duplicates.many rows data set left_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set left_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set left_join(df2, df1, = c(\"id\" = \"id\"))?many rows data set left_join(df2, df1, = c(\"id\" = \"id\"))?many rows data set full_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set full_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set inner_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set inner_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set semi_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set semi_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set anti_join(df1, df2, = c(\"id\" = \"id\"))?many rows data set anti_join(df1, df2, = c(\"id\" = \"id\"))?","code":""},{"path":"merging-with-dplyr.html","id":"chapexercise-10","chapter":" 12 Merging with dplyr","heading":"12.4 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 12.5.* Read gun violence data set, suppose want add row data set statistics gun ownership mortality rate District Columbia (Washington D.C., NE region, 16.7 deaths per 100,000 people, gun ownership rate 8.7%). , create tibble() single row representing D.C. combine new tibble overall gun violence data set. Name new data set all_df.Explain attempt combining D.C. data overall data doesn’t work incorrect.Examine following data sets R’s base library demographic statistics U.S. states state abbreviations:Combine two data sets bind_cols(). assuming data sets order use function?* Combine columns states data set made Exercise 3 mortality data set without Washington D.C.* Combine columns states data set made Exercise 3 mortality data set without Washington D.C.* Use join function combine mortality data set (all_df) D.C. states data set Exercise 3 (states_df). exercise, keep row Washington D.C., take NA values variable observed states data.* Use join function combine mortality data set (all_df) D.C. states data set Exercise 3 (states_df). exercise, keep row Washington D.C., take NA values variable observed states data.* Repeat Exercise 5, now drop Washington D.C. merging process. Practice join function (opposed slice()-ing explicitly).* Repeat Exercise 5, now drop Washington D.C. merging process. Practice join function (opposed slice()-ing explicitly).* Use semi_join() create subset states_df NE region. Hint: need filter all_df first contain states NE region.* Use semi_join() create subset states_df NE region. Hint: need filter all_df first contain states NE region.* thing Exercise 7, time, use anti_join(). Hint: ’ll need filter all_df different way achieve .* thing Exercise 7, time, use anti_join(). Hint: ’ll need filter all_df different way achieve .","code":"\nlibrary(tidyverse)\nmortality_df <- read_csv(here(\"data/gun_violence_us.csv\"))\ntest1 <- tibble(state = \"Washington D.C.\", mortality_rate = 16.7,\n                ownership_rate = 8.7, region = \"NE\")\nbind_rows(mortality_df, test1)\n\ntest2 <- tibble(state = \"Washington D.C.\", mortality_rate = 16.7,\n       ownership_rate = 0.087, region = NE)\n#> Error in eval_tidy(xs[[j]], mask): object 'NE' not found\nbind_rows(mortality_df, test2)\n#> Error in list2(...): object 'test2' not found\n\ntest3 <- tibble(state = \"Washington D.C.\", mortality_rate = \"16.7\",\n       ownership_rate = \"0.087\", region = \"NE\")\nbind_rows(mortality_df, test3)\n#> Error in `bind_rows()`:\n#> ! Can't combine `mortality_rate` <double> and `mortality_rate` <character>.\ndf1 <- as_tibble(state.x77)\ndf2 <- as_tibble(state.abb)\ndf1\n#> # A tibble: 50 × 8\n#>    Population Income Illiteracy Life …¹ Murder HS Gr…² Frost\n#>         <dbl>  <dbl>      <dbl>   <dbl>  <dbl>   <dbl> <dbl>\n#>  1       3615   3624        2.1    69.0   15.1    41.3    20\n#>  2        365   6315        1.5    69.3   11.3    66.7   152\n#>  3       2212   4530        1.8    70.6    7.8    58.1    15\n#>  4       2110   3378        1.9    70.7   10.1    39.9    65\n#>  5      21198   5114        1.1    71.7   10.3    62.6    20\n#>  6       2541   4884        0.7    72.1    6.8    63.9   166\n#>  7       3100   5348        1.1    72.5    3.1    56     139\n#>  8        579   4809        0.9    70.1    6.2    54.6   103\n#>  9       8277   4815        1.3    70.7   10.7    52.6    11\n#> 10       4931   4091        2      68.5   13.9    40.6    60\n#> # … with 40 more rows, 1 more variable: Area <dbl>, and\n#> #   abbreviated variable names ¹​`Life Exp`, ²​`HS Grad`\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\ndf2\n#> # A tibble: 50 × 1\n#>    value\n#>    <chr>\n#>  1 AL   \n#>  2 AK   \n#>  3 AZ   \n#>  4 AR   \n#>  5 CA   \n#>  6 CO   \n#>  7 CT   \n#>  8 DE   \n#>  9 FL   \n#> 10 GA   \n#> # … with 40 more rows\n#> # ℹ Use `print(n = ...)` to see more rows"},{"path":"merging-with-dplyr.html","id":"solutions-10","chapter":" 12 Merging with dplyr","heading":"12.5 Exercise Solutions","text":"","code":""},{"path":"merging-with-dplyr.html","id":"bind_rows-and-bind_cols-s","chapter":" 12 Merging with dplyr","heading":"12.5.1 bind_rows() and bind_cols() S","text":"* Run following explain R simply stack rows. , fix issue rename() function.","code":"\ndf_test1a <- tibble(xvar = c(1, 2), yvar = c(5, 1))\ndf_test1b <- tibble(x = c(1, 2), y = c(5, 1))\nbind_rows(df_test1a, df_test1b)\n#> # A tibble: 4 × 4\n#>    xvar  yvar     x     y\n#>   <dbl> <dbl> <dbl> <dbl>\n#> 1     1     5    NA    NA\n#> 2     2     1    NA    NA\n#> 3    NA    NA     1     5\n#> 4    NA    NA     2     1\n## This doesn't stack rows because the columns are named differently\n## in the two data sets. If xvar is the same variable as x and \n## yvar is the same variable as y, then we can rename the columns in\n## one of the data sets:\n\ndf_test1a <- df_test1a |> rename(x = \"xvar\", y = \"yvar\")\nbind_rows(df_test1a, df_test1b)\n#> # A tibble: 4 × 2\n#>       x     y\n#>   <dbl> <dbl>\n#> 1     1     5\n#> 2     2     1\n#> 3     1     5\n#> 4     2     1"},{"path":"merging-with-dplyr.html","id":"mutating-joins-s","chapter":" 12 Merging with dplyr","heading":"12.5.2 Mutating Joins S","text":"","code":""},{"path":"merging-with-dplyr.html","id":"filtering-joins-s","chapter":" 12 Merging with dplyr","heading":"12.5.3 Filtering Joins S","text":"","code":""},{"path":"merging-with-dplyr.html","id":"chapexercise-10-S","chapter":" 12 Merging with dplyr","heading":"12.5.4 Chapter Exercises S","text":"* Read gun violence data set, suppose want add row data set statistics gun ownership mortality rate District Columbia (Washington D.C., NE region, 16.7 deaths per 100,000 people, gun ownership rate 8.7%). , create tibble() single row representing D.C. combine new tibble overall gun violence data set. Name new data set all_df.* Combine columns states data set made Section Exercise 3 mortality data set without Washington D.C.* Use join function combine mortality data set D.C. states data set Exercise 3. exercise, keep row Washington D.C., take NA values variable observed states data.* Repeat Exercise 5, now drop Washington D.C. merging process. Practice join function (opposed slice() ing explictly).* Use semi_join() create subset states_df NE region. Hint: need filter all_df first contain states NE region.* thing Exercise 7, time, use anti_join(). Hint: ’ll need filter all_df different way achieve .","code":"\nlibrary(tidyverse)\nmortality_df <- read_csv(here(\"data/gun_violence_us.csv\"))\n#> Rows: 50 Columns: 4\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> chr (2): state, region\n#> dbl (2): mortality_rate, ownership_rate\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\ndc_df <- tibble(state = \"Washington D.C.\", mortality_rate = 16.7,\n       ownership_rate = 0.087, region = \"NE\")\nall_df <- bind_rows(mortality_df, dc_df)\nbind_cols(mortality_df, states_df)\nleft_join(all_df, states_df, by = c(\"state\" = \"value\"))\n#> # A tibble: 51 × 12\n#>    state mortality_r…¹ owner…² region Popul…³ Income Illit…⁴\n#>    <chr>         <dbl>   <dbl> <chr>    <dbl>  <dbl>   <dbl>\n#>  1 AL             16.7   0.489 South     3615   3624     2.1\n#>  2 AK             18.8   0.617 West       365   6315     1.5\n#>  3 AZ             13.4   0.323 West      2212   4530     1.8\n#>  4 AR             16.4   0.579 South     2110   3378     1.9\n#>  5 CA              7.4   0.201 West     21198   5114     1.1\n#>  6 CO             12.1   0.343 West      2541   4884     0.7\n#>  7 CT              4.9   0.166 NE        3100   5348     1.1\n#>  8 DE             11.1   0.052 NE         579   4809     0.9\n#>  9 FL             11.5   0.325 South     8277   4815     1.3\n#> 10 GA             13.7   0.316 South     4931   4091     2  \n#> # … with 41 more rows, 5 more variables: `Life Exp` <dbl>,\n#> #   Murder <dbl>, `HS Grad` <dbl>, Frost <dbl>, Area <dbl>,\n#> #   and abbreviated variable names ¹​mortality_rate,\n#> #   ²​ownership_rate, ³​Population, ⁴​Illiteracy\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n## or\nfull_join(all_df, states_df, by = c(\"state\" = \"value\"))\n#> # A tibble: 51 × 12\n#>    state mortality_r…¹ owner…² region Popul…³ Income Illit…⁴\n#>    <chr>         <dbl>   <dbl> <chr>    <dbl>  <dbl>   <dbl>\n#>  1 AL             16.7   0.489 South     3615   3624     2.1\n#>  2 AK             18.8   0.617 West       365   6315     1.5\n#>  3 AZ             13.4   0.323 West      2212   4530     1.8\n#>  4 AR             16.4   0.579 South     2110   3378     1.9\n#>  5 CA              7.4   0.201 West     21198   5114     1.1\n#>  6 CO             12.1   0.343 West      2541   4884     0.7\n#>  7 CT              4.9   0.166 NE        3100   5348     1.1\n#>  8 DE             11.1   0.052 NE         579   4809     0.9\n#>  9 FL             11.5   0.325 South     8277   4815     1.3\n#> 10 GA             13.7   0.316 South     4931   4091     2  \n#> # … with 41 more rows, 5 more variables: `Life Exp` <dbl>,\n#> #   Murder <dbl>, `HS Grad` <dbl>, Frost <dbl>, Area <dbl>,\n#> #   and abbreviated variable names ¹​mortality_rate,\n#> #   ²​ownership_rate, ³​Population, ⁴​Illiteracy\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\ninner_join(all_df, states_df, by = c(\"state\" = \"value\"))\n#> # A tibble: 50 × 12\n#>    state mortality_r…¹ owner…² region Popul…³ Income Illit…⁴\n#>    <chr>         <dbl>   <dbl> <chr>    <dbl>  <dbl>   <dbl>\n#>  1 AL             16.7   0.489 South     3615   3624     2.1\n#>  2 AK             18.8   0.617 West       365   6315     1.5\n#>  3 AZ             13.4   0.323 West      2212   4530     1.8\n#>  4 AR             16.4   0.579 South     2110   3378     1.9\n#>  5 CA              7.4   0.201 West     21198   5114     1.1\n#>  6 CO             12.1   0.343 West      2541   4884     0.7\n#>  7 CT              4.9   0.166 NE        3100   5348     1.1\n#>  8 DE             11.1   0.052 NE         579   4809     0.9\n#>  9 FL             11.5   0.325 South     8277   4815     1.3\n#> 10 GA             13.7   0.316 South     4931   4091     2  \n#> # … with 40 more rows, 5 more variables: `Life Exp` <dbl>,\n#> #   Murder <dbl>, `HS Grad` <dbl>, Frost <dbl>, Area <dbl>,\n#> #   and abbreviated variable names ¹​mortality_rate,\n#> #   ²​ownership_rate, ³​Population, ⁴​Illiteracy\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n## or\nleft_join(states_df, all_df, by = c(\"value\" = \"state\"))\n#> # A tibble: 50 × 12\n#>    Population Income Illiteracy Life …¹ Murder HS Gr…² Frost\n#>         <dbl>  <dbl>      <dbl>   <dbl>  <dbl>   <dbl> <dbl>\n#>  1       3615   3624        2.1    69.0   15.1    41.3    20\n#>  2        365   6315        1.5    69.3   11.3    66.7   152\n#>  3       2212   4530        1.8    70.6    7.8    58.1    15\n#>  4       2110   3378        1.9    70.7   10.1    39.9    65\n#>  5      21198   5114        1.1    71.7   10.3    62.6    20\n#>  6       2541   4884        0.7    72.1    6.8    63.9   166\n#>  7       3100   5348        1.1    72.5    3.1    56     139\n#>  8        579   4809        0.9    70.1    6.2    54.6   103\n#>  9       8277   4815        1.3    70.7   10.7    52.6    11\n#> 10       4931   4091        2      68.5   13.9    40.6    60\n#> # … with 40 more rows, 5 more variables: Area <dbl>,\n#> #   value <chr>, mortality_rate <dbl>,\n#> #   ownership_rate <dbl>, region <chr>, and abbreviated\n#> #   variable names ¹​`Life Exp`, ²​`HS Grad`\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\nne_df <- all_df |> filter(region == \"NE\")\nsemi_join(states_df, ne_df, by = c(\"value\" = \"state\"))\n#> # A tibble: 10 × 9\n#>    Popul…¹ Income Illit…² Life …³ Murder HS Gr…⁴ Frost  Area\n#>      <dbl>  <dbl>   <dbl>   <dbl>  <dbl>   <dbl> <dbl> <dbl>\n#>  1    3100   5348     1.1    72.5    3.1    56     139  4862\n#>  2     579   4809     0.9    70.1    6.2    54.6   103  1982\n#>  3    1058   3694     0.7    70.4    2.7    54.7   161 30920\n#>  4    4122   5299     0.9    70.2    8.5    52.3   101  9891\n#>  5    5814   4755     1.1    71.8    3.3    58.5   103  7826\n#>  6     812   4281     0.7    71.2    3.3    57.6   174  9027\n#>  7    7333   5237     1.1    70.9    5.2    52.5   115  7521\n#>  8   18076   4903     1.4    70.6   10.9    52.7    82 47831\n#>  9     931   4558     1.3    71.9    2.4    46.4   127  1049\n#> 10     472   3907     0.6    71.6    5.5    57.1   168  9267\n#> # … with 1 more variable: value <chr>, and abbreviated\n#> #   variable names ¹​Population, ²​Illiteracy, ³​`Life Exp`,\n#> #   ⁴​`HS Grad`\n#> # ℹ Use `colnames()` to see all variable names\nnotne_df <- all_df |> filter(region != \"NE\")\nanti_join(states_df, notne_df, by = c(\"value\" = \"state\"))\n#> # A tibble: 10 × 9\n#>    Popul…¹ Income Illit…² Life …³ Murder HS Gr…⁴ Frost  Area\n#>      <dbl>  <dbl>   <dbl>   <dbl>  <dbl>   <dbl> <dbl> <dbl>\n#>  1    3100   5348     1.1    72.5    3.1    56     139  4862\n#>  2     579   4809     0.9    70.1    6.2    54.6   103  1982\n#>  3    1058   3694     0.7    70.4    2.7    54.7   161 30920\n#>  4    4122   5299     0.9    70.2    8.5    52.3   101  9891\n#>  5    5814   4755     1.1    71.8    3.3    58.5   103  7826\n#>  6     812   4281     0.7    71.2    3.3    57.6   174  9027\n#>  7    7333   5237     1.1    70.9    5.2    52.5   115  7521\n#>  8   18076   4903     1.4    70.6   10.9    52.7    82 47831\n#>  9     931   4558     1.3    71.9    2.4    46.4   127  1049\n#> 10     472   3907     0.6    71.6    5.5    57.1   168  9267\n#> # … with 1 more variable: value <chr>, and abbreviated\n#> #   variable names ¹​Population, ²​Illiteracy, ³​`Life Exp`,\n#> #   ⁴​`HS Grad`\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"merging-with-dplyr.html","id":"rcode-10","chapter":" 12 Merging with dplyr","heading":"12.6 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\nlibrary(here)\natp_2019 <- read_csv(here(\"data/atp_matches_2019.csv\"))\natp_2018 <- read_csv(here(\"data/atp_matches_2018.csv\"))\nhead(atp_2019) \nhead(atp_2018)\nspec(atp_2018)\natp_2018 <- read_csv(here(\"data/atp_matches_2018.csv\"),\n                     col_types = cols(winner_seed = col_character(),\n                                      loser_seed = col_character()))\natp_df <- bind_rows(atp_2018, atp_2019)\natp_df\ndf_test2a <- tibble(xvar = c(1, 2))\ndf_test2b <- tibble(xvar = c(1, 2), y = c(5, 1))\nbind_rows(df_test2a, df_test2b)\ndf_test1a <- tibble(xvar = c(1, 2), yvar = c(5, 1))\ndf_test1b <- tibble(x = c(1, 2), y = c(5, 1))\nbind_cols(df_test1a, df_test1b)\nlibrary(tidyverse)\ndf1 <- tibble(name = c(\"Emily\", \"Miguel\", \"Tonya\"), fav_sport = c(\"Swimming\", \"Football\", \"Tennis\"))\ndf2 <- tibble(name = c(\"Tonya\", \"Miguel\", \"Emily\"),\n              fav_colour = c(\"Robin's Egg Blue\", \"Tickle Me Pink\", \"Goldenrod\"))\n##install.packages(\"babynames\")\nlibrary(babynames)\nlife_df <- babynames::lifetables\nbirth_df <- babynames::births\nbabynames_df <- babynames::babynames\nhead(babynames)\nhead(births)\nhead(lifetables)\ncombined_left <- left_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))\nhead(combined_left)\ntail(combined_left)\n## these will always do the same exact thing\nright_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))\nleft_join(birth_df, babynames_df, by = c(\"year\" = \"year\"))\nfull_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))\ninner_join(babynames_df, birth_df, by = c(\"year\" = \"year\"))\nslumajors_df <- read_csv(here(\"data/SLU_Majors_15_19.csv\"))\ncollegemajors_df <- read_csv(here(\"data/college-majors.csv\"))\nhead(slumajors_df)\nhead(collegemajors_df)\nleft_join(slumajors_df, collegemajors_df, by = c(\"Major\" = \"Major\"))\ncollegemajors_df <- collegemajors_df |>\n  mutate(Major = str_to_title(Major))\nleft_join(slumajors_df, collegemajors_df)\natp_2019 <- read_csv(here(\"data/atp_matches_2019.csv\"))\natp_2018 <- read_csv(here(\"data/atp_matches_2018.csv\"))\natp_2019\natp_2018\nwin10 <- atp_2018 |> group_by(winner_name) |>\n  summarise(nwin = n()) |> \n  filter(nwin >= 10)\nwin10\ntennis_2019_10 <- semi_join(atp_2019, win10,\n                            by = c(\"winner_name\" = \"winner_name\"))\ntennis_2019_10$winner_name\nnew_winners <- anti_join(atp_2019, atp_2018,\n                         by = c(\"winner_name\" = \"winner_name\")) \nnew_winners$winner_name\nnew_winners |> group_by(winner_name) |>\n  summarise(nwin = n()) |>\n  arrange(desc(nwin))"},{"path":"dates-with-lubridate.html","id":"dates-with-lubridate","chapter":" 13 Dates with lubridate","heading":" 13 Dates with lubridate","text":"Goals:use lubridate functions convert character variable <date> variable.use lubridate functions extract useful information <date> variable, including year, month, day week, day year.","code":""},{"path":"dates-with-lubridate.html","id":"converting-variables-to-date","chapter":" 13 Dates with lubridate","heading":"13.1 Converting Variables to <date>","text":"lubridate package built easily work Date objects DateTime objects. R actually class stores Time objects (unless install separate package). Dates tend much common Times, , primarily focus Dates, functions see easy extensions Times.begin, install lubridate package, load package library(). today() function prints today’s date now() prints today’s date time. can sometimes useful contexts, just run code see R stores dates date-times.first section deal convert variable R Date. use data set holidays Animal Crossing January April. columns data set :Holiday, name holiday andvarious columns different date formatsRead data set withWhich columns specified Dates? example, none columns <date> specification: date columns read character variables.","code":"\nlibrary(tidyverse)\nlibrary(lubridate)\ntoday()\n#> [1] \"2022-10-18\"\nnow()\n#> [1] \"2022-10-18 15:20:33 EDT\"\nlibrary(here)\nholiday_df <- read_csv(here(\"data/animal_crossing_holidays.csv\"))\nholiday_df\n#> # A tibble: 6 × 10\n#>   Holiday    Date1 Date2 Date3 Date4 Date5 Month  Year   Day\n#>   <chr>      <chr> <chr> <chr> <chr> <chr> <dbl> <dbl> <dbl>\n#> 1 New Year'… 1-Ja… Jan-… 1/1/… 1/1/… 2020…     1  2020     1\n#> 2 Groundhog… 2-Fe… Feb-… 2/2/… 2/2/… 2020…     2  2020     2\n#> 3 Valentine… 14-F… Feb-… 2/14… 2020… 2020…     2  2020    14\n#> 4 Shamrock … 17-M… Mar-… 3/17… 2020… 2020…     3  2020    17\n#> 5 Bunny Day  12-A… Apr-… 4/12… 12/4… 2020…     4  2020    12\n#> 6 Earth Day  22-A… Apr-… 4/22… 2020… 2020…     4  2020    22\n#> # … with 1 more variable: Month2 <chr>\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"dates-with-lubridate.html","id":"from-chr-to-date","chapter":" 13 Dates with lubridate","heading":"13.1.1 From <chr> to <date>","text":"use dmy() series functions lubridate convert character variables dates. typically pair new function mutate() statement: much like forcats functions, almost always creating new variable.series dmy()-type variables, corresponding different Day-Month-Year order.dmy() used parse date character vector day first, month second, year last.ymd() used parse date year first, month second, date lastydm() used parse date year first, day second, month last,….dym(), mdy(), myd() work similarly. lubridate usually “smart” picks dates kinds different formats (e.g. can pick specifying October month Oct month 10 month).Let’s try Date1 Date2:Reminder: <date> objects even matter? Compare following two plots: one made date <chr> form date appropriate <date> form.plot ordering x-axis make sense?","code":"\nholiday_df |> mutate(Date_test = dmy(Date1)) |>\n  select(Date_test, everything())\n#> # A tibble: 6 × 11\n#>   Date_test  Holiday     Date1 Date2 Date3 Date4 Date5 Month\n#>   <date>     <chr>       <chr> <chr> <chr> <chr> <chr> <dbl>\n#> 1 2020-01-01 New Year's… 1-Ja… Jan-… 1/1/… 1/1/… 2020…     1\n#> 2 2020-02-02 Groundhog … 2-Fe… Feb-… 2/2/… 2/2/… 2020…     2\n#> 3 2020-02-14 Valentine'… 14-F… Feb-… 2/14… 2020… 2020…     2\n#> 4 2020-03-17 Shamrock D… 17-M… Mar-… 3/17… 2020… 2020…     3\n#> 5 2020-04-12 Bunny Day   12-A… Apr-… 4/12… 12/4… 2020…     4\n#> 6 2020-04-22 Earth Day   22-A… Apr-… 4/22… 2020… 2020…     4\n#> # … with 3 more variables: Year <dbl>, Day <dbl>,\n#> #   Month2 <chr>\n#> # ℹ Use `colnames()` to see all variable names\nholiday_df |> mutate(Date_test = mdy(Date2)) |>\n  select(Date_test, everything())\n#> # A tibble: 6 × 11\n#>   Date_test  Holiday     Date1 Date2 Date3 Date4 Date5 Month\n#>   <date>     <chr>       <chr> <chr> <chr> <chr> <chr> <dbl>\n#> 1 2020-01-01 New Year's… 1-Ja… Jan-… 1/1/… 1/1/… 2020…     1\n#> 2 2020-02-02 Groundhog … 2-Fe… Feb-… 2/2/… 2/2/… 2020…     2\n#> 3 2020-02-14 Valentine'… 14-F… Feb-… 2/14… 2020… 2020…     2\n#> 4 2020-03-17 Shamrock D… 17-M… Mar-… 3/17… 2020… 2020…     3\n#> 5 2020-04-12 Bunny Day   12-A… Apr-… 4/12… 12/4… 2020…     4\n#> 6 2020-04-22 Earth Day   22-A… Apr-… 4/22… 2020… 2020…     4\n#> # … with 3 more variables: Year <dbl>, Day <dbl>,\n#> #   Month2 <chr>\n#> # ℹ Use `colnames()` to see all variable names\nggplot(data = holiday_df, aes(x = Date1, y = Holiday)) +\n  geom_point()\nholiday_df <- holiday_df |> mutate(Date_test_plot = dmy(Date1)) |>\n  select(Date_test_plot, everything())\nggplot(data = holiday_df, aes(x = Date_test_plot, y = Holiday)) +\n  geom_point()"},{"path":"dates-with-lubridate.html","id":"making-a-date-variable-from-date-components","chapter":" 13 Dates with lubridate","heading":"13.1.2 Making a <date> variable from Date Components","text":"Another way create Date object assemble make_date() month, day, year components, stored separate column:, Month stored character (e.g. February) instead number (e.g. 2), problems arise make_date() function:make_date() function requires specific format year, month, day columns. may take little pre-processing put particular data set format.","code":"\nholiday_df |> mutate(Date_test2 = make_date(year = Year,\n                                             month = Month,\n                                             day = Day)) |>\n  select(Date_test2, everything())\n#> # A tibble: 6 × 12\n#>   Date_test2 Date_test_plot Holiday  Date1 Date2 Date3 Date4\n#>   <date>     <date>         <chr>    <chr> <chr> <chr> <chr>\n#> 1 2020-01-01 2020-01-01     New Yea… 1-Ja… Jan-… 1/1/… 1/1/…\n#> 2 2020-02-02 2020-02-02     Groundh… 2-Fe… Feb-… 2/2/… 2/2/…\n#> 3 2020-02-14 2020-02-14     Valenti… 14-F… Feb-… 2/14… 2020…\n#> 4 2020-03-17 2020-03-17     Shamroc… 17-M… Mar-… 3/17… 2020…\n#> 5 2020-04-12 2020-04-12     Bunny D… 12-A… Apr-… 4/12… 12/4…\n#> 6 2020-04-22 2020-04-22     Earth D… 22-A… Apr-… 4/22… 2020…\n#> # … with 5 more variables: Date5 <chr>, Month <dbl>,\n#> #   Year <dbl>, Day <dbl>, Month2 <chr>\n#> # ℹ Use `colnames()` to see all variable names\nholiday_df |> mutate(Date_test2 = make_date(year = Year,\n                                             month = Month2,\n                                             day = Day)) |>\n  select(Date_test2, everything())\n#> # A tibble: 6 × 12\n#>   Date_test2 Date_test_plot Holiday  Date1 Date2 Date3 Date4\n#>   <date>     <date>         <chr>    <chr> <chr> <chr> <chr>\n#> 1 NA         2020-01-01     New Yea… 1-Ja… Jan-… 1/1/… 1/1/…\n#> 2 NA         2020-02-02     Groundh… 2-Fe… Feb-… 2/2/… 2/2/…\n#> 3 NA         2020-02-14     Valenti… 14-F… Feb-… 2/14… 2020…\n#> 4 NA         2020-03-17     Shamroc… 17-M… Mar-… 3/17… 2020…\n#> 5 NA         2020-04-12     Bunny D… 12-A… Apr-… 4/12… 12/4…\n#> 6 NA         2020-04-22     Earth D… 22-A… Apr-… 4/22… 2020…\n#> # … with 5 more variables: Date5 <chr>, Month <dbl>,\n#> #   Year <dbl>, Day <dbl>, Month2 <chr>\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"dates-with-lubridate.html","id":"exercise-11-1","chapter":" 13 Dates with lubridate","heading":"13.1.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 13.4.* ’s issue trying convert Date4 <date> form? may want investigate Date4 answer question.* Practice converting Date3 Date5 <date> variables lubridate functions.","code":"\nholiday_df |> mutate(Date_test = ymd(Date4)) |>\n  select(Date_test, everything())\n#> # A tibble: 6 × 12\n#>   Date_test  Date_test_plot Holiday  Date1 Date2 Date3 Date4\n#>   <date>     <date>         <chr>    <chr> <chr> <chr> <chr>\n#> 1 2001-01-20 2020-01-01     New Yea… 1-Ja… Jan-… 1/1/… 1/1/…\n#> 2 2002-02-20 2020-02-02     Groundh… 2-Fe… Feb-… 2/2/… 2/2/…\n#> 3 NA         2020-02-14     Valenti… 14-F… Feb-… 2/14… 2020…\n#> 4 NA         2020-03-17     Shamroc… 17-M… Mar-… 3/17… 2020…\n#> 5 2012-04-20 2020-04-12     Bunny D… 12-A… Apr-… 4/12… 12/4…\n#> 6 NA         2020-04-22     Earth D… 22-A… Apr-… 4/22… 2020…\n#> # … with 5 more variables: Date5 <chr>, Month <dbl>,\n#> #   Year <dbl>, Day <dbl>, Month2 <chr>\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"dates-with-lubridate.html","id":"functions-for-date-variables","chapter":" 13 Dates with lubridate","heading":"13.2 Functions for <date> Variables","text":"object <date> format, special functions lubridate can used date variable. investigate functions, pull stock market data Yahoo using quantmod package. Install package, run following code, gets stock market price data Apple, Nintendo, Chipotle, S & P 500 Index 2011 now. Note ability understand code , skip code now focus new information section (information date functions).’ll chance Exercises choose stocks investigate. now, ’ve made data set three variables:start_date, opening date stock marketStock_Type, factor 4 levels: Apple, Nintendo, Chipotle, S & P 500Price, price stock?First, let’s make line plot shows S & P 500 changed time:, ’s information can get start_date variable. might interested things like day week, monthly trends, yearly trends. extract variables like “weekday” “month” <date> variable, series functions fairly straightforward use. discuss year() month(), mday(), yday(), wday() functions.","code":"\n## install.packages(\"quantmod\")\nlibrary(quantmod)\n\nstart <- ymd(\"2011-01-01\")\nend <- ymd(\"2021-5-19\")\ngetSymbols(c(\"AAPL\", \"NTDOY\", \"CMG\", \"SPY\"), src = \"yahoo\",\n           from = start, to = end)\n#> [1] \"AAPL\"  \"NTDOY\" \"CMG\"   \"SPY\"\n\ndate_tib <- as_tibble(index(AAPL)) |>\n  rename(start_date = value)\napp_tib <- as_tibble(AAPL)\nnint_tib <- as_tibble(NTDOY)\nchip_tib <- as_tibble(CMG)\nspy_tib <- as_tibble(SPY)\nall_stocks <- bind_cols(date_tib, app_tib, nint_tib, chip_tib, spy_tib)\n\nstocks_long <- all_stocks |>\n  select(start_date, AAPL.Adjusted, NTDOY.Adjusted,\n                      CMG.Adjusted, SPY.Adjusted) |>\n  pivot_longer(2:5, names_to = \"Stock_Type\", values_to = \"Price\") |>\n  mutate(Stock_Type = fct_recode(Stock_Type,\n                                 Apple = \"AAPL.Adjusted\",\n                                 Nintendo = \"NTDOY.Adjusted\",\n                                 Chipotle = \"CMG.Adjusted\",\n                                 `S & P 500` = \"SPY.Adjusted\"\n                                 ))\ntail(stocks_long)\n#> # A tibble: 6 × 3\n#>   start_date Stock_Type  Price\n#>   <date>     <fct>       <dbl>\n#> 1 2021-05-17 Chipotle   1332. \n#> 2 2021-05-17 S & P 500   407. \n#> 3 2021-05-18 Apple       124. \n#> 4 2021-05-18 Nintendo     14.1\n#> 5 2021-05-18 Chipotle   1325. \n#> 6 2021-05-18 S & P 500   403.\nstocks_sp <- stocks_long |> filter(Stock_Type == \"S & P 500\")\nggplot(data = stocks_sp, aes(x = start_date, y = Price)) +\n  geom_line()"},{"path":"dates-with-lubridate.html","id":"year-month-and-mday","chapter":" 13 Dates with lubridate","heading":"13.2.1 year(), month(), and mday()","text":"functions year(), month(), mday() can grab year, month, day month, respectively, <date> variable. Like forcats functions, almost always paired mutate() statement create new variable:","code":"\nstocks_long |> mutate(year_stock = year(start_date))\nstocks_long |> mutate(month_stock = month(start_date))\nstocks_long |> mutate(day_stock = mday(start_date))"},{"path":"dates-with-lubridate.html","id":"yday-and-wday","chapter":" 13 Dates with lubridate","heading":"13.2.2 yday() and wday()","text":"yday() function grabs day year <date> object. example,returns 309, indicating November 4th 309th day year 2020. Using function mutate() statement creates new variable yday observation:Finally, function wday() grabs day week <date>. default, wday() puts day week numeric, find confusing, can’t ever remember whether 1 means Sunday 1 means Monday. Adding, label = TRUE creates weekday variable Sunday, Monday, Tuesday, etc.:Possible uses functions :want look differences years (year())want look differences years (year())want look differences months (month())want look differences months (month())want look differences days week (wday())want look differences days week (wday())want see whether yearly trends within years (yday())want see whether yearly trends within years (yday())Note: Working times extremely similar working dates. Instead ymd(), mdy(), etc., tack extra letters specify order hour, minute, seconds appear variable: ymd_hms() converts character vector order year, month, day, hour, minute, second <datetime>.Additionally, functions hour(), minute(), second() grab hour, minute, second <datetime> variable.Note Complications: Things can get complicated, especially start consider things like time duration. reason time system inherently confusing. Consider following might affect analysis involving time duration:time zonesleap years (years number days)differing number days given monthdaylight saving time (days number hours)","code":"\ntest <- mdy(\"November 4, 2020\")\nyday(test)\n#> [1] 309\nstocks_long |> mutate(day_in_year = yday(start_date))\n#> # A tibble: 10,444 × 4\n#>    start_date Stock_Type  Price day_in_year\n#>    <date>     <fct>       <dbl>       <dbl>\n#>  1 2011-01-03 Apple       10.0            3\n#>  2 2011-01-03 Nintendo     7.34           3\n#>  3 2011-01-03 Chipotle   224.             3\n#>  4 2011-01-03 S & P 500  102.             3\n#>  5 2011-01-04 Apple       10.1            4\n#>  6 2011-01-04 Nintendo     7.1            4\n#>  7 2011-01-04 Chipotle   222.             4\n#>  8 2011-01-04 S & P 500  102.             4\n#>  9 2011-01-05 Apple       10.2            5\n#> 10 2011-01-05 Nintendo     6.92           5\n#> # … with 10,434 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\nstocks_long |> mutate(day_of_week = wday(start_date))\nstocks_long |> mutate(day_of_week = wday(start_date,\n                                          label = TRUE, abbr = FALSE))"},{"path":"dates-with-lubridate.html","id":"exercise-11-2","chapter":" 13 Dates with lubridate","heading":"13.2.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 13.4.month() function gives numbers corresponding month default. Type ?month figure argument need change get names (January, February, etc.) instead month numbers. abbreviations (Jan, Feb, etc.) month instead month numbers? Try making changes mutate() statement .","code":"\nstocks_long |> mutate(month_stock = month(start_date))"},{"path":"dates-with-lubridate.html","id":"chapexercise-11","chapter":" 13 Dates with lubridate","heading":"13.3 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 13.4.truncated argument ymd(), dmy(), mdy(), etc. allow R parse dates aren’t actually complete. example,parses 2019 January 1, 2019 month day missing. 2 means last two parts date (case, month day) allowed missing. Similarly,truncates year (given 0000). truncate function usually useful context first example truncated month /day.Examine ds_google.csv, containsMonth, year month 2004 nowData_Science, relative popularity data science (Google keeps calculates “popularity” somewhat mystery likely based number times people search term “Data Science”)* Use lubridate function truncated option convert Month variable <date> format.* Use lubridate function truncated option convert Month variable <date> format.* Make plot popularity Data Science Time. Add smoother plot. patterns notice?* Make plot popularity Data Science Time. Add smoother plot. patterns notice?data obtained Google Trends: Google Trends. Google Trends incredibly cool explore, even without R.* Google Trends, Enter search term, change Time dropdown menu 2004-present. , enter second search term want compare. can also change country want (, can keep country United States).search terms “super smash” “animal crossing”, something interests !top-right window graph, click arrow download data set. Delete first two rows data set (either Excel R), read data set, change date variable ’s Date format.* Make plot Popularity variables time. Hint: data set need tidied first?* Make plot Popularity variables time. Hint: data set need tidied first?* Using data set explored variable two 2004 now, make table average popularity year. Hint: ’ll need lubridate function extract year variable date object.* Using data set explored variable two 2004 now, make table average popularity year. Hint: ’ll need lubridate function extract year variable date object.* Clear search now enter search term ’d like investigate past 90 days. Mine “Pittsburgh Steelers” , , something interests .* Clear search now enter search term ’d like investigate past 90 days. Mine “Pittsburgh Steelers” , , something interests ., click download button read data R. Convert date variable <date> format.* Make plot popularity variable time, adding smoother.* Make plot popularity variable time, adding smoother.Using data set explored variable past 90 days, construct table compares average popularity day week (Monday Saturday).Using data set explored variable past 90 days, construct table compares average popularity day week (Monday Saturday).Examine ds_df data set , data set data science Google Trends, suppose observation day every year (just one observation per month). want look whether data science popular certain days week. Explain following strategy wouldn’t really work well.Examine ds_df data set , data set data science Google Trends, suppose observation day every year (just one observation per month). want look whether data science popular certain days week. Explain following strategy wouldn’t really work well.create weekday variable wday()use summarise() group_by() find average popularity day weekUse code tutorial section Stocks data get data frame stock prices couple different stocks interest . start end date use completely .Explore stock data chose, constructing line plot price time, well graphs summaries show interesting patterns across years, months, days, days week, etc.Use lag() function create new variable previous day’s stock price. Can predict current stock price based previous day’s stock price accurately? ? Use either graphical numerical evidence.","code":"\nlibrary(lubridate)\nymd(\"2019\", truncated = 2)\n#> [1] \"2019-01-01\"\ndmy(\"19-10\", truncated = 1)\n#> [1] \"0000-10-19\"\nlibrary(tidyverse)\nlibrary(lubridate)\nds_df <- read_csv(here(\"data/ds_google.csv\"))\nds_df\n#> # A tibble: 202 × 2\n#>    Month   Data_Science\n#>    <chr>          <dbl>\n#>  1 2004-01           14\n#>  2 2004-02            8\n#>  3 2004-03           16\n#>  4 2004-04           11\n#>  5 2004-05            5\n#>  6 2004-06            8\n#>  7 2004-07            7\n#>  8 2004-08            9\n#>  9 2004-09           13\n#> 10 2004-10           11\n#> # … with 192 more rows\n#> # ℹ Use `print(n = ...)` to see more rows"},{"path":"dates-with-lubridate.html","id":"solutions-11","chapter":" 13 Dates with lubridate","heading":"13.4 Exercise Solutions","text":"","code":""},{"path":"dates-with-lubridate.html","id":"converting-variables-to-date-s","chapter":" 13 Dates with lubridate","heading":"13.4.1 Converting Variables to <date> S","text":"* ’s issue trying convert Date4 <date> form?* Practice converting Date3 Date5 date objects lubridate functions.","code":"\nholiday_df |> mutate(Date_test = ymd(Date4)) |>\n  select(Date_test, everything())\n#> # A tibble: 6 × 12\n#>   Date_test  Date_test_plot Holiday  Date1 Date2 Date3 Date4\n#>   <date>     <date>         <chr>    <chr> <chr> <chr> <chr>\n#> 1 2001-01-20 2020-01-01     New Yea… 1-Ja… Jan-… 1/1/… 1/1/…\n#> 2 2002-02-20 2020-02-02     Groundh… 2-Fe… Feb-… 2/2/… 2/2/…\n#> 3 NA         2020-02-14     Valenti… 14-F… Feb-… 2/14… 2020…\n#> 4 NA         2020-03-17     Shamroc… 17-M… Mar-… 3/17… 2020…\n#> 5 2012-04-20 2020-04-12     Bunny D… 12-A… Apr-… 4/12… 12/4…\n#> 6 NA         2020-04-22     Earth D… 22-A… Apr-… 4/22… 2020…\n#> # … with 5 more variables: Date5 <chr>, Month <dbl>,\n#> #   Year <dbl>, Day <dbl>, Month2 <chr>\n#> # ℹ Use `colnames()` to see all variable names\n## Date4 has two __different__ formats, \n## which creates problems for `lubridate` functions\nholiday_df |> mutate(Date_test = mdy(Date3)) |>\n  select(Date_test, everything())\n#> # A tibble: 6 × 12\n#>   Date_test  Date_test_plot Holiday  Date1 Date2 Date3 Date4\n#>   <date>     <date>         <chr>    <chr> <chr> <chr> <chr>\n#> 1 2020-01-01 2020-01-01     New Yea… 1-Ja… Jan-… 1/1/… 1/1/…\n#> 2 2020-02-02 2020-02-02     Groundh… 2-Fe… Feb-… 2/2/… 2/2/…\n#> 3 2020-02-14 2020-02-14     Valenti… 14-F… Feb-… 2/14… 2020…\n#> 4 2020-03-17 2020-03-17     Shamroc… 17-M… Mar-… 3/17… 2020…\n#> 5 2020-04-12 2020-04-12     Bunny D… 12-A… Apr-… 4/12… 12/4…\n#> 6 2020-04-22 2020-04-22     Earth D… 22-A… Apr-… 4/22… 2020…\n#> # … with 5 more variables: Date5 <chr>, Month <dbl>,\n#> #   Year <dbl>, Day <dbl>, Month2 <chr>\n#> # ℹ Use `colnames()` to see all variable names\nholiday_df |> mutate(Date_test = ymd(Date5)) |>\n  select(Date_test, everything())\n#> # A tibble: 6 × 12\n#>   Date_test  Date_test_plot Holiday  Date1 Date2 Date3 Date4\n#>   <date>     <date>         <chr>    <chr> <chr> <chr> <chr>\n#> 1 2020-01-01 2020-01-01     New Yea… 1-Ja… Jan-… 1/1/… 1/1/…\n#> 2 2020-02-02 2020-02-02     Groundh… 2-Fe… Feb-… 2/2/… 2/2/…\n#> 3 2020-02-14 2020-02-14     Valenti… 14-F… Feb-… 2/14… 2020…\n#> 4 2020-03-17 2020-03-17     Shamroc… 17-M… Mar-… 3/17… 2020…\n#> 5 2020-04-12 2020-04-12     Bunny D… 12-A… Apr-… 4/12… 12/4…\n#> 6 2020-04-22 2020-04-22     Earth D… 22-A… Apr-… 4/22… 2020…\n#> # … with 5 more variables: Date5 <chr>, Month <dbl>,\n#> #   Year <dbl>, Day <dbl>, Month2 <chr>\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"dates-with-lubridate.html","id":"functions-for-date-variables-s","chapter":" 13 Dates with lubridate","heading":"13.4.2 Functions for <date> Variables S","text":"","code":""},{"path":"dates-with-lubridate.html","id":"chapexercise-11-S","chapter":" 13 Dates with lubridate","heading":"13.4.3 Chapter Exercises S","text":"* Use lubridate function truncated option convert Month variable <date> format.* Make plot popularity Data Science Time. Add smoother plot. patterns notice?* Google Trends, Enter search term, change Time dropdown menu 2004-present. , enter second search term want compare. can also change country want (, can keep country United States).search terms “super smash” “animal crossing”, something interests !top-right window graph, click arrow download data set. Delete first two rows data set (either Excel R), read data set, change date variable ’s Date format.* Make plot Popularity variables time. Hint: data set need tidied first?* Using data set explored variable two 2004 now, make table average popularity year. Hint: ’ll need lubridate function extract year variable date object.* Using data set explored variable two 2004 now, make table average popularity year. Hint: ’ll need lubridate function extract year variable date object.* Clear search now enter search term ’d like investigate past 90 days. Mine “pittsburgh steelers” , , something interests .* Clear search now enter search term ’d like investigate past 90 days. Mine “pittsburgh steelers” , , something interests ., click download button read data R. Convert date variable <date> format.* Make plot popularity variable time, adding smoother.","code":"\nds_df <- ds_df |> mutate(Month = ymd(Month, truncated = 1))\nds_df\nggplot(data = ds_df, aes(x = Month, y = Data_Science)) +\n  geom_line() +\n  geom_smooth(se = FALSE)\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'\n## it's like super popular!!!!\nvideogame_df <- read_csv(here(\"data/smash_animal_crossing.csv\"))\n#> Rows: 203 Columns: 3\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> chr (1): Month\n#> dbl (2): super_smash, animal_crossing\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nvideogame_df <- videogame_df |> mutate(date = ymd(Month, truncated = 1))\nvideogame_long <- videogame_df |>\n  pivot_longer(cols = c(\"super_smash\", \"animal_crossing\"),\n                              names_to = \"game\",\n                              values_to = \"popularity\")\nggplot(data = videogame_long, aes(x = date, \n                                  y = popularity,\n                                  colour = game)) +\n  geom_line() +\n  scale_colour_viridis_d(begin = 0, end = 0.9)\nsteelers_df <- read_csv(here(\"data/steelers.csv\"))\n#> Rows: 91 Columns: 2\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> chr (1): Day\n#> dbl (1): Steelers\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nsteelers_df <- steelers_df |> mutate(day_var = mdy(Day))\nggplot(data = steelers_df, aes(x = day_var, y = Steelers)) +\n  geom_smooth() + \n  geom_line() +\n  labs(y = \"Popularity\")\n#> `geom_smooth()` using method = 'loess' and formula 'y ~ x'"},{"path":"dates-with-lubridate.html","id":"rcode-11","chapter":" 13 Dates with lubridate","heading":"13.5 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\nlibrary(lubridate)\ntoday()\nnow()\nlibrary(here)\nholiday_df <- read_csv(here(\"data/animal_crossing_holidays.csv\"))\nholiday_df\nholiday_df |> mutate(Date_test = dmy(Date1)) |>\n  select(Date_test, everything())\nholiday_df |> mutate(Date_test = mdy(Date2)) |>\n  select(Date_test, everything())\nggplot(data = holiday_df, aes(x = Date1, y = Holiday)) +\n  geom_point()\nholiday_df <- holiday_df |> mutate(Date_test_plot = dmy(Date1)) |>\n  select(Date_test_plot, everything())\nggplot(data = holiday_df, aes(x = Date_test_plot, y = Holiday)) +\n  geom_point()\nholiday_df |> mutate(Date_test2 = make_date(year = Year,\n                                             month = Month,\n                                             day = Day)) |>\n  select(Date_test2, everything())\nholiday_df |> mutate(Date_test2 = make_date(year = Year,\n                                             month = Month2,\n                                             day = Day)) |>\n  select(Date_test2, everything())\n## install.packages(\"quantmod\")\nlibrary(quantmod)\n\nstart <- ymd(\"2011-01-01\")\nend <- ymd(\"2021-5-19\")\ngetSymbols(c(\"AAPL\", \"NTDOY\", \"CMG\", \"SPY\"), src = \"yahoo\",\n           from = start, to = end)\n\ndate_tib <- as_tibble(index(AAPL)) |>\n  rename(start_date = value)\napp_tib <- as_tibble(AAPL)\nnint_tib <- as_tibble(NTDOY)\nchip_tib <- as_tibble(CMG)\nspy_tib <- as_tibble(SPY)\nall_stocks <- bind_cols(date_tib, app_tib, nint_tib, chip_tib, spy_tib)\n\nstocks_long <- all_stocks |>\n  select(start_date, AAPL.Adjusted, NTDOY.Adjusted,\n                      CMG.Adjusted, SPY.Adjusted) |>\n  pivot_longer(2:5, names_to = \"Stock_Type\", values_to = \"Price\") |>\n  mutate(Stock_Type = fct_recode(Stock_Type,\n                                 Apple = \"AAPL.Adjusted\",\n                                 Nintendo = \"NTDOY.Adjusted\",\n                                 Chipotle = \"CMG.Adjusted\",\n                                 `S & P 500` = \"SPY.Adjusted\"\n                                 ))\ntail(stocks_long)\nstocks_sp <- stocks_long |> filter(Stock_Type == \"S & P 500\")\nggplot(data = stocks_sp, aes(x = start_date, y = Price)) +\n  geom_line()\nstocks_long |> mutate(year_stock = year(start_date))\nstocks_long |> mutate(month_stock = month(start_date))\nstocks_long |> mutate(day_stock = mday(start_date))\ntest <- mdy(\"November 4, 2020\")\nyday(test)\nstocks_long |> mutate(day_in_year = yday(start_date))\nstocks_long |> mutate(day_of_week = wday(start_date))\nstocks_long |> mutate(day_of_week = wday(start_date,\n                                          label = TRUE, abbr = FALSE))"},{"path":"text-data-with-tidytext-and-stringr.html","id":"text-data-with-tidytext-and-stringr","chapter":" 14 Text Data with tidytext and stringr","heading":" 14 Text Data with tidytext and stringr","text":"Goals:use functions stringr package tidytext package analyze text data.introduce issues manipulating strings don’t pertain numeric factor data.perform basic sentiment analysis.","code":""},{"path":"text-data-with-tidytext-and-stringr.html","id":"text-analysis","chapter":" 14 Text Data with tidytext and stringr","heading":"14.1 Text Analysis","text":"Beyonce legend. example, work text analysis lyrics songs Beyonce’s albums, utilizing functions stringr parse strings tidytext convert text data tidy format. begin, read data set Beyonce’s lyrics:focused line variable, value variable contains line Beyonce song. ’s variables present well, song_name artist_name (data set originally came data set artists Beyonce).can look first 4 values line withOur end goal construct plot shows popular words Beyonce’s albums. much challenging sounds deal nuances working text data.tidytext package makes lot easier work text data many regards. Let’s use unnest_tokens() functions tidytext separate lines individual words. ’ll name new data set beyonce_unnest:’ll want make sure either words capitalized words capitalized, consistency (remember R case-sensitive). end, ’ll modify word variable use stringr’s str_to_lower() change letters lower-case:Let’s try counting Beyonce’s popular words data set just made:’s issue ?remedy , can use called stop words: words common carry little meaningful information. example , , , etc. stop words. need eliminate data set continue . Luckily, tidytext package also provides data set common stop words data set named stop_words:Let’s join Beyonce lyrics data set stop words data set elminate stop words:, can re-make table stop words removed:Looking list, still stop words picked stop_words data set. address , well make plot, exercises.","code":"\nlibrary(tidyverse)\nlibrary(here)\nbeyonce <- read_csv(here(\"data/beyonce_lyrics.csv\"))\nhead(beyonce)\nbeyonce$line[1:4]\n#> [1] \"If I ain't got nothing, I got you\"                       \n#> [2] \"If I ain't got something, I don't give a damn\"           \n#> [3] \"'Cause I got it with you\"                                \n#> [4] \"I don't know much about algebra, but I know 1+1 equals 2\"\nlibrary(tidytext)\nbeyonce_unnest <- beyonce |> unnest_tokens(output = \"word\", input = \"line\")\nbeyonce_unnest\n#> # A tibble: 164,740 × 6\n#>    song_id song_name artist_id artist_name song_line word   \n#>      <dbl> <chr>         <dbl> <chr>           <dbl> <chr>  \n#>  1   50396 1+1             498 Beyoncé             1 if     \n#>  2   50396 1+1             498 Beyoncé             1 i      \n#>  3   50396 1+1             498 Beyoncé             1 ain't  \n#>  4   50396 1+1             498 Beyoncé             1 got    \n#>  5   50396 1+1             498 Beyoncé             1 nothing\n#>  6   50396 1+1             498 Beyoncé             1 i      \n#>  7   50396 1+1             498 Beyoncé             1 got    \n#>  8   50396 1+1             498 Beyoncé             1 you    \n#>  9   50396 1+1             498 Beyoncé             2 if     \n#> 10   50396 1+1             498 Beyoncé             2 i      \n#> # … with 164,730 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\nbeyonce_unnest <- beyonce_unnest |> mutate(word = str_to_lower(word))\nbeyonce_unnest |> group_by(word) |>\n  summarise(n = n()) |>\n  arrange(desc(n))\n#> # A tibble: 6,469 × 2\n#>    word      n\n#>    <chr> <int>\n#>  1 you    7693\n#>  2 i      6669\n#>  3 the    4719\n#>  4 me     3774\n#>  5 to     3070\n#>  6 it     2999\n#>  7 a      2798\n#>  8 my     2676\n#>  9 and    2385\n#> 10 on     2344\n#> # … with 6,459 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\nhead(stop_words)\n#> # A tibble: 6 × 2\n#>   word      lexicon\n#>   <chr>     <chr>  \n#> 1 a         SMART  \n#> 2 a's       SMART  \n#> 3 able      SMART  \n#> 4 about     SMART  \n#> 5 above     SMART  \n#> 6 according SMART\nbeyonce_stop <- anti_join(beyonce_unnest, stop_words, by = c(\"word\" = \"word\"))\nbeyonce_sum <- beyonce_stop |> group_by(word) |>\n  summarise(n = n()) |>\n  arrange(desc(n)) |>\n  print(n = 25)\n#> # A tibble: 5,937 × 2\n#>    word        n\n#>    <chr>   <int>\n#>  1 love     1362\n#>  2 baby     1024\n#>  3 girl      592\n#>  4 wanna     564\n#>  5 hey       499\n#>  6 boy       494\n#>  7 yeah      491\n#>  8 feel      488\n#>  9 time      452\n#> 10 uh        408\n#> 11 halo      383\n#> 12 check     366\n#> 13 tonight   342\n#> 14 girls     341\n#> 15 ya        327\n#> 16 run       325\n#> 17 crazy     308\n#> 18 world     301\n#> 19 body      287\n#> 20 ooh       281\n#> 21 ladies    269\n#> 22 top       241\n#> 23 gotta     240\n#> 24 beyoncé   238\n#> 25 night     213\n#> # … with 5,912 more rows\n#> # ℹ Use `print(n = ...)` to see more rows\nbeyonce_sum\n#> # A tibble: 5,937 × 2\n#>    word      n\n#>    <chr> <int>\n#>  1 love   1362\n#>  2 baby   1024\n#>  3 girl    592\n#>  4 wanna   564\n#>  5 hey     499\n#>  6 boy     494\n#>  7 yeah    491\n#>  8 feel    488\n#>  9 time    452\n#> 10 uh      408\n#> # … with 5,927 more rows\n#> # ℹ Use `print(n = ...)` to see more rows"},{"path":"text-data-with-tidytext-and-stringr.html","id":"exercise-12-1","chapter":" 14 Text Data with tidytext and stringr","heading":"14.1.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 14.5.Look remaining words. look like stop words missed stop words tidytext package? Create tibble remaining stop words (like ooh, gotta, ya, uh, yeah) picked tidytext package, use join function drop words data set.Look remaining words. look like stop words missed stop words tidytext package? Create tibble remaining stop words (like ooh, gotta, ya, uh, yeah) picked tidytext package, use join function drop words data set.new data set, construct lollipop plot bar plot shows 20 common words Beyonce uses, well number times word used.new data set, construct lollipop plot bar plot shows 20 common words Beyonce uses, well number times word used.Use wordcloud() function wordcloud library code make wordcloud Beyonce’s words.Use wordcloud() function wordcloud library code make wordcloud Beyonce’s words., use ?wordcloud read various arguments like random.order, scale, random.color .want delve text data , ’ll need learn regular expressions , regexes. interested, can read R4DS textbook. Starting bad, learning escaping special characters R can much challenging!analyzed short text data set, , can imagine extending type analysis things like:song lyrics, lyrics songs artist https://rpubs.com/RosieB/taylorswiftlyricanalysisbook analysis, text entire book series bookstv analysis, scripts episodes tv showIf one analyses, lots cool functions tidytext help ! one example, time looking Donald Trump’s twitter account 2016.","code":"\n## install.packages(\"wordcloud\")\nlibrary(wordcloud)\n#> Loading required package: RColorBrewer\nbeyonce_small <- beyonce_sum |> filter(n > 50)\nwordcloud(beyonce_small$word, beyonce_small$n, \n          colors = brewer.pal(8, \"Dark2\"), scale = c(5, .2),\n          random.order = FALSE, random.color = FALSE)"},{"path":"text-data-with-tidytext-and-stringr.html","id":"basic-sentiment-analysis","chapter":" 14 Text Data with tidytext and stringr","heading":"14.2 Basic Sentiment Analysis","text":"use provided .qmd file replicate sentiment analysis Trump’s twitter account 2016. analysis used conjunction major news story hypothesized Trump wrote tweets Android device campaign staff wrote tweets iPhone device. investigate properties tweets led author believe ..qmd file used posted Canvas. see uses stringr particular analysis. entire section, able follow along understand line code . However, unlike previous sections, expected sentiment analysis .","code":""},{"path":"text-data-with-tidytext-and-stringr.html","id":"introduction-to-stringr","chapter":" 14 Text Data with tidytext and stringr","heading":"14.3 Introduction to stringr","text":"previous examples, string data consisted primarily words. tools tidytext make working data consisting words painful. However, data exists strings words. non-trivial example, consider data sets obtained https://github.com/JeffSackmann/tennis_MatchChartingProject, repository professional tennis match charting put together Jeff Sackmann. following code modified project completed James Wolpe data visualization course.repository, put together data set one particular tennis match make bit easier us get started. match chosen 2021 U.S. Open Final Daniil Medvedev Novak Djokovic. match? arguably important match Djokovic’s career: won, win four grand slams calendar year. don’t like Djokovic lost looking back match brings joy. Read data set :observations data set correspond points played (one row per point). ton variables data set, important variable first variable, point, contains string information types shots played point. coding point variable includes:4 serve wide, 5 serve body, 6 serve “t (center)”.f forehand stroke, b backhand stroke.1 right-hander’s forehand side, 2 middle court, 3 right-hander’s backhand side.d ball hit deep, w ball hit wide, n ball hit net@ symbol end point ended unforced errorand ’s lots numbers symbols correspond things (volleys, return depths, hitting top net, etc.)example, Djokovic served 7th point match, point value 4f18f1f2b3b2f1w@. reads that4: Djokovic served wide,f18: Medvedev hit forehand cross-court Djokovic’s forehand sidef1: Djokovic hit forehand cross-court Medvedev’s forehand sidef2: Medvedev hit forehand center courtb3: Djokovic hit backhand Medvedev’s backhand sideb2: Medvedev hit backhand center courtf1w@: Djokovic hit forehand Medvedev’s forehand side, shot landed wide recorded unforced error.Clearly, lot data encoded point variable. going introduce stringr answering relatively simple question: serving patterns Medvedev Djokovic match?","code":"\nlibrary(here)\nlibrary(tidyverse)\nmed_djok_df <- read_csv(here(\"data/med_djok.csv\"))\n#> Rows: 182 Columns: 46\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> chr (19): point, Serving, match_id, Pts, Gm#, 1st, 2nd, ...\n#> dbl (19): Pt, Set1, Set2, Gm1, Gm2, TbSet, TB?, Svr, Ret...\n#> lgl  (8): TBpt, isAce, isUnret, isRallyWinner, isForced,...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nhead(med_djok_df)\n#> # A tibble: 6 × 46\n#>   point  Serving match…¹    Pt  Set1  Set2   Gm1   Gm2 Pts  \n#>   <chr>  <chr>   <chr>   <dbl> <dbl> <dbl> <dbl> <dbl> <chr>\n#> 1 4f2d@  ND      202109…     1     0     0     0     0 0-0  \n#> 2 6d     ND      202109…     2     0     0     0     0 15-0 \n#> 3 6b29f… ND      202109…     3     0     0     0     0 15-15\n#> 4 4b28f… ND      202109…     4     0     0     0     0 30-15\n#> 5 5b37b… ND      202109…     5     0     0     0     0 40-15\n#> 6 6f28f… ND      202109…     6     0     0     0     0 40-30\n#> # … with 37 more variables: `Gm#` <chr>, TbSet <dbl>,\n#> #   `TB?` <dbl>, TBpt <lgl>, Svr <dbl>, Ret <dbl>,\n#> #   `1st` <chr>, `2nd` <chr>, Notes <chr>, `1stSV` <dbl>,\n#> #   `2ndSV` <dbl>, `1stIn` <dbl>, `2ndIn` <dbl>,\n#> #   isAce <lgl>, isUnret <lgl>, isRallyWinner <lgl>,\n#> #   isForced <lgl>, isUnforced <lgl>, isDouble <lgl>,\n#> #   PtWinner <dbl>, isSvrWinner <dbl>, rallyCount <dbl>, …\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"text-data-with-tidytext-and-stringr.html","id":"regular-expressions","chapter":" 14 Text Data with tidytext and stringr","heading":"14.3.1 Regular Expressions","text":"regex, regular expression, string used identify particular patterns string data. Regular expressions used many languages (, google something regular expression, need limit just looking resources pertaining R).Regex’s can used functions stringr package. functions stringr package begin str_(), much like functions forcats began fct_(). first focus str_detect() function, detects whether particular regex present string variable. str_detect() takes name string first argument regex second argument. example,returns TRUE letter f appears anywhere string FALSE . , can examine many points forehand hit Medvedev Djokovic match. second example,returns TRUE d@ appears string FALSE . Note d@ must appear together order return TRUE. lets us examine many points ball hit deep recorded unforced error. looks likepoints ended unforced error ball hit deep,points ended unforced error ball hit wide, andpoints ended unforced error ball hit net.","code":"\nstr_detect(med_djok_df$point, pattern = \"f\")\n#>   [1]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n#>  [10] FALSE FALSE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE\n#>  [19]  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE\n#>  [28] FALSE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE FALSE\n#>  [37]  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE\n#>  [46]  TRUE FALSE  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE\n#>  [55]  TRUE  TRUE FALSE FALSE  TRUE FALSE  TRUE  TRUE FALSE\n#>  [64]  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE\n#>  [73] FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE\n#>  [82]  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE FALSE  TRUE\n#>  [91]  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE\n#> [100]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n#> [109] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE\n#> [118] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE\n#> [127]  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE\n#> [136]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE\n#> [145] FALSE  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE FALSE\n#> [154] FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE\n#> [163] FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE  TRUE\n#> [172]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n#> [181] FALSE FALSE\nstr_detect(med_djok_df$point, pattern = \"d@\")\nsum(str_detect(med_djok_df$point, pattern = \"d@\"))\n#> [1] 21\nsum(str_detect(med_djok_df$point, pattern = \"w@\"))\n#> [1] 19\nsum(str_detect(med_djok_df$point, pattern = \"n@\"))\n#> [1] 22"},{"path":"text-data-with-tidytext-and-stringr.html","id":"stringr-functions-with-dplyr","chapter":" 14 Text Data with tidytext and stringr","heading":"14.3.2 stringr Functions with dplyr","text":"can combine stringr functions dplyr functions already know love. example, interested points end unforced error (points @ symbol ), can filter points don’t @:can use mutate() case_when() create variable corresponding error type summarise() error types made two players.output , PtWinner 1 corresponds points Djokovic won (therefore points Medvedev made unforced error) PtWinner 2 corresponds points Medvedev won (therefore points Djokovic made unforced error). see , match, Djokovic unforced errors overall. Medvedev’s unforced errors tended deep wide highest proportion Djokovic’s unforced errors balls went net.explore original “service patterns” question exercises. close section, just emphasize done simple introduction regexes. can get cumbersome, especially patterns want extract get complicated. Consider examples .Detect points aces, coded variable *. Regexes “special characters, like \\, *, ., , present variable need ”escaped” backslash. , backslash special character, needs escaped : need two \\\\ front * pull points *.Detect points start 4 using ^ denote “beginning”:Detect points end @ using $ denote “end” (safer code , just assumed @ appear anywhere else string except end).\n* Extract forehand shots hit str_extract_all(). regex says extract anything f followed number digits another non-digit symbol.purpose examples just show things can get complicated strings. purposes assessment course, responsible relatively simple cases discussed earlier section exercises.","code":"\nmed_djok_df |> filter(str_detect(point, pattern = \"@\") == TRUE)\n#> # A tibble: 63 × 46\n#>    point Serving match…¹    Pt  Set1  Set2   Gm1   Gm2 Pts  \n#>    <chr> <chr>   <chr>   <dbl> <dbl> <dbl> <dbl> <dbl> <chr>\n#>  1 4f2d@ ND      202109…     1     0     0     0     0 0-0  \n#>  2 6b29… ND      202109…     3     0     0     0     0 15-15\n#>  3 5b37… ND      202109…     5     0     0     0     0 40-15\n#>  4 4f18… ND      202109…     7     0     0     0     0 40-40\n#>  5 5b28… ND      202109…     8     0     0     0     0 40-AD\n#>  6 6b27… DM      202109…    13     0     0     0     1 40-15\n#>  7 6b38… ND      202109…    14     0     0     0     2 0-0  \n#>  8 5b28… ND      202109…    16     0     0     0     2 0-30 \n#>  9 6f38… ND      202109…    17     0     0     0     2 15-30\n#> 10 5b1w@ ND      202109…    28     0     0     1     3 30-0 \n#> # … with 53 more rows, 37 more variables: `Gm#` <chr>,\n#> #   TbSet <dbl>, `TB?` <dbl>, TBpt <lgl>, Svr <dbl>,\n#> #   Ret <dbl>, `1st` <chr>, `2nd` <chr>, Notes <chr>,\n#> #   `1stSV` <dbl>, `2ndSV` <dbl>, `1stIn` <dbl>,\n#> #   `2ndIn` <dbl>, isAce <lgl>, isUnret <lgl>,\n#> #   isRallyWinner <lgl>, isForced <lgl>, isUnforced <lgl>,\n#> #   isDouble <lgl>, PtWinner <dbl>, isSvrWinner <dbl>, …\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\nmed_djok_df |> filter(str_detect(point, pattern = \"@\") == TRUE) |>\n  mutate(error_type = case_when(str_detect(point, pattern = \"d@\") ~ \"deep error\",\n                                   str_detect(point, pattern = \"w@\") ~ \"wide error\",\n            str_detect(point, pattern = \"n@\") ~ \"net error\")) |>\n  group_by(PtWinner, error_type) |>\n  summarise(n_errors = n())\n#> `summarise()` has grouped output by 'PtWinner'. You can\n#> override using the `.groups` argument.\n#> # A tibble: 7 × 3\n#> # Groups:   PtWinner [2]\n#>   PtWinner error_type n_errors\n#>      <dbl> <chr>         <int>\n#> 1        1 deep error        9\n#> 2        1 net error         6\n#> 3        1 wide error       10\n#> 4        2 deep error       12\n#> 5        2 net error        16\n#> 6        2 wide error        9\n#> 7        2 <NA>              1\nstr_detect(med_djok_df$point, pattern = \"\\\\*\")\nstr_detect(med_djok_df$point, pattern = \"^4\")\nstr_detect(med_djok_df$point, pattern = \"@$\")\nstr_extract_all(med_djok_df$point, pattern = \"f[:digit:]+\")"},{"path":"text-data-with-tidytext-and-stringr.html","id":"exercise-12-1","chapter":" 14 Text Data with tidytext and stringr","heading":"14.3.3 Exercises","text":"Use str_detect() dplyr functions create variable serve_location either \"wide\" point starts 4, \"body\" point starts 5, \"center\" point starts 6.Use str_detect() dplyr functions create variable serve_location either \"wide\" point starts 4, \"body\" point starts 5, \"center\" point starts 6.Use dplyr functions Serving variable count number serve locations player. (.e. many points Medvedev hit serve wide?).Use dplyr functions Serving variable count number serve locations player. (.e. many points Medvedev hit serve wide?).Use dplyr functions, Serving variable, isSrvWinner variable find proportion points player won serving locations (.e. Medvedev won 5 points serving wide lost 3 points, proportion 5 / 8 = 0.625).Use dplyr functions, Serving variable, isSrvWinner variable find proportion points player won serving locations (.e. Medvedev won 5 points serving wide lost 3 points, proportion 5 / 8 = 0.625).Note isSrvWinner variable coded 1 serving player won point 0 serving player lost point.letters v, z, , k denote volleys (different types). Use str_detect() dplyr functions figure proportion points volley hit.","code":""},{"path":"text-data-with-tidytext-and-stringr.html","id":"chapexercise-12","chapter":" 14 Text Data with tidytext and stringr","heading":"14.4 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 14.5.Chapter Exercises.","code":""},{"path":"text-data-with-tidytext-and-stringr.html","id":"solutions-12","chapter":" 14 Text Data with tidytext and stringr","heading":"14.5 Exercise Solutions","text":"","code":""},{"path":"text-data-with-tidytext-and-stringr.html","id":"text-analysis-s","chapter":" 14 Text Data with tidytext and stringr","heading":"14.5.1 Text Analysis S","text":"solutions.","code":""},{"path":"text-data-with-tidytext-and-stringr.html","id":"basic-sentiment-analysis-s","chapter":" 14 Text Data with tidytext and stringr","heading":"14.5.2 Basic Sentiment Analysis S","text":"solutions.","code":""},{"path":"text-data-with-tidytext-and-stringr.html","id":"introduction-to-stringr-s","chapter":" 14 Text Data with tidytext and stringr","heading":"14.5.3 Introduction to stringr S","text":"solutions.","code":""},{"path":"text-data-with-tidytext-and-stringr.html","id":"chapexercise-12-S","chapter":" 14 Text Data with tidytext and stringr","heading":"14.5.4 Chapter Exercises S","text":"solutions.","code":""},{"path":"text-data-with-tidytext-and-stringr.html","id":"rcode-12","chapter":" 14 Text Data with tidytext and stringr","heading":"14.6 Non-Exercise R Code","text":"","code":"\nlibrary(tidyverse)\nlibrary(here)\nbeyonce <- read_csv(here(\"data/beyonce_lyrics.csv\"))\nhead(beyonce)\nbeyonce$line[1:4]\nlibrary(tidytext)\nbeyonce_unnest <- beyonce |> unnest_tokens(output = \"word\", input = \"line\")\nbeyonce_unnest\nbeyonce_unnest <- beyonce_unnest |> mutate(word = str_to_lower(word))\nbeyonce_unnest |> group_by(word) |>\n  summarise(n = n()) |>\n  arrange(desc(n))\nhead(stop_words)\nbeyonce_stop <- anti_join(beyonce_unnest, stop_words, by = c(\"word\" = \"word\"))\nbeyonce_sum <- beyonce_stop |> group_by(word) |>\n  summarise(n = n()) |>\n  arrange(desc(n)) |>\n  print(n = 25)\nbeyonce_sum\n## install.packages(\"wordcloud\")\nlibrary(wordcloud)\nbeyonce_small <- beyonce_sum |> filter(n > 50)\nwordcloud(beyonce_small$word, beyonce_small$n, \n          colors = brewer.pal(8, \"Dark2\"), scale = c(5, .2),\n          random.order = FALSE, random.color = FALSE)\nlibrary(here)\nlibrary(tidyverse)\nmed_djok_df <- read_csv(here(\"data/med_djok.csv\"))\nhead(med_djok_df)\nstr_detect(med_djok_df$point, pattern = \"f\")\nstr_detect(med_djok_df$point, pattern = \"d@\")\nsum(str_detect(med_djok_df$point, pattern = \"d@\"))\nsum(str_detect(med_djok_df$point, pattern = \"w@\"))\nsum(str_detect(med_djok_df$point, pattern = \"n@\"))\nmed_djok_df |> filter(str_detect(point, pattern = \"@\") == TRUE)\nmed_djok_df |> filter(str_detect(point, pattern = \"@\") == TRUE) |>\n  mutate(error_type = case_when(str_detect(point, pattern = \"d@\") ~ \"deep error\",\n                                   str_detect(point, pattern = \"w@\") ~ \"wide error\",\n            str_detect(point, pattern = \"n@\") ~ \"net error\")) |>\n  group_by(PtWinner, error_type) |>\n  summarise(n_errors = n())\nstr_detect(med_djok_df$point, pattern = \"\\\\*\")\nstr_detect(med_djok_df$point, pattern = \"^4\")\nstr_detect(med_djok_df$point, pattern = \"@$\")\nstr_extract_all(med_djok_df$point, pattern = \"f[:digit:]+\")"},{"path":"predictive-modeling-with-knn.html","id":"predictive-modeling-with-knn","chapter":" 15 Predictive Modeling with knn","heading":" 15 Predictive Modeling with knn","text":"Goalsexplain ’s necessary use training data test data building predictive model.describe k-nearest neighbors (knn) procedure.interpret confusion matrix.use knn predict level categorical response variable.","code":""},{"path":"predictive-modeling-with-knn.html","id":"introduction-to-classification","chapter":" 15 Predictive Modeling with knn","heading":"15.1 Introduction to Classification","text":"k-nearest neighbors (knn) introductory supervised machine learning algorithm, commonly used classification algorithm. Classification refers prediction categorical response variable two categories. example, data set SLU students, might interested predicting whether student graduates four years (response two categories: graduates 4 years doesn’t). might want classify response based various student characteristics like anticipated major, GPA, standardized test scores, etc. knn can also used predict quantitative response, ’ll focus categorical responses throughout section.’ve STAT 213, might try draw parallels knn classification using logistic regression. Note, however, logistic regression required response two levels knn can classify response variable two levels.introduce , using pokemon_full.csv data. Pokemon different Types: use Type categorical response interested predicting. simplicity, use Pokemon’s primary type use 4 different types:goal develop k-nearest-neighbors model able classify/predict Pokemon Type set predictors, like Pokemon HP, Attack, Defense, etc.","code":"\nset.seed(1119)\nlibrary(tidyverse)\nlibrary(here)\npokemon <- read_csv(here(\"data/pokemon_full.csv\")) |>\n  filter(Type %in% c(\"Steel\", \"Dark\", \"Fire\", \"Ice\"))"},{"path":"predictive-modeling-with-knn.html","id":"training-and-test-data","chapter":" 15 Predictive Modeling with knn","heading":"15.1.1 Training and Test Data","text":"order develop knn model (note still haven’t discussed knn actually yet!), first need discuss terms applies almost predictive/classification modeling: training test data. training data set subset full data set used fit various models. example , training data set just 15 observations pedagogical purposes. commonly, training data set contain 50%-80% observations full data set.test data set consists remaining 20%-50% observations training data set. test data set used assess different performances various models fit using training data set. need division? Using full data set training model testing model “cheating:” model perform better using observation twice: fitting testing. separate test data set wasn’t used fit model gives model “fair” test, observations supposed new data model hasn’t yet seen.following code uses slice_sample() function randomly select 15 observations training data set. anti_join() makes test data set without 15 pokemon training data set.ideas training data set test data set pervasive predictive classification models, including models related knn. Note going method ’s simplest: wanted take step , ’d repeat training test process 5 10 times, using ’s known k-fold cross-validation.","code":"\ntrain_sample <- pokemon |>\n  slice_sample(n = 15)\ntest_sample <- anti_join(pokemon, train_sample)\n\ntrain_sample |> head()\n#> # A tibble: 6 × 14\n#>    ...1 Name    Type     HP Attack Defense Speed SpAtk SpDef\n#>   <dbl> <chr>   <chr> <dbl>  <dbl>   <dbl> <dbl> <dbl> <dbl>\n#> 1   491 Darkrai Dark     70     90      90   125   135    90\n#> 2   136 Flareon Fire     65    130      60    65    95   110\n#> 3   571 Zoroark Dark     60    105      60   105   120    60\n#> 4   221 Pilosw… Ice     100    100      80    50    60    60\n#> 5   668 Pyroar  Fire     86     68      72   106   109    66\n#> 6   262 Mighty… Dark     70     90      70    70    60    60\n#> # … with 5 more variables: Generation <dbl>,\n#> #   Legendary <lgl>, height <dbl>, weight <dbl>,\n#> #   base_experience <dbl>\n#> # ℹ Use `colnames()` to see all variable names\ntest_sample |> head()\n#> # A tibble: 6 × 14\n#>    ...1 Name    Type     HP Attack Defense Speed SpAtk SpDef\n#>   <dbl> <chr>   <chr> <dbl>  <dbl>   <dbl> <dbl> <dbl> <dbl>\n#> 1     4 Charma… Fire     39     52      43    65    60    50\n#> 2     5 Charme… Fire     58     64      58    80    80    65\n#> 3    37 Vulpix  Fire     38     41      40    65    50    65\n#> 4    38 Nineta… Fire     73     76      75   100    81   100\n#> 5    58 Growli… Fire     55     70      45    60    70    50\n#> 6    59 Arcani… Fire     90    110      80    95   100    80\n#> # … with 5 more variables: Generation <dbl>,\n#> #   Legendary <lgl>, height <dbl>, weight <dbl>,\n#> #   base_experience <dbl>\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"predictive-modeling-with-knn.html","id":"exercise-13-1","chapter":" 15 Predictive Modeling with knn","heading":"15.1.2 Exercises","text":"Exercises marked * indicate exercise solution end chapter 15.5.Explain anti_join() joins isn’t specified specifying argument works example.","code":""},{"path":"predictive-modeling-with-knn.html","id":"knn-introduction","chapter":" 15 Predictive Modeling with knn","heading":"15.2 knn Introduction","text":"","code":""},{"path":"predictive-modeling-with-knn.html","id":"knn-with-k-1-and-1-predictor","chapter":" 15 Predictive Modeling with knn","heading":"15.2.1 knn with k = 1 and 1 Predictor","text":"Suppose just 15 pokemon training data set. want predict Type just one predictor, Defense. plot shows defenses 15 pokemon training data set, points coloured Type different shapes Type.see plot Steel type Pokemon tend pretty high defense values. Now suppose want predict Type one Pokemon test data set, Dialga. know Dialga Defense stat 120: plot shows Dialga marked large black X.prediction Dialga ? ? According knn k = 1, predict Dialga Fire type. k = 1 means using 1st nearest neighbor: case point closest Dialga green triangle, corresponding Fire type Pokemon.","code":"\nggplot(data = train_sample, aes(x = Defense, y = 1, colour = Type, shape = Type)) +\n  geom_point(size = 4) +  theme(axis.title.y=element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())\ndialga <- test_sample |> slice(63)\nggplot(data = train_sample, aes(x = Defense, y = 1, colour = Type, shape = Type)) +\n  geom_point(size = 4) +  theme(axis.title.y=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank()) +\n  geom_point(data = dialga, colour = \"black\", shape = 4, size = 7)"},{"path":"predictive-modeling-with-knn.html","id":"knn-with-k-1-and-one-predictor","chapter":" 15 Predictive Modeling with knn","heading":"15.2.2 knn with k > 1 and One Predictor","text":", might necessarily want predict response value based single nearest neighbor. Dialga also near many purple plus signs: factor ? can extend knn different values k. example, \\(k = 3\\) looks 3 nearest neighbors, assigns prediction category appears among 3 nearest neighbors.Using k = 3, prediction Dialga ? ?","code":""},{"path":"predictive-modeling-with-knn.html","id":"knn-with-k-1-and-more-than-one-predictor","chapter":" 15 Predictive Modeling with knn","heading":"15.2.3 knn with k > 1 and More Than One Predictor","text":"can increase number predictors knn model well. can generally include many predictors like, visualizing becomes challenging 2 predictors nearly impossible 3 predictors. case two predictors, suppose want use Defense Speed predictors Type. Dialga, Pokemon want predict , marked large black X.\\(k = 1\\), predict Dialga Steel, closest point purple + sign top-left corner graph. \\(k = 3\\), Type predict Dialga? question, ’s little hard tell three points closest Dialga without computing distances numerically, something let R knn() function.","code":"\nggplot(data = train_sample, aes(x = Defense, y = Speed, colour = Type, shape = Type)) +\n  geom_point(size = 3) +\n  geom_point(data = dialga, colour = \"black\", shape = 4, size = 5)"},{"path":"predictive-modeling-with-knn.html","id":"scaling-predictor-variables-before-using-knn","chapter":" 15 Predictive Modeling with knn","heading":"15.2.4 Scaling Predictor Variables before Using knn","text":"general, want scale quantitative predictors using knn relies distances points predictions. easiest see example. Suppose, Pokemon example, want use height weight predictors knn model. just 2 observations training data set: Dark Type pokemon height 15 centimeters weight 505 pounds, Fire Type Pokemon height 9 centimeters weight 250 pounds.plot also given Pokemon test data set wish predict Type , marked black X. Upon visual inspection, k = 1, looks like classify pokemon Dark. However, units weight height different scales. compute actual distances class see conclusion calculation matches visual conclusion.get around issue, customary scale quantitative predictors applying knn. One method applying\\[\nscaled_x = \\frac{x - min(x)}{max(x) - min(x)}\n\\]example, scaling weight 15 original pokemon:puts weights 0 1:height, variables contribute “equally” distance metric used knn.code scales numeric variables data set, using across() function. across() applies transformation every column data set satisfies condition given argument.","code":"\ntrain_tiny <- train_sample |> slice(1:2)\nnewobs <- tibble(height = 15, weight = 350, Type = \"Unknown\")\nggplot(data = train_tiny, aes(x = height, y = weight, shape = Type)) +\n  geom_point(size = 5, aes(colour = Type)) + xlim(c(7, 17)) + ylim(c(200, 550)) +\n  geom_point(data = newobs, shape = 4, size = 10)\ntrain_sample |> select(weight) |> head()\n#> # A tibble: 6 × 1\n#>   weight\n#>    <dbl>\n#> 1    505\n#> 2    250\n#> 3    811\n#> 4    558\n#> 5    815\n#> 6    370\ntrain_sample |> mutate(weight_s = (weight - min(weight)) / \n                          (max(weight) - min(weight))) |>\n  select(weight_s) |>\n  head()\n#> # A tibble: 6 × 1\n#>   weight_s\n#>      <dbl>\n#> 1   0.187 \n#> 2   0.0835\n#> 3   0.312 \n#> 4   0.209 \n#> 5   0.314 \n#> 6   0.132\n## ?across\nlibrary(pander)\ntrain_sample |>\n  mutate(across(where(is.numeric), ~ (.x - min(.x)) /\n                                 (max(.x) - min(.x)))) |>\n  slice(1:3)\n#> # A tibble: 3 × 14\n#>    ...1 Name    Type     HP Attack Defense Speed SpAtk SpDef\n#>   <dbl> <chr>   <chr> <dbl>  <dbl>   <dbl> <dbl> <dbl> <dbl>\n#> 1 0.720 Darkrai Dark  0.417  0.444     0.4 1     1     0.658\n#> 2 0.193 Flareon Fire  0.333  0.889     0.1 0.368 0.619 0.921\n#> 3 0.838 Zoroark Dark  0.25   0.611     0.1 0.789 0.857 0.263\n#> # … with 5 more variables: Generation <dbl>,\n#> #   Legendary <lgl>, height <dbl>, weight <dbl>,\n#> #   base_experience <dbl>\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"predictive-modeling-with-knn.html","id":"exercise-13-2","chapter":" 15 Predictive Modeling with knn","heading":"15.2.5 Exercises","text":"Exercises marked * indicate exercise solution end chapter 15.5.* Consider toy example just two observations training data set unscaled weight height predictors.actual (height, weight) coordinates Fire pokemon (9, 250), actual coordinates Dark pokemon (15, 505), actual coordinates test pokemon (15, 350). mentioned , visually, pokemon looks “closer” Dark type pokemon. Verify actually case computing actual distances numerically.* scaling according formula section, coordinates (height, weight) Fire pokemon (0, 0) coordinates Dark pokemon (1, 1). (Since two observations, formula doesn’t give output 0 1 tiny example). scaled coordinates test pokemon (1, 0.39). Verify , scaling, test pokemon “closer” Dark type pokemon numerically computing distances.* scaling according formula section, coordinates (height, weight) Fire pokemon (0, 0) coordinates Dark pokemon (1, 1). (Since two observations, formula doesn’t give output 0 1 tiny example). scaled coordinates test pokemon (1, 0.39). Verify , scaling, test pokemon “closer” Dark type pokemon numerically computing distances.Consider example 15 pokemon training data set single predictor, Defense.Consider example 15 pokemon training data set single predictor, Defense.k = 2, tie Fire Steel. Come way might break ties knn algorithm.Explain knn use prediction test observations k equals number observations training data set.Explain knn use prediction test observations k equals number observations training data set.advantages making k smaller advantages making k larger?advantages making k smaller advantages making k larger?","code":"\nggplot(data = train_tiny, aes(x = height, y = weight, shape = Type)) +\n  geom_point(size = 5, aes(colour = Type)) + xlim(c(7, 17)) +\n  ylim(c(200, 550)) +\n  geom_point(data = newobs, shape = 4, size = 10)\nggplot(data = train_sample, aes(x = Defense, y = 1, colour = Type, shape = Type)) +\n  geom_point(size = 4) +  theme(axis.title.y=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank()) +\n  geom_point(data = dialga, colour = \"black\", shape = 4, size = 7)"},{"path":"predictive-modeling-with-knn.html","id":"choosing-predictors-and-k","chapter":" 15 Predictive Modeling with knn","heading":"15.3 Choosing Predictors and k","text":"now know knn classifies observations test data set, choose predictors used knn algorithm? choose number neighbors, k? want measure “good” models different predictors different k’s , first need define “good” means.Much “choosing predictors” part trial error evaluating different models criterion talk next section. However, always helpful explore data set graphics get us good starting point. scatterplot matrix useful exploratory tool. following scatterplot matrix response variable, Type, just three candidate predictors, HP, Attack, Defense, created GGally (“g-g-ally”) package.lower argument changes number bins faceted histograms bottom row. can mostly ignore .columns argument important: allows specify columns want look . prefer putting response, Type (column 3) last slot.can examine see variables seem relationship Type. want look ?","code":"\n## install.packages(\"GGally\")\nlibrary(GGally)\n#> Registered S3 method overwritten by 'GGally':\n#>   method from   \n#>   +.gg   ggplot2\n#> \n#> Attaching package: 'GGally'\n#> The following object is masked from 'package:pander':\n#> \n#>     wrap\nggpairs(data = train_sample, columns = c(4, 5, 6, 3), \n        lower = list(combo = wrap(ggally_facethist, bins = 15)))"},{"path":"predictive-modeling-with-knn.html","id":"the-confusion-matrix","chapter":" 15 Predictive Modeling with knn","heading":"15.3.1 The Confusion Matrix","text":", still need metric evaluate models different predictors. One definition “good” model classification context model high proportion correct predictions test data set. make intuitive sense, hope “good” model correctly classifies Dark pokemon Dark, Fire pokemon Fire, etc.order examine performance particular model, ’ll create confusion matrix shows results model’s classification observations test data set. Note STAT 213, didn’t call confusion matrix; instead called classification table.following video explains confusion matrices detail also cement ideas training test data. https://www.youtube.com/watch?v=Kdsp6soqA7o.","code":""},{"path":"predictive-modeling-with-knn.html","id":"using-knn-in-r","chapter":" 15 Predictive Modeling with knn","heading":"15.3.2 Using knn in R","text":"make confusion matrix model using pokemon data set, first need obtain predictions model. ’ll use class library fit knn model pokemon data. Note , instead 15 Pokemon training data set, now 70 pokemon give reasonable number. test set remaining 50 pokemon.following code chunk sets seed get training test samples, scales numeric variables pokemon data set, randomly selects 70 pokemon training sample.first knn model investigate HP, Attack, Defense, Speed predictors. class library can fit knn models knn() function requires training test data sets predictors want use fit model. knn() function also requires response variable, Type, given vector.Now data prepared knn() function class library, fit model 9 nearest neighbors. arguments knn() aretrain, data set training data contains predictors want use (predictors response).test, data set test data contains predictors want use (predictors response).cl, vector response variable training data.k, number nearest neighbors.output knn_mod gives predicted categories test sample. can compare predictions knn model actual pokemon Types test sample table(), makes confusion matrix:columns confusion matrix give actual Pokemon types test data rows give predicted types knn model. table tells us 0 pokemon Dark type knn model correctly classified Dark. 6 pokemon Dark type knn model incorrectly classified Fire. 5 pokemon Dark type knn model incorrectly classified Ice. words, correct predictions appear diagonal, incorrect predictions appear -diagonal.One common metric used assess overall model performance model’s classification rate, computed number correct classifications divided total number observations test data set. case, classification rate isCode automatically obtain classification rate confusion matrix isWhat diag() seem code ?","code":"\nlibrary(tidyverse)\nset.seed(11232020) ## run this line so that you get the same \n## results as I do!\n\n## scale the quantitative predictors\npokemon_scaled <- pokemon |>\n    mutate(across(where(is.numeric), ~ (.x - min(.x)) /\n                                 (max(.x) - min(.x)))) \n\ntrain_sample_2 <- pokemon_scaled |>\n  slice_sample(n = 70)\ntest_sample_2 <- anti_join(pokemon_scaled, train_sample_2)\n#> Joining, by = c(\"...1\", \"Name\", \"Type\", \"HP\", \"Attack\",\n#> \"Defense\", \"Speed\", \"SpAtk\", \"SpDef\", \"Generation\",\n#> \"Legendary\", \"height\", \"weight\", \"base_experience\")\n## install.packages(\"class\")\nlibrary(class)\n\n## create a data frame that only has the predictors\n## that we will use\ntrain_small <- train_sample_2 |> select(HP, Attack, Defense, Speed)\ntest_small <- test_sample_2 |> select(HP, Attack, Defense, Speed)\n\n## put our response variable into a vector\ntrain_cat <- train_sample_2$Type\ntest_cat <- test_sample_2$Type\n## fit the knn model with 9 nearest neighbors\nknn_mod <- knn(train = train_small, test = test_small,\n               cl = train_cat, k = 9)\nknn_mod\n#>  [1] Ice   Fire  Fire  Fire  Fire  Fire  Steel Fire  Ice  \n#> [10] Fire  Fire  Fire  Fire  Ice   Ice   Steel Ice   Dark \n#> [19] Ice   Fire  Steel Fire  Fire  Ice   Fire  Ice   Steel\n#> [28] Fire  Fire  Ice   Dark  Fire  Fire  Fire  Dark  Ice  \n#> [37] Ice   Fire  Ice   Fire  Fire  Fire  Fire  Fire  Fire \n#> [46] Fire  Fire  Fire  Ice   Fire \n#> Levels: Dark Fire Ice Steel\ntable(knn_mod, test_cat) \n#>        test_cat\n#> knn_mod Dark Fire Ice Steel\n#>   Dark     0    3   0     0\n#>   Fire     6   13   7     4\n#>   Ice      5    5   2     1\n#>   Steel    0    1   0     3\n(0 + 13 + 2 + 3) / 50\n#> [1] 0.36\ntab <- table(knn_mod, test_cat) \nsum(diag(tab)) / sum(tab)\n#> [1] 0.36"},{"path":"predictive-modeling-with-knn.html","id":"exercise-13-3","chapter":" 15 Predictive Modeling with knn","heading":"15.3.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 15.5.Change predictors used change k improve classification rate model k = 9 Attack, Defense, HP, Speed predictors.","code":""},{"path":"predictive-modeling-with-knn.html","id":"chapexercise-13","chapter":" 15 Predictive Modeling with knn","heading":"15.4 Chapter Exercises","text":"chapter exercises section. Instead, ’ll devote -class time begin work final project.","code":""},{"path":"predictive-modeling-with-knn.html","id":"solutions-13","chapter":" 15 Predictive Modeling with knn","heading":"15.5 Exercise Solutions","text":"","code":""},{"path":"predictive-modeling-with-knn.html","id":"introduction-to-classification-s","chapter":" 15 Predictive Modeling with knn","heading":"15.5.1 Introduction to Classification S","text":"","code":""},{"path":"predictive-modeling-with-knn.html","id":"knn-introduction-s","chapter":" 15 Predictive Modeling with knn","heading":"15.5.2 knn Introduction S","text":"* Consider toy example just two observations training data set unscaled weight height predictors.actual (height, weight) coordinates Fire pokemon (9, 250), actual coordinates Dark pokemon (15, 505), actual coordinates test pokemon (15, 350). mentioned , visually, pokemon looks “closer” Dark type pokemon. Verify case computing actual distances numerically.* scaling according formula section, coordinates (height, weight) Fire pokemon (0, 0) coordinates Dark pokemon (1, 1). (Since two observations, formula doesn’t give output 0 1 tiny example). scaled coordinates test pokemon (1, 0.39). Verify , scaling, test pokemon “closer” Dark type pokemon bu numerically computing distances.","code":"\nggplot(data = train_tiny, aes(x = height, y = weight, shape = Type)) +\n  geom_point(size = 5, aes(colour = Type)) + xlim(c(7, 17)) +\n  ylim(c(200, 550)) +\n  geom_point(data = newobs, shape = 4, size = 10)"},{"path":"predictive-modeling-with-knn.html","id":"choosing-predictors-and-k-s","chapter":" 15 Predictive Modeling with knn","heading":"15.5.3 Choosing Predictors and k S","text":"","code":""},{"path":"predictive-modeling-with-knn.html","id":"rcode-13","chapter":" 15 Predictive Modeling with knn","heading":"15.6 Non-Exercise R Code","text":"","code":"\nset.seed(1119)\nlibrary(tidyverse)\nlibrary(here)\npokemon <- read_csv(here(\"data/pokemon_full.csv\")) |>\n  filter(Type %in% c(\"Steel\", \"Dark\", \"Fire\", \"Ice\"))\ntrain_sample <- pokemon |>\n  slice_sample(n = 15)\ntest_sample <- anti_join(pokemon, train_sample)\n\ntrain_sample |> head()\ntest_sample |> head()\nggplot(data = train_sample, aes(x = Defense, y = 1, colour = Type, shape = Type)) +\n  geom_point(size = 4) +  theme(axis.title.y=element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())\ndialga <- test_sample |> slice(63)\nggplot(data = train_sample, aes(x = Defense, y = 1, colour = Type, shape = Type)) +\n  geom_point(size = 4) +  theme(axis.title.y=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank()) +\n  geom_point(data = dialga, colour = \"black\", shape = 4, size = 7)\nggplot(data = train_sample, aes(x = Defense, y = Speed, colour = Type, shape = Type)) +\n  geom_point(size = 3) +\n  geom_point(data = dialga, colour = \"black\", shape = 4, size = 5)\ntrain_tiny <- train_sample |> slice(1:2)\nnewobs <- tibble(height = 15, weight = 350, Type = \"Unknown\")\nggplot(data = train_tiny, aes(x = height, y = weight, shape = Type)) +\n  geom_point(size = 5, aes(colour = Type)) + xlim(c(7, 17)) + ylim(c(200, 550)) +\n  geom_point(data = newobs, shape = 4, size = 10)\ntrain_sample |> select(weight) |> head()\ntrain_sample |> mutate(weight_s = (weight - min(weight)) / \n                          (max(weight) - min(weight))) |>\n  select(weight_s) |>\n  head()\n## ?across\nlibrary(pander)\ntrain_sample |>\n  mutate(across(where(is.numeric), ~ (.x - min(.x)) /\n                                 (max(.x) - min(.x)))) |>\n  slice(1:3)\n## install.packages(\"GGally\")\nlibrary(GGally)\nggpairs(data = train_sample, columns = c(4, 5, 6, 3), \n        lower = list(combo = wrap(ggally_facethist, bins = 15)))\nlibrary(tidyverse)\nset.seed(11232020) ## run this line so that you get the same \n## results as I do!\n\n## scale the quantitative predictors\npokemon_scaled <- pokemon |>\n    mutate(across(where(is.numeric), ~ (.x - min(.x)) /\n                                 (max(.x) - min(.x)))) \n\ntrain_sample_2 <- pokemon_scaled |>\n  slice_sample(n = 70)\ntest_sample_2 <- anti_join(pokemon_scaled, train_sample_2)\n## install.packages(\"class\")\nlibrary(class)\n\n## create a data frame that only has the predictors\n## that we will use\ntrain_small <- train_sample_2 |> select(HP, Attack, Defense, Speed)\ntest_small <- test_sample_2 |> select(HP, Attack, Defense, Speed)\n\n## put our response variable into a vector\ntrain_cat <- train_sample_2$Type\ntest_cat <- test_sample_2$Type\n## fit the knn model with 9 nearest neighbors\nknn_mod <- knn(train = train_small, test = test_small,\n               cl = train_cat, k = 9)\nknn_mod\ntable(knn_mod, test_cat) \n(0 + 13 + 2 + 3) / 50\ntab <- table(knn_mod, test_cat) \nsum(diag(tab)) / sum(tab)"},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"connections-to-stat-113-stat-213-and-cs-140","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":" 16 Connections to STAT 113, STAT 213, and CS 140","text":"","code":""},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"stat-113","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.1 STAT 113","text":"section, discuss learned data science course connects concepts learned STAT 113. quick refresher, concepts learned STAT 113 :exploring data numerical graphical summaries. connection class fairly straightforward: ’ve learned lot actually compute numerical summaries make appropriate graphics potentially messy data.explaining sampling distributions relate confidence intervals hypothesis tests. topic probably least connected learned far class.conducting hypothesis tests creating confidence intervals answer questions interest. focus third general objective section.example use experiment designed assess effects race sex whether employee received callback job. order conduct experiment, researchers randomly assigned names resumes name associated particular race gender, sent resumes employers, recorded whether resume received callback. addition race, sex, whether employee received callback, variables collected, like resume quality, whether applicant computer skills, years experience, etc. 1 received_callback indicates applicant received callback.may recall example STAT 113: used introduce chi-square test association. example others like , appropriate graphic summary statistics provided. , create .data set called resume openintro package: ’ll need install package install.packages(\"openintro\"). , load data ","code":"\nlibrary(openintro)\n#> Loading required package: airports\n#> Loading required package: cherryblossom\n#> Loading required package: usdata\nresume\n#> # A tibble: 4,870 × 30\n#>    job_ad_id job_c…¹ job_i…² job_t…³ job_f…⁴ job_e…⁵ job_o…⁶\n#>        <dbl> <chr>   <chr>   <chr>     <dbl>   <dbl> <chr>  \n#>  1       384 Chicago manufa… superv…      NA       1 unknown\n#>  2       384 Chicago manufa… superv…      NA       1 unknown\n#>  3       384 Chicago manufa… superv…      NA       1 unknown\n#>  4       384 Chicago manufa… superv…      NA       1 unknown\n#>  5       385 Chicago other_… secret…       0       1 nonpro…\n#>  6       386 Chicago wholes… sales_…       0       1 private\n#>  7       386 Chicago wholes… sales_…       0       1 private\n#>  8       385 Chicago other_… secret…       0       1 nonpro…\n#>  9       386 Chicago wholes… sales_…       0       1 private\n#> 10       386 Chicago wholes… sales_…       0       1 private\n#> # … with 4,860 more rows, 23 more variables:\n#> #   job_req_any <dbl>, job_req_communication <dbl>,\n#> #   job_req_education <dbl>, job_req_min_experience <chr>,\n#> #   job_req_computer <dbl>, job_req_organization <dbl>,\n#> #   job_req_school <chr>, received_callback <dbl>,\n#> #   firstname <chr>, race <chr>, gender <chr>,\n#> #   years_college <int>, college_degree <dbl>, …\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names"},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"chi-square-test-of-association","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.1.1 Chi-square Test of Association","text":"goal assess whether evidence racial discrimination study. words, variables race received_callback associated?Prepare. Let’s start writing null alternative hypotheses.\\(H_0:\\) association race received_callback.\\(H_a:\\) association race received_callback.Next, can construct summary graphic. One graphic explore two categorical variables stacked bar plot.notice recieved_callback variable scale? fix ?might also want generate two-way table:Check: two assumptions test independence observations expected counts larger 5. don’t time discuss detail assume satisfied .Calculate: next want calculate p-value hypothesis test. core tidyverse packages offer functionality hypothesis testing. Instead, functions base R perform various tests. may used lm() function STAT 213 perform hypothesis testing regression context. t.test() chisq.test() couple functions can perform one two-sample t-test (t.test()) chi-square goodness--fit test chi-square test association chisq.test().\narguments chisq.test() test association two vectors. arguments data.frames, need specify appropriate vectors directly resume$race resume$received_callback.output chisq.test() gives p-value 0.00004998 chi-square statistic 16.449 1 degree freedom.Conclude. Finally, write conclusion context problem.strong evidence race callback associated. graph shows white applicants receive callback often black applicants hypothesis test shows statistically significant.","code":"\nlibrary(tidyverse)\n#> ── Attaching packages ─────────────────── tidyverse 1.3.2 ──\n#> ✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n#> ✔ tibble  3.1.8     ✔ dplyr   1.0.9\n#> ✔ tidyr   1.2.0     ✔ stringr 1.4.0\n#> ✔ readr   2.1.2     ✔ forcats 0.5.1\n#> ── Conflicts ────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\nresume_sum <- resume |> \n  mutate(received_callback = received_callback) |>\n           group_by(race, received_callback) |>\n  summarise(count = n())\n#> `summarise()` has grouped output by 'race'. You can\n#> override using the `.groups` argument.\nggplot(data = resume_sum, aes(x = race, y = count)) +\n  geom_col(aes(fill = received_callback)) +\n  scale_fill_viridis_c()\nresume <- resume |>\n  mutate(received_callback = as.factor(received_callback))\nresume_sum <- resume |> \n           group_by(race, received_callback) |>\n  summarise(count = n())\n#> `summarise()` has grouped output by 'race'. You can\n#> override using the `.groups` argument.\nggplot(data = resume_sum, aes(x = race, y = count)) +\n  geom_col(aes(fill = received_callback)) +\n  scale_fill_viridis_d()\nresume |> group_by(race, received_callback) |>\n  summarise(count = n()) |>\n  pivot_wider(names_from = race,\n              values_from = count)\n#> `summarise()` has grouped output by 'race'. You can\n#> override using the `.groups` argument.\n#> # A tibble: 2 × 3\n#>   received_callback black white\n#>   <fct>             <int> <int>\n#> 1 0                  2278  2200\n#> 2 1                   157   235\nchisq.test(x = resume$race, y = resume$received_callback)\n#> \n#>  Pearson's Chi-squared test with Yates' continuity\n#>  correction\n#> \n#> data:  resume$race and resume$received_callback\n#> X-squared = 16.449, df = 1, p-value = 4.998e-05"},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"additional-analysis","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.1.2 Additional Analysis","text":"addition carrying steps statistical hypothesis test, can also use skills learned course provide information study. questions might answer include:distribution job types job_type job industries job_industry study?distribution job types job_type job industries job_industry study?first names (firstname) used bias first names?first names (firstname) used bias first names?variables associated whether applicant received callback?variables associated whether applicant received callback?answer question distribution job types job industries used study, can make simple bar plot:code, fct_infreq() orders levels job_type highest count/frequency lowest. fct_rev() reverses order , resulting bar plot, level highest count appears first.answer question whether first names biased others, might make graph proportion resumes received callback first name.can label name lowest callback rate name highest callback rate.","code":"\nggplot(data = resume, aes(x = fct_rev(fct_infreq(job_type)))) +\n  geom_bar() +\n  coord_flip() +\n  labs(x = \"Job Type\")\nggplot(data = resume, aes(x = fct_rev(fct_infreq(job_industry)))) +\n  geom_bar() +\n  coord_flip() +\n  labs(x = \"Job Industry\")\nresume_firstname <- resume |>\n  group_by(firstname) |>\n  summarise(propcallback = mean(received_callback == \"1\"),\n            gender = unique(gender),\n            race = unique(race)) |>\n  arrange(desc(propcallback)) |>\n  unite(\"gender_race\", c(gender, race))\n\nggplot(data = resume_firstname, aes(x = gender_race, y = propcallback)) +\n  geom_point()\nlibrary(ggrepel)\nlabel_df <- resume_firstname |> \n  filter(propcallback == max(propcallback) |\n           propcallback == min(propcallback))\n\nggplot(data = resume_firstname, aes(x = gender_race, y = propcallback)) +\n  geom_point() +\n  geom_label_repel(data = label_df, aes(label = firstname))"},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"exercise-15-1","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.1.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 16.5.Construct graphic make table explores whether one variables data set associated whether applicant receives callback job. variables include gender, years_college, college_degree, honors, worked_during_school, years_experience, computer_skills, special_skills, volunteer, military, employment_holes, resume_quality.Construct graphic make table explores whether one variables data set associated whether applicant receives callback job. variables include gender, years_college, college_degree, honors, worked_during_school, years_experience, computer_skills, special_skills, volunteer, military, employment_holes, resume_quality.Construct graphic make table explores one variables data set associated whether applicant receives callback job. variable Exercise 1 categorical, choose quantitative variable exercise. variable Exercise 1 quantitative, choose categorical variable exercise.Construct graphic make table explores one variables data set associated whether applicant receives callback job. variable Exercise 1 categorical, choose quantitative variable exercise. variable Exercise 1 quantitative, choose categorical variable exercise.categorical variable chose, conduct Chi-square test association see statistical evidence variable associated received_callback. test, (), write null alternative hypotheses, run test chisq.test() make note whether get warning assumptions test, write conclusion context problem.categorical variable chose, conduct Chi-square test association see statistical evidence variable associated received_callback. test, (), write null alternative hypotheses, run test chisq.test() make note whether get warning assumptions test, write conclusion context problem.","code":""},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"stat-213","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.2 STAT 213","text":"Much concepts connecting STAT 113 course hold connecting STAT 213 course. can still use learned explore data set, conduct hypothesis test, perform analysis exploration data set.section, however, focus tidy approach modeling. particular, use broom package return tibbles model summary information can use analysis, plotting, presentation.use coffee_ratings data set, contains observations ratings various coffees throughout world. data obtained Github account (https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-07-07/readme.md).description variable data set given .total_cup_points, score coffee panel experts (response variable section)species, species coffee bean (Arabica Robusta)aroma, aroma (smell) gradeflavor, flavor gradeaftertaste, aftertaste gradeacidity, acidity gradebody, body gradebalance, balance gradeuniformity, uniformity gradeclean_cup, clean cup gradesweetness, sweetness grademoisture, moisture gradecategory_one_defects, count category one defectsquakers, quakerscategory_two_defects, number category two defects","code":""},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"broom-package-functions","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.2.1 broom Package Functions","text":"broom package consists three primary functions: tidy(), glance(), augment().tidy()tidy() analagous summary() linear model object. Let’s start fitting linear model lm() total_cup_points response species, aroma, flavor, sweetness, moisture predictors.Read data, load broom package (install install.packages(\"broom\")), fit model withIn STAT 213, likely used summary() look model output:However, inconveniences involving summary(). First, ’s just nice look : output isn’t formatted way easy look . Second, can challenging pull items summary output code. example, want pull p-value moisture, need write something like:tidy() alternative puts model coefficients, standard errors, t-stats, p-values tidy tibble:advantage format output can now use tidyverse functions output. pull p-values,, grab output particular variable interest:glance()glance() puts model summary statistics tidy tibble. example, runyou notice lot statistics familiar STAT 213, including r.squared, adj.r.squared, sigma (residual standard error), statistic (overall F-statistic), AIC, BIC.augment()augment() personal favourite three. function returns tibble contains variables used fit model appended commonly used diagnostic statistics like fitted values (.fitted), cook’s distance (.cooksd), .hat values leverage, residuals (.resid).augment() data set makes really easy things like:filter() data set examine values high cook’s distance might influentialWe see right away potentially influential observation 0 total_cup_points. Examining variable , see probably data entry error can removed data.also find observations high leverageor observations outliers:Finally, can use ggplot2 skills construct plots like residuals versus fitted values plot (filtering outlying observation first):","code":"\nlibrary(broom)\nlibrary(here)\n#> here() starts at /Users/highamm/Desktop/datascience234\ncoffee_df <- read_csv(here(\"data/coffee_ratings.csv\"))\n#> Rows: 1339 Columns: 43\n#> ── Column specification ────────────────────────────────────\n#> Delimiter: \",\"\n#> chr (24): species, owner, country_of_origin, farm_name, ...\n#> dbl (19): total_cup_points, number_of_bags, aroma, flavo...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\ncoffee_mod <- lm(total_cup_points ~ species + aroma + flavor +\n                   sweetness + moisture,\n   data = coffee_df)\nsummary(coffee_mod)\n#> \n#> Call:\n#> lm(formula = total_cup_points ~ species + aroma + flavor + sweetness + \n#>     moisture, data = coffee_df)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -9.5132 -0.3705  0.0726  0.5610  5.5844 \n#> \n#> Coefficients:\n#>                Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)     7.04039    0.77377   9.099  < 2e-16 ***\n#> speciesRobusta  2.85365    0.26861  10.624  < 2e-16 ***\n#> aroma           1.95188    0.14575  13.392  < 2e-16 ***\n#> flavor          5.09440    0.14042  36.281  < 2e-16 ***\n#> sweetness       2.23956    0.06553  34.173  < 2e-16 ***\n#> moisture       -1.88033    0.67368  -2.791  0.00533 ** \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 1.168 on 1333 degrees of freedom\n#> Multiple R-squared:  0.8891, Adjusted R-squared:  0.8887 \n#> F-statistic:  2137 on 5 and 1333 DF,  p-value: < 2.2e-16\nsummary(coffee_mod)$coefficients[\"moisture\", 4]\n#> [1] 0.005327594\ntidy(coffee_mod)\n#> # A tibble: 6 × 5\n#>   term           estimate std.error statistic   p.value\n#>   <chr>             <dbl>     <dbl>     <dbl>     <dbl>\n#> 1 (Intercept)        7.04    0.774       9.10 3.23e- 19\n#> 2 speciesRobusta     2.85    0.269      10.6  2.31e- 25\n#> 3 aroma              1.95    0.146      13.4  1.82e- 38\n#> 4 flavor             5.09    0.140      36.3  4.73e-201\n#> 5 sweetness          2.24    0.0655     34.2  2.41e-184\n#> 6 moisture          -1.88    0.674      -2.79 5.33e-  3\ntidy(coffee_mod) |> select(p.value)\n#> # A tibble: 6 × 1\n#>     p.value\n#>       <dbl>\n#> 1 3.23e- 19\n#> 2 2.31e- 25\n#> 3 1.82e- 38\n#> 4 4.73e-201\n#> 5 2.41e-184\n#> 6 5.33e-  3\ntidy(coffee_mod) |> filter(term == \"aroma\")\n#> # A tibble: 1 × 5\n#>   term  estimate std.error statistic  p.value\n#>   <chr>    <dbl>     <dbl>     <dbl>    <dbl>\n#> 1 aroma     1.95     0.146      13.4 1.82e-38\nglance(coffee_mod)\n#> # A tibble: 1 × 12\n#>   r.squared adj.r…¹ sigma stati…² p.value    df logLik   AIC\n#>       <dbl>   <dbl> <dbl>   <dbl>   <dbl> <dbl>  <dbl> <dbl>\n#> 1     0.889   0.889  1.17   2137.       0     5 -2105. 4224.\n#> # … with 4 more variables: BIC <dbl>, deviance <dbl>,\n#> #   df.residual <int>, nobs <int>, and abbreviated variable\n#> #   names ¹​adj.r.squared, ²​statistic\n#> # ℹ Use `colnames()` to see all variable names\naugment(coffee_mod)\n#> # A tibble: 1,339 × 12\n#>    total_cup_…¹ species aroma flavor sweet…² moist…³ .fitted\n#>           <dbl> <chr>   <dbl>  <dbl>   <dbl>   <dbl>   <dbl>\n#>  1         90.6 Arabica  8.67   8.83   10       0.12    91.1\n#>  2         89.9 Arabica  8.75   8.67   10       0.12    90.5\n#>  3         89.8 Arabica  8.42   8.5    10       0       89.2\n#>  4         89   Arabica  8.17   8.58   10       0.11    88.9\n#>  5         88.8 Arabica  8.25   8.5    10       0.12    88.6\n#>  6         88.8 Arabica  8.58   8.42   10       0.11    88.9\n#>  7         88.8 Arabica  8.42   8.5    10       0.11    89.0\n#>  8         88.7 Arabica  8.25   8.33    9.33    0.03    86.4\n#>  9         88.4 Arabica  8.67   8.67    9.33    0.03    89.0\n#> 10         88.2 Arabica  8.08   8.58   10       0.1     88.7\n#> # … with 1,329 more rows, 5 more variables: .resid <dbl>,\n#> #   .hat <dbl>, .sigma <dbl>, .cooksd <dbl>,\n#> #   .std.resid <dbl>, and abbreviated variable names\n#> #   ¹​total_cup_points, ²​sweetness, ³​moisture\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\naugment_df <- augment(coffee_mod)\naugment_df |> filter(.cooksd > 1)\n#> # A tibble: 1 × 12\n#>   total_cup_p…¹ species aroma flavor sweet…² moist…³ .fitted\n#>           <dbl> <chr>   <dbl>  <dbl>   <dbl>   <dbl>   <dbl>\n#> 1             0 Arabica     0      0       0    0.12    6.81\n#> # … with 5 more variables: .resid <dbl>, .hat <dbl>,\n#> #   .sigma <dbl>, .cooksd <dbl>, .std.resid <dbl>, and\n#> #   abbreviated variable names ¹​total_cup_points,\n#> #   ²​sweetness, ³​moisture\n#> # ℹ Use `colnames()` to see all variable names\nggplot(data = coffee_df, aes(x = total_cup_points)) +\n  geom_histogram(bins = 15, fill = \"white\", colour = \"black\")\naugment_df |> filter(.hat > 0.2)\n#> # A tibble: 2 × 12\n#>   total_cup_p…¹ species aroma flavor sweet…² moist…³ .fitted\n#>           <dbl> <chr>   <dbl>  <dbl>   <dbl>   <dbl>   <dbl>\n#> 1          59.8 Arabica   7.5   6.67    1.33    0.1    58.4 \n#> 2           0   Arabica   0     0       0       0.12    6.81\n#> # … with 5 more variables: .resid <dbl>, .hat <dbl>,\n#> #   .sigma <dbl>, .cooksd <dbl>, .std.resid <dbl>, and\n#> #   abbreviated variable names ¹​total_cup_points,\n#> #   ²​sweetness, ³​moisture\n#> # ℹ Use `colnames()` to see all variable names\naugment_df |> filter(.std.resid > 3 | .std.resid < -3)\n#> # A tibble: 25 × 12\n#>    total_cup_…¹ species aroma flavor sweet…² moist…³ .fitted\n#>           <dbl> <chr>   <dbl>  <dbl>   <dbl>   <dbl>   <dbl>\n#>  1         82.8 Arabica  8.08   8.17   10       0.12    86.6\n#>  2         82.4 Arabica  5.08   7.75   10       0.11    78.6\n#>  3         82.3 Arabica  7.75   8.08    6.67    0.11    78.1\n#>  4         80.7 Arabica  7.67   7.5     6.67    0       75.2\n#>  5         80   Arabica  7.58   7.75   10       0       83.7\n#>  6         79.9 Arabica  7.83   7.67   10       0       83.8\n#>  7         79.2 Arabica  7.17   7.42    6.67    0.1     73.6\n#>  8         78.6 Arabica  7.92   7.58   10       0.1     83.3\n#>  9         78.3 Arabica  7.17   6.08   10       0.11    74.2\n#> 10         77.6 Arabica  7.58   7.67    6       0.12    74.1\n#> # … with 15 more rows, 5 more variables: .resid <dbl>,\n#> #   .hat <dbl>, .sigma <dbl>, .cooksd <dbl>,\n#> #   .std.resid <dbl>, and abbreviated variable names\n#> #   ¹​total_cup_points, ²​sweetness, ³​moisture\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\nggplot(data = augment_df |> filter(.fitted > 25), aes(x = .fitted, y = .resid)) +\n  geom_point() "},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"exercise-15-2","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.2.2 Exercises","text":"Exercises marked * indicate exercise solution end chapter 16.5.Add couple predictors linear model fit earlier. , use glance() obtain model fit statistics. model “better” according metrics learned STAT 213?Add couple predictors linear model fit earlier. , use glance() obtain model fit statistics. model “better” according metrics learned STAT 213?one fitted models, construct histogram residuals assess normality assumption (using ggplot2 augment()).one fitted models, construct histogram residuals assess normality assumption (using ggplot2 augment()).Make table 5 coffees highest predicted coffee rating, according one models.Make table 5 coffees highest predicted coffee rating, according one models.","code":""},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"cs-140","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.3 CS 140","text":"section, repeat couple topics CS 140, Python, R. particular ,write function. syntax R similar Python.write function. syntax R similar Python.perform iteration repeat similar task multiple times.perform iteration repeat similar task multiple times.start, suppose interested scraping hitting data SLU’s baseball team web address https://saintsathletics.com/sports/baseball/stats/2022. hitting data, want create statistic player’s weighted -base-average (wOBA). Information wOBA can found : https://www.mlb.com/glossary/advanced-stats/weighted--base-average. following code modified project completed Jack Sylvia data visualization course.Code task given following chunk.can make sure statistic calculated :","code":"\nlibrary(tidyverse)\nlibrary(rvest)\n#> \n#> Attaching package: 'rvest'\n#> The following object is masked from 'package:readr':\n#> \n#>     guess_encoding\n\nurl_SLU <- \"https://saintsathletics.com/sports/baseball/stats/2022\"\ntab_SLU <- read_html(url_SLU) |> html_nodes(\"table\")\nSLU_Hitting <- tab_SLU[[1]] |> html_table(fill = TRUE) |>\n  head(-2) |>\n  select(-23) |>\n  mutate(wOBA = (0.69 * BB + 0.72 * HBP + 0.89 * (H-`2B`-`3B`-`HR`) + 1.27 * `2B` + 1.62 * `3B` + 2.10 * HR) / (AB + BB + SF + HBP))\nSLU_Hitting |> select(wOBA, everything()) |> arrange(desc(wOBA))\n#> # A tibble: 20 × 23\n#>     wOBA   `#` Player    AVG   OPS `GP-GS`    AB     R     H\n#>    <dbl> <int> <chr>   <dbl> <dbl> <chr>   <int> <int> <int>\n#>  1 0.514     7 \"Brink… 0.556 1.16  5-1         9     3     5\n#>  2 0.497    25 \"Liber… 0.379 1.16  25-19      66    19    25\n#>  3 0.46      1 \"Verra… 0.5   1.1   4-0         2     1     1\n#>  4 0.452    13 \"Butle… 0.325 1.08  35-35     126    31    41\n#>  5 0.433     6 \"Clark… 0.367 1.02  29-19      79    24    29\n#>  6 0.425    11 \"Circe… 0.252 1.00  35-33     111    27    28\n#>  7 0.412     9 \"Burke… 0.308 0.885 6-4        13     4     4\n#>  8 0.391    30 \"Watso… 0.318 0.853 35-33     110    29    35\n#>  9 0.365    19 \"Delan… 0.33  0.817 34-34     115    18    38\n#> 10 0.358     8 \"Forgi… 0.244 0.799 27-27      86    22    21\n#> 11 0.356     5 \"Desja… 0.284 0.741 28-20      67    23    19\n#> 12 0.347    37 \"Goret… 0.268 0.771 32-32      97    18    26\n#> 13 0.345     3 \"Haun,… 0     0.5   11-0        2     1     0\n#> 14 0.335    18 \"Feder… 0.275 0.733 25-7       40    13    11\n#> 15 0.309    23 \"Conno… 0.286 0.661 6-0         7     2     2\n#> 16 0.294    22 \"Court… 0.256 0.63  20-10      39     7    10\n#> 17 0.292    20 \"Court… 0.281 0.646 27-17      64     6    18\n#> 18 0.285    41 \"Comer… 0.222 0.582 31-21      72    16    16\n#> 19 0.154    24 \"Colan… 0.095 0.295 15-3       21     6     2\n#> 20 0        36 \"Boldu… 0     0     2-0         2     0     0\n#> # … with 14 more variables: `2B` <int>, `3B` <int>,\n#> #   HR <int>, RBI <int>, TB <int>, `SLG%` <dbl>, BB <int>,\n#> #   HBP <int>, SO <int>, GDP <int>, `OB%` <dbl>, SF <int>,\n#> #   SH <int>, `SB-ATT` <chr>\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"functions","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.3.1 Functions","text":"Now, suppose might want repeat scraping calculation wOBA years SLU teams. , course, obtain new URL address copy paste code used , replacing old URL address new one. reasonable thing wanted one url. , wanted 10, 20, 50, 1000, urls, might consider writing function scrape data calculate wOBA.format function R :used functions throughout entire semester, always functions others defined imported R packages. expand toolbox, might encounter situations want write specialized functions performing tasks covered functions others written.get back example, let’s write simple function, called get_sum_squares, computes sum squares numeric vector argument named x_vec. sum squares function take number x_vec, square , add numbers .Now, let’s test function numeric vector c(2, 4, 1)Now, move back example. want write function called get_hitting_data takes url_name, scrapes data url, calculates wOBA variables scraped. Note function work urls contain data table formatted various baseball statistics column names.create function, can simply copy paste code replace SLU url web address argument url_name body function.can test function SLU url:","code":"\nname_of_function <- function(argument1, argument2, ....) {\n  body_of_function ## performs various tasks with the arguments\n  \n  return(output) ## tells the function what to return\n}\nget_sum_squares <- function(x_vec) {\n  \n  sum_of_squares <- sum(x_vec ^ 2)\n  \n  return(sum_of_squares)\n}\nget_sum_squares(x_vec = c(2, 4, 1))\n#> [1] 21\nget_hitting_data <- function(url_name) {\n  \n  tab <- read_html(url_name) |> html_nodes(\"table\")\n  \n  hitting <- tab[[1]] |> html_table(fill = TRUE) |>\n    head(-2) |>\n    select(-23) |>\n    mutate(wOBA = (0.69 * BB + 0.72 * HBP + 0.89 *\n                     (H- `2B` - `3B` - `HR`) +\n                     1.27 * `2B` + 1.62 * `3B` + 2.10 * HR) / \n             (AB + BB + SF + HBP),\n           url_name = url_name)\n  \n  return(hitting)\n}\nget_hitting_data(url_name = \"https://saintsathletics.com/sports/baseball/stats/2022\")\n#> # A tibble: 20 × 24\n#>      `#` Player    AVG   OPS `GP-GS`    AB     R     H  `2B`\n#>    <int> <chr>   <dbl> <dbl> <chr>   <int> <int> <int> <int>\n#>  1     6 \"Clark… 0.367 1.02  29-19      79    24    29     5\n#>  2    19 \"Delan… 0.33  0.817 34-34     115    18    38     5\n#>  3    13 \"Butle… 0.325 1.08  35-35     126    31    41     9\n#>  4    30 \"Watso… 0.318 0.853 35-33     110    29    35     6\n#>  5     5 \"Desja… 0.284 0.741 28-20      67    23    19     1\n#>  6    20 \"Court… 0.281 0.646 27-17      64     6    18     2\n#>  7    37 \"Goret… 0.268 0.771 32-32      97    18    26     6\n#>  8    11 \"Circe… 0.252 1.00  35-33     111    27    28     9\n#>  9     8 \"Forgi… 0.244 0.799 27-27      86    22    21     4\n#> 10    41 \"Comer… 0.222 0.582 31-21      72    16    16     0\n#> 11     7 \"Brink… 0.556 1.16  5-1         9     3     5     0\n#> 12     1 \"Verra… 0.5   1.1   4-0         2     1     1     0\n#> 13    25 \"Liber… 0.379 1.16  25-19      66    19    25     8\n#> 14     9 \"Burke… 0.308 0.885 6-4        13     4     4     1\n#> 15    23 \"Conno… 0.286 0.661 6-0         7     2     2     0\n#> 16    18 \"Feder… 0.275 0.733 25-7       40    13    11     3\n#> 17    22 \"Court… 0.256 0.63  20-10      39     7    10     1\n#> 18    24 \"Colan… 0.095 0.295 15-3       21     6     2     0\n#> 19     3 \"Haun,… 0     0.5   11-0        2     1     0     0\n#> 20    36 \"Boldu… 0     0     2-0         2     0     0     0\n#> # … with 15 more variables: `3B` <int>, HR <int>,\n#> #   RBI <int>, TB <int>, `SLG%` <dbl>, BB <int>, HBP <int>,\n#> #   SO <int>, GDP <int>, `OB%` <dbl>, SF <int>, SH <int>,\n#> #   `SB-ATT` <chr>, wOBA <dbl>, url_name <chr>\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"iteration","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.3.2 Iteration","text":"Now suppose want use function scrape 2022 baseball statistics teams Liberty League. 10 teams total. websites team’s statistics well school name given tibble :One option obtain hitting statistics 10 teams calculating wOBA (assuming tables structured way web page) apply function 10 times bind together results. first three applications function shown .just 10 teams, approach certainly doable bit annoying. , wanted type calculation league teams, MLB (Major League Baseball)? , multiple years team?better approach use iteration write code repeatedly scrape data website calculate wOBA statistic function. CS 140, primary form iteration used probably loop. loops R similar syntax loops Python. However, general, loops clunky, can take lot lines code, can difficult read.section, instead focus functional programming approach iteration map() function family purrr. purrr part core tidyverse package gets loaded library(tidyverse). map() function two arguments: first vector list second function. map() applies function second argument element vector list first argument. example, consider applying get_sum_squares function wrote earlier list vectors:output list sums squares calculated get_sum_squares() function.apply map() approach iteration baseball web urls, create object called url_vec urls school., apply map() first argument url_vec second argument function get_hitting_data() wrote earlier.Scraping performing wOBA calculation take seconds. output list 10 tibbles. bind_rows() function used stack rows different data frames tibbles can also used stack rows data frames tibbles given list. apply function scraped data add name school data frame left_join():data set, can now things like figure top 3 hitters team, according wOBA metric:find players team bats AB:","code":"\nschool_df <- tibble(school_name = c(\"SLU\", \"Clarkson\", \"Rochester\", \"RIT\", \"Ithaca\", \"Skidmore\", \"RPI\", \"Union\", \"Bard\", \"Vassar\"),\n                    hitting_web_url = c(\"https://saintsathletics.com/sports/baseball/stats/2022\",\n                 \"https://clarksonathletics.com/sports/baseball/stats/2022\", \n                 \"https://uofrathletics.com/sports/baseball/stats/2022\",\n                 \"https://ritathletics.com/sports/baseball/stats/2022\",\n                 \"https://athletics.ithaca.edu/sports/baseball/stats/2022\",\n                 \"https://skidmoreathletics.com/sports/baseball/stats/2022\",\n                 \"https://rpiathletics.com/sports/baseball/stats/2022\",\n                 \"https://unionathletics.com/sports/baseball/stats/2022\",\n                 \"https://bardathletics.com/sports/baseball/stats/2022\",\n                 \"https://www.vassarathletics.com/sports/baseball/stats/2022\"))\nschool_df\nget_hitting_data(url_name = \"https://saintsathletics.com/sports/baseball/stats/2022\")\nget_hitting_data(url_name = \"https://clarksonathletics.com/sports/baseball/stats/2022\")\nget_hitting_data(url_name = \"https://uofrathletics.com/sports/baseball/stats/2022\")\nnum_list <- list(vec1 = c(1, 4, 5), vec2 = c(9, 8, 3, 5), vec3 = 1)\nmap(num_list, get_sum_squares)\n#> $vec1\n#> [1] 42\n#> \n#> $vec2\n#> [1] 179\n#> \n#> $vec3\n#> [1] 1\nurl_vec <- school_df$hitting_web_url\nhitting_list <- map(url_vec, get_hitting_data)\nhitting_list\nhitting_ll <- hitting_list |> bind_rows() |>\n  left_join(school_df, by = c(\"url_name\" = \"hitting_web_url\"))\nhitting_ll\n#> # A tibble: 213 × 25\n#>      `#` Player    AVG   OPS `GP-GS`    AB     R     H  `2B`\n#>    <int> <chr>   <dbl> <dbl> <chr>   <int> <int> <int> <int>\n#>  1     6 \"Clark… 0.367 1.02  29-19      79    24    29     5\n#>  2    19 \"Delan… 0.33  0.817 34-34     115    18    38     5\n#>  3    13 \"Butle… 0.325 1.08  35-35     126    31    41     9\n#>  4    30 \"Watso… 0.318 0.853 35-33     110    29    35     6\n#>  5     5 \"Desja… 0.284 0.741 28-20      67    23    19     1\n#>  6    20 \"Court… 0.281 0.646 27-17      64     6    18     2\n#>  7    37 \"Goret… 0.268 0.771 32-32      97    18    26     6\n#>  8    11 \"Circe… 0.252 1.00  35-33     111    27    28     9\n#>  9     8 \"Forgi… 0.244 0.799 27-27      86    22    21     4\n#> 10    41 \"Comer… 0.222 0.582 31-21      72    16    16     0\n#> # … with 203 more rows, and 16 more variables: `3B` <int>,\n#> #   HR <int>, RBI <int>, TB <int>, `SLG%` <dbl>, BB <int>,\n#> #   HBP <int>, SO <int>, GDP <int>, `OB%` <dbl>, SF <int>,\n#> #   SH <int>, `SB-ATT` <chr>, wOBA <dbl>, url_name <chr>,\n#> #   school_name <chr>\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\nhitting_ll |> group_by(school_name) |>\n  arrange(desc(wOBA)) |>\n  slice(1:3) |>\n  select(Player, school_name, wOBA)\n#> # A tibble: 30 × 3\n#> # Groups:   school_name [10]\n#>    Player                                      schoo…¹  wOBA\n#>    <chr>                                       <chr>   <dbl>\n#>  1 \"Toby, Jared\\r\\n                          … Bard    0.488\n#>  2 \"Dumper, Sam\\r\\n                          … Bard    0.475\n#>  3 \"Myers, Jordan\\r\\n                        … Bard    0.431\n#>  4 \"Cantor, Danny\\r\\n                        … Clarks… 0.805\n#>  5 \"Price, Grant\\r\\n                         … Clarks… 0.475\n#>  6 \"Doyle, Caleb\\r\\n                         … Clarks… 0.473\n#>  7 \"Shirley, Buzz\\r\\n                        … Ithaca  0.524\n#>  8 \"Fabbo, Louis\\r\\n                         … Ithaca  0.465\n#>  9 \"Fabian, Matt\\r\\n                         … Ithaca  0.428\n#> 10 \"Blackall, Patrick \\r\\n                   … RIT     0.399\n#> # … with 20 more rows, and abbreviated variable name\n#> #   ¹​school_name\n#> # ℹ Use `print(n = ...)` to see more rows\nhitting_ll |> group_by(school_name) |>\n  arrange(desc(AB)) |>\n  slice(1:3) |>\n  select(Player, school_name, AB)\n#> # A tibble: 30 × 3\n#> # Groups:   school_name [10]\n#>    Player                                      schoo…¹    AB\n#>    <chr>                                       <chr>   <int>\n#>  1 \"Toby, Jared\\r\\n                          … Bard      107\n#>  2 \"Myers, Jordan\\r\\n                        … Bard      107\n#>  3 \"Luscher, Alex\\r\\n                        … Bard      101\n#>  4 \"Brouillette, Colby\\r\\n                   … Clarks…   127\n#>  5 \"Wilson, Kent\\r\\n                         … Clarks…   126\n#>  6 \"Doyle, Caleb\\r\\n                         … Clarks…   103\n#>  7 \"Pedersen, Connor\\r\\n                     … Ithaca    207\n#>  8 \"Cutaia, Nicholas\\r\\n                     … Ithaca    180\n#>  9 \"Merod, Gil\\r\\n                           … Ithaca    169\n#> 10 \"Reilly, Chris\\r\\n                        … RIT       152\n#> # … with 20 more rows, and abbreviated variable name\n#> #   ¹​school_name\n#> # ℹ Use `print(n = ...)` to see more rows"},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"exercise-15-3","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.3.3 Exercises","text":"Exercises marked * indicate exercise solution end chapter 16.5.code scrapes data wikipedia page listing billboard end year “hot 100” songs year 2021Wrap code function scrapes data Wikipedia user-provided year_scrape argument.Wrap code function scrapes data Wikipedia user-provided year_scrape argument.Create either vector years 2014 2021 list years 2014 2021. Use vector list, along function wrote Exercise 1 map() function, scrape data tables year.Create either vector years 2014 2021 list years 2014 2021. Use vector list, along function wrote Exercise 1 map() function, scrape data tables year.Combine data frames scraped Exercise 2 bind_rows() use combined data set figure artist appears highest number times billboard hot 100 list within years 2014 2021. save time, data frames combined able something like:Combine data frames scraped Exercise 2 bind_rows() use combined data set figure artist appears highest number times billboard hot 100 list within years 2014 2021. save time, data frames combined able something like:* Note solution Exercise 3 likely imperfect songs feature another musical artist. songs present problem counting number songs artist?","code":"\nlibrary(rvest)\nlibrary(tidyverse)\n\nyear_scrape <- 2021\nurl <- paste0(\"https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_\", year_scrape)\n\n## convert the html code into something R can read\nbillboard_tab <- read_html(url) |> html_nodes(\"table\")\n\n## grabs the tables\nbillboard_df <- billboard_tab[[1]] |> html_table() |>\n  mutate(year = year_scrape)\nbillboard_df\n#> # A tibble: 100 × 4\n#>      No. Title                                Artist…¹  year\n#>    <int> <chr>                                <chr>    <dbl>\n#>  1     1 \"\\\"Levitating\\\"\"                     Dua Lipa  2021\n#>  2     2 \"\\\"Save Your Tears\\\"\"                The Wee…  2021\n#>  3     3 \"\\\"Blinding Lights\\\"\"                The Wee…  2021\n#>  4     4 \"\\\"Mood\\\"\"                           24kGold…  2021\n#>  5     5 \"\\\"Good 4 U\\\"\"                       Olivia …  2021\n#>  6     6 \"\\\"Kiss Me More\\\"\"                   Doja Ca…  2021\n#>  7     7 \"\\\"Leave the Door Open\\\"\"            Silk So…  2021\n#>  8     8 \"\\\"Drivers License\\\"\"                Olivia …  2021\n#>  9     9 \"\\\"Montero (Call Me by Your Name)\\\"\" Lil Nas…  2021\n#> 10    10 \"\\\"Peaches\\\"\"                        Justin …  2021\n#> # … with 90 more rows, and abbreviated variable name\n#> #   ¹​`Artist(s)`\n#> # ℹ Use `print(n = ...)` to see more rows\ncombined_df |> group_by(`Artist(s)`) |>\n  summarise(n_appear = n()) |>\n  arrange(desc(n_appear))"},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"chapexercise-15","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.4 Chapter Exercises","text":"chapter exercises section connections STAT 113, STAT 213, CS 140.","code":""},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"solutions-15","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.5 Exercise Solutions","text":"","code":""},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"stat-113-s","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.5.1 STAT 113 S","text":"","code":""},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"stat-213-s","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.5.2 STAT 213 S","text":"","code":""},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"cs-140-s","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.5.3 CS 140 S","text":"* Note solution Exercise 3 likely imperfect songs feature another musical artist. songs present problem counting number songs artist?group_by() musical artist use counting function n(), artist artist featuring musician counted separately table.","code":""},{"path":"connections-to-stat-113-stat-213-and-cs-140.html","id":"rcode-15","chapter":" 16 Connections to STAT 113, STAT 213, and CS 140","heading":"16.6 Non-Exercise R Code","text":"","code":"\nlibrary(openintro)\nresume\nlibrary(tidyverse)\nresume_sum <- resume |> \n  mutate(received_callback = received_callback) |>\n           group_by(race, received_callback) |>\n  summarise(count = n())\nggplot(data = resume_sum, aes(x = race, y = count)) +\n  geom_col(aes(fill = received_callback)) +\n  scale_fill_viridis_c()\nresume <- resume |>\n  mutate(received_callback = as.factor(received_callback))\nresume_sum <- resume |> \n           group_by(race, received_callback) |>\n  summarise(count = n())\nggplot(data = resume_sum, aes(x = race, y = count)) +\n  geom_col(aes(fill = received_callback)) +\n  scale_fill_viridis_d()\nresume |> group_by(race, received_callback) |>\n  summarise(count = n()) |>\n  pivot_wider(names_from = race,\n              values_from = count)\nchisq.test(x = resume$race, y = resume$received_callback)\nggplot(data = resume, aes(x = fct_rev(fct_infreq(job_type)))) +\n  geom_bar() +\n  coord_flip() +\n  labs(x = \"Job Type\")\nggplot(data = resume, aes(x = fct_rev(fct_infreq(job_industry)))) +\n  geom_bar() +\n  coord_flip() +\n  labs(x = \"Job Industry\")\nresume_firstname <- resume |>\n  group_by(firstname) |>\n  summarise(propcallback = mean(received_callback == \"1\"),\n            gender = unique(gender),\n            race = unique(race)) |>\n  arrange(desc(propcallback)) |>\n  unite(\"gender_race\", c(gender, race))\n\nggplot(data = resume_firstname, aes(x = gender_race, y = propcallback)) +\n  geom_point()\nlibrary(ggrepel)\nlabel_df <- resume_firstname |> \n  filter(propcallback == max(propcallback) |\n           propcallback == min(propcallback))\n\nggplot(data = resume_firstname, aes(x = gender_race, y = propcallback)) +\n  geom_point() +\n  geom_label_repel(data = label_df, aes(label = firstname))\nlibrary(broom)\nlibrary(here)\ncoffee_df <- read_csv(here(\"data/coffee_ratings.csv\"))\ncoffee_mod <- lm(total_cup_points ~ species + aroma + flavor +\n                   sweetness + moisture,\n   data = coffee_df)\nsummary(coffee_mod)\nsummary(coffee_mod)$coefficients[\"moisture\", 4]\ntidy(coffee_mod)\ntidy(coffee_mod) |> select(p.value)\ntidy(coffee_mod) |> filter(term == \"aroma\")\nglance(coffee_mod)\naugment(coffee_mod)\naugment_df <- augment(coffee_mod)\naugment_df |> filter(.cooksd > 1)\nggplot(data = coffee_df, aes(x = total_cup_points)) +\n  geom_histogram(bins = 15, fill = \"white\", colour = \"black\")\naugment_df |> filter(.hat > 0.2)\naugment_df |> filter(.std.resid > 3 | .std.resid < -3)\nggplot(data = augment_df |> filter(.fitted > 25), aes(x = .fitted, y = .resid)) +\n  geom_point() \nlibrary(tidyverse)\nlibrary(rvest)\n\nurl_SLU <- \"https://saintsathletics.com/sports/baseball/stats/2022\"\ntab_SLU <- read_html(url_SLU) |> html_nodes(\"table\")\nSLU_Hitting <- tab_SLU[[1]] |> html_table(fill = TRUE) |>\n  head(-2) |>\n  select(-23) |>\n  mutate(wOBA = (0.69 * BB + 0.72 * HBP + 0.89 * (H-`2B`-`3B`-`HR`) + 1.27 * `2B` + 1.62 * `3B` + 2.10 * HR) / (AB + BB + SF + HBP))\nSLU_Hitting |> select(wOBA, everything()) |> arrange(desc(wOBA))\nget_sum_squares <- function(x_vec) {\n  \n  sum_of_squares <- sum(x_vec ^ 2)\n  \n  return(sum_of_squares)\n}\nget_sum_squares(x_vec = c(2, 4, 1))\nget_hitting_data <- function(url_name) {\n  \n  tab <- read_html(url_name) |> html_nodes(\"table\")\n  \n  hitting <- tab[[1]] |> html_table(fill = TRUE) |>\n    head(-2) |>\n    select(-23) |>\n    mutate(wOBA = (0.69 * BB + 0.72 * HBP + 0.89 *\n                     (H- `2B` - `3B` - `HR`) +\n                     1.27 * `2B` + 1.62 * `3B` + 2.10 * HR) / \n             (AB + BB + SF + HBP),\n           url_name = url_name)\n  \n  return(hitting)\n}\nget_hitting_data(url_name = \"https://saintsathletics.com/sports/baseball/stats/2022\")\nschool_df <- tibble(school_name = c(\"SLU\", \"Clarkson\", \"Rochester\", \"RIT\", \"Ithaca\", \"Skidmore\", \"RPI\", \"Union\", \"Bard\", \"Vassar\"),\n                    hitting_web_url = c(\"https://saintsathletics.com/sports/baseball/stats/2022\",\n                 \"https://clarksonathletics.com/sports/baseball/stats/2022\", \n                 \"https://uofrathletics.com/sports/baseball/stats/2022\",\n                 \"https://ritathletics.com/sports/baseball/stats/2022\",\n                 \"https://athletics.ithaca.edu/sports/baseball/stats/2022\",\n                 \"https://skidmoreathletics.com/sports/baseball/stats/2022\",\n                 \"https://rpiathletics.com/sports/baseball/stats/2022\",\n                 \"https://unionathletics.com/sports/baseball/stats/2022\",\n                 \"https://bardathletics.com/sports/baseball/stats/2022\",\n                 \"https://www.vassarathletics.com/sports/baseball/stats/2022\"))\nschool_df\nget_hitting_data(url_name = \"https://saintsathletics.com/sports/baseball/stats/2022\")\nget_hitting_data(url_name = \"https://clarksonathletics.com/sports/baseball/stats/2022\")\nget_hitting_data(url_name = \"https://uofrathletics.com/sports/baseball/stats/2022\")\nnum_list <- list(vec1 = c(1, 4, 5), vec2 = c(9, 8, 3, 5), vec3 = 1)\nmap(num_list, get_sum_squares)\nurl_vec <- school_df$hitting_web_url\nhitting_list <- map(url_vec, get_hitting_data)\nhitting_list\nhitting_ll <- hitting_list |> bind_rows() |>\n  left_join(school_df, by = c(\"url_name\" = \"hitting_web_url\"))\nhitting_ll\nhitting_ll |> group_by(school_name) |>\n  arrange(desc(wOBA)) |>\n  slice(1:3) |>\n  select(Player, school_name, wOBA)\nhitting_ll |> group_by(school_name) |>\n  arrange(desc(AB)) |>\n  slice(1:3) |>\n  select(Player, school_name, AB)"},{"path":"introduction-to-sql-with-dbplyr.html","id":"introduction-to-sql-with-dbplyr","chapter":" 17 Introduction to SQL with dbplyr","heading":" 17 Introduction to SQL with dbplyr","text":"Goals:explain database , different data set, might use database.use dbplyr translate R code dplyr SQL queries database tables.draw parallels dplyr functions syntax used SQL.dplyr functions ’ve used (ones early semester xxxx_join() family recently) corresponding components SQL. SQL stands Structured Query Language common language used databases. Compared dplyr, general, SQL code much harder read, SQL isn’t designed specifically data analysis like dplyr . section, introduce databases give brief introduction SQL analyzing data database.","code":""},{"path":"introduction-to-sql-with-dbplyr.html","id":"what-is-a-database","chapter":" 17 Introduction to SQL with dbplyr","heading":"17.1 What is a Database","text":"R Data Science textbook defines database “collection data frames,” called database table. key differences data frame (’ve using entire semester) database table. summarised R Data Science :database table can larger stored disk data frame stored memory size limited.database table usually indices data frames .many , , data base tables “row-oriented” tidy data frames “column-oriented.”Databases run Database Management Systems. R Data Science textbook divides Database Management Systems 3 types:client-server like PostgreSQL SQL ServerCloud-based like Amazon’s RedshiftIn-process like SQLiteWe won’t really discuss , advanced course database systems CS department give information Database Management Systems (databases general).connect database R depends type database management system. R package major Database Management Systems. purposes, connect Database management system depends heavily type, focus database management system contained R package duckdb.also need database interface connect database tables duckdb DBI package.Note: section connecting database management systems may confusing, particularly computer science background. don’t let derail learning rest chapter, consist primarily R code ! take-home message need way connect system within R. ’s challenging give specific directions connection depends type system, avoiding connecting database management system duckdb R package using functions DBI package.https://r4ds.hadley.nz/databases.html\nSQL short Structured Query Language.\nfirst load duckdb DBI libraries make connection database management system, name con:can type con see stores:’ve created brand-new database, can next add data tables duckdb_read_csv() function. Compared read_csv() readr package, duckdb_read_csv() couple extra arguments: conn argument giving database management connection name argument giving name want give data table:doListTables() function lists names data tables database just created:, dbExistsTable() can used examine whether data table exists current database:Note , many practical situations, data tables already exist database working , step duckdb_read_csv() necessary.use raw SQL code query database just created, can create string SQL code, name sql, pass dbGetQuery() function. also load tidyverse package use as_tibble() function convert data.frame tibble.","code":"\nlibrary(DBI)\nlibrary(duckdb)\ncon <- DBI::dbConnect(duckdb::duckdb())\ncon\n#> <duckdb_connection 95c00 driver=<duckdb_driver a45b0 dbdir=':memory:' read_only=FALSE>>\nlibrary(here)\n#> here() starts at /Users/highamm/Desktop/datascience234\nduckdb_read_csv(conn = con, name = \"tennis2018\", \n                files = here(\"data/atp_matches_2018.csv\"))\nduckdb_read_csv(conn = con, name = \"tennis2019\", \n                files = here(\"data/atp_matches_2019.csv\"))\ndbListTables(con)\n#> [1] \"tennis2018\" \"tennis2019\"\ndbExistsTable(con, \"tennis2019\")\n#> [1] TRUE\ndbExistsTable(con, \"tennis2020\")\n#> [1] FALSE\nlibrary(tidyverse)\n#> ── Attaching packages ─────────────────── tidyverse 1.3.2 ──\n#> ✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n#> ✔ tibble  3.1.8     ✔ dplyr   1.0.9\n#> ✔ tidyr   1.2.0     ✔ stringr 1.4.0\n#> ✔ readr   2.1.2     ✔ forcats 0.5.1\n#> ── Conflicts ────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n\nsql <- \"\n  SELECT surface, winner_name, loser_name, w_ace, l_ace, minutes\n  FROM tennis2019 \n  WHERE minutes > 240\n\"\ndbGetQuery(con, sql)|>\n  as_tibble()\n#> # A tibble: 30 × 6\n#>    surface winner_name           loser…¹ w_ace l_ace minutes\n#>    <chr>   <chr>                 <chr>   <int> <int>   <int>\n#>  1 Hard    Joao Sousa            Guido …    19    18     241\n#>  2 Hard    Jeremy Chardy         Ugo Hu…    29    20     244\n#>  3 Hard    Roberto Bautista Agut Andy M…     7    19     249\n#>  4 Hard    Joao Sousa            Philip…    28    20     258\n#>  5 Hard    Alex Bolt             Gilles…    11    14     244\n#>  6 Hard    Milos Raonic          Stan W…    39    28     241\n#>  7 Hard    Marin Cilic           Fernan…     8    27     258\n#>  8 Hard    Kei Nishikori         Pablo …    15     5     305\n#>  9 Hard    Frances Tiafoe        David …     3    11     244\n#> 10 Clay    Alexander Zverev      John M…    17     0     248\n#> # … with 20 more rows, and abbreviated variable name\n#> #   ¹​loser_name\n#> # ℹ Use `print(n = ...)` to see more rows"},{"path":"introduction-to-sql-with-dbplyr.html","id":"exercise-16-1","chapter":" 17 Introduction to SQL with dbplyr","heading":"17.1.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 17.5.* Though know SQL code, can probably figure code . matches returned query?* Though know SQL code, can probably figure code . matches returned query?dplyr equivalent function SQL code ? dplyr equivalent function SELECT SQL code ?dplyr equivalent function SQL code ? dplyr equivalent function SELECT SQL code ?","code":""},{"path":"introduction-to-sql-with-dbplyr.html","id":"dbplyr-a-database-version-of-dplyr","chapter":" 17 Introduction to SQL with dbplyr","heading":"17.2 dbplyr: A Database Version of dplyr","text":"dbplyr package allow us continue write dplyr-style code query databases instead writing native SQL, code-chunk .begin loading package creating database table object tbl() function. case, create database table tennis2019 data name tennis_db:Examine print tennis_db, look similar print tibble data.frame. Let’s use dplyr code obtain matches lasted longer 240 minutes keep columns. name result tennis_query1:note result still database object: ’s “usual” tibble. One major difference database object usual tibble tennis_query1 tell us many rows data (see ?? specification rows). code wrote actually looking entire data set matches longer 240 minutes: saving time performing query part database table. useful behaviour database tables , large, code might take long time run.want obtain result query tibble, can use collect() function:result tibble can now use R functions (just functions dplyr packages).show_query() function can used tennis_query1 give SQL code executed:get better idea SQL code looks like, let’s make one query dplyr code use show_query() function give native SQL:show_query() shows native SQL code pivot: yikes! Remember SQL designed data analysis, doesn’t always look pretty. ’ll one simpler query:Can match SQL code corresponding dplyr functions used?","code":"\nlibrary(dbplyr)\n#> \n#> Attaching package: 'dbplyr'\n#> The following objects are masked from 'package:dplyr':\n#> \n#>     ident, sql\ntennis_db <- tbl(con, \"tennis2019\")\ntennis_db\n#> # Source:   table<tennis2019> [?? x 49]\n#> # Database: DuckDB 0.3.5-dev1410 [root@Darwin 21.6.0:R 4.2.1/:memory:]\n#>    tourney…¹ tourn…² surface draw_…³ tourn…⁴ tourn…⁵ match…⁶\n#>    <chr>     <chr>   <chr>     <int> <chr>     <int>   <int>\n#>  1 2019-M020 Brisba… Hard         32 A        2.02e7     300\n#>  2 2019-M020 Brisba… Hard         32 A        2.02e7     299\n#>  3 2019-M020 Brisba… Hard         32 A        2.02e7     298\n#>  4 2019-M020 Brisba… Hard         32 A        2.02e7     297\n#>  5 2019-M020 Brisba… Hard         32 A        2.02e7     296\n#>  6 2019-M020 Brisba… Hard         32 A        2.02e7     295\n#>  7 2019-M020 Brisba… Hard         32 A        2.02e7     294\n#>  8 2019-M020 Brisba… Hard         32 A        2.02e7     293\n#>  9 2019-M020 Brisba… Hard         32 A        2.02e7     292\n#> 10 2019-M020 Brisba… Hard         32 A        2.02e7     291\n#> # … with more rows, 42 more variables: winner_id <int>,\n#> #   winner_seed <chr>, winner_entry <chr>,\n#> #   winner_name <chr>, winner_hand <chr>, winner_ht <int>,\n#> #   winner_ioc <chr>, winner_age <dbl>, loser_id <int>,\n#> #   loser_seed <chr>, loser_entry <chr>, loser_name <chr>,\n#> #   loser_hand <chr>, loser_ht <int>, loser_ioc <chr>,\n#> #   loser_age <dbl>, score <chr>, best_of <int>, …\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\ntennis_query1 <- tennis_db |> \n  filter(minutes > 240) |> \n  select(minutes, winner_name, loser_name, minutes, tourney_name)\ntennis_query1\n#> # Source:   SQL [?? x 4]\n#> # Database: DuckDB 0.3.5-dev1410 [root@Darwin 21.6.0:R 4.2.1/:memory:]\n#>    minutes winner_name           loser_name          tourn…¹\n#>      <int> <chr>                 <chr>               <chr>  \n#>  1     241 Joao Sousa            Guido Pella         Austra…\n#>  2     244 Jeremy Chardy         Ugo Humbert         Austra…\n#>  3     249 Roberto Bautista Agut Andy Murray         Austra…\n#>  4     258 Joao Sousa            Philipp Kohlschrei… Austra…\n#>  5     244 Alex Bolt             Gilles Simon        Austra…\n#>  6     241 Milos Raonic          Stan Wawrinka       Austra…\n#>  7     258 Marin Cilic           Fernando Verdasco   Austra…\n#>  8     305 Kei Nishikori         Pablo Carreno Busta Austra…\n#>  9     244 Frances Tiafoe        David Goffin        Miami …\n#> 10     248 Alexander Zverev      John Millman        Roland…\n#> # … with more rows, and abbreviated variable name\n#> #   ¹​tourney_name\n#> # ℹ Use `print(n = ...)` to see more rows\ntennis_query1 |>\n  collect()\n#> # A tibble: 30 × 4\n#>    minutes winner_name           loser_name          tourn…¹\n#>      <int> <chr>                 <chr>               <chr>  \n#>  1     241 Joao Sousa            Guido Pella         Austra…\n#>  2     244 Jeremy Chardy         Ugo Humbert         Austra…\n#>  3     249 Roberto Bautista Agut Andy Murray         Austra…\n#>  4     258 Joao Sousa            Philipp Kohlschrei… Austra…\n#>  5     244 Alex Bolt             Gilles Simon        Austra…\n#>  6     241 Milos Raonic          Stan Wawrinka       Austra…\n#>  7     258 Marin Cilic           Fernando Verdasco   Austra…\n#>  8     305 Kei Nishikori         Pablo Carreno Busta Austra…\n#>  9     244 Frances Tiafoe        David Goffin        Miami …\n#> 10     248 Alexander Zverev      John Millman        Roland…\n#> # … with 20 more rows, and abbreviated variable name\n#> #   ¹​tourney_name\n#> # ℹ Use `print(n = ...)` to see more rows\ntennis_query1 |>\n  show_query()\n#> <SQL>\n#> SELECT \"minutes\", \"winner_name\", \"loser_name\", \"tourney_name\"\n#> FROM \"tennis2019\"\n#> WHERE (\"minutes\" > 240.0)\nmedvedev_query <- tennis_db |>\n  pivot_longer(c(winner_name, loser_name), names_to = \"win_loss\",\n               values_to = \"player\") |>\n  filter(player == \"Daniil Medvedev\") |>\n  group_by(win_loss) |>\n  summarise(win_loss_count = n())\nmedvedev_query\n#> # Source:   SQL [2 x 2]\n#> # Database: DuckDB 0.3.5-dev1410 [root@Darwin 21.6.0:R 4.2.1/:memory:]\n#>   win_loss    win_loss_count\n#>   <chr>                <dbl>\n#> 1 winner_name             59\n#> 2 loser_name              21\nshow_query(medvedev_query)\n#> <SQL>\n#> SELECT \"win_loss\", COUNT(*) AS \"win_loss_count\"\n#> FROM (\n#>   (\n#>     SELECT\n#>       \"tourney_id\",\n#>       \"tourney_name\",\n#>       \"surface\",\n#>       \"draw_size\",\n#>       \"tourney_level\",\n#>       \"tourney_date\",\n#>       \"match_num\",\n#>       \"winner_id\",\n#>       \"winner_seed\",\n#>       \"winner_entry\",\n#>       \"winner_hand\",\n#>       \"winner_ht\",\n#>       \"winner_ioc\",\n#>       \"winner_age\",\n#>       \"loser_id\",\n#>       \"loser_seed\",\n#>       \"loser_entry\",\n#>       \"loser_hand\",\n#>       \"loser_ht\",\n#>       \"loser_ioc\",\n#>       \"loser_age\",\n#>       \"score\",\n#>       \"best_of\",\n#>       \"round\",\n#>       \"minutes\",\n#>       \"w_ace\",\n#>       \"w_df\",\n#>       \"w_svpt\",\n#>       \"w_1stIn\",\n#>       \"w_1stWon\",\n#>       \"w_2ndWon\",\n#>       \"w_SvGms\",\n#>       \"w_bpSaved\",\n#>       \"w_bpFaced\",\n#>       \"l_ace\",\n#>       \"l_df\",\n#>       \"l_svpt\",\n#>       \"l_1stIn\",\n#>       \"l_1stWon\",\n#>       \"l_2ndWon\",\n#>       \"l_SvGms\",\n#>       \"l_bpSaved\",\n#>       \"l_bpFaced\",\n#>       \"winner_rank\",\n#>       \"winner_rank_points\",\n#>       \"loser_rank\",\n#>       \"loser_rank_points\",\n#>       'winner_name' AS \"win_loss\",\n#>       \"winner_name\" AS \"player\"\n#>     FROM \"tennis2019\"\n#>   )\n#>   UNION ALL\n#>   (\n#>     SELECT\n#>       \"tourney_id\",\n#>       \"tourney_name\",\n#>       \"surface\",\n#>       \"draw_size\",\n#>       \"tourney_level\",\n#>       \"tourney_date\",\n#>       \"match_num\",\n#>       \"winner_id\",\n#>       \"winner_seed\",\n#>       \"winner_entry\",\n#>       \"winner_hand\",\n#>       \"winner_ht\",\n#>       \"winner_ioc\",\n#>       \"winner_age\",\n#>       \"loser_id\",\n#>       \"loser_seed\",\n#>       \"loser_entry\",\n#>       \"loser_hand\",\n#>       \"loser_ht\",\n#>       \"loser_ioc\",\n#>       \"loser_age\",\n#>       \"score\",\n#>       \"best_of\",\n#>       \"round\",\n#>       \"minutes\",\n#>       \"w_ace\",\n#>       \"w_df\",\n#>       \"w_svpt\",\n#>       \"w_1stIn\",\n#>       \"w_1stWon\",\n#>       \"w_2ndWon\",\n#>       \"w_SvGms\",\n#>       \"w_bpSaved\",\n#>       \"w_bpFaced\",\n#>       \"l_ace\",\n#>       \"l_df\",\n#>       \"l_svpt\",\n#>       \"l_1stIn\",\n#>       \"l_1stWon\",\n#>       \"l_2ndWon\",\n#>       \"l_SvGms\",\n#>       \"l_bpSaved\",\n#>       \"l_bpFaced\",\n#>       \"winner_rank\",\n#>       \"winner_rank_points\",\n#>       \"loser_rank\",\n#>       \"loser_rank_points\",\n#>       'loser_name' AS \"win_loss\",\n#>       \"loser_name\" AS \"player\"\n#>     FROM \"tennis2019\"\n#>   )\n#> ) \"q01\"\n#> WHERE (\"player\" = 'Daniil Medvedev')\n#> GROUP BY \"win_loss\"\nover20aces <- tennis_db |> filter(w_ace > 20) |>\n  select(w_ace, winner_name) |>\n  group_by(winner_name) |>\n  summarise(nmatch = n()) |>\n  arrange(desc(nmatch))\nover20aces\n#> # Source:     SQL [?? x 2]\n#> # Database:   DuckDB 0.3.5-dev1410 [root@Darwin 21.6.0:R 4.2.1/:memory:]\n#> # Ordered by: desc(nmatch)\n#>    winner_name        nmatch\n#>    <chr>               <dbl>\n#>  1 John Isner             15\n#>  2 Reilly Opelka          14\n#>  3 Milos Raonic           10\n#>  4 Sam Querrey             9\n#>  5 Nick Kyrgios            8\n#>  6 Alexander Bublik        7\n#>  7 Ivo Karlovic            6\n#>  8 Jan Lennard Struff      4\n#>  9 Jo-Wilfried Tsonga      4\n#> 10 Alexander Zverev        4\n#> # … with more rows\n#> # ℹ Use `print(n = ...)` to see more rows\n\nover20aces |> show_query()\n#> <SQL>\n#> SELECT \"winner_name\", COUNT(*) AS \"nmatch\"\n#> FROM (\n#>   SELECT \"w_ace\", \"winner_name\"\n#>   FROM \"tennis2019\"\n#>   WHERE (\"w_ace\" > 20.0)\n#> ) \"q01\"\n#> GROUP BY \"winner_name\"\n#> ORDER BY \"nmatch\" DESC"},{"path":"introduction-to-sql-with-dbplyr.html","id":"exercise-16-2","chapter":" 17 Introduction to SQL with dbplyr","heading":"17.2.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 17.5.* Obtain distribution surface variable making table total number matches played surface 2019 season using dplyr functions tennis_db. , use show_query() show corresponding SQL code.* Obtain distribution surface variable making table total number matches played surface 2019 season using dplyr functions tennis_db. , use show_query() show corresponding SQL code.Create new variable difference winner_rank_points loser_rank_points using dplyr function. , query return column just created, winner_name column, loser_name column. Use show_query() function show corresponding SQL code.Create new variable difference winner_rank_points loser_rank_points using dplyr function. , query return column just created, winner_name column, loser_name column. Use show_query() function show corresponding SQL code.Perform query choosing tennis_db use show_query() function show corresponding SQL code.Perform query choosing tennis_db use show_query() function show corresponding SQL code.","code":""},{"path":"introduction-to-sql-with-dbplyr.html","id":"sql","chapter":" 17 Introduction to SQL with dbplyr","heading":"17.3 SQL","text":"purpose section explore SQL syntax little , focusing connections dplyr. Knowing dplyr quite helpful learning SQL syntax , syntax differs, concepts quite similar. Much text section paraphrased R Data Science textbook.five core components SQL query. two basic SELECT statement (similar select(), , discussed , mutate() summarise()) statement (similar data argument). Using show_query() function directly tennis_db shows SQL query SELECTs columns (denoted *), tennis2019 database.ORDER statements control rows returned (similar filter()) order rows get returned (similar arrange()):Finally, GROUP used aggregation (similar dplyr group_by() summarise() combination).code chunk, remove na.rm = TRUE argument run query. learn?SQL syntax must always follow order SELECT, , , GROUP , ORDER , even though operations can performed different order specified. one aspect makes SQL harder pick something like dplyr, specify want done order want.give little detail 5 operations.SELECT: SELECT covers lot dplyr functions. code , explore used SQL choose columns get returned, rename columns, create new variables:SELECT choose columns return:SELECT rename columns:SELECT create new variableSELECT create new variable summary:GROUP : GROUP covers aggregation similar way dplyr’s group_by() function:: used filter(), though SQL uses different Boolean operators R (example, & becomes , | becomes ).ORDER : ORDER used arrange(). one quite straightforward:SQL also corresponding syntax xxxx_join() family functions, time discuss detail. Note really just scratched surface SQL. entire courses devoted learning SQL syntax databases general. ever find situation need learn SQL, either course job, major head-start dplyr knowledge!","code":"\ntennis_db |> show_query()\n#> <SQL>\n#> SELECT *\n#> FROM \"tennis2019\"\ntennis_db |> filter(winner_hand == \"L\") |>\n  arrange(desc(tourney_date)) |>\n  show_query()\n#> <SQL>\n#> SELECT *\n#> FROM \"tennis2019\"\n#> WHERE (\"winner_hand\" = 'L')\n#> ORDER BY \"tourney_date\" DESC\ntennis_db |>\n  group_by(winner_name) |>\n  summarise(meanace = mean(w_ace, na.rm = TRUE)) |>\n  show_query()\n#> <SQL>\n#> SELECT \"winner_name\", AVG(\"w_ace\") AS \"meanace\"\n#> FROM \"tennis2019\"\n#> GROUP BY \"winner_name\"\ntennis_db |> select(1:4) |> show_query()\n#> <SQL>\n#> SELECT \"tourney_id\", \"tourney_name\", \"surface\", \"draw_size\"\n#> FROM \"tennis2019\"\ntennis_db |> rename(tournament = tourney_name) |>\n  show_query()\n#> <SQL>\n#> SELECT\n#>   \"tourney_id\",\n#>   \"tourney_name\" AS \"tournament\",\n#>   \"surface\",\n#>   \"draw_size\",\n#>   \"tourney_level\",\n#>   \"tourney_date\",\n#>   \"match_num\",\n#>   \"winner_id\",\n#>   \"winner_seed\",\n#>   \"winner_entry\",\n#>   \"winner_name\",\n#>   \"winner_hand\",\n#>   \"winner_ht\",\n#>   \"winner_ioc\",\n#>   \"winner_age\",\n#>   \"loser_id\",\n#>   \"loser_seed\",\n#>   \"loser_entry\",\n#>   \"loser_name\",\n#>   \"loser_hand\",\n#>   \"loser_ht\",\n#>   \"loser_ioc\",\n#>   \"loser_age\",\n#>   \"score\",\n#>   \"best_of\",\n#>   \"round\",\n#>   \"minutes\",\n#>   \"w_ace\",\n#>   \"w_df\",\n#>   \"w_svpt\",\n#>   \"w_1stIn\",\n#>   \"w_1stWon\",\n#>   \"w_2ndWon\",\n#>   \"w_SvGms\",\n#>   \"w_bpSaved\",\n#>   \"w_bpFaced\",\n#>   \"l_ace\",\n#>   \"l_df\",\n#>   \"l_svpt\",\n#>   \"l_1stIn\",\n#>   \"l_1stWon\",\n#>   \"l_2ndWon\",\n#>   \"l_SvGms\",\n#>   \"l_bpSaved\",\n#>   \"l_bpFaced\",\n#>   \"winner_rank\",\n#>   \"winner_rank_points\",\n#>   \"loser_rank\",\n#>   \"loser_rank_points\"\n#> FROM \"tennis2019\"\ntennis_db |> mutate(prop_first_won = w_1stIn / w_1stWon) |>\n  select(prop_first_won, winner_name) |>\n  show_query()\n#> <SQL>\n#> SELECT \"w_1stIn\" / \"w_1stWon\" AS \"prop_first_won\", \"winner_name\"\n#> FROM \"tennis2019\"\ntennis_db |> summarise(mean_length = mean(minutes)) |>\n  show_query()\n#> <SQL>\n#> SELECT AVG(\"minutes\") AS \"mean_length\"\n#> FROM \"tennis2019\"\ntennis_db |> group_by(winner_name) |>\n  summarise(meanlength = mean(minutes)) |>\n  show_query()\n#> <SQL>\n#> SELECT \"winner_name\", AVG(\"minutes\") AS \"meanlength\"\n#> FROM \"tennis2019\"\n#> GROUP BY \"winner_name\"\ntennis_db |> filter(winner_age > 35 | loser_age > 35) |>\n  show_query()\n#> <SQL>\n#> SELECT *\n#> FROM \"tennis2019\"\n#> WHERE (\"winner_age\" > 35.0 OR \"loser_age\" > 35.0)\ntennis_db |> arrange(desc(winner_rank_points)) |>\n  show_query()\n#> <SQL>\n#> SELECT *\n#> FROM \"tennis2019\"\n#> ORDER BY \"winner_rank_points\" DESC"},{"path":"introduction-to-sql-with-dbplyr.html","id":"exercise-16-3","chapter":" 17 Introduction to SQL with dbplyr","heading":"17.3.1 Exercises","text":"Exercises marked * indicate exercise solution end chapter 17.5.much section, created code dplyr seen code translates SQL. exercises, intead given SQL code asked write dplyr code achieves thing.* Examine SQL code write equivalent dplyr code.Examine SQL code write equivalent dplyr code.Examine SQL code write equivalent dplyr code.","code":"SELECT * \nFROM \"tennis2019\"\nWHERE (\"tourney_name\" = 'Wimbledon')SELECT \"winner_name\", \"loser_name\", \"w_ace\", \"l_ace\", \"w_ace\" - \"l_ace\" AS \"ace_diff\"\nFROM \"tennis2019\"\nORDER BY \"ace_diff\" DESCSELECT \"tourney_name\", AVG(\"minutes\") AS \"mean_min\"\nFROM \"tennis2019\"\nGROUP BY \"tourney_name\""},{"path":"introduction-to-sql-with-dbplyr.html","id":"chapexercise-16","chapter":" 17 Introduction to SQL with dbplyr","heading":"17.4 Chapter Exercises","text":"Exercises marked * indicate exercise solution end chapter 17.5.Run following code:Make hypothesis function like slice() compatible dbplyr.* Try run function lubridate forcats tennis_db mutate(). function work? expect work?* Try run function lubridate forcats tennis_db mutate(). function work? expect work?Run following code write ! translated SQL.Run following code write ! translated SQL.Run following code write %% symbol translated SQL.","code":"\ntennis_db |> slice(1000:1005) |>\n  show_query()\ntennis_db |> filter(winner_name != \"Daniil Medvedev\") |>\n  show_query()\n#> <SQL>\n#> SELECT *\n#> FROM \"tennis2019\"\n#> WHERE (\"winner_name\" != 'Daniil Medvedev')\ntennis_db |>\n  filter(winner_name %in% c(\"Daniil Medvedev\", \"Dominic Thiem\")) |>\n  show_query()\n#> <SQL>\n#> SELECT *\n#> FROM \"tennis2019\"\n#> WHERE (\"winner_name\" IN ('Daniil Medvedev', 'Dominic Thiem'))"},{"path":"introduction-to-sql-with-dbplyr.html","id":"solutions-16","chapter":" 17 Introduction to SQL with dbplyr","heading":"17.5 Exercise Solutions","text":"","code":""},{"path":"introduction-to-sql-with-dbplyr.html","id":"what-is-a-database-s","chapter":" 17 Introduction to SQL with dbplyr","heading":"17.5.1 What is a Database S","text":"* Though know SQL code, can probably figure code . matches returned query?code keeping matches longer 240 minutes. also getting rid columns except specified SELECT.","code":""},{"path":"introduction-to-sql-with-dbplyr.html","id":"dbplyr-a-database-version-of-dplyr-s","chapter":" 17 Introduction to SQL with dbplyr","heading":"17.5.2 dbplyr: A Database Version of dplyr S","text":"* Obtain distribution surface variable making table total number matches played surface 2019 season using dplyr functions tennis_db. , use show_query() show corresponding SQL code.","code":"\ntennis_db |> group_by(surface) |> summarise(nmatch = n())\n#> # Source:   SQL [3 x 2]\n#> # Database: DuckDB 0.3.5-dev1410 [root@Darwin 21.6.0:R 4.2.1/:memory:]\n#>   surface nmatch\n#>   <chr>    <dbl>\n#> 1 Hard      1626\n#> 2 Clay       828\n#> 3 Grass      327\n\ntennis_db |> group_by(surface) |> summarise(nmatch = n()) |>\n  show_query()\n#> <SQL>\n#> SELECT \"surface\", COUNT(*) AS \"nmatch\"\n#> FROM \"tennis2019\"\n#> GROUP BY \"surface\""},{"path":"introduction-to-sql-with-dbplyr.html","id":"sql-s","chapter":" 17 Introduction to SQL with dbplyr","heading":"17.5.3 SQL S","text":"* Examine SQL code write equivalent dplyr code.","code":"SELECT * \nFROM \"tennis2019\"\nWHERE (\"tourney_name\" = 'Wimbledon')\ntennis_db |>\n  filter(tourney_name == \"Wimbledon\")\n#> # Source:   SQL [?? x 49]\n#> # Database: DuckDB 0.3.5-dev1410 [root@Darwin 21.6.0:R 4.2.1/:memory:]\n#>    tourney…¹ tourn…² surface draw_…³ tourn…⁴ tourn…⁵ match…⁶\n#>    <chr>     <chr>   <chr>     <int> <chr>     <int>   <int>\n#>  1 2019-540  Wimble… Grass       128 G        2.02e7     100\n#>  2 2019-540  Wimble… Grass       128 G        2.02e7     101\n#>  3 2019-540  Wimble… Grass       128 G        2.02e7     102\n#>  4 2019-540  Wimble… Grass       128 G        2.02e7     103\n#>  5 2019-540  Wimble… Grass       128 G        2.02e7     104\n#>  6 2019-540  Wimble… Grass       128 G        2.02e7     105\n#>  7 2019-540  Wimble… Grass       128 G        2.02e7     106\n#>  8 2019-540  Wimble… Grass       128 G        2.02e7     107\n#>  9 2019-540  Wimble… Grass       128 G        2.02e7     108\n#> 10 2019-540  Wimble… Grass       128 G        2.02e7     109\n#> # … with more rows, 42 more variables: winner_id <int>,\n#> #   winner_seed <chr>, winner_entry <chr>,\n#> #   winner_name <chr>, winner_hand <chr>, winner_ht <int>,\n#> #   winner_ioc <chr>, winner_age <dbl>, loser_id <int>,\n#> #   loser_seed <chr>, loser_entry <chr>, loser_name <chr>,\n#> #   loser_hand <chr>, loser_ht <int>, loser_ioc <chr>,\n#> #   loser_age <dbl>, score <chr>, best_of <int>, …\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n## check query:\ntennis_db |>\n  filter(tourney_name == \"Wimbledon\") |>\n  show_query()\n#> <SQL>\n#> SELECT *\n#> FROM \"tennis2019\"\n#> WHERE (\"tourney_name\" = 'Wimbledon')"},{"path":"introduction-to-sql-with-dbplyr.html","id":"chapexercise-16-S","chapter":" 17 Introduction to SQL with dbplyr","heading":"17.5.4 Chapter Exercises S","text":"* Try run function lubridate forcats tennis_db mutate(). function work? expect work?result error. functions compatible dbplyr package can used database table. Functions specific R, like lubridate forcats work collect() database table data frame tibble:","code":"\ntennis_db |> mutate(tourney_name_reorder = fct_reorder(tourney_name, \n                                                       draw_size))\ntennis_db |> collect() |>\n  mutate(tourney_name_reorder = fct_reorder(tourney_name, \n                                                       draw_size))\n#> # A tibble: 2,781 × 50\n#>    tourney…¹ tourn…² surface draw_…³ tourn…⁴ tourn…⁵ match…⁶\n#>    <chr>     <chr>   <chr>     <int> <chr>     <int>   <int>\n#>  1 2019-M020 Brisba… Hard         32 A        2.02e7     300\n#>  2 2019-M020 Brisba… Hard         32 A        2.02e7     299\n#>  3 2019-M020 Brisba… Hard         32 A        2.02e7     298\n#>  4 2019-M020 Brisba… Hard         32 A        2.02e7     297\n#>  5 2019-M020 Brisba… Hard         32 A        2.02e7     296\n#>  6 2019-M020 Brisba… Hard         32 A        2.02e7     295\n#>  7 2019-M020 Brisba… Hard         32 A        2.02e7     294\n#>  8 2019-M020 Brisba… Hard         32 A        2.02e7     293\n#>  9 2019-M020 Brisba… Hard         32 A        2.02e7     292\n#> 10 2019-M020 Brisba… Hard         32 A        2.02e7     291\n#> # … with 2,771 more rows, 43 more variables:\n#> #   winner_id <int>, winner_seed <chr>, winner_entry <chr>,\n#> #   winner_name <chr>, winner_hand <chr>, winner_ht <int>,\n#> #   winner_ioc <chr>, winner_age <dbl>, loser_id <int>,\n#> #   loser_seed <chr>, loser_entry <chr>, loser_name <chr>,\n#> #   loser_hand <chr>, loser_ht <int>, loser_ioc <chr>,\n#> #   loser_age <dbl>, score <chr>, best_of <int>, …\n#> # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names"},{"path":"introduction-to-sql-with-dbplyr.html","id":"rcode-16","chapter":" 17 Introduction to SQL with dbplyr","heading":"17.6 Non-Exercise R Code","text":"","code":"\nlibrary(DBI)\nlibrary(duckdb)\ncon <- DBI::dbConnect(duckdb::duckdb())\ncon\nlibrary(here)\nduckdb_read_csv(conn = con, name = \"tennis2018\", \n                files = here(\"data/atp_matches_2018.csv\"))\nduckdb_read_csv(conn = con, name = \"tennis2019\", \n                files = here(\"data/atp_matches_2019.csv\"))\ndbListTables(con)\ndbExistsTable(con, \"tennis2019\")\ndbExistsTable(con, \"tennis2020\")\nlibrary(tidyverse)\n\nsql <- \"\n  SELECT surface, winner_name, loser_name, w_ace, l_ace, minutes\n  FROM tennis2019 \n  WHERE minutes > 240\n\"\ndbGetQuery(con, sql)|>\n  as_tibble()\nlibrary(dbplyr)\ntennis_db <- tbl(con, \"tennis2019\")\ntennis_db\ntennis_query1 <- tennis_db |> \n  filter(minutes > 240) |> \n  select(minutes, winner_name, loser_name, minutes, tourney_name)\ntennis_query1\ntennis_query1 |>\n  collect()\ntennis_query1 |>\n  show_query()\nmedvedev_query <- tennis_db |>\n  pivot_longer(c(winner_name, loser_name), names_to = \"win_loss\",\n               values_to = \"player\") |>\n  filter(player == \"Daniil Medvedev\") |>\n  group_by(win_loss) |>\n  summarise(win_loss_count = n())\nmedvedev_query\nshow_query(medvedev_query)\nover20aces <- tennis_db |> filter(w_ace > 20) |>\n  select(w_ace, winner_name) |>\n  group_by(winner_name) |>\n  summarise(nmatch = n()) |>\n  arrange(desc(nmatch))\nover20aces\n\nover20aces |> show_query()\ntennis_db |> show_query()\ntennis_db |> filter(winner_hand == \"L\") |>\n  arrange(desc(tourney_date)) |>\n  show_query()\ntennis_db |>\n  group_by(winner_name) |>\n  summarise(meanace = mean(w_ace, na.rm = TRUE)) |>\n  show_query()\ntennis_db |> select(1:4) |> show_query()\ntennis_db |> rename(tournament = tourney_name) |>\n  show_query()\ntennis_db |> mutate(prop_first_won = w_1stIn / w_1stWon) |>\n  select(prop_first_won, winner_name) |>\n  show_query()\ntennis_db |> summarise(mean_length = mean(minutes)) |>\n  show_query()\ntennis_db |> group_by(winner_name) |>\n  summarise(meanlength = mean(minutes)) |>\n  show_query()\ntennis_db |> filter(winner_age > 35 | loser_age > 35) |>\n  show_query()\ntennis_db |> arrange(desc(winner_rank_points)) |>\n  show_query()"}]
